Optimizing /home/cw4287/gaussian-model/train_30k
Output folder: /home/cw4287/gaussian-model/train_30k [03/12 21:27:54]
Tensorboard not available: not logging progress [03/12 21:27:54]
------------LLFF HOLD------------- [03/12 21:27:56]

Reading camera 1/301
Reading camera 2/301
Reading camera 3/301
Reading camera 4/301
Reading camera 5/301
Reading camera 6/301
Reading camera 7/301
Reading camera 8/301
Reading camera 9/301
Reading camera 10/301
Reading camera 11/301
Reading camera 12/301
Reading camera 13/301
Reading camera 14/301
Reading camera 15/301
Reading camera 16/301
Reading camera 17/301
Reading camera 18/301
Reading camera 19/301
Reading camera 20/301
Reading camera 21/301
Reading camera 22/301
Reading camera 23/301
Reading camera 24/301
Reading camera 25/301
Reading camera 26/301
Reading camera 27/301
Reading camera 28/301
Reading camera 29/301
Reading camera 30/301
Reading camera 31/301
Reading camera 32/301
Reading camera 33/301
Reading camera 34/301
Reading camera 35/301
Reading camera 36/301
Reading camera 37/301
Reading camera 38/301
Reading camera 39/301
Reading camera 40/301
Reading camera 41/301
Reading camera 42/301
Reading camera 43/301
Reading camera 44/301
Reading camera 45/301
Reading camera 46/301
Reading camera 47/301
Reading camera 48/301
Reading camera 49/301
Reading camera 50/301
Reading camera 51/301
Reading camera 52/301
Reading camera 53/301
Reading camera 54/301
Reading camera 55/301
Reading camera 56/301
Reading camera 57/301
Reading camera 58/301
Reading camera 59/301
Reading camera 60/301
Reading camera 61/301
Reading camera 62/301
Reading camera 63/301
Reading camera 64/301
Reading camera 65/301
Reading camera 66/301
Reading camera 67/301
Reading camera 68/301
Reading camera 69/301
Reading camera 70/301
Reading camera 71/301
Reading camera 72/301
Reading camera 73/301
Reading camera 74/301
Reading camera 75/301
Reading camera 76/301
Reading camera 77/301
Reading camera 78/301
Reading camera 79/301
Reading camera 80/301
Reading camera 81/301
Reading camera 82/301
Reading camera 83/301
Reading camera 84/301
Reading camera 85/301
Reading camera 86/301
Reading camera 87/301
Reading camera 88/301
Reading camera 89/301
Reading camera 90/301
Reading camera 91/301
Reading camera 92/301
Reading camera 93/301
Reading camera 94/301
Reading camera 95/301
Reading camera 96/301
Reading camera 97/301
Reading camera 98/301
Reading camera 99/301
Reading camera 100/301
Reading camera 101/301
Reading camera 102/301
Reading camera 103/301
Reading camera 104/301
Reading camera 105/301
Reading camera 106/301
Reading camera 107/301
Reading camera 108/301
Reading camera 109/301
Reading camera 110/301
Reading camera 111/301
Reading camera 112/301
Reading camera 113/301
Reading camera 114/301
Reading camera 115/301
Reading camera 116/301
Reading camera 117/301
Reading camera 118/301
Reading camera 119/301
Reading camera 120/301
Reading camera 121/301
Reading camera 122/301
Reading camera 123/301
Reading camera 124/301
Reading camera 125/301
Reading camera 126/301
Reading camera 127/301
Reading camera 128/301
Reading camera 129/301
Reading camera 130/301
Reading camera 131/301
Reading camera 132/301
Reading camera 133/301
Reading camera 134/301
Reading camera 135/301
Reading camera 136/301
Reading camera 137/301
Reading camera 138/301
Reading camera 139/301
Reading camera 140/301
Reading camera 141/301
Reading camera 142/301
Reading camera 143/301
Reading camera 144/301
Reading camera 145/301
Reading camera 146/301
Reading camera 147/301
Reading camera 148/301
Reading camera 149/301
Reading camera 150/301
Reading camera 151/301
Reading camera 152/301
Reading camera 153/301
Reading camera 154/301
Reading camera 155/301
Reading camera 156/301
Reading camera 157/301
Reading camera 158/301
Reading camera 159/301
Reading camera 160/301
Reading camera 161/301
Reading camera 162/301
Reading camera 163/301
Reading camera 164/301
Reading camera 165/301
Reading camera 166/301
Reading camera 167/301
Reading camera 168/301
Reading camera 169/301
Reading camera 170/301
Reading camera 171/301
Reading camera 172/301
Reading camera 173/301
Reading camera 174/301
Reading camera 175/301
Reading camera 176/301
Reading camera 177/301
Reading camera 178/301
Reading camera 179/301
Reading camera 180/301
Reading camera 181/301
Reading camera 182/301
Reading camera 183/301
Reading camera 184/301
Reading camera 185/301
Reading camera 186/301
Reading camera 187/301
Reading camera 188/301
Reading camera 189/301
Reading camera 190/301
Reading camera 191/301
Reading camera 192/301
Reading camera 193/301
Reading camera 194/301
Reading camera 195/301
Reading camera 196/301
Reading camera 197/301
Reading camera 198/301
Reading camera 199/301
Reading camera 200/301
Reading camera 201/301
Reading camera 202/301
Reading camera 203/301
Reading camera 204/301
Reading camera 205/301
Reading camera 206/301
Reading camera 207/301
Reading camera 208/301
Reading camera 209/301
Reading camera 210/301
Reading camera 211/301
Reading camera 212/301
Reading camera 213/301
Reading camera 214/301
Reading camera 215/301
Reading camera 216/301
Reading camera 217/301
Reading camera 218/301
Reading camera 219/301
Reading camera 220/301
Reading camera 221/301
Reading camera 222/301
Reading camera 223/301
Reading camera 224/301
Reading camera 225/301
Reading camera 226/301
Reading camera 227/301
Reading camera 228/301
Reading camera 229/301
Reading camera 230/301
Reading camera 231/301
Reading camera 232/301
Reading camera 233/301
Reading camera 234/301
Reading camera 235/301
Reading camera 236/301
Reading camera 237/301
Reading camera 238/301
Reading camera 239/301
Reading camera 240/301
Reading camera 241/301
Reading camera 242/301
Reading camera 243/301
Reading camera 244/301
Reading camera 245/301
Reading camera 246/301
Reading camera 247/301
Reading camera 248/301
Reading camera 249/301
Reading camera 250/301
Reading camera 251/301
Reading camera 252/301
Reading camera 253/301
Reading camera 254/301
Reading camera 255/301
Reading camera 256/301
Reading camera 257/301
Reading camera 258/301
Reading camera 259/301
Reading camera 260/301
Reading camera 261/301
Reading camera 262/301
Reading camera 263/301
Reading camera 264/301
Reading camera 265/301
Reading camera 266/301
Reading camera 267/301
Reading camera 268/301
Reading camera 269/301
Reading camera 270/301
Reading camera 271/301
Reading camera 272/301
Reading camera 273/301
Reading camera 274/301
Reading camera 275/301
Reading camera 276/301
Reading camera 277/301
Reading camera 278/301
Reading camera 279/301
Reading camera 280/301
Reading camera 281/301
Reading camera 282/301
Reading camera 283/301
Reading camera 284/301
Reading camera 285/301
Reading camera 286/301
Reading camera 287/301
Reading camera 288/301
Reading camera 289/301
Reading camera 290/301
Reading camera 291/301
Reading camera 292/301
Reading camera 293/301
Reading camera 294/301
Reading camera 295/301
Reading camera 296/301
Reading camera 297/301
Reading camera 298/301
Reading camera 299/301
Reading camera 300/301
Reading camera 301/301 [03/12 21:27:56]
Loading Training Cameras [03/12 21:27:56]
Loading Test Cameras [03/12 21:28:12]
Number of points at initialisation :  182686 [03/12 21:28:14]

Training progress:   0%|          | 0/2000 [00:00<?, ?it/s]/ext3/conda/envs/3dgs/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/ext3/conda/envs/3dgs/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)

Training progress:   0%|          | 0/2000 [00:05<?, ?it/s, Loss=0.0218163, Gaussian number=182686, print grad=1.1915580216736998e-05, Depth Loss=0.0000000]
Training progress:   0%|          | 10/2000 [00:05<18:42,  1.77it/s, Loss=0.0218163, Gaussian number=182686, print grad=1.1915580216736998e-05, Depth Loss=0.0000000]
Training progress:   0%|          | 10/2000 [00:09<18:42,  1.77it/s, Loss=0.0199319, Gaussian number=182686, print grad=2.9506896680686623e-05, Depth Loss=0.0000000]
Training progress:   1%|          | 20/2000 [00:09<15:31,  2.13it/s, Loss=0.0199319, Gaussian number=182686, print grad=2.9506896680686623e-05, Depth Loss=0.0000000]
Training progress:   1%|          | 20/2000 [00:13<15:31,  2.13it/s, Loss=0.0197479, Gaussian number=182686, print grad=4.6155069867381826e-05, Depth Loss=0.0000000]
Training progress:   2%|▏         | 30/2000 [00:13<14:25,  2.28it/s, Loss=0.0197479, Gaussian number=182686, print grad=4.6155069867381826e-05, Depth Loss=0.0000000]
Training progress:   2%|▏         | 30/2000 [00:17<14:25,  2.28it/s, Loss=0.0209220, Gaussian number=182686, print grad=6.273558392422274e-05, Depth Loss=0.0000000] 
Training progress:   2%|▏         | 40/2000 [00:17<13:54,  2.35it/s, Loss=0.0209220, Gaussian number=182686, print grad=6.273558392422274e-05, Depth Loss=0.0000000]
Training progress:   2%|▏         | 40/2000 [00:21<13:54,  2.35it/s, Loss=0.0159821, Gaussian number=182686, print grad=7.679871487198398e-05, Depth Loss=0.0000000]
Training progress:   2%|▎         | 50/2000 [00:21<13:33,  2.40it/s, Loss=0.0159821, Gaussian number=182686, print grad=7.679871487198398e-05, Depth Loss=0.0000000]
Training progress:   2%|▎         | 50/2000 [00:25<13:33,  2.40it/s, Loss=0.0170657, Gaussian number=182686, print grad=9.659956413088366e-05, Depth Loss=0.0000000]
Training progress:   3%|▎         | 60/2000 [00:25<13:19,  2.43it/s, Loss=0.0170657, Gaussian number=182686, print grad=9.659956413088366e-05, Depth Loss=0.0000000]
Training progress:   3%|▎         | 60/2000 [00:29<13:19,  2.43it/s, Loss=0.0151179, Gaussian number=182686, print grad=0.00011914702918147668, Depth Loss=0.0000000]
Training progress:   4%|▎         | 70/2000 [00:29<13:08,  2.45it/s, Loss=0.0151179, Gaussian number=182686, print grad=0.00011914702918147668, Depth Loss=0.0000000]
Training progress:   4%|▎         | 70/2000 [00:33<13:08,  2.45it/s, Loss=0.0193663, Gaussian number=182686, print grad=0.00013828932424075902, Depth Loss=0.0000000]
Training progress:   4%|▍         | 80/2000 [00:33<13:01,  2.46it/s, Loss=0.0193663, Gaussian number=182686, print grad=0.00013828932424075902, Depth Loss=0.0000000]
Training progress:   4%|▍         | 80/2000 [00:37<13:01,  2.46it/s, Loss=0.0162847, Gaussian number=182686, print grad=0.0001585533464094624, Depth Loss=0.0000000] 
Training progress:   4%|▍         | 90/2000 [00:37<12:54,  2.47it/s, Loss=0.0162847, Gaussian number=182686, print grad=0.0001585533464094624, Depth Loss=0.0000000]
Training progress:   4%|▍         | 90/2000 [00:41<12:54,  2.47it/s, Loss=0.0149905, Gaussian number=182686, print grad=0.00018142515909858048, Depth Loss=0.0000000]
Training progress:   5%|▌         | 100/2000 [00:41<12:48,  2.47it/s, Loss=0.0149905, Gaussian number=182686, print grad=0.00018142515909858048, Depth Loss=0.0000000]
Training progress:   5%|▌         | 100/2000 [01:50<12:48,  2.47it/s, Loss=0.0177330, Gaussian number=182686, print grad=0.00020557288371492177, Depth Loss=0.0000000]
Training progress:   6%|▌         | 110/2000 [01:50<1:14:35,  2.37s/it, Loss=0.0177330, Gaussian number=182686, print grad=0.00020557288371492177, Depth Loss=0.0000000]
Training progress:   6%|▌         | 110/2000 [01:54<1:14:35,  2.37s/it, Loss=0.0143775, Gaussian number=182686, print grad=0.00022855137649457902, Depth Loss=0.0000000]
Training progress:   6%|▌         | 120/2000 [01:54<55:26,  1.77s/it, Loss=0.0143775, Gaussian number=182686, print grad=0.00022855137649457902, Depth Loss=0.0000000]  
Training progress:   6%|▌         | 120/2000 [01:58<55:26,  1.77s/it, Loss=0.0161085, Gaussian number=182686, print grad=0.00025552473380230367, Depth Loss=0.0000000]
Training progress:   6%|▋         | 130/2000 [01:58<42:14,  1.36s/it, Loss=0.0161085, Gaussian number=182686, print grad=0.00025552473380230367, Depth Loss=0.0000000]
Training progress:   6%|▋         | 130/2000 [02:02<42:14,  1.36s/it, Loss=0.0145897, Gaussian number=182686, print grad=0.00028284970903769135, Depth Loss=0.0000000]
Training progress:   7%|▋         | 140/2000 [02:02<33:05,  1.07s/it, Loss=0.0145897, Gaussian number=182686, print grad=0.00028284970903769135, Depth Loss=0.0000000]
Training progress:   7%|▋         | 140/2000 [02:06<33:05,  1.07s/it, Loss=0.0128554, Gaussian number=182686, print grad=0.00030711761792190373, Depth Loss=0.0000000]
Training progress:   8%|▊         | 150/2000 [02:06<26:42,  1.15it/s, Loss=0.0128554, Gaussian number=182686, print grad=0.00030711761792190373, Depth Loss=0.0000000]
Training progress:   8%|▊         | 150/2000 [02:10<26:42,  1.15it/s, Loss=0.0139394, Gaussian number=182686, print grad=0.0003364727017469704, Depth Loss=0.0000000] 
Training progress:   8%|▊         | 160/2000 [02:10<22:15,  1.38it/s, Loss=0.0139394, Gaussian number=182686, print grad=0.0003364727017469704, Depth Loss=0.0000000]
Training progress:   8%|▊         | 160/2000 [02:14<22:15,  1.38it/s, Loss=0.0138929, Gaussian number=182686, print grad=0.00036202676710672677, Depth Loss=0.0000000]
Training progress:   8%|▊         | 170/2000 [02:14<19:09,  1.59it/s, Loss=0.0138929, Gaussian number=182686, print grad=0.00036202676710672677, Depth Loss=0.0000000]
Training progress:   8%|▊         | 170/2000 [02:18<19:09,  1.59it/s, Loss=0.0113580, Gaussian number=182686, print grad=0.0003889140207320452, Depth Loss=0.0000000] 
Training progress:   9%|▉         | 180/2000 [02:18<16:58,  1.79it/s, Loss=0.0113580, Gaussian number=182686, print grad=0.0003889140207320452, Depth Loss=0.0000000]
Training progress:   9%|▉         | 180/2000 [02:22<16:58,  1.79it/s, Loss=0.0146170, Gaussian number=182686, print grad=0.0004142151738051325, Depth Loss=0.0000000]
Training progress:  10%|▉         | 190/2000 [02:22<15:26,  1.95it/s, Loss=0.0146170, Gaussian number=182686, print grad=0.0004142151738051325, Depth Loss=0.0000000]
Training progress:  10%|▉         | 190/2000 [02:26<15:26,  1.95it/s, Loss=0.0123978, Gaussian number=182686, print grad=0.00044255563989281654, Depth Loss=0.0000000]
Training progress:  10%|█         | 200/2000 [02:26<14:19,  2.09it/s, Loss=0.0123978, Gaussian number=182686, print grad=0.00044255563989281654, Depth Loss=0.0000000]
Training progress:  10%|█         | 200/2000 [03:34<14:19,  2.09it/s, Loss=0.0140334, Gaussian number=182686, print grad=0.0004716581606771797, Depth Loss=0.0000000] 
Training progress:  10%|█         | 210/2000 [03:34<1:10:57,  2.38s/it, Loss=0.0140334, Gaussian number=182686, print grad=0.0004716581606771797, Depth Loss=0.0000000]
Training progress:  10%|█         | 210/2000 [03:38<1:10:57,  2.38s/it, Loss=0.0111873, Gaussian number=182686, print grad=0.0004988235305063426, Depth Loss=0.0000000]
Training progress:  11%|█         | 220/2000 [03:38<52:56,  1.78s/it, Loss=0.0111873, Gaussian number=182686, print grad=0.0004988235305063426, Depth Loss=0.0000000]  
Training progress:  11%|█         | 220/2000 [03:42<52:56,  1.78s/it, Loss=0.0126248, Gaussian number=182686, print grad=0.000527716358192265, Depth Loss=0.0000000] 
Training progress:  12%|█▏        | 230/2000 [03:42<40:23,  1.37s/it, Loss=0.0126248, Gaussian number=182686, print grad=0.000527716358192265, Depth Loss=0.0000000]
Training progress:  12%|█▏        | 230/2000 [03:46<40:23,  1.37s/it, Loss=0.0160170, Gaussian number=182686, print grad=0.0005540166748687625, Depth Loss=0.0000000]
Training progress:  12%|█▏        | 240/2000 [03:46<31:37,  1.08s/it, Loss=0.0160170, Gaussian number=182686, print grad=0.0005540166748687625, Depth Loss=0.0000000]
Training progress:  12%|█▏        | 240/2000 [03:50<31:37,  1.08s/it, Loss=0.0123501, Gaussian number=182686, print grad=0.000583382323384285, Depth Loss=0.0000000] 
Training progress:  12%|█▎        | 250/2000 [03:50<25:29,  1.14it/s, Loss=0.0123501, Gaussian number=182686, print grad=0.000583382323384285, Depth Loss=0.0000000]
Training progress:  12%|█▎        | 250/2000 [03:54<25:29,  1.14it/s, Loss=0.0135973, Gaussian number=182686, print grad=0.0006103602354414761, Depth Loss=0.0000000]
Training progress:  13%|█▎        | 260/2000 [03:54<21:11,  1.37it/s, Loss=0.0135973, Gaussian number=182686, print grad=0.0006103602354414761, Depth Loss=0.0000000]
Training progress:  13%|█▎        | 260/2000 [03:58<21:11,  1.37it/s, Loss=0.0091061, Gaussian number=182686, print grad=0.0006387376342900097, Depth Loss=0.0000000]
Training progress:  14%|█▎        | 270/2000 [03:58<18:11,  1.58it/s, Loss=0.0091061, Gaussian number=182686, print grad=0.0006387376342900097, Depth Loss=0.0000000]
Training progress:  14%|█▎        | 270/2000 [04:02<18:11,  1.58it/s, Loss=0.0118754, Gaussian number=182686, print grad=0.0006681142840534449, Depth Loss=0.0000000]
Training progress:  14%|█▍        | 280/2000 [04:02<16:04,  1.78it/s, Loss=0.0118754, Gaussian number=182686, print grad=0.0006681142840534449, Depth Loss=0.0000000]
Training progress:  14%|█▍        | 280/2000 [04:06<16:04,  1.78it/s, Loss=0.0121969, Gaussian number=182686, print grad=0.0006985370418988168, Depth Loss=0.0000000]
Training progress:  14%|█▍        | 290/2000 [04:06<14:35,  1.95it/s, Loss=0.0121969, Gaussian number=182686, print grad=0.0006985370418988168, Depth Loss=0.0000000]
Training progress:  14%|█▍        | 290/2000 [04:10<14:35,  1.95it/s, Loss=0.0115300, Gaussian number=182686, print grad=0.0007297371048480272, Depth Loss=0.0000000]
Training progress:  15%|█▌        | 300/2000 [04:10<13:32,  2.09it/s, Loss=0.0115300, Gaussian number=182686, print grad=0.0007297371048480272, Depth Loss=0.0000000]
Training progress:  15%|█▌        | 300/2000 [05:18<13:32,  2.09it/s, Loss=0.0094726, Gaussian number=182686, print grad=0.0007601044490002096, Depth Loss=0.0000000]
Training progress:  16%|█▌        | 310/2000 [05:18<1:06:52,  2.37s/it, Loss=0.0094726, Gaussian number=182686, print grad=0.0007601044490002096, Depth Loss=0.0000000]
Training progress:  16%|█▌        | 310/2000 [05:22<1:06:52,  2.37s/it, Loss=0.0097210, Gaussian number=182686, print grad=0.000784298696089536, Depth Loss=0.0000000] 
Training progress:  16%|█▌        | 320/2000 [05:22<49:52,  1.78s/it, Loss=0.0097210, Gaussian number=182686, print grad=0.000784298696089536, Depth Loss=0.0000000]  
Training progress:  16%|█▌        | 320/2000 [05:26<49:52,  1.78s/it, Loss=0.0129746, Gaussian number=182686, print grad=0.000810885860119015, Depth Loss=0.0000000]
Training progress:  16%|█▋        | 330/2000 [05:26<38:01,  1.37s/it, Loss=0.0129746, Gaussian number=182686, print grad=0.000810885860119015, Depth Loss=0.0000000]
Training progress:  16%|█▋        | 330/2000 [05:30<38:01,  1.37s/it, Loss=0.0093114, Gaussian number=182686, print grad=0.0008418637444265187, Depth Loss=0.0000000]
Training progress:  17%|█▋        | 340/2000 [05:30<29:45,  1.08s/it, Loss=0.0093114, Gaussian number=182686, print grad=0.0008418637444265187, Depth Loss=0.0000000]
Training progress:  17%|█▋        | 340/2000 [05:33<29:45,  1.08s/it, Loss=0.0098290, Gaussian number=182686, print grad=0.0008706797962076962, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 350/2000 [05:33<23:58,  1.15it/s, Loss=0.0098290, Gaussian number=182686, print grad=0.0008706797962076962, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 350/2000 [05:37<23:58,  1.15it/s, Loss=0.0096898, Gaussian number=182686, print grad=0.0009032013476826251, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 360/2000 [05:37<19:55,  1.37it/s, Loss=0.0096898, Gaussian number=182686, print grad=0.0009032013476826251, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 360/2000 [05:41<19:55,  1.37it/s, Loss=0.0088095, Gaussian number=182686, print grad=0.000931860413402319, Depth Loss=0.0000000] 
Training progress:  18%|█▊        | 370/2000 [05:41<17:06,  1.59it/s, Loss=0.0088095, Gaussian number=182686, print grad=0.000931860413402319, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 370/2000 [05:45<17:06,  1.59it/s, Loss=0.0125976, Gaussian number=182686, print grad=0.0009577396558597684, Depth Loss=0.0000000]
Training progress:  19%|█▉        | 380/2000 [05:45<15:06,  1.79it/s, Loss=0.0125976, Gaussian number=182686, print grad=0.0009577396558597684, Depth Loss=0.0000000]
Training progress:  19%|█▉        | 380/2000 [05:49<15:06,  1.79it/s, Loss=0.0106839, Gaussian number=182686, print grad=0.0009888758650049567, Depth Loss=0.0000000]
Training progress:  20%|█▉        | 390/2000 [05:49<13:43,  1.95it/s, Loss=0.0106839, Gaussian number=182686, print grad=0.0009888758650049567, Depth Loss=0.0000000]
Training progress:  20%|█▉        | 390/2000 [05:53<13:43,  1.95it/s, Loss=0.0133521, Gaussian number=182686, print grad=0.001018284005112946, Depth Loss=0.0000000] 
Training progress:  20%|██        | 400/2000 [05:53<12:42,  2.10it/s, Loss=0.0133521, Gaussian number=182686, print grad=0.001018284005112946, Depth Loss=0.0000000]
Training progress:  20%|██        | 400/2000 [05:57<12:42,  2.10it/s, Loss=0.0111823, Gaussian number=182686, print grad=0.001052460866048932, Depth Loss=0.0000000]
Training progress:  20%|██        | 410/2000 [05:57<11:59,  2.21it/s, Loss=0.0111823, Gaussian number=182686, print grad=0.001052460866048932, Depth Loss=0.0000000]
Training progress:  20%|██        | 410/2000 [06:01<11:59,  2.21it/s, Loss=0.0098105, Gaussian number=182686, print grad=0.0010858058230951428, Depth Loss=0.0000000]
Training progress:  21%|██        | 420/2000 [06:01<11:28,  2.30it/s, Loss=0.0098105, Gaussian number=182686, print grad=0.0010858058230951428, Depth Loss=0.0000000]
Training progress:  21%|██        | 420/2000 [06:05<11:28,  2.30it/s, Loss=0.0123651, Gaussian number=182686, print grad=0.0011196192353963852, Depth Loss=0.0000000]
Training progress:  22%|██▏       | 430/2000 [06:05<11:05,  2.36it/s, Loss=0.0123651, Gaussian number=182686, print grad=0.0011196192353963852, Depth Loss=0.0000000]
Training progress:  22%|██▏       | 430/2000 [06:09<11:05,  2.36it/s, Loss=0.0096606, Gaussian number=182686, print grad=0.001149763585999608, Depth Loss=0.0000000] 
Training progress:  22%|██▏       | 440/2000 [06:09<10:48,  2.41it/s, Loss=0.0096606, Gaussian number=182686, print grad=0.001149763585999608, Depth Loss=0.0000000]
Training progress:  22%|██▏       | 440/2000 [06:13<10:48,  2.41it/s, Loss=0.0113066, Gaussian number=182686, print grad=0.0011809056159108877, Depth Loss=0.0000000]
Training progress:  22%|██▎       | 450/2000 [06:13<10:34,  2.44it/s, Loss=0.0113066, Gaussian number=182686, print grad=0.0011809056159108877, Depth Loss=0.0000000]
Training progress:  22%|██▎       | 450/2000 [06:17<10:34,  2.44it/s, Loss=0.0120271, Gaussian number=182686, print grad=0.0012119788443669677, Depth Loss=0.0000000]
Training progress:  23%|██▎       | 460/2000 [06:17<10:24,  2.47it/s, Loss=0.0120271, Gaussian number=182686, print grad=0.0012119788443669677, Depth Loss=0.0000000]
Training progress:  23%|██▎       | 460/2000 [06:21<10:24,  2.47it/s, Loss=0.0137702, Gaussian number=182686, print grad=0.0012421293649822474, Depth Loss=0.0000000]
Training progress:  24%|██▎       | 470/2000 [06:21<10:15,  2.48it/s, Loss=0.0137702, Gaussian number=182686, print grad=0.0012421293649822474, Depth Loss=0.0000000]
Training progress:  24%|██▎       | 470/2000 [06:25<10:15,  2.48it/s, Loss=0.0088872, Gaussian number=182686, print grad=0.0012759534874930978, Depth Loss=0.0000000]
Training progress:  24%|██▍       | 480/2000 [06:25<10:08,  2.50it/s, Loss=0.0088872, Gaussian number=182686, print grad=0.0012759534874930978, Depth Loss=0.0000000]
Training progress:  24%|██▍       | 480/2000 [06:29<10:08,  2.50it/s, Loss=0.0099340, Gaussian number=182686, print grad=0.0013066217070445418, Depth Loss=0.0000000]
Training progress:  24%|██▍       | 490/2000 [06:29<10:02,  2.51it/s, Loss=0.0099340, Gaussian number=182686, print grad=0.0013066217070445418, Depth Loss=0.0000000]
Training progress:  24%|██▍       | 490/2000 [06:33<10:02,  2.51it/s, Loss=0.0073125, Gaussian number=182686, print grad=0.0013378345174714923, Depth Loss=0.0000000]
Training progress:  25%|██▌       | 500/2000 [06:33<09:57,  2.51it/s, Loss=0.0073125, Gaussian number=182686, print grad=0.0013378345174714923, Depth Loss=0.0000000]
Training progress:  25%|██▌       | 500/2000 [07:41<09:57,  2.51it/s, Loss=0.0088778, Gaussian number=182686, print grad=0.00136879354249686, Depth Loss=0.0000000]  
Training progress:  26%|██▌       | 510/2000 [07:41<57:28,  2.31s/it, Loss=0.0088778, Gaussian number=182686, print grad=0.00136879354249686, Depth Loss=0.0000000]
Training progress:  26%|██▌       | 510/2000 [07:45<57:28,  2.31s/it, Loss=0.0095727, Gaussian number=182686, print grad=0.0014012152096256614, Depth Loss=0.0000000]
Training progress:  26%|██▌       | 520/2000 [07:45<42:54,  1.74s/it, Loss=0.0095727, Gaussian number=182686, print grad=0.0014012152096256614, Depth Loss=0.0000000]
Training progress:  26%|██▌       | 520/2000 [07:49<42:54,  1.74s/it, Loss=0.0068854, Gaussian number=182686, print grad=0.0014291794504970312, Depth Loss=0.0000000]
Training progress:  26%|██▋       | 530/2000 [07:49<32:43,  1.34s/it, Loss=0.0068854, Gaussian number=182686, print grad=0.0014291794504970312, Depth Loss=0.0000000]
Training progress:  26%|██▋       | 530/2000 [07:53<32:43,  1.34s/it, Loss=0.0095791, Gaussian number=182686, print grad=0.0014597990084439516, Depth Loss=0.0000000]
Training progress:  27%|██▋       | 540/2000 [07:53<25:38,  1.05s/it, Loss=0.0095791, Gaussian number=182686, print grad=0.0014597990084439516, Depth Loss=0.0000000]
Training progress:  27%|██▋       | 540/2000 [07:57<25:38,  1.05s/it, Loss=0.0088543, Gaussian number=182686, print grad=0.0014931299956515431, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 550/2000 [07:57<20:41,  1.17it/s, Loss=0.0088543, Gaussian number=182686, print grad=0.0014931299956515431, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 550/2000 [08:01<20:41,  1.17it/s, Loss=0.0070046, Gaussian number=182686, print grad=0.001523136394098401, Depth Loss=0.0000000] 
Training progress:  28%|██▊       | 560/2000 [08:01<17:13,  1.39it/s, Loss=0.0070046, Gaussian number=182686, print grad=0.001523136394098401, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 560/2000 [08:05<17:13,  1.39it/s, Loss=0.0097321, Gaussian number=182686, print grad=0.001555684837512672, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 570/2000 [08:05<14:47,  1.61it/s, Loss=0.0097321, Gaussian number=182686, print grad=0.001555684837512672, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 570/2000 [08:08<14:47,  1.61it/s, Loss=0.0085280, Gaussian number=182686, print grad=0.0015890029026195407, Depth Loss=0.0000000]
Training progress:  29%|██▉       | 580/2000 [08:08<13:05,  1.81it/s, Loss=0.0085280, Gaussian number=182686, print grad=0.0015890029026195407, Depth Loss=0.0000000]
Training progress:  29%|██▉       | 580/2000 [08:12<13:05,  1.81it/s, Loss=0.0097106, Gaussian number=182686, print grad=0.0016220516990870237, Depth Loss=0.0000000]
Training progress:  30%|██▉       | 590/2000 [08:12<11:53,  1.98it/s, Loss=0.0097106, Gaussian number=182686, print grad=0.0016220516990870237, Depth Loss=0.0000000]
Training progress:  30%|██▉       | 590/2000 [08:16<11:53,  1.98it/s, Loss=0.0102185, Gaussian number=182686, print grad=0.0016526910476386547, Depth Loss=0.0000000]
Training progress:  30%|███       | 600/2000 [08:16<11:01,  2.12it/s, Loss=0.0102185, Gaussian number=182686, print grad=0.0016526910476386547, Depth Loss=0.0000000]
Training progress:  30%|███       | 600/2000 [08:20<11:01,  2.12it/s, Loss=0.0080892, Gaussian number=182682, print grad=2.8065835067536682e-05, Depth Loss=0.0000000]
Training progress:  30%|███       | 610/2000 [08:20<10:24,  2.23it/s, Loss=0.0080892, Gaussian number=182682, print grad=2.8065835067536682e-05, Depth Loss=0.0000000]
Training progress:  30%|███       | 610/2000 [08:24<10:24,  2.23it/s, Loss=0.0106295, Gaussian number=182682, print grad=6.021627632435411e-05, Depth Loss=0.0000000] 
Training progress:  31%|███       | 620/2000 [08:24<09:57,  2.31it/s, Loss=0.0106295, Gaussian number=182682, print grad=6.021627632435411e-05, Depth Loss=0.0000000]
Training progress:  31%|███       | 620/2000 [08:28<09:57,  2.31it/s, Loss=0.0074437, Gaussian number=182682, print grad=9.092458640225232e-05, Depth Loss=0.0000000]
Training progress:  32%|███▏      | 630/2000 [08:28<09:37,  2.37it/s, Loss=0.0074437, Gaussian number=182682, print grad=9.092458640225232e-05, Depth Loss=0.0000000]
Training progress:  32%|███▏      | 630/2000 [08:32<09:37,  2.37it/s, Loss=0.0082535, Gaussian number=182682, print grad=0.0001250713539775461, Depth Loss=0.0000000]
Training progress:  32%|███▏      | 640/2000 [08:32<09:23,  2.41it/s, Loss=0.0082535, Gaussian number=182682, print grad=0.0001250713539775461, Depth Loss=0.0000000]
Training progress:  32%|███▏      | 640/2000 [08:36<09:23,  2.41it/s, Loss=0.0096125, Gaussian number=182682, print grad=0.0001546757121104747, Depth Loss=0.0000000]
Training progress:  32%|███▎      | 650/2000 [08:36<09:11,  2.45it/s, Loss=0.0096125, Gaussian number=182682, print grad=0.0001546757121104747, Depth Loss=0.0000000]
Training progress:  32%|███▎      | 650/2000 [08:40<09:11,  2.45it/s, Loss=0.0093481, Gaussian number=182682, print grad=0.00018892751540988684, Depth Loss=0.0000000]
Training progress:  33%|███▎      | 660/2000 [08:40<09:01,  2.47it/s, Loss=0.0093481, Gaussian number=182682, print grad=0.00018892751540988684, Depth Loss=0.0000000]
Training progress:  33%|███▎      | 660/2000 [08:44<09:01,  2.47it/s, Loss=0.0086150, Gaussian number=182682, print grad=0.0002191443636547774, Depth Loss=0.0000000] 
Training progress:  34%|███▎      | 670/2000 [08:44<08:54,  2.49it/s, Loss=0.0086150, Gaussian number=182682, print grad=0.0002191443636547774, Depth Loss=0.0000000]
Training progress:  34%|███▎      | 670/2000 [08:48<08:54,  2.49it/s, Loss=0.0076833, Gaussian number=182682, print grad=0.00025183375691995025, Depth Loss=0.0000000]
Training progress:  34%|███▍      | 680/2000 [08:48<08:47,  2.50it/s, Loss=0.0076833, Gaussian number=182682, print grad=0.00025183375691995025, Depth Loss=0.0000000]
Training progress:  34%|███▍      | 680/2000 [08:52<08:47,  2.50it/s, Loss=0.0097550, Gaussian number=182682, print grad=0.0002841796085704118, Depth Loss=0.0000000] 
Training progress:  34%|███▍      | 690/2000 [08:52<08:41,  2.51it/s, Loss=0.0097550, Gaussian number=182682, print grad=0.0002841796085704118, Depth Loss=0.0000000]
Training progress:  34%|███▍      | 690/2000 [08:56<08:41,  2.51it/s, Loss=0.0093485, Gaussian number=182682, print grad=0.0003160370688419789, Depth Loss=0.0000000]
Training progress:  35%|███▌      | 700/2000 [08:56<08:36,  2.52it/s, Loss=0.0093485, Gaussian number=182682, print grad=0.0003160370688419789, Depth Loss=0.0000000]
Training progress:  35%|███▌      | 700/2000 [09:00<08:36,  2.52it/s, Loss=0.0082143, Gaussian number=182734, print grad=2.855098500731401e-05, Depth Loss=0.0000000]
Training progress:  36%|███▌      | 710/2000 [09:00<08:31,  2.52it/s, Loss=0.0082143, Gaussian number=182734, print grad=2.855098500731401e-05, Depth Loss=0.0000000]
Training progress:  36%|███▌      | 710/2000 [09:04<08:31,  2.52it/s, Loss=0.0076886, Gaussian number=182734, print grad=6.018360363668762e-05, Depth Loss=0.0000000]
Training progress:  36%|███▌      | 720/2000 [09:04<08:27,  2.52it/s, Loss=0.0076886, Gaussian number=182734, print grad=6.018360363668762e-05, Depth Loss=0.0000000]
Training progress:  36%|███▌      | 720/2000 [09:08<08:27,  2.52it/s, Loss=0.0101368, Gaussian number=182734, print grad=9.073162073036656e-05, Depth Loss=0.0000000]
Training progress:  36%|███▋      | 730/2000 [09:08<08:22,  2.53it/s, Loss=0.0101368, Gaussian number=182734, print grad=9.073162073036656e-05, Depth Loss=0.0000000]
Training progress:  36%|███▋      | 730/2000 [09:12<08:22,  2.53it/s, Loss=0.0113897, Gaussian number=182734, print grad=0.0001253079972229898, Depth Loss=0.0000000]
Training progress:  37%|███▋      | 740/2000 [09:12<08:18,  2.53it/s, Loss=0.0113897, Gaussian number=182734, print grad=0.0001253079972229898, Depth Loss=0.0000000]
Training progress:  37%|███▋      | 740/2000 [09:16<08:18,  2.53it/s, Loss=0.0081412, Gaussian number=182734, print grad=0.00015780380635987967, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 750/2000 [09:16<08:13,  2.53it/s, Loss=0.0081412, Gaussian number=182734, print grad=0.00015780380635987967, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 750/2000 [09:20<08:13,  2.53it/s, Loss=0.0080779, Gaussian number=182734, print grad=0.0001890956045826897, Depth Loss=0.0000000] 
Training progress:  38%|███▊      | 760/2000 [09:20<08:09,  2.53it/s, Loss=0.0080779, Gaussian number=182734, print grad=0.0001890956045826897, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 760/2000 [09:24<08:09,  2.53it/s, Loss=0.0070010, Gaussian number=182734, print grad=0.00022322629229165614, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 770/2000 [09:24<08:05,  2.53it/s, Loss=0.0070010, Gaussian number=182734, print grad=0.00022322629229165614, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 770/2000 [09:27<08:05,  2.53it/s, Loss=0.0095655, Gaussian number=182734, print grad=0.0002544215531088412, Depth Loss=0.0000000] 
Training progress:  39%|███▉      | 780/2000 [09:27<08:01,  2.53it/s, Loss=0.0095655, Gaussian number=182734, print grad=0.0002544215531088412, Depth Loss=0.0000000]
Training progress:  39%|███▉      | 780/2000 [09:31<08:01,  2.53it/s, Loss=0.0116807, Gaussian number=182734, print grad=0.0002868474693968892, Depth Loss=0.0000000]
Training progress:  40%|███▉      | 790/2000 [09:31<07:58,  2.53it/s, Loss=0.0116807, Gaussian number=182734, print grad=0.0002868474693968892, Depth Loss=0.0000000]
Training progress:  40%|███▉      | 790/2000 [09:35<07:58,  2.53it/s, Loss=0.0094292, Gaussian number=182734, print grad=0.00032016754266805947, Depth Loss=0.0000000]
Training progress:  40%|████      | 800/2000 [09:35<07:53,  2.53it/s, Loss=0.0094292, Gaussian number=182734, print grad=0.00032016754266805947, Depth Loss=0.0000000]
Training progress:  40%|████      | 800/2000 [09:39<07:53,  2.53it/s, Loss=0.0086142, Gaussian number=182768, print grad=2.8194443075335585e-05, Depth Loss=0.0000000]
Training progress:  40%|████      | 810/2000 [09:39<07:50,  2.53it/s, Loss=0.0086142, Gaussian number=182768, print grad=2.8194443075335585e-05, Depth Loss=0.0000000]
Training progress:  40%|████      | 810/2000 [09:43<07:50,  2.53it/s, Loss=0.0087463, Gaussian number=182768, print grad=5.9673955547623336e-05, Depth Loss=0.0000000]
Training progress:  41%|████      | 820/2000 [09:43<07:46,  2.53it/s, Loss=0.0087463, Gaussian number=182768, print grad=5.9673955547623336e-05, Depth Loss=0.0000000]
Training progress:  41%|████      | 820/2000 [09:47<07:46,  2.53it/s, Loss=0.0066464, Gaussian number=182768, print grad=9.434542153030634e-05, Depth Loss=0.0000000] 
Training progress:  42%|████▏     | 830/2000 [09:47<07:45,  2.52it/s, Loss=0.0066464, Gaussian number=182768, print grad=9.434542153030634e-05, Depth Loss=0.0000000]
Training progress:  42%|████▏     | 830/2000 [09:51<07:45,  2.52it/s, Loss=0.0076764, Gaussian number=182768, print grad=0.00012620036432053894, Depth Loss=0.0000000]
Training progress:  42%|████▏     | 840/2000 [09:51<07:39,  2.52it/s, Loss=0.0076764, Gaussian number=182768, print grad=0.00012620036432053894, Depth Loss=0.0000000]
Training progress:  42%|████▏     | 840/2000 [09:55<07:39,  2.52it/s, Loss=0.0078119, Gaussian number=182768, print grad=0.0001585718127898872, Depth Loss=0.0000000] 
Training progress:  42%|████▎     | 850/2000 [09:55<07:35,  2.53it/s, Loss=0.0078119, Gaussian number=182768, print grad=0.0001585718127898872, Depth Loss=0.0000000]
Training progress:  42%|████▎     | 850/2000 [09:59<07:35,  2.53it/s, Loss=0.0076166, Gaussian number=182768, print grad=0.0001894156011985615, Depth Loss=0.0000000]
Training progress:  43%|████▎     | 860/2000 [09:59<07:30,  2.53it/s, Loss=0.0076166, Gaussian number=182768, print grad=0.0001894156011985615, Depth Loss=0.0000000]
Training progress:  43%|████▎     | 860/2000 [10:03<07:30,  2.53it/s, Loss=0.0091476, Gaussian number=182768, print grad=0.0002203496260335669, Depth Loss=0.0000000]
Training progress:  44%|████▎     | 870/2000 [10:03<07:27,  2.53it/s, Loss=0.0091476, Gaussian number=182768, print grad=0.0002203496260335669, Depth Loss=0.0000000]
Training progress:  44%|████▎     | 870/2000 [10:07<07:27,  2.53it/s, Loss=0.0086546, Gaussian number=182768, print grad=0.0002534670929890126, Depth Loss=0.0000000]
Training progress:  44%|████▍     | 880/2000 [10:07<07:22,  2.53it/s, Loss=0.0086546, Gaussian number=182768, print grad=0.0002534670929890126, Depth Loss=0.0000000]
Training progress:  44%|████▍     | 880/2000 [10:11<07:22,  2.53it/s, Loss=0.0071153, Gaussian number=182768, print grad=0.0002853816549759358, Depth Loss=0.0000000]
Training progress:  44%|████▍     | 890/2000 [10:11<07:18,  2.53it/s, Loss=0.0071153, Gaussian number=182768, print grad=0.0002853816549759358, Depth Loss=0.0000000]
Training progress:  44%|████▍     | 890/2000 [10:15<07:18,  2.53it/s, Loss=0.0090357, Gaussian number=182768, print grad=0.00031879651942290366, Depth Loss=0.0000000]
Training progress:  45%|████▌     | 900/2000 [10:15<07:14,  2.53it/s, Loss=0.0090357, Gaussian number=182768, print grad=0.00031879651942290366, Depth Loss=0.0000000]
Training progress:  45%|████▌     | 900/2000 [10:19<07:14,  2.53it/s, Loss=0.0066578, Gaussian number=182790, print grad=2.76286227745004e-05, Depth Loss=0.0000000]  
Training progress:  46%|████▌     | 910/2000 [10:19<07:09,  2.54it/s, Loss=0.0066578, Gaussian number=182790, print grad=2.76286227745004e-05, Depth Loss=0.0000000]
Training progress:  46%|████▌     | 910/2000 [10:23<07:09,  2.54it/s, Loss=0.0084404, Gaussian number=182790, print grad=5.6508175475755706e-05, Depth Loss=0.0000000]
Training progress:  46%|████▌     | 920/2000 [10:23<07:06,  2.54it/s, Loss=0.0084404, Gaussian number=182790, print grad=5.6508175475755706e-05, Depth Loss=0.0000000]
Training progress:  46%|████▌     | 920/2000 [10:27<07:06,  2.54it/s, Loss=0.0084973, Gaussian number=182790, print grad=9.025265899254009e-05, Depth Loss=0.0000000] 
Training progress:  46%|████▋     | 930/2000 [10:27<07:01,  2.54it/s, Loss=0.0084973, Gaussian number=182790, print grad=9.025265899254009e-05, Depth Loss=0.0000000]
Training progress:  46%|████▋     | 930/2000 [10:31<07:01,  2.54it/s, Loss=0.0078898, Gaussian number=182790, print grad=0.00012257120397407562, Depth Loss=0.0000000]
Training progress:  47%|████▋     | 940/2000 [10:31<06:58,  2.54it/s, Loss=0.0078898, Gaussian number=182790, print grad=0.00012257120397407562, Depth Loss=0.0000000]
Training progress:  47%|████▋     | 940/2000 [10:35<06:58,  2.54it/s, Loss=0.0078291, Gaussian number=182790, print grad=0.00015366668230853975, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 950/2000 [10:35<06:54,  2.53it/s, Loss=0.0078291, Gaussian number=182790, print grad=0.00015366668230853975, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 950/2000 [10:39<06:54,  2.53it/s, Loss=0.0076034, Gaussian number=182790, print grad=0.00018416497914586216, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 960/2000 [10:39<06:50,  2.53it/s, Loss=0.0076034, Gaussian number=182790, print grad=0.00018416497914586216, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 960/2000 [10:43<06:50,  2.53it/s, Loss=0.0100845, Gaussian number=182790, print grad=0.00021884191664867103, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 970/2000 [10:43<06:46,  2.53it/s, Loss=0.0100845, Gaussian number=182790, print grad=0.00021884191664867103, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 970/2000 [10:47<06:46,  2.53it/s, Loss=0.0063273, Gaussian number=182790, print grad=0.00025079111219383776, Depth Loss=0.0000000]
Training progress:  49%|████▉     | 980/2000 [10:47<06:43,  2.53it/s, Loss=0.0063273, Gaussian number=182790, print grad=0.00025079111219383776, Depth Loss=0.0000000]
Training progress:  49%|████▉     | 980/2000 [10:50<06:43,  2.53it/s, Loss=0.0068205, Gaussian number=182790, print grad=0.00027921327273361385, Depth Loss=0.0000000]
Training progress:  50%|████▉     | 990/2000 [10:50<06:39,  2.53it/s, Loss=0.0068205, Gaussian number=182790, print grad=0.00027921327273361385, Depth Loss=0.0000000]
Training progress:  50%|████▉     | 990/2000 [10:54<06:39,  2.53it/s, Loss=0.0086872, Gaussian number=182790, print grad=0.00030673391302116215, Depth Loss=0.0000000]
Training progress:  50%|█████     | 1000/2000 [10:54<06:34,  2.53it/s, Loss=0.0086872, Gaussian number=182790, print grad=0.00030673391302116215, Depth Loss=0.0000000]
Training progress:  50%|█████     | 1000/2000 [12:02<06:34,  2.53it/s, Loss=0.0078740, Gaussian number=182826, print grad=2.7894622689927928e-05, Depth Loss=0.0000000]
Training progress:  50%|█████     | 1010/2000 [12:02<38:11,  2.31s/it, Loss=0.0078740, Gaussian number=182826, print grad=2.7894622689927928e-05, Depth Loss=0.0000000]
Training progress:  50%|█████     | 1010/2000 [12:06<38:11,  2.31s/it, Loss=0.0096159, Gaussian number=182826, print grad=6.391069473465905e-05, Depth Loss=0.0000000] 
Training progress:  51%|█████     | 1020/2000 [12:06<28:24,  1.74s/it, Loss=0.0096159, Gaussian number=182826, print grad=6.391069473465905e-05, Depth Loss=0.0000000]
Training progress:  51%|█████     | 1020/2000 [12:10<28:24,  1.74s/it, Loss=0.0076917, Gaussian number=182826, print grad=9.800861880648881e-05, Depth Loss=0.0000000]
Training progress:  52%|█████▏    | 1030/2000 [12:10<21:35,  1.34s/it, Loss=0.0076917, Gaussian number=182826, print grad=9.800861880648881e-05, Depth Loss=0.0000000]
Training progress:  52%|█████▏    | 1030/2000 [12:14<21:35,  1.34s/it, Loss=0.0081455, Gaussian number=182826, print grad=0.00013391867105383426, Depth Loss=0.0000000]
Training progress:  52%|█████▏    | 1040/2000 [12:14<16:50,  1.05s/it, Loss=0.0081455, Gaussian number=182826, print grad=0.00013391867105383426, Depth Loss=0.0000000]
Training progress:  52%|█████▏    | 1040/2000 [12:18<16:50,  1.05s/it, Loss=0.0077280, Gaussian number=182826, print grad=0.0001621059636818245, Depth Loss=0.0000000] 
Training progress:  52%|█████▎    | 1050/2000 [12:18<13:32,  1.17it/s, Loss=0.0077280, Gaussian number=182826, print grad=0.0001621059636818245, Depth Loss=0.0000000]
Training progress:  52%|█████▎    | 1050/2000 [12:22<13:32,  1.17it/s, Loss=0.0067737, Gaussian number=182826, print grad=0.00019255190272815526, Depth Loss=0.0000000]
Training progress:  53%|█████▎    | 1060/2000 [12:22<11:13,  1.40it/s, Loss=0.0067737, Gaussian number=182826, print grad=0.00019255190272815526, Depth Loss=0.0000000]
Training progress:  53%|█████▎    | 1060/2000 [12:26<11:13,  1.40it/s, Loss=0.0058395, Gaussian number=182826, print grad=0.00022561242803931236, Depth Loss=0.0000000]
Training progress:  54%|█████▎    | 1070/2000 [12:26<09:36,  1.61it/s, Loss=0.0058395, Gaussian number=182826, print grad=0.00022561242803931236, Depth Loss=0.0000000]
Training progress:  54%|█████▎    | 1070/2000 [12:30<09:36,  1.61it/s, Loss=0.0065389, Gaussian number=182826, print grad=0.00025648812879808247, Depth Loss=0.0000000]
Training progress:  54%|█████▍    | 1080/2000 [12:30<08:27,  1.81it/s, Loss=0.0065389, Gaussian number=182826, print grad=0.00025648812879808247, Depth Loss=0.0000000]
Training progress:  54%|█████▍    | 1080/2000 [12:34<08:27,  1.81it/s, Loss=0.0078946, Gaussian number=182826, print grad=0.0002881028922274709, Depth Loss=0.0000000] 
Training progress:  55%|█████▍    | 1090/2000 [12:34<07:39,  1.98it/s, Loss=0.0078946, Gaussian number=182826, print grad=0.0002881028922274709, Depth Loss=0.0000000]
Training progress:  55%|█████▍    | 1090/2000 [12:38<07:39,  1.98it/s, Loss=0.0083740, Gaussian number=182826, print grad=0.00031977175967767835, Depth Loss=0.0000000]
Training progress:  55%|█████▌    | 1100/2000 [12:38<07:04,  2.12it/s, Loss=0.0083740, Gaussian number=182826, print grad=0.00031977175967767835, Depth Loss=0.0000000]
Training progress:  55%|█████▌    | 1100/2000 [12:42<07:04,  2.12it/s, Loss=0.0082805, Gaussian number=182846, print grad=2.9260410883580334e-05, Depth Loss=0.0000000]
Training progress:  56%|█████▌    | 1110/2000 [12:42<06:39,  2.23it/s, Loss=0.0082805, Gaussian number=182846, print grad=2.9260410883580334e-05, Depth Loss=0.0000000]
Training progress:  56%|█████▌    | 1110/2000 [12:46<06:39,  2.23it/s, Loss=0.0073742, Gaussian number=182846, print grad=6.333746568998322e-05, Depth Loss=0.0000000] 
Training progress:  56%|█████▌    | 1120/2000 [12:46<06:20,  2.31it/s, Loss=0.0073742, Gaussian number=182846, print grad=6.333746568998322e-05, Depth Loss=0.0000000]
Training progress:  56%|█████▌    | 1120/2000 [12:50<06:20,  2.31it/s, Loss=0.0061709, Gaussian number=182846, print grad=9.75808798102662e-05, Depth Loss=0.0000000] 
Training progress:  56%|█████▋    | 1130/2000 [12:50<06:06,  2.38it/s, Loss=0.0061709, Gaussian number=182846, print grad=9.75808798102662e-05, Depth Loss=0.0000000]
Training progress:  56%|█████▋    | 1130/2000 [12:54<06:06,  2.38it/s, Loss=0.0078776, Gaussian number=182846, print grad=0.00013283138105180115, Depth Loss=0.0000000]
Training progress:  57%|█████▋    | 1140/2000 [12:54<05:54,  2.42it/s, Loss=0.0078776, Gaussian number=182846, print grad=0.00013283138105180115, Depth Loss=0.0000000]
Training progress:  57%|█████▋    | 1140/2000 [12:58<05:54,  2.42it/s, Loss=0.0053176, Gaussian number=182846, print grad=0.00016528446576558053, Depth Loss=0.0000000]
Training progress:  57%|█████▊    | 1150/2000 [12:58<05:46,  2.45it/s, Loss=0.0053176, Gaussian number=182846, print grad=0.00016528446576558053, Depth Loss=0.0000000]
Training progress:  57%|█████▊    | 1150/2000 [13:01<05:46,  2.45it/s, Loss=0.0060851, Gaussian number=182846, print grad=0.00019614225311670452, Depth Loss=0.0000000]
Training progress:  58%|█████▊    | 1160/2000 [13:01<05:38,  2.48it/s, Loss=0.0060851, Gaussian number=182846, print grad=0.00019614225311670452, Depth Loss=0.0000000]
Training progress:  58%|█████▊    | 1160/2000 [13:05<05:38,  2.48it/s, Loss=0.0076694, Gaussian number=182846, print grad=0.00022838191944174469, Depth Loss=0.0000000]
Training progress:  58%|█████▊    | 1170/2000 [13:05<05:32,  2.50it/s, Loss=0.0076694, Gaussian number=182846, print grad=0.00022838191944174469, Depth Loss=0.0000000]
Training progress:  58%|█████▊    | 1170/2000 [13:09<05:32,  2.50it/s, Loss=0.0078259, Gaussian number=182846, print grad=0.00025935142184607685, Depth Loss=0.0000000]
Training progress:  59%|█████▉    | 1180/2000 [13:09<05:26,  2.51it/s, Loss=0.0078259, Gaussian number=182846, print grad=0.00025935142184607685, Depth Loss=0.0000000]
Training progress:  59%|█████▉    | 1180/2000 [13:13<05:26,  2.51it/s, Loss=0.0069870, Gaussian number=182846, print grad=0.00029410625575110316, Depth Loss=0.0000000]
Training progress:  60%|█████▉    | 1190/2000 [13:13<05:22,  2.51it/s, Loss=0.0069870, Gaussian number=182846, print grad=0.00029410625575110316, Depth Loss=0.0000000]
Training progress:  60%|█████▉    | 1190/2000 [13:17<05:22,  2.51it/s, Loss=0.0083121, Gaussian number=182846, print grad=0.0003223965468350798, Depth Loss=0.0000000] 
Training progress:  60%|██████    | 1200/2000 [13:17<05:17,  2.52it/s, Loss=0.0083121, Gaussian number=182846, print grad=0.0003223965468350798, Depth Loss=0.0000000]
Training progress:  60%|██████    | 1200/2000 [13:21<05:17,  2.52it/s, Loss=0.0062177, Gaussian number=182878, print grad=3.0101024094619788e-05, Depth Loss=0.0000000]
Training progress:  60%|██████    | 1210/2000 [13:21<05:12,  2.52it/s, Loss=0.0062177, Gaussian number=182878, print grad=3.0101024094619788e-05, Depth Loss=0.0000000]
Training progress:  60%|██████    | 1210/2000 [13:25<05:12,  2.52it/s, Loss=0.0050616, Gaussian number=182878, print grad=6.381017010426149e-05, Depth Loss=0.0000000] 
Training progress:  61%|██████    | 1220/2000 [13:25<05:08,  2.53it/s, Loss=0.0050616, Gaussian number=182878, print grad=6.381017010426149e-05, Depth Loss=0.0000000]
Training progress:  61%|██████    | 1220/2000 [13:29<05:08,  2.53it/s, Loss=0.0058054, Gaussian number=182878, print grad=9.330078319180757e-05, Depth Loss=0.0000000]
Training progress:  62%|██████▏   | 1230/2000 [13:29<05:04,  2.53it/s, Loss=0.0058054, Gaussian number=182878, print grad=9.330078319180757e-05, Depth Loss=0.0000000]
Training progress:  62%|██████▏   | 1230/2000 [13:33<05:04,  2.53it/s, Loss=0.0055588, Gaussian number=182878, print grad=0.00012542676995508373, Depth Loss=0.0000000]
Training progress:  62%|██████▏   | 1240/2000 [13:33<05:00,  2.53it/s, Loss=0.0055588, Gaussian number=182878, print grad=0.00012542676995508373, Depth Loss=0.0000000]
Training progress:  62%|██████▏   | 1240/2000 [13:37<05:00,  2.53it/s, Loss=0.0055798, Gaussian number=182878, print grad=0.00015493232058361173, Depth Loss=0.0000000]
Training progress:  62%|██████▎   | 1250/2000 [13:37<04:55,  2.53it/s, Loss=0.0055798, Gaussian number=182878, print grad=0.00015493232058361173, Depth Loss=0.0000000]
Training progress:  62%|██████▎   | 1250/2000 [13:41<04:55,  2.53it/s, Loss=0.0058710, Gaussian number=182878, print grad=0.0001838934695115313, Depth Loss=0.0000000] 
Training progress:  63%|██████▎   | 1260/2000 [13:41<04:51,  2.53it/s, Loss=0.0058710, Gaussian number=182878, print grad=0.0001838934695115313, Depth Loss=0.0000000]
Training progress:  63%|██████▎   | 1260/2000 [13:45<04:51,  2.53it/s, Loss=0.0077915, Gaussian number=182878, print grad=0.0002166545600630343, Depth Loss=0.0000000]
Training progress:  64%|██████▎   | 1270/2000 [13:45<04:48,  2.53it/s, Loss=0.0077915, Gaussian number=182878, print grad=0.0002166545600630343, Depth Loss=0.0000000]
Training progress:  64%|██████▎   | 1270/2000 [13:49<04:48,  2.53it/s, Loss=0.0076007, Gaussian number=182878, print grad=0.00024782848777249455, Depth Loss=0.0000000]
Training progress:  64%|██████▍   | 1280/2000 [13:49<04:44,  2.53it/s, Loss=0.0076007, Gaussian number=182878, print grad=0.00024782848777249455, Depth Loss=0.0000000]
Training progress:  64%|██████▍   | 1280/2000 [13:53<04:44,  2.53it/s, Loss=0.0057468, Gaussian number=182878, print grad=0.00028143616509623826, Depth Loss=0.0000000]
Training progress:  64%|██████▍   | 1290/2000 [13:53<04:40,  2.53it/s, Loss=0.0057468, Gaussian number=182878, print grad=0.00028143616509623826, Depth Loss=0.0000000]
Training progress:  64%|██████▍   | 1290/2000 [13:57<04:40,  2.53it/s, Loss=0.0085789, Gaussian number=182878, print grad=0.00031153467716649175, Depth Loss=0.0000000]
Training progress:  65%|██████▌   | 1300/2000 [13:57<04:36,  2.53it/s, Loss=0.0085789, Gaussian number=182878, print grad=0.00031153467716649175, Depth Loss=0.0000000]
Training progress:  65%|██████▌   | 1300/2000 [14:01<04:36,  2.53it/s, Loss=0.0082925, Gaussian number=182894, print grad=3.149513577227481e-05, Depth Loss=0.0000000] 
Training progress:  66%|██████▌   | 1310/2000 [14:01<04:32,  2.53it/s, Loss=0.0082925, Gaussian number=182894, print grad=3.149513577227481e-05, Depth Loss=0.0000000]
Training progress:  66%|██████▌   | 1310/2000 [14:05<04:32,  2.53it/s, Loss=0.0077342, Gaussian number=182894, print grad=6.19787024334073e-05, Depth Loss=0.0000000] 
Training progress:  66%|██████▌   | 1320/2000 [14:05<04:28,  2.53it/s, Loss=0.0077342, Gaussian number=182894, print grad=6.19787024334073e-05, Depth Loss=0.0000000]
Training progress:  66%|██████▌   | 1320/2000 [14:09<04:28,  2.53it/s, Loss=0.0059816, Gaussian number=182894, print grad=9.316356590716168e-05, Depth Loss=0.0000000]
Training progress:  66%|██████▋   | 1330/2000 [14:09<04:24,  2.54it/s, Loss=0.0059816, Gaussian number=182894, print grad=9.316356590716168e-05, Depth Loss=0.0000000]
Training progress:  66%|██████▋   | 1330/2000 [14:12<04:24,  2.54it/s, Loss=0.0066004, Gaussian number=182894, print grad=0.00012606238306034356, Depth Loss=0.0000000]
Training progress:  67%|██████▋   | 1340/2000 [14:12<04:20,  2.54it/s, Loss=0.0066004, Gaussian number=182894, print grad=0.00012606238306034356, Depth Loss=0.0000000]
Training progress:  67%|██████▋   | 1340/2000 [14:16<04:20,  2.54it/s, Loss=0.0091598, Gaussian number=182894, print grad=0.00015508060459978878, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1350/2000 [14:16<04:16,  2.54it/s, Loss=0.0091598, Gaussian number=182894, print grad=0.00015508060459978878, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1350/2000 [14:20<04:16,  2.54it/s, Loss=0.0056584, Gaussian number=182894, print grad=0.00018511635425966233, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1360/2000 [14:20<04:12,  2.54it/s, Loss=0.0056584, Gaussian number=182894, print grad=0.00018511635425966233, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1360/2000 [14:24<04:12,  2.54it/s, Loss=0.0099436, Gaussian number=182894, print grad=0.00021655361342709512, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1370/2000 [14:24<04:08,  2.54it/s, Loss=0.0099436, Gaussian number=182894, print grad=0.00021655361342709512, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1370/2000 [14:28<04:08,  2.54it/s, Loss=0.0064483, Gaussian number=182894, print grad=0.0002468939346726984, Depth Loss=0.0000000] 
Training progress:  69%|██████▉   | 1380/2000 [14:28<04:04,  2.54it/s, Loss=0.0064483, Gaussian number=182894, print grad=0.0002468939346726984, Depth Loss=0.0000000]
Training progress:  69%|██████▉   | 1380/2000 [14:32<04:04,  2.54it/s, Loss=0.0059733, Gaussian number=182894, print grad=0.0002756068715825677, Depth Loss=0.0000000]
Training progress:  70%|██████▉   | 1390/2000 [14:32<04:00,  2.53it/s, Loss=0.0059733, Gaussian number=182894, print grad=0.0002756068715825677, Depth Loss=0.0000000]
Training progress:  70%|██████▉   | 1390/2000 [14:36<04:00,  2.53it/s, Loss=0.0064838, Gaussian number=182894, print grad=0.0003072759136557579, Depth Loss=0.0000000]
Training progress:  70%|███████   | 1400/2000 [14:36<03:56,  2.53it/s, Loss=0.0064838, Gaussian number=182894, print grad=0.0003072759136557579, Depth Loss=0.0000000]
Training progress:  70%|███████   | 1400/2000 [14:40<03:56,  2.53it/s, Loss=0.0074877, Gaussian number=182929, print grad=3.061512325075455e-05, Depth Loss=0.0000000]
Training progress:  70%|███████   | 1410/2000 [14:40<03:53,  2.53it/s, Loss=0.0074877, Gaussian number=182929, print grad=3.061512325075455e-05, Depth Loss=0.0000000]
Training progress:  70%|███████   | 1410/2000 [14:44<03:53,  2.53it/s, Loss=0.0065172, Gaussian number=182929, print grad=6.484714685939252e-05, Depth Loss=0.0000000]
Training progress:  71%|███████   | 1420/2000 [14:44<03:49,  2.53it/s, Loss=0.0065172, Gaussian number=182929, print grad=6.484714685939252e-05, Depth Loss=0.0000000]
Training progress:  71%|███████   | 1420/2000 [14:48<03:49,  2.53it/s, Loss=0.0068254, Gaussian number=182929, print grad=9.973679698305205e-05, Depth Loss=0.0000000]
Training progress:  72%|███████▏  | 1430/2000 [14:48<03:44,  2.54it/s, Loss=0.0068254, Gaussian number=182929, print grad=9.973679698305205e-05, Depth Loss=0.0000000]
Training progress:  72%|███████▏  | 1430/2000 [14:52<03:44,  2.54it/s, Loss=0.0064817, Gaussian number=182929, print grad=0.00013015295553486794, Depth Loss=0.0000000]
Training progress:  72%|███████▏  | 1440/2000 [14:52<03:40,  2.54it/s, Loss=0.0064817, Gaussian number=182929, print grad=0.00013015295553486794, Depth Loss=0.0000000]
Training progress:  72%|███████▏  | 1440/2000 [14:56<03:40,  2.54it/s, Loss=0.0059742, Gaussian number=182929, print grad=0.0001605356956133619, Depth Loss=0.0000000] 
Training progress:  72%|███████▎  | 1450/2000 [14:56<03:36,  2.54it/s, Loss=0.0059742, Gaussian number=182929, print grad=0.0001605356956133619, Depth Loss=0.0000000]
Training progress:  72%|███████▎  | 1450/2000 [15:00<03:36,  2.54it/s, Loss=0.0051317, Gaussian number=182929, print grad=0.00019155556219629943, Depth Loss=0.0000000]
Training progress:  73%|███████▎  | 1460/2000 [15:00<03:32,  2.54it/s, Loss=0.0051317, Gaussian number=182929, print grad=0.00019155556219629943, Depth Loss=0.0000000]
Training progress:  73%|███████▎  | 1460/2000 [15:04<03:32,  2.54it/s, Loss=0.0067316, Gaussian number=182929, print grad=0.00022275095398072153, Depth Loss=0.0000000]
Training progress:  74%|███████▎  | 1470/2000 [15:04<03:28,  2.54it/s, Loss=0.0067316, Gaussian number=182929, print grad=0.00022275095398072153, Depth Loss=0.0000000]
Training progress:  74%|███████▎  | 1470/2000 [15:08<03:28,  2.54it/s, Loss=0.0070441, Gaussian number=182929, print grad=0.00025578177883289754, Depth Loss=0.0000000]
Training progress:  74%|███████▍  | 1480/2000 [15:08<03:24,  2.54it/s, Loss=0.0070441, Gaussian number=182929, print grad=0.00025578177883289754, Depth Loss=0.0000000]
Training progress:  74%|███████▍  | 1480/2000 [15:12<03:24,  2.54it/s, Loss=0.0071001, Gaussian number=182929, print grad=0.0002888882299885154, Depth Loss=0.0000000] 
Training progress:  74%|███████▍  | 1490/2000 [15:12<03:20,  2.54it/s, Loss=0.0071001, Gaussian number=182929, print grad=0.0002888882299885154, Depth Loss=0.0000000]
Training progress:  74%|███████▍  | 1490/2000 [15:16<03:20,  2.54it/s, Loss=0.0072379, Gaussian number=182929, print grad=0.00032157462555915117, Depth Loss=0.0000000]
Training progress:  75%|███████▌  | 1500/2000 [15:16<03:17,  2.54it/s, Loss=0.0072379, Gaussian number=182929, print grad=0.00032157462555915117, Depth Loss=0.0000000]
Training progress:  75%|███████▌  | 1500/2000 [16:24<03:17,  2.54it/s, Loss=0.0076163, Gaussian number=182937, print grad=2.773613960016519e-05, Depth Loss=0.0000000] 
Training progress:  76%|███████▌  | 1510/2000 [16:24<18:54,  2.32s/it, Loss=0.0076163, Gaussian number=182937, print grad=2.773613960016519e-05, Depth Loss=0.0000000]
Training progress:  76%|███████▌  | 1510/2000 [16:27<18:54,  2.32s/it, Loss=0.0065055, Gaussian number=182937, print grad=5.7944398577092215e-05, Depth Loss=0.0000000]
Training progress:  76%|███████▌  | 1520/2000 [16:27<13:54,  1.74s/it, Loss=0.0065055, Gaussian number=182937, print grad=5.7944398577092215e-05, Depth Loss=0.0000000]
Training progress:  76%|███████▌  | 1520/2000 [16:31<13:54,  1.74s/it, Loss=0.0042973, Gaussian number=182937, print grad=9.025794133776799e-05, Depth Loss=0.0000000] 
Training progress:  76%|███████▋  | 1530/2000 [16:31<10:27,  1.33s/it, Loss=0.0042973, Gaussian number=182937, print grad=9.025794133776799e-05, Depth Loss=0.0000000]
Training progress:  76%|███████▋  | 1530/2000 [16:35<10:27,  1.33s/it, Loss=0.0061273, Gaussian number=182937, print grad=0.00012132605479564518, Depth Loss=0.0000000]
Training progress:  77%|███████▋  | 1540/2000 [16:35<08:03,  1.05s/it, Loss=0.0061273, Gaussian number=182937, print grad=0.00012132605479564518, Depth Loss=0.0000000]
Training progress:  77%|███████▋  | 1540/2000 [16:39<08:03,  1.05s/it, Loss=0.0062488, Gaussian number=182937, print grad=0.00015527551295235753, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1550/2000 [16:39<06:24,  1.17it/s, Loss=0.0062488, Gaussian number=182937, print grad=0.00015527551295235753, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1550/2000 [16:43<06:24,  1.17it/s, Loss=0.0063762, Gaussian number=182937, print grad=0.0001892680156743154, Depth Loss=0.0000000] 
Training progress:  78%|███████▊  | 1560/2000 [16:43<05:14,  1.40it/s, Loss=0.0063762, Gaussian number=182937, print grad=0.0001892680156743154, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1560/2000 [16:47<05:14,  1.40it/s, Loss=0.0057765, Gaussian number=182937, print grad=0.0002212080726167187, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1570/2000 [16:47<04:25,  1.62it/s, Loss=0.0057765, Gaussian number=182937, print grad=0.0002212080726167187, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1570/2000 [16:51<04:25,  1.62it/s, Loss=0.0042408, Gaussian number=182937, print grad=0.0002476746740285307, Depth Loss=0.0000000]
Training progress:  79%|███████▉  | 1580/2000 [16:51<03:51,  1.82it/s, Loss=0.0042408, Gaussian number=182937, print grad=0.0002476746740285307, Depth Loss=0.0000000]
Training progress:  79%|███████▉  | 1580/2000 [16:55<03:51,  1.82it/s, Loss=0.0059330, Gaussian number=182937, print grad=0.0002767301630228758, Depth Loss=0.0000000]
Training progress:  80%|███████▉  | 1590/2000 [16:55<03:26,  1.99it/s, Loss=0.0059330, Gaussian number=182937, print grad=0.0002767301630228758, Depth Loss=0.0000000]
Training progress:  80%|███████▉  | 1590/2000 [16:59<03:26,  1.99it/s, Loss=0.0059027, Gaussian number=182937, print grad=0.0003089802630711347, Depth Loss=0.0000000]
Training progress:  80%|████████  | 1600/2000 [16:59<03:07,  2.13it/s, Loss=0.0059027, Gaussian number=182937, print grad=0.0003089802630711347, Depth Loss=0.0000000]
Training progress:  80%|████████  | 1600/2000 [17:03<03:07,  2.13it/s, Loss=0.0058711, Gaussian number=182939, print grad=3.071853643632494e-05, Depth Loss=0.0000000]
Training progress:  80%|████████  | 1610/2000 [17:03<02:54,  2.24it/s, Loss=0.0058711, Gaussian number=182939, print grad=3.071853643632494e-05, Depth Loss=0.0000000]
Training progress:  80%|████████  | 1610/2000 [17:07<02:54,  2.24it/s, Loss=0.0066610, Gaussian number=182939, print grad=6.393688090611249e-05, Depth Loss=0.0000000]
Training progress:  81%|████████  | 1620/2000 [17:07<02:43,  2.32it/s, Loss=0.0066610, Gaussian number=182939, print grad=6.393688090611249e-05, Depth Loss=0.0000000]
Training progress:  81%|████████  | 1620/2000 [17:11<02:43,  2.32it/s, Loss=0.0058399, Gaussian number=182939, print grad=9.467756899539381e-05, Depth Loss=0.0000000]
Training progress:  82%|████████▏ | 1630/2000 [17:11<02:36,  2.37it/s, Loss=0.0058399, Gaussian number=182939, print grad=9.467756899539381e-05, Depth Loss=0.0000000]
Training progress:  82%|████████▏ | 1630/2000 [17:15<02:36,  2.37it/s, Loss=0.0042109, Gaussian number=182939, print grad=0.0001256762188859284, Depth Loss=0.0000000]
Training progress:  82%|████████▏ | 1640/2000 [17:15<02:28,  2.42it/s, Loss=0.0042109, Gaussian number=182939, print grad=0.0001256762188859284, Depth Loss=0.0000000]
Training progress:  82%|████████▏ | 1640/2000 [17:19<02:28,  2.42it/s, Loss=0.0058636, Gaussian number=182939, print grad=0.00015395786613225937, Depth Loss=0.0000000]
Training progress:  82%|████████▎ | 1650/2000 [17:19<02:22,  2.46it/s, Loss=0.0058636, Gaussian number=182939, print grad=0.00015395786613225937, Depth Loss=0.0000000]
Training progress:  82%|████████▎ | 1650/2000 [17:23<02:22,  2.46it/s, Loss=0.0057039, Gaussian number=182939, print grad=0.00018400594126433134, Depth Loss=0.0000000]
Training progress:  83%|████████▎ | 1660/2000 [17:23<02:17,  2.48it/s, Loss=0.0057039, Gaussian number=182939, print grad=0.00018400594126433134, Depth Loss=0.0000000]
Training progress:  83%|████████▎ | 1660/2000 [17:26<02:17,  2.48it/s, Loss=0.0054067, Gaussian number=182939, print grad=0.00021355181524995714, Depth Loss=0.0000000]
Training progress:  84%|████████▎ | 1670/2000 [17:26<02:11,  2.50it/s, Loss=0.0054067, Gaussian number=182939, print grad=0.00021355181524995714, Depth Loss=0.0000000]
Training progress:  84%|████████▎ | 1670/2000 [17:30<02:11,  2.50it/s, Loss=0.0047595, Gaussian number=182939, print grad=0.0002457655791658908, Depth Loss=0.0000000] 
Training progress:  84%|████████▍ | 1680/2000 [17:30<02:07,  2.51it/s, Loss=0.0047595, Gaussian number=182939, print grad=0.0002457655791658908, Depth Loss=0.0000000]
Training progress:  84%|████████▍ | 1680/2000 [17:34<02:07,  2.51it/s, Loss=0.0059657, Gaussian number=182939, print grad=0.00027638868778012693, Depth Loss=0.0000000]
Training progress:  84%|████████▍ | 1690/2000 [17:34<02:03,  2.52it/s, Loss=0.0059657, Gaussian number=182939, print grad=0.00027638868778012693, Depth Loss=0.0000000]
Training progress:  84%|████████▍ | 1690/2000 [17:38<02:03,  2.52it/s, Loss=0.0060594, Gaussian number=182939, print grad=0.00030434568179771304, Depth Loss=0.0000000]
Training progress:  85%|████████▌ | 1700/2000 [17:38<01:58,  2.53it/s, Loss=0.0060594, Gaussian number=182939, print grad=0.00030434568179771304, Depth Loss=0.0000000]
Training progress:  85%|████████▌ | 1700/2000 [17:42<01:58,  2.53it/s, Loss=0.0064292, Gaussian number=182955, print grad=3.123341593891382e-05, Depth Loss=0.0000000] 
Training progress:  86%|████████▌ | 1710/2000 [17:42<01:54,  2.53it/s, Loss=0.0064292, Gaussian number=182955, print grad=3.123341593891382e-05, Depth Loss=0.0000000]
Training progress:  86%|████████▌ | 1710/2000 [17:46<01:54,  2.53it/s, Loss=0.0067837, Gaussian number=182955, print grad=5.928173413849436e-05, Depth Loss=0.0000000]
Training progress:  86%|████████▌ | 1720/2000 [17:46<01:50,  2.53it/s, Loss=0.0067837, Gaussian number=182955, print grad=5.928173413849436e-05, Depth Loss=0.0000000]
Training progress:  86%|████████▌ | 1720/2000 [17:50<01:50,  2.53it/s, Loss=0.0057029, Gaussian number=182955, print grad=9.072417014976963e-05, Depth Loss=0.0000000]
Training progress:  86%|████████▋ | 1730/2000 [17:50<01:46,  2.53it/s, Loss=0.0057029, Gaussian number=182955, print grad=9.072417014976963e-05, Depth Loss=0.0000000]
Training progress:  86%|████████▋ | 1730/2000 [17:54<01:46,  2.53it/s, Loss=0.0075428, Gaussian number=182955, print grad=0.0001244630548171699, Depth Loss=0.0000000]
Training progress:  87%|████████▋ | 1740/2000 [17:54<01:42,  2.54it/s, Loss=0.0075428, Gaussian number=182955, print grad=0.0001244630548171699, Depth Loss=0.0000000]
Training progress:  87%|████████▋ | 1740/2000 [17:58<01:42,  2.54it/s, Loss=0.0074311, Gaussian number=182955, print grad=0.00015834141231607646, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1750/2000 [17:58<01:38,  2.54it/s, Loss=0.0074311, Gaussian number=182955, print grad=0.00015834141231607646, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1750/2000 [18:02<01:38,  2.54it/s, Loss=0.0060822, Gaussian number=182955, print grad=0.00018989465024787933, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1760/2000 [18:02<01:34,  2.54it/s, Loss=0.0060822, Gaussian number=182955, print grad=0.00018989465024787933, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1760/2000 [18:06<01:34,  2.54it/s, Loss=0.0050255, Gaussian number=182955, print grad=0.00021922995802015066, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1770/2000 [18:06<01:30,  2.54it/s, Loss=0.0050255, Gaussian number=182955, print grad=0.00021922995802015066, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1770/2000 [18:10<01:30,  2.54it/s, Loss=0.0062709, Gaussian number=182955, print grad=0.000248936063144356, Depth Loss=0.0000000]  
Training progress:  89%|████████▉ | 1780/2000 [18:10<01:26,  2.54it/s, Loss=0.0062709, Gaussian number=182955, print grad=0.000248936063144356, Depth Loss=0.0000000]
Training progress:  89%|████████▉ | 1780/2000 [18:14<01:26,  2.54it/s, Loss=0.0053124, Gaussian number=182955, print grad=0.0002763885713648051, Depth Loss=0.0000000]
Training progress:  90%|████████▉ | 1790/2000 [18:14<01:22,  2.54it/s, Loss=0.0053124, Gaussian number=182955, print grad=0.0002763885713648051, Depth Loss=0.0000000]
Training progress:  90%|████████▉ | 1790/2000 [18:18<01:22,  2.54it/s, Loss=0.0054583, Gaussian number=182955, print grad=0.0003093566629104316, Depth Loss=0.0000000]
Training progress:  90%|█████████ | 1800/2000 [18:18<01:18,  2.54it/s, Loss=0.0054583, Gaussian number=182955, print grad=0.0003093566629104316, Depth Loss=0.0000000]
Training progress:  90%|█████████ | 1800/2000 [18:22<01:18,  2.54it/s, Loss=0.0061489, Gaussian number=182969, print grad=3.153076613671146e-05, Depth Loss=0.0000000]
Training progress:  90%|█████████ | 1810/2000 [18:22<01:14,  2.54it/s, Loss=0.0061489, Gaussian number=182969, print grad=3.153076613671146e-05, Depth Loss=0.0000000]
Training progress:  90%|█████████ | 1810/2000 [18:26<01:14,  2.54it/s, Loss=0.0055020, Gaussian number=182969, print grad=6.447488703997806e-05, Depth Loss=0.0000000]
Training progress:  91%|█████████ | 1820/2000 [18:26<01:10,  2.54it/s, Loss=0.0055020, Gaussian number=182969, print grad=6.447488703997806e-05, Depth Loss=0.0000000]
Training progress:  91%|█████████ | 1820/2000 [18:29<01:10,  2.54it/s, Loss=0.0044259, Gaussian number=182969, print grad=9.32783295866102e-05, Depth Loss=0.0000000] 
Training progress:  92%|█████████▏| 1830/2000 [18:29<01:07,  2.54it/s, Loss=0.0044259, Gaussian number=182969, print grad=9.32783295866102e-05, Depth Loss=0.0000000]
Training progress:  92%|█████████▏| 1830/2000 [18:33<01:07,  2.54it/s, Loss=0.0051252, Gaussian number=182969, print grad=0.00012621928181033581, Depth Loss=0.0000000]
Training progress:  92%|█████████▏| 1840/2000 [18:33<01:03,  2.54it/s, Loss=0.0051252, Gaussian number=182969, print grad=0.00012621928181033581, Depth Loss=0.0000000]
Training progress:  92%|█████████▏| 1840/2000 [18:37<01:03,  2.54it/s, Loss=0.0053431, Gaussian number=182969, print grad=0.0001573164772707969, Depth Loss=0.0000000] 
Training progress:  92%|█████████▎| 1850/2000 [18:37<00:59,  2.54it/s, Loss=0.0053431, Gaussian number=182969, print grad=0.0001573164772707969, Depth Loss=0.0000000]
Training progress:  92%|█████████▎| 1850/2000 [18:41<00:59,  2.54it/s, Loss=0.0054430, Gaussian number=182969, print grad=0.0001837802556110546, Depth Loss=0.0000000]
Training progress:  93%|█████████▎| 1860/2000 [18:41<00:55,  2.54it/s, Loss=0.0054430, Gaussian number=182969, print grad=0.0001837802556110546, Depth Loss=0.0000000]
Training progress:  93%|█████████▎| 1860/2000 [18:45<00:55,  2.54it/s, Loss=0.0060175, Gaussian number=182969, print grad=0.00021806993754580617, Depth Loss=0.0000000]
Training progress:  94%|█████████▎| 1870/2000 [18:45<00:51,  2.54it/s, Loss=0.0060175, Gaussian number=182969, print grad=0.00021806993754580617, Depth Loss=0.0000000]
Training progress:  94%|█████████▎| 1870/2000 [18:49<00:51,  2.54it/s, Loss=0.0047673, Gaussian number=182969, print grad=0.00024870558991096914, Depth Loss=0.0000000]
Training progress:  94%|█████████▍| 1880/2000 [18:49<00:47,  2.54it/s, Loss=0.0047673, Gaussian number=182969, print grad=0.00024870558991096914, Depth Loss=0.0000000]
Training progress:  94%|█████████▍| 1880/2000 [18:53<00:47,  2.54it/s, Loss=0.0053613, Gaussian number=182969, print grad=0.00027827286976389587, Depth Loss=0.0000000]
Training progress:  94%|█████████▍| 1890/2000 [18:53<00:43,  2.54it/s, Loss=0.0053613, Gaussian number=182969, print grad=0.00027827286976389587, Depth Loss=0.0000000]
Training progress:  94%|█████████▍| 1890/2000 [18:57<00:43,  2.54it/s, Loss=0.0067138, Gaussian number=182969, print grad=0.0003102193877566606, Depth Loss=0.0000000] 
Training progress:  95%|█████████▌| 1900/2000 [18:57<00:39,  2.54it/s, Loss=0.0067138, Gaussian number=182969, print grad=0.0003102193877566606, Depth Loss=0.0000000]
Training progress:  95%|█████████▌| 1900/2000 [19:01<00:39,  2.54it/s, Loss=0.0061811, Gaussian number=183007, print grad=2.8460941393859684e-05, Depth Loss=0.0000000]
Training progress:  96%|█████████▌| 1910/2000 [19:01<00:35,  2.54it/s, Loss=0.0061811, Gaussian number=183007, print grad=2.8460941393859684e-05, Depth Loss=0.0000000]
Training progress:  96%|█████████▌| 1910/2000 [19:05<00:35,  2.54it/s, Loss=0.0046081, Gaussian number=183007, print grad=5.923026037635282e-05, Depth Loss=0.0000000] 
Training progress:  96%|█████████▌| 1920/2000 [19:05<00:31,  2.54it/s, Loss=0.0046081, Gaussian number=183007, print grad=5.923026037635282e-05, Depth Loss=0.0000000]
Training progress:  96%|█████████▌| 1920/2000 [19:09<00:31,  2.54it/s, Loss=0.0042449, Gaussian number=183007, print grad=9.041368321049958e-05, Depth Loss=0.0000000]
Training progress:  96%|█████████▋| 1930/2000 [19:09<00:27,  2.54it/s, Loss=0.0042449, Gaussian number=183007, print grad=9.041368321049958e-05, Depth Loss=0.0000000]
Training progress:  96%|█████████▋| 1930/2000 [19:13<00:27,  2.54it/s, Loss=0.0062328, Gaussian number=183007, print grad=0.00012035276449751109, Depth Loss=0.0000000]
Training progress:  97%|█████████▋| 1940/2000 [19:13<00:23,  2.53it/s, Loss=0.0062328, Gaussian number=183007, print grad=0.00012035276449751109, Depth Loss=0.0000000]
Training progress:  97%|█████████▋| 1940/2000 [19:17<00:23,  2.53it/s, Loss=0.0046282, Gaussian number=183007, print grad=0.00015133689157664776, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1950/2000 [19:17<00:19,  2.53it/s, Loss=0.0046282, Gaussian number=183007, print grad=0.00015133689157664776, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1950/2000 [19:21<00:19,  2.53it/s, Loss=0.0073592, Gaussian number=183007, print grad=0.00018035962420981377, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1960/2000 [19:21<00:15,  2.53it/s, Loss=0.0073592, Gaussian number=183007, print grad=0.00018035962420981377, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1960/2000 [19:25<00:15,  2.53it/s, Loss=0.0062659, Gaussian number=183007, print grad=0.00021169305546209216, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1970/2000 [19:25<00:11,  2.53it/s, Loss=0.0062659, Gaussian number=183007, print grad=0.00021169305546209216, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1970/2000 [19:29<00:11,  2.53it/s, Loss=0.0055621, Gaussian number=183007, print grad=0.00024218148610088974, Depth Loss=0.0000000]
Training progress:  99%|█████████▉| 1980/2000 [19:29<00:07,  2.53it/s, Loss=0.0055621, Gaussian number=183007, print grad=0.00024218148610088974, Depth Loss=0.0000000]
Training progress:  99%|█████████▉| 1980/2000 [19:33<00:07,  2.53it/s, Loss=0.0052606, Gaussian number=183007, print grad=0.00027765132836066186, Depth Loss=0.0000000]
Training progress: 100%|█████████▉| 1990/2000 [19:33<00:03,  2.53it/s, Loss=0.0052606, Gaussian number=183007, print grad=0.00027765132836066186, Depth Loss=0.0000000]
Training progress: 100%|█████████▉| 1990/2000 [19:37<00:03,  2.53it/s, Loss=0.0044194, Gaussian number=183007, print grad=0.0003106500953435898, Depth Loss=0.0000000] 
Training progress: 100%|██████████| 2000/2000 [19:37<00:00,  2.53it/s, Loss=0.0044194, Gaussian number=183007, print grad=0.0003106500953435898, Depth Loss=0.0000000]
Training progress: 100%|██████████| 2000/2000 [19:37<00:00,  1.70it/s, Loss=0.0044194, Gaussian number=183007, print grad=0.0003106500953435898, Depth Loss=0.0000000]
Iteration 100 [03/12 21:28:56]

[ITER 100] Evaluating test: WD 0.021026, PSNR 12.7832,lpips 0.601429,ssim 0.441037 [03/12 21:29:53]

[ITER 100] Evaluating train: WD 0.022012, PSNR 13.0800,lpips 0.603840,ssim 0.458579 [03/12 21:30:00]
Gaussian number:182686,print gradients:2.712482455535792e-06 [03/12 21:30:01]
Iteration 200 [03/12 21:30:40]

[ITER 200] Evaluating test: WD 0.019094, PSNR 14.2066,lpips 0.551745,ssim 0.472920 [03/12 21:31:37]

[ITER 200] Evaluating train: WD 0.019399, PSNR 14.3655,lpips 0.542783,ssim 0.486473 [03/12 21:31:45]
Gaussian number:182686,print gradients:3.260982339270413e-06 [03/12 21:31:45]
Iteration 300 [03/12 21:32:24]

[ITER 300] Evaluating test: WD 0.017862, PSNR 14.8740,lpips 0.519664,ssim 0.489625 [03/12 21:33:21]

[ITER 300] Evaluating train: WD 0.018221, PSNR 15.1132,lpips 0.508521,ssim 0.501818 [03/12 21:33:29]
Gaussian number:182686,print gradients:3.578813675630954e-06 [03/12 21:33:29]
Iteration 400 [03/12 21:34:08]
Iteration 500 [03/12 21:34:47]

[ITER 500] Evaluating test: WD 0.016525, PSNR 15.6671,lpips 0.486954,ssim 0.507906 [03/12 21:35:44]

[ITER 500] Evaluating train: WD 0.017768, PSNR 15.6246,lpips 0.486014,ssim 0.512928 [03/12 21:35:52]
Gaussian number:182686,print gradients:3.949781330447877e-06 [03/12 21:35:52]
Iteration 600 [03/12 21:36:31]
Iteration 700 [03/12 21:37:10]
Iteration 800 [03/12 21:37:50]
Iteration 900 [03/12 21:38:29]
Iteration 1000 [03/12 21:39:09]

[ITER 1000] Evaluating test: WD 0.014494, PSNR 16.4211,lpips 0.437016,ssim 0.529495 [03/12 21:40:06]

[ITER 1000] Evaluating train: WD 0.015511, PSNR 16.4552,lpips 0.438495,ssim 0.536056 [03/12 21:40:13]
Gaussian number:182790,print gradients:4.756659564009169e-06 [03/12 21:40:13]
Iteration 1100 [03/12 21:40:52]
Iteration 1200 [03/12 21:41:32]
Iteration 1300 [03/12 21:42:11]
Iteration 1400 [03/12 21:42:51]
Iteration 1500 [03/12 21:43:30]

[ITER 1500] Evaluating test: WD 0.013089, PSNR 16.8780,lpips 0.403939,ssim 0.543478 [03/12 21:44:27]

[ITER 1500] Evaluating train: WD 0.013775, PSNR 17.1438,lpips 0.402127,ssim 0.553347 [03/12 21:44:35]
Gaussian number:182929,print gradients:4.911305495625129e-06 [03/12 21:44:35]
Iteration 1600 [03/12 21:45:13]
Iteration 1700 [03/12 21:45:53]
Iteration 1800 [03/12 21:46:32]
Iteration 1900 [03/12 21:47:12]
Iteration 2000 [03/12 21:47:51]

[ITER 2000] Evaluating test: WD 0.012334, PSNR 17.1696,lpips 0.386310,ssim 0.553023 [03/12 21:48:48]

[ITER 2000] Evaluating train: WD 0.013537, PSNR 17.4878,lpips 0.388256,ssim 0.557384 [03/12 21:48:55]
Gaussian number:183007,print gradients:4.7998391892178915e-06 [03/12 21:48:55]

[ITER 2000] Saving Gaussians [03/12 21:48:55]

Training complete. [03/12 21:48:57]
