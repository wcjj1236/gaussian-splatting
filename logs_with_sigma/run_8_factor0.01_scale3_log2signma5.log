Optimizing /home/cw4287/gaussian-model/train_30k
Output folder: /home/cw4287/gaussian-model/train_30k [03/12 19:05:07]
Tensorboard not available: not logging progress [03/12 19:05:07]
------------LLFF HOLD------------- [03/12 19:05:08]

Reading camera 1/301
Reading camera 2/301
Reading camera 3/301
Reading camera 4/301
Reading camera 5/301
Reading camera 6/301
Reading camera 7/301
Reading camera 8/301
Reading camera 9/301
Reading camera 10/301
Reading camera 11/301
Reading camera 12/301
Reading camera 13/301
Reading camera 14/301
Reading camera 15/301
Reading camera 16/301
Reading camera 17/301
Reading camera 18/301
Reading camera 19/301
Reading camera 20/301
Reading camera 21/301
Reading camera 22/301
Reading camera 23/301
Reading camera 24/301
Reading camera 25/301
Reading camera 26/301
Reading camera 27/301
Reading camera 28/301
Reading camera 29/301
Reading camera 30/301
Reading camera 31/301
Reading camera 32/301
Reading camera 33/301
Reading camera 34/301
Reading camera 35/301
Reading camera 36/301
Reading camera 37/301
Reading camera 38/301
Reading camera 39/301
Reading camera 40/301
Reading camera 41/301
Reading camera 42/301
Reading camera 43/301
Reading camera 44/301
Reading camera 45/301
Reading camera 46/301
Reading camera 47/301
Reading camera 48/301
Reading camera 49/301
Reading camera 50/301
Reading camera 51/301
Reading camera 52/301
Reading camera 53/301
Reading camera 54/301
Reading camera 55/301
Reading camera 56/301
Reading camera 57/301
Reading camera 58/301
Reading camera 59/301
Reading camera 60/301
Reading camera 61/301
Reading camera 62/301
Reading camera 63/301
Reading camera 64/301
Reading camera 65/301
Reading camera 66/301
Reading camera 67/301
Reading camera 68/301
Reading camera 69/301
Reading camera 70/301
Reading camera 71/301
Reading camera 72/301
Reading camera 73/301
Reading camera 74/301
Reading camera 75/301
Reading camera 76/301
Reading camera 77/301
Reading camera 78/301
Reading camera 79/301
Reading camera 80/301
Reading camera 81/301
Reading camera 82/301
Reading camera 83/301
Reading camera 84/301
Reading camera 85/301
Reading camera 86/301
Reading camera 87/301
Reading camera 88/301
Reading camera 89/301
Reading camera 90/301
Reading camera 91/301
Reading camera 92/301
Reading camera 93/301
Reading camera 94/301
Reading camera 95/301
Reading camera 96/301
Reading camera 97/301
Reading camera 98/301
Reading camera 99/301
Reading camera 100/301
Reading camera 101/301
Reading camera 102/301
Reading camera 103/301
Reading camera 104/301
Reading camera 105/301
Reading camera 106/301
Reading camera 107/301
Reading camera 108/301
Reading camera 109/301
Reading camera 110/301
Reading camera 111/301
Reading camera 112/301
Reading camera 113/301
Reading camera 114/301
Reading camera 115/301
Reading camera 116/301
Reading camera 117/301
Reading camera 118/301
Reading camera 119/301
Reading camera 120/301
Reading camera 121/301
Reading camera 122/301
Reading camera 123/301
Reading camera 124/301
Reading camera 125/301
Reading camera 126/301
Reading camera 127/301
Reading camera 128/301
Reading camera 129/301
Reading camera 130/301
Reading camera 131/301
Reading camera 132/301
Reading camera 133/301
Reading camera 134/301
Reading camera 135/301
Reading camera 136/301
Reading camera 137/301
Reading camera 138/301
Reading camera 139/301
Reading camera 140/301
Reading camera 141/301
Reading camera 142/301
Reading camera 143/301
Reading camera 144/301
Reading camera 145/301
Reading camera 146/301
Reading camera 147/301
Reading camera 148/301
Reading camera 149/301
Reading camera 150/301
Reading camera 151/301
Reading camera 152/301
Reading camera 153/301
Reading camera 154/301
Reading camera 155/301
Reading camera 156/301
Reading camera 157/301
Reading camera 158/301
Reading camera 159/301
Reading camera 160/301
Reading camera 161/301
Reading camera 162/301
Reading camera 163/301
Reading camera 164/301
Reading camera 165/301
Reading camera 166/301
Reading camera 167/301
Reading camera 168/301
Reading camera 169/301
Reading camera 170/301
Reading camera 171/301
Reading camera 172/301
Reading camera 173/301
Reading camera 174/301
Reading camera 175/301
Reading camera 176/301
Reading camera 177/301
Reading camera 178/301
Reading camera 179/301
Reading camera 180/301
Reading camera 181/301
Reading camera 182/301
Reading camera 183/301
Reading camera 184/301
Reading camera 185/301
Reading camera 186/301
Reading camera 187/301
Reading camera 188/301
Reading camera 189/301
Reading camera 190/301
Reading camera 191/301
Reading camera 192/301
Reading camera 193/301
Reading camera 194/301
Reading camera 195/301
Reading camera 196/301
Reading camera 197/301
Reading camera 198/301
Reading camera 199/301
Reading camera 200/301
Reading camera 201/301
Reading camera 202/301
Reading camera 203/301
Reading camera 204/301
Reading camera 205/301
Reading camera 206/301
Reading camera 207/301
Reading camera 208/301
Reading camera 209/301
Reading camera 210/301
Reading camera 211/301
Reading camera 212/301
Reading camera 213/301
Reading camera 214/301
Reading camera 215/301
Reading camera 216/301
Reading camera 217/301
Reading camera 218/301
Reading camera 219/301
Reading camera 220/301
Reading camera 221/301
Reading camera 222/301
Reading camera 223/301
Reading camera 224/301
Reading camera 225/301
Reading camera 226/301
Reading camera 227/301
Reading camera 228/301
Reading camera 229/301
Reading camera 230/301
Reading camera 231/301
Reading camera 232/301
Reading camera 233/301
Reading camera 234/301
Reading camera 235/301
Reading camera 236/301
Reading camera 237/301
Reading camera 238/301
Reading camera 239/301
Reading camera 240/301
Reading camera 241/301
Reading camera 242/301
Reading camera 243/301
Reading camera 244/301
Reading camera 245/301
Reading camera 246/301
Reading camera 247/301
Reading camera 248/301
Reading camera 249/301
Reading camera 250/301
Reading camera 251/301
Reading camera 252/301
Reading camera 253/301
Reading camera 254/301
Reading camera 255/301
Reading camera 256/301
Reading camera 257/301
Reading camera 258/301
Reading camera 259/301
Reading camera 260/301
Reading camera 261/301
Reading camera 262/301
Reading camera 263/301
Reading camera 264/301
Reading camera 265/301
Reading camera 266/301
Reading camera 267/301
Reading camera 268/301
Reading camera 269/301
Reading camera 270/301
Reading camera 271/301
Reading camera 272/301
Reading camera 273/301
Reading camera 274/301
Reading camera 275/301
Reading camera 276/301
Reading camera 277/301
Reading camera 278/301
Reading camera 279/301
Reading camera 280/301
Reading camera 281/301
Reading camera 282/301
Reading camera 283/301
Reading camera 284/301
Reading camera 285/301
Reading camera 286/301
Reading camera 287/301
Reading camera 288/301
Reading camera 289/301
Reading camera 290/301
Reading camera 291/301
Reading camera 292/301
Reading camera 293/301
Reading camera 294/301
Reading camera 295/301
Reading camera 296/301
Reading camera 297/301
Reading camera 298/301
Reading camera 299/301
Reading camera 300/301
Reading camera 301/301 [03/12 19:05:08]
Loading Training Cameras [03/12 19:05:08]
Loading Test Cameras [03/12 19:05:25]
Number of points at initialisation :  182686 [03/12 19:05:27]

Training progress:   0%|          | 0/2000 [00:00<?, ?it/s]/ext3/conda/envs/3dgs/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/ext3/conda/envs/3dgs/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)

Training progress:   0%|          | 0/2000 [00:05<?, ?it/s, Loss=0.1964085, Gaussian number=182686, print grad=0.00012397651153150946, Depth Loss=0.0000000]
Training progress:   0%|          | 10/2000 [00:05<18:58,  1.75it/s, Loss=0.1964085, Gaussian number=182686, print grad=0.00012397651153150946, Depth Loss=0.0000000]
Training progress:   0%|          | 10/2000 [00:09<18:58,  1.75it/s, Loss=0.1781950, Gaussian number=182686, print grad=0.0002950776251964271, Depth Loss=0.0000000] 
Training progress:   1%|          | 20/2000 [00:09<15:38,  2.11it/s, Loss=0.1781950, Gaussian number=182686, print grad=0.0002950776251964271, Depth Loss=0.0000000]
Training progress:   1%|          | 20/2000 [00:13<15:38,  2.11it/s, Loss=0.1747458, Gaussian number=182686, print grad=0.00045789979049004614, Depth Loss=0.0000000]
Training progress:   2%|▏         | 30/2000 [00:13<14:29,  2.26it/s, Loss=0.1747458, Gaussian number=182686, print grad=0.00045789979049004614, Depth Loss=0.0000000]
Training progress:   2%|▏         | 30/2000 [00:17<14:29,  2.26it/s, Loss=0.1815665, Gaussian number=182686, print grad=0.0006119738100096583, Depth Loss=0.0000000] 
Training progress:   2%|▏         | 40/2000 [00:17<13:56,  2.34it/s, Loss=0.1815665, Gaussian number=182686, print grad=0.0006119738100096583, Depth Loss=0.0000000]
Training progress:   2%|▏         | 40/2000 [00:21<13:56,  2.34it/s, Loss=0.1374031, Gaussian number=182686, print grad=0.0007403708295896649, Depth Loss=0.0000000]
Training progress:   2%|▎         | 50/2000 [00:21<13:34,  2.39it/s, Loss=0.1374031, Gaussian number=182686, print grad=0.0007403708295896649, Depth Loss=0.0000000]
Training progress:   2%|▎         | 50/2000 [00:25<13:34,  2.39it/s, Loss=0.1431665, Gaussian number=182686, print grad=0.0009200450731441379, Depth Loss=0.0000000]
Training progress:   3%|▎         | 60/2000 [00:25<13:20,  2.42it/s, Loss=0.1431665, Gaussian number=182686, print grad=0.0009200450731441379, Depth Loss=0.0000000]
Training progress:   3%|▎         | 60/2000 [00:29<13:20,  2.42it/s, Loss=0.1245874, Gaussian number=182686, print grad=0.0011118443217128515, Depth Loss=0.0000000]
Training progress:   4%|▎         | 70/2000 [00:29<13:09,  2.44it/s, Loss=0.1245874, Gaussian number=182686, print grad=0.0011118443217128515, Depth Loss=0.0000000]
Training progress:   4%|▎         | 70/2000 [00:33<13:09,  2.44it/s, Loss=0.1617995, Gaussian number=182686, print grad=0.0012769688619300723, Depth Loss=0.0000000]
Training progress:   4%|▍         | 80/2000 [00:33<13:00,  2.46it/s, Loss=0.1617995, Gaussian number=182686, print grad=0.0012769688619300723, Depth Loss=0.0000000]
Training progress:   4%|▍         | 80/2000 [00:37<13:00,  2.46it/s, Loss=0.1355516, Gaussian number=182686, print grad=0.0014551273779943585, Depth Loss=0.0000000]
Training progress:   4%|▍         | 90/2000 [00:37<12:54,  2.47it/s, Loss=0.1355516, Gaussian number=182686, print grad=0.0014551273779943585, Depth Loss=0.0000000]
Training progress:   4%|▍         | 90/2000 [00:41<12:54,  2.47it/s, Loss=0.1213012, Gaussian number=182686, print grad=0.0016551042208448052, Depth Loss=0.0000000]
Training progress:   5%|▌         | 100/2000 [00:41<12:48,  2.47it/s, Loss=0.1213012, Gaussian number=182686, print grad=0.0016551042208448052, Depth Loss=0.0000000]
Training progress:   5%|▌         | 100/2000 [01:51<12:48,  2.47it/s, Loss=0.1464825, Gaussian number=182686, print grad=0.0018578279996290803, Depth Loss=0.0000000]
Training progress:   6%|▌         | 110/2000 [01:51<1:15:43,  2.40s/it, Loss=0.1464825, Gaussian number=182686, print grad=0.0018578279996290803, Depth Loss=0.0000000]
Training progress:   6%|▌         | 110/2000 [01:55<1:15:43,  2.40s/it, Loss=0.1167845, Gaussian number=182686, print grad=0.002050546696409583, Depth Loss=0.0000000] 
Training progress:   6%|▌         | 120/2000 [01:55<56:13,  1.79s/it, Loss=0.1167845, Gaussian number=182686, print grad=0.002050546696409583, Depth Loss=0.0000000]  
Training progress:   6%|▌         | 120/2000 [01:59<56:13,  1.79s/it, Loss=0.1269425, Gaussian number=182686, print grad=0.002266070805490017, Depth Loss=0.0000000]
Training progress:   6%|▋         | 130/2000 [01:59<42:46,  1.37s/it, Loss=0.1269425, Gaussian number=182686, print grad=0.002266070805490017, Depth Loss=0.0000000]
Training progress:   6%|▋         | 130/2000 [02:03<42:46,  1.37s/it, Loss=0.1175238, Gaussian number=182686, print grad=0.0024817748926579952, Depth Loss=0.0000000]
Training progress:   7%|▋         | 140/2000 [02:03<33:27,  1.08s/it, Loss=0.1175238, Gaussian number=182686, print grad=0.0024817748926579952, Depth Loss=0.0000000]
Training progress:   7%|▋         | 140/2000 [02:07<33:27,  1.08s/it, Loss=0.1013897, Gaussian number=182686, print grad=0.0026734608691185713, Depth Loss=0.0000000]
Training progress:   8%|▊         | 150/2000 [02:07<26:58,  1.14it/s, Loss=0.1013897, Gaussian number=182686, print grad=0.0026734608691185713, Depth Loss=0.0000000]
Training progress:   8%|▊         | 150/2000 [02:11<26:58,  1.14it/s, Loss=0.1112607, Gaussian number=182686, print grad=0.0029049725271761417, Depth Loss=0.0000000]
Training progress:   8%|▊         | 160/2000 [02:11<22:26,  1.37it/s, Loss=0.1112607, Gaussian number=182686, print grad=0.0029049725271761417, Depth Loss=0.0000000]
Training progress:   8%|▊         | 160/2000 [02:15<22:26,  1.37it/s, Loss=0.1105653, Gaussian number=182686, print grad=0.003105226904153824, Depth Loss=0.0000000] 
Training progress:   8%|▊         | 170/2000 [02:15<19:16,  1.58it/s, Loss=0.1105653, Gaussian number=182686, print grad=0.003105226904153824, Depth Loss=0.0000000]
Training progress:   8%|▊         | 170/2000 [02:19<19:16,  1.58it/s, Loss=0.0887821, Gaussian number=182686, print grad=0.0033132873941212893, Depth Loss=0.0000000]
Training progress:   9%|▉         | 180/2000 [02:19<17:03,  1.78it/s, Loss=0.0887821, Gaussian number=182686, print grad=0.0033132873941212893, Depth Loss=0.0000000]
Training progress:   9%|▉         | 180/2000 [02:23<17:03,  1.78it/s, Loss=0.1122823, Gaussian number=182686, print grad=0.0035166016314178705, Depth Loss=0.0000000]
Training progress:  10%|▉         | 190/2000 [02:23<15:30,  1.95it/s, Loss=0.1122823, Gaussian number=182686, print grad=0.0035166016314178705, Depth Loss=0.0000000]
Training progress:  10%|▉         | 190/2000 [02:27<15:30,  1.95it/s, Loss=0.0963120, Gaussian number=182686, print grad=0.0037267059087753296, Depth Loss=0.0000000]
Training progress:  10%|█         | 200/2000 [02:27<14:23,  2.09it/s, Loss=0.0963120, Gaussian number=182686, print grad=0.0037267059087753296, Depth Loss=0.0000000]
Training progress:  10%|█         | 200/2000 [03:36<14:23,  2.09it/s, Loss=0.1071042, Gaussian number=182686, print grad=0.003944795578718185, Depth Loss=0.0000000] 
Training progress:  10%|█         | 210/2000 [03:36<1:12:04,  2.42s/it, Loss=0.1071042, Gaussian number=182686, print grad=0.003944795578718185, Depth Loss=0.0000000]
Training progress:  10%|█         | 210/2000 [03:40<1:12:04,  2.42s/it, Loss=0.0851208, Gaussian number=182686, print grad=0.0041525051929056644, Depth Loss=0.0000000]
Training progress:  11%|█         | 220/2000 [03:40<53:43,  1.81s/it, Loss=0.0851208, Gaussian number=182686, print grad=0.0041525051929056644, Depth Loss=0.0000000]  
Training progress:  11%|█         | 220/2000 [03:44<53:43,  1.81s/it, Loss=0.0976584, Gaussian number=182686, print grad=0.004371224902570248, Depth Loss=0.0000000] 
Training progress:  12%|█▏        | 230/2000 [03:44<40:55,  1.39s/it, Loss=0.0976584, Gaussian number=182686, print grad=0.004371224902570248, Depth Loss=0.0000000]
Training progress:  12%|█▏        | 230/2000 [03:48<40:55,  1.39s/it, Loss=0.1230983, Gaussian number=182686, print grad=0.004573080688714981, Depth Loss=0.0000000]
Training progress:  12%|█▏        | 240/2000 [03:48<31:59,  1.09s/it, Loss=0.1230983, Gaussian number=182686, print grad=0.004573080688714981, Depth Loss=0.0000000]
Training progress:  12%|█▏        | 240/2000 [03:52<31:59,  1.09s/it, Loss=0.0958763, Gaussian number=182686, print grad=0.004801816772669554, Depth Loss=0.0000000]
Training progress:  12%|█▎        | 250/2000 [03:52<25:44,  1.13it/s, Loss=0.0958763, Gaussian number=182686, print grad=0.004801816772669554, Depth Loss=0.0000000]
Training progress:  12%|█▎        | 250/2000 [03:56<25:44,  1.13it/s, Loss=0.1027782, Gaussian number=182686, print grad=0.005007681902498007, Depth Loss=0.0000000]
Training progress:  13%|█▎        | 260/2000 [03:56<21:22,  1.36it/s, Loss=0.1027782, Gaussian number=182686, print grad=0.005007681902498007, Depth Loss=0.0000000]
Training progress:  13%|█▎        | 260/2000 [04:00<21:22,  1.36it/s, Loss=0.0691872, Gaussian number=182686, print grad=0.005223667249083519, Depth Loss=0.0000000]
Training progress:  14%|█▎        | 270/2000 [04:00<18:19,  1.57it/s, Loss=0.0691872, Gaussian number=182686, print grad=0.005223667249083519, Depth Loss=0.0000000]
Training progress:  14%|█▎        | 270/2000 [04:04<18:19,  1.57it/s, Loss=0.0901836, Gaussian number=182686, print grad=0.005442172288894653, Depth Loss=0.0000000]
Training progress:  14%|█▍        | 280/2000 [04:04<16:10,  1.77it/s, Loss=0.0901836, Gaussian number=182686, print grad=0.005442172288894653, Depth Loss=0.0000000]
Training progress:  14%|█▍        | 280/2000 [04:08<16:10,  1.77it/s, Loss=0.0915400, Gaussian number=182686, print grad=0.0056730518117547035, Depth Loss=0.0000000]
Training progress:  14%|█▍        | 290/2000 [04:08<14:39,  1.94it/s, Loss=0.0915400, Gaussian number=182686, print grad=0.0056730518117547035, Depth Loss=0.0000000]
Training progress:  14%|█▍        | 290/2000 [04:12<14:39,  1.94it/s, Loss=0.0853056, Gaussian number=182686, print grad=0.005909043829888105, Depth Loss=0.0000000] 
Training progress:  15%|█▌        | 300/2000 [04:12<13:35,  2.08it/s, Loss=0.0853056, Gaussian number=182686, print grad=0.005909043829888105, Depth Loss=0.0000000]
Training progress:  15%|█▌        | 300/2000 [05:21<13:35,  2.08it/s, Loss=0.0715927, Gaussian number=182686, print grad=0.006135535426437855, Depth Loss=0.0000000]
Training progress:  16%|█▌        | 310/2000 [05:21<1:07:54,  2.41s/it, Loss=0.0715927, Gaussian number=182686, print grad=0.006135535426437855, Depth Loss=0.0000000]
Training progress:  16%|█▌        | 310/2000 [05:25<1:07:54,  2.41s/it, Loss=0.0727938, Gaussian number=182686, print grad=0.006323162466287613, Depth Loss=0.0000000]
Training progress:  16%|█▌        | 320/2000 [05:25<50:35,  1.81s/it, Loss=0.0727938, Gaussian number=182686, print grad=0.006323162466287613, Depth Loss=0.0000000]  
Training progress:  16%|█▌        | 320/2000 [05:29<50:35,  1.81s/it, Loss=0.0967620, Gaussian number=182686, print grad=0.006522668991237879, Depth Loss=0.0000000]
Training progress:  16%|█▋        | 330/2000 [05:29<38:31,  1.38s/it, Loss=0.0967620, Gaussian number=182686, print grad=0.006522668991237879, Depth Loss=0.0000000]
Training progress:  16%|█▋        | 330/2000 [05:33<38:31,  1.38s/it, Loss=0.0705503, Gaussian number=182686, print grad=0.006749903317540884, Depth Loss=0.0000000]
Training progress:  17%|█▋        | 340/2000 [05:33<30:05,  1.09s/it, Loss=0.0705503, Gaussian number=182686, print grad=0.006749903317540884, Depth Loss=0.0000000]
Training progress:  17%|█▋        | 340/2000 [05:37<30:05,  1.09s/it, Loss=0.0725094, Gaussian number=182686, print grad=0.006972542032599449, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 350/2000 [05:37<24:12,  1.14it/s, Loss=0.0725094, Gaussian number=182686, print grad=0.006972542032599449, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 350/2000 [05:41<24:12,  1.14it/s, Loss=0.0728885, Gaussian number=182686, print grad=0.0072096725925803185, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 360/2000 [05:41<20:05,  1.36it/s, Loss=0.0728885, Gaussian number=182686, print grad=0.0072096725925803185, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 360/2000 [05:45<20:05,  1.36it/s, Loss=0.0660064, Gaussian number=182686, print grad=0.0074202511459589005, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 370/2000 [05:45<17:12,  1.58it/s, Loss=0.0660064, Gaussian number=182686, print grad=0.0074202511459589005, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 370/2000 [05:49<17:12,  1.58it/s, Loss=0.0946372, Gaussian number=182686, print grad=0.007614280097186565, Depth Loss=0.0000000] 
Training progress:  19%|█▉        | 380/2000 [05:49<15:10,  1.78it/s, Loss=0.0946372, Gaussian number=182686, print grad=0.007614280097186565, Depth Loss=0.0000000]
Training progress:  19%|█▉        | 380/2000 [05:53<15:10,  1.78it/s, Loss=0.0791071, Gaussian number=182686, print grad=0.007840369828045368, Depth Loss=0.0000000]
Training progress:  20%|█▉        | 390/2000 [05:53<13:45,  1.95it/s, Loss=0.0791071, Gaussian number=182686, print grad=0.007840369828045368, Depth Loss=0.0000000]
Training progress:  20%|█▉        | 390/2000 [05:57<13:45,  1.95it/s, Loss=0.0981182, Gaussian number=182686, print grad=0.008060651831328869, Depth Loss=0.0000000]
Training progress:  20%|██        | 400/2000 [05:57<12:43,  2.09it/s, Loss=0.0981182, Gaussian number=182686, print grad=0.008060651831328869, Depth Loss=0.0000000]
Training progress:  20%|██        | 400/2000 [06:01<12:43,  2.09it/s, Loss=0.0816733, Gaussian number=182686, print grad=0.008315477520227432, Depth Loss=0.0000000]
Training progress:  20%|██        | 410/2000 [06:01<12:00,  2.21it/s, Loss=0.0816733, Gaussian number=182686, print grad=0.008315477520227432, Depth Loss=0.0000000]
Training progress:  20%|██        | 410/2000 [06:05<12:00,  2.21it/s, Loss=0.0718884, Gaussian number=182686, print grad=0.008565365336835384, Depth Loss=0.0000000]
Training progress:  21%|██        | 420/2000 [06:05<11:30,  2.29it/s, Loss=0.0718884, Gaussian number=182686, print grad=0.008565365336835384, Depth Loss=0.0000000]
Training progress:  21%|██        | 420/2000 [06:09<11:30,  2.29it/s, Loss=0.0903712, Gaussian number=182686, print grad=0.008812745101749897, Depth Loss=0.0000000]
Training progress:  22%|██▏       | 430/2000 [06:09<11:06,  2.35it/s, Loss=0.0903712, Gaussian number=182686, print grad=0.008812745101749897, Depth Loss=0.0000000]
Training progress:  22%|██▏       | 430/2000 [06:13<11:06,  2.35it/s, Loss=0.0709983, Gaussian number=182686, print grad=0.009036240167915821, Depth Loss=0.0000000]
Training progress:  22%|██▏       | 440/2000 [06:13<10:49,  2.40it/s, Loss=0.0709983, Gaussian number=182686, print grad=0.009036240167915821, Depth Loss=0.0000000]
Training progress:  22%|██▏       | 440/2000 [06:17<10:49,  2.40it/s, Loss=0.0845226, Gaussian number=182686, print grad=0.00926879607141018, Depth Loss=0.0000000] 
Training progress:  22%|██▎       | 450/2000 [06:17<10:35,  2.44it/s, Loss=0.0845226, Gaussian number=182686, print grad=0.00926879607141018, Depth Loss=0.0000000]
Training progress:  22%|██▎       | 450/2000 [06:21<10:35,  2.44it/s, Loss=0.0886344, Gaussian number=182686, print grad=0.00950098130851984, Depth Loss=0.0000000]
Training progress:  23%|██▎       | 460/2000 [06:21<10:25,  2.46it/s, Loss=0.0886344, Gaussian number=182686, print grad=0.00950098130851984, Depth Loss=0.0000000]
Training progress:  23%|██▎       | 460/2000 [06:25<10:25,  2.46it/s, Loss=0.1003325, Gaussian number=182686, print grad=0.009727764874696732, Depth Loss=0.0000000]
Training progress:  24%|██▎       | 470/2000 [06:25<10:16,  2.48it/s, Loss=0.1003325, Gaussian number=182686, print grad=0.009727764874696732, Depth Loss=0.0000000]
Training progress:  24%|██▎       | 470/2000 [06:29<10:16,  2.48it/s, Loss=0.0647366, Gaussian number=182686, print grad=0.009976292960345745, Depth Loss=0.0000000]
Training progress:  24%|██▍       | 480/2000 [06:29<10:09,  2.49it/s, Loss=0.0647366, Gaussian number=182686, print grad=0.009976292960345745, Depth Loss=0.0000000]
Training progress:  24%|██▍       | 480/2000 [06:33<10:09,  2.49it/s, Loss=0.0719372, Gaussian number=182686, print grad=0.010204698890447617, Depth Loss=0.0000000]
Training progress:  24%|██▍       | 490/2000 [06:33<10:03,  2.50it/s, Loss=0.0719372, Gaussian number=182686, print grad=0.010204698890447617, Depth Loss=0.0000000]
Training progress:  24%|██▍       | 490/2000 [06:37<10:03,  2.50it/s, Loss=0.0533408, Gaussian number=182686, print grad=0.010437876917421818, Depth Loss=0.0000000]
Training progress:  25%|██▌       | 500/2000 [06:37<09:57,  2.51it/s, Loss=0.0533408, Gaussian number=182686, print grad=0.010437876917421818, Depth Loss=0.0000000]
Training progress:  25%|██▌       | 500/2000 [07:46<09:57,  2.51it/s, Loss=0.0640562, Gaussian number=182686, print grad=0.010670850053429604, Depth Loss=0.0000000]
Training progress:  26%|██▌       | 510/2000 [07:46<58:29,  2.36s/it, Loss=0.0640562, Gaussian number=182686, print grad=0.010670850053429604, Depth Loss=0.0000000]
Training progress:  26%|██▌       | 510/2000 [07:50<58:29,  2.36s/it, Loss=0.0725105, Gaussian number=182686, print grad=0.01090572215616703, Depth Loss=0.0000000] 
Training progress:  26%|██▌       | 520/2000 [07:50<43:35,  1.77s/it, Loss=0.0725105, Gaussian number=182686, print grad=0.01090572215616703, Depth Loss=0.0000000]
Training progress:  26%|██▌       | 520/2000 [07:54<43:35,  1.77s/it, Loss=0.0496840, Gaussian number=182686, print grad=0.011107662692666054, Depth Loss=0.0000000]
Training progress:  26%|██▋       | 530/2000 [07:54<33:11,  1.35s/it, Loss=0.0496840, Gaussian number=182686, print grad=0.011107662692666054, Depth Loss=0.0000000]
Training progress:  26%|██▋       | 530/2000 [07:58<33:11,  1.35s/it, Loss=0.0687956, Gaussian number=182686, print grad=0.011332214809954166, Depth Loss=0.0000000]
Training progress:  27%|██▋       | 540/2000 [07:58<25:58,  1.07s/it, Loss=0.0687956, Gaussian number=182686, print grad=0.011332214809954166, Depth Loss=0.0000000]
Training progress:  27%|██▋       | 540/2000 [08:02<25:58,  1.07s/it, Loss=0.0635659, Gaussian number=182686, print grad=0.011576404795050621, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 550/2000 [08:02<20:54,  1.16it/s, Loss=0.0635659, Gaussian number=182686, print grad=0.011576404795050621, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 550/2000 [08:05<20:54,  1.16it/s, Loss=0.0509485, Gaussian number=182686, print grad=0.011797715909779072, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 560/2000 [08:05<17:22,  1.38it/s, Loss=0.0509485, Gaussian number=182686, print grad=0.011797715909779072, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 560/2000 [08:09<17:22,  1.38it/s, Loss=0.0688285, Gaussian number=182686, print grad=0.012033109553158283, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 570/2000 [08:09<14:53,  1.60it/s, Loss=0.0688285, Gaussian number=182686, print grad=0.012033109553158283, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 570/2000 [08:13<14:53,  1.60it/s, Loss=0.0612660, Gaussian number=182686, print grad=0.012274988926947117, Depth Loss=0.0000000]
Training progress:  29%|██▉       | 580/2000 [08:13<13:08,  1.80it/s, Loss=0.0612660, Gaussian number=182686, print grad=0.012274988926947117, Depth Loss=0.0000000]
Training progress:  29%|██▉       | 580/2000 [08:17<13:08,  1.80it/s, Loss=0.0677573, Gaussian number=182686, print grad=0.012511225417256355, Depth Loss=0.0000000]
Training progress:  30%|██▉       | 590/2000 [08:17<11:55,  1.97it/s, Loss=0.0677573, Gaussian number=182686, print grad=0.012511225417256355, Depth Loss=0.0000000]
Training progress:  30%|██▉       | 590/2000 [08:21<11:55,  1.97it/s, Loss=0.0760304, Gaussian number=182686, print grad=0.012736906297504902, Depth Loss=0.0000000]
Training progress:  30%|███       | 600/2000 [08:21<11:02,  2.11it/s, Loss=0.0760304, Gaussian number=182686, print grad=0.012736906297504902, Depth Loss=0.0000000]
Training progress:  30%|███       | 600/2000 [08:25<11:02,  2.11it/s, Loss=0.0620872, Gaussian number=184044, print grad=0.00021370525064412504, Depth Loss=0.0000000]
Training progress:  30%|███       | 610/2000 [08:25<10:25,  2.22it/s, Loss=0.0620872, Gaussian number=184044, print grad=0.00021370525064412504, Depth Loss=0.0000000]
Training progress:  30%|███       | 610/2000 [08:29<10:25,  2.22it/s, Loss=0.0776740, Gaussian number=184044, print grad=0.0004591421748045832, Depth Loss=0.0000000] 
Training progress:  31%|███       | 620/2000 [08:29<09:58,  2.31it/s, Loss=0.0776740, Gaussian number=184044, print grad=0.0004591421748045832, Depth Loss=0.0000000]
Training progress:  31%|███       | 620/2000 [08:33<09:58,  2.31it/s, Loss=0.0550480, Gaussian number=184044, print grad=0.000696880801115185, Depth Loss=0.0000000] 
Training progress:  32%|███▏      | 630/2000 [08:33<09:38,  2.37it/s, Loss=0.0550480, Gaussian number=184044, print grad=0.000696880801115185, Depth Loss=0.0000000]
Training progress:  32%|███▏      | 630/2000 [08:37<09:38,  2.37it/s, Loss=0.0604094, Gaussian number=184044, print grad=0.0009501852910034359, Depth Loss=0.0000000]
Training progress:  32%|███▏      | 640/2000 [08:37<09:22,  2.42it/s, Loss=0.0604094, Gaussian number=184044, print grad=0.0009501852910034359, Depth Loss=0.0000000]
Training progress:  32%|███▏      | 640/2000 [08:41<09:22,  2.42it/s, Loss=0.0684564, Gaussian number=184044, print grad=0.0011753625003620982, Depth Loss=0.0000000]
Training progress:  32%|███▎      | 650/2000 [08:41<09:11,  2.45it/s, Loss=0.0684564, Gaussian number=184044, print grad=0.0011753625003620982, Depth Loss=0.0000000]
Training progress:  32%|███▎      | 650/2000 [08:45<09:11,  2.45it/s, Loss=0.0650495, Gaussian number=184044, print grad=0.0014222848694771528, Depth Loss=0.0000000]
Training progress:  33%|███▎      | 660/2000 [08:45<09:02,  2.47it/s, Loss=0.0650495, Gaussian number=184044, print grad=0.0014222848694771528, Depth Loss=0.0000000]
Training progress:  33%|███▎      | 660/2000 [08:49<09:02,  2.47it/s, Loss=0.0650731, Gaussian number=184044, print grad=0.0016439351020380855, Depth Loss=0.0000000]
Training progress:  34%|███▎      | 670/2000 [08:49<08:54,  2.49it/s, Loss=0.0650731, Gaussian number=184044, print grad=0.0016439351020380855, Depth Loss=0.0000000]
Training progress:  34%|███▎      | 670/2000 [08:53<08:54,  2.49it/s, Loss=0.0538662, Gaussian number=184044, print grad=0.001887583639472723, Depth Loss=0.0000000] 
Training progress:  34%|███▍      | 680/2000 [08:53<08:48,  2.50it/s, Loss=0.0538662, Gaussian number=184044, print grad=0.001887583639472723, Depth Loss=0.0000000]
Training progress:  34%|███▍      | 680/2000 [08:57<08:48,  2.50it/s, Loss=0.0707131, Gaussian number=184044, print grad=0.0021240864880383015, Depth Loss=0.0000000]
Training progress:  34%|███▍      | 690/2000 [08:57<08:42,  2.51it/s, Loss=0.0707131, Gaussian number=184044, print grad=0.0021240864880383015, Depth Loss=0.0000000]
Training progress:  34%|███▍      | 690/2000 [09:01<08:42,  2.51it/s, Loss=0.0695016, Gaussian number=184044, print grad=0.002357285004109144, Depth Loss=0.0000000] 
Training progress:  35%|███▌      | 700/2000 [09:01<08:36,  2.52it/s, Loss=0.0695016, Gaussian number=184044, print grad=0.002357285004109144, Depth Loss=0.0000000]
Training progress:  35%|███▌      | 700/2000 [09:05<08:36,  2.52it/s, Loss=0.0625644, Gaussian number=188378, print grad=0.0002185390767408535, Depth Loss=0.0000000]
Training progress:  36%|███▌      | 710/2000 [09:05<08:32,  2.52it/s, Loss=0.0625644, Gaussian number=188378, print grad=0.0002185390767408535, Depth Loss=0.0000000]
Training progress:  36%|███▌      | 710/2000 [09:09<08:32,  2.52it/s, Loss=0.0566177, Gaussian number=188378, print grad=0.000477336609037593, Depth Loss=0.0000000] 
Training progress:  36%|███▌      | 720/2000 [09:09<08:27,  2.52it/s, Loss=0.0566177, Gaussian number=188378, print grad=0.000477336609037593, Depth Loss=0.0000000]
Training progress:  36%|███▌      | 720/2000 [09:13<08:27,  2.52it/s, Loss=0.0767903, Gaussian number=188378, print grad=0.0007163997506722808, Depth Loss=0.0000000]
Training progress:  36%|███▋      | 730/2000 [09:13<08:23,  2.52it/s, Loss=0.0767903, Gaussian number=188378, print grad=0.0007163997506722808, Depth Loss=0.0000000]
Training progress:  36%|███▋      | 730/2000 [09:17<08:23,  2.52it/s, Loss=0.0816482, Gaussian number=188378, print grad=0.000984942656941712, Depth Loss=0.0000000] 
Training progress:  37%|███▋      | 740/2000 [09:17<08:19,  2.52it/s, Loss=0.0816482, Gaussian number=188378, print grad=0.000984942656941712, Depth Loss=0.0000000]
Training progress:  37%|███▋      | 740/2000 [09:21<08:19,  2.52it/s, Loss=0.0563335, Gaussian number=188378, print grad=0.0012318389490246773, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 750/2000 [09:21<08:15,  2.53it/s, Loss=0.0563335, Gaussian number=188378, print grad=0.0012318389490246773, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 750/2000 [09:25<08:15,  2.53it/s, Loss=0.0589068, Gaussian number=188378, print grad=0.0014730555703863502, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 760/2000 [09:25<08:11,  2.52it/s, Loss=0.0589068, Gaussian number=188378, print grad=0.0014730555703863502, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 760/2000 [09:28<08:11,  2.52it/s, Loss=0.0481269, Gaussian number=188378, print grad=0.001726816757582128, Depth Loss=0.0000000] 
Training progress:  38%|███▊      | 770/2000 [09:28<08:07,  2.52it/s, Loss=0.0481269, Gaussian number=188378, print grad=0.001726816757582128, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 770/2000 [09:32<08:07,  2.52it/s, Loss=0.0686957, Gaussian number=188378, print grad=0.0019621809478849173, Depth Loss=0.0000000]
Training progress:  39%|███▉      | 780/2000 [09:32<08:02,  2.53it/s, Loss=0.0686957, Gaussian number=188378, print grad=0.0019621809478849173, Depth Loss=0.0000000]
Training progress:  39%|███▉      | 780/2000 [09:36<08:02,  2.53it/s, Loss=0.0835127, Gaussian number=188378, print grad=0.002209983766078949, Depth Loss=0.0000000] 
Training progress:  40%|███▉      | 790/2000 [09:36<07:59,  2.52it/s, Loss=0.0835127, Gaussian number=188378, print grad=0.002209983766078949, Depth Loss=0.0000000]
Training progress:  40%|███▉      | 790/2000 [09:40<07:59,  2.52it/s, Loss=0.0633027, Gaussian number=188378, print grad=0.0024612685665488243, Depth Loss=0.0000000]
Training progress:  40%|████      | 800/2000 [09:40<07:55,  2.53it/s, Loss=0.0633027, Gaussian number=188378, print grad=0.0024612685665488243, Depth Loss=0.0000000]
Training progress:  40%|████      | 800/2000 [09:44<07:55,  2.53it/s, Loss=0.0610273, Gaussian number=193666, print grad=0.00022667979646939784, Depth Loss=0.0000000]
Training progress:  40%|████      | 810/2000 [09:44<07:51,  2.52it/s, Loss=0.0610273, Gaussian number=193666, print grad=0.00022667979646939784, Depth Loss=0.0000000]
Training progress:  40%|████      | 810/2000 [09:48<07:51,  2.52it/s, Loss=0.0618463, Gaussian number=193666, print grad=0.0004822623741347343, Depth Loss=0.0000000] 
Training progress:  41%|████      | 820/2000 [09:48<07:47,  2.52it/s, Loss=0.0618463, Gaussian number=193666, print grad=0.0004822623741347343, Depth Loss=0.0000000]
Training progress:  41%|████      | 820/2000 [09:52<07:47,  2.52it/s, Loss=0.0473182, Gaussian number=193666, print grad=0.0007531070150434971, Depth Loss=0.0000000]
Training progress:  42%|████▏     | 830/2000 [09:52<07:46,  2.51it/s, Loss=0.0473182, Gaussian number=193666, print grad=0.0007531070150434971, Depth Loss=0.0000000]
Training progress:  42%|████▏     | 830/2000 [09:56<07:46,  2.51it/s, Loss=0.0573823, Gaussian number=193666, print grad=0.0010078230407088995, Depth Loss=0.0000000]
Training progress:  42%|████▏     | 840/2000 [09:56<07:41,  2.52it/s, Loss=0.0573823, Gaussian number=193666, print grad=0.0010078230407088995, Depth Loss=0.0000000]
Training progress:  42%|████▏     | 840/2000 [10:00<07:41,  2.52it/s, Loss=0.0546070, Gaussian number=193666, print grad=0.0012534632114693522, Depth Loss=0.0000000]
Training progress:  42%|████▎     | 850/2000 [10:00<07:36,  2.52it/s, Loss=0.0546070, Gaussian number=193666, print grad=0.0012534632114693522, Depth Loss=0.0000000]
Training progress:  42%|████▎     | 850/2000 [10:04<07:36,  2.52it/s, Loss=0.0540843, Gaussian number=193666, print grad=0.0014898161171004176, Depth Loss=0.0000000]
Training progress:  43%|████▎     | 860/2000 [10:04<07:32,  2.52it/s, Loss=0.0540843, Gaussian number=193666, print grad=0.0014898161171004176, Depth Loss=0.0000000]
Training progress:  43%|████▎     | 860/2000 [10:08<07:32,  2.52it/s, Loss=0.0635740, Gaussian number=193666, print grad=0.0017248626099899411, Depth Loss=0.0000000]
Training progress:  44%|████▎     | 870/2000 [10:08<07:28,  2.52it/s, Loss=0.0635740, Gaussian number=193666, print grad=0.0017248626099899411, Depth Loss=0.0000000]
Training progress:  44%|████▎     | 870/2000 [10:12<07:28,  2.52it/s, Loss=0.0602854, Gaussian number=193666, print grad=0.001978346612304449, Depth Loss=0.0000000] 
Training progress:  44%|████▍     | 880/2000 [10:12<07:24,  2.52it/s, Loss=0.0602854, Gaussian number=193666, print grad=0.001978346612304449, Depth Loss=0.0000000]
Training progress:  44%|████▍     | 880/2000 [10:16<07:24,  2.52it/s, Loss=0.0476486, Gaussian number=193666, print grad=0.0022241617552936077, Depth Loss=0.0000000]
Training progress:  44%|████▍     | 890/2000 [10:16<07:19,  2.52it/s, Loss=0.0476486, Gaussian number=193666, print grad=0.0022241617552936077, Depth Loss=0.0000000]
Training progress:  44%|████▍     | 890/2000 [10:20<07:19,  2.52it/s, Loss=0.0629280, Gaussian number=193666, print grad=0.0024798621889203787, Depth Loss=0.0000000]
Training progress:  45%|████▌     | 900/2000 [10:20<07:15,  2.53it/s, Loss=0.0629280, Gaussian number=193666, print grad=0.0024798621889203787, Depth Loss=0.0000000]
Training progress:  45%|████▌     | 900/2000 [10:24<07:15,  2.53it/s, Loss=0.0534783, Gaussian number=199368, print grad=0.00022381629969459027, Depth Loss=0.0000000]
Training progress:  46%|████▌     | 910/2000 [10:24<07:10,  2.53it/s, Loss=0.0534783, Gaussian number=199368, print grad=0.00022381629969459027, Depth Loss=0.0000000]
Training progress:  46%|████▌     | 910/2000 [10:28<07:10,  2.53it/s, Loss=0.0603485, Gaussian number=199368, print grad=0.00046657718485221267, Depth Loss=0.0000000]
Training progress:  46%|████▌     | 920/2000 [10:28<07:05,  2.54it/s, Loss=0.0603485, Gaussian number=199368, print grad=0.00046657718485221267, Depth Loss=0.0000000]
Training progress:  46%|████▌     | 920/2000 [10:32<07:05,  2.54it/s, Loss=0.0602625, Gaussian number=199368, print grad=0.0007448592223227024, Depth Loss=0.0000000] 
Training progress:  46%|████▋     | 930/2000 [10:32<07:01,  2.54it/s, Loss=0.0602625, Gaussian number=199368, print grad=0.0007448592223227024, Depth Loss=0.0000000]
Training progress:  46%|████▋     | 930/2000 [10:36<07:01,  2.54it/s, Loss=0.0544459, Gaussian number=199368, print grad=0.0010032238205894828, Depth Loss=0.0000000]
Training progress:  47%|████▋     | 940/2000 [10:36<06:57,  2.54it/s, Loss=0.0544459, Gaussian number=199368, print grad=0.0010032238205894828, Depth Loss=0.0000000]
Training progress:  47%|████▋     | 940/2000 [10:40<06:57,  2.54it/s, Loss=0.0553090, Gaussian number=199368, print grad=0.001240706886164844, Depth Loss=0.0000000] 
Training progress:  48%|████▊     | 950/2000 [10:40<06:52,  2.54it/s, Loss=0.0553090, Gaussian number=199368, print grad=0.001240706886164844, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 950/2000 [10:44<06:52,  2.54it/s, Loss=0.0548629, Gaussian number=199368, print grad=0.001475829747505486, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 960/2000 [10:44<06:48,  2.54it/s, Loss=0.0548629, Gaussian number=199368, print grad=0.001475829747505486, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 960/2000 [10:48<06:48,  2.54it/s, Loss=0.0750210, Gaussian number=199368, print grad=0.001749345799908042, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 970/2000 [10:48<06:45,  2.54it/s, Loss=0.0750210, Gaussian number=199368, print grad=0.001749345799908042, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 970/2000 [10:51<06:45,  2.54it/s, Loss=0.0420992, Gaussian number=199368, print grad=0.0019882332999259233, Depth Loss=0.0000000]
Training progress:  49%|████▉     | 980/2000 [10:51<06:40,  2.54it/s, Loss=0.0420992, Gaussian number=199368, print grad=0.0019882332999259233, Depth Loss=0.0000000]
Training progress:  49%|████▉     | 980/2000 [10:55<06:40,  2.54it/s, Loss=0.0468197, Gaussian number=199368, print grad=0.002197292633354664, Depth Loss=0.0000000] 
Training progress:  50%|████▉     | 990/2000 [10:55<06:37,  2.54it/s, Loss=0.0468197, Gaussian number=199368, print grad=0.002197292633354664, Depth Loss=0.0000000]
Training progress:  50%|████▉     | 990/2000 [10:59<06:37,  2.54it/s, Loss=0.0576404, Gaussian number=199368, print grad=0.002397049916908145, Depth Loss=0.0000000]
Training progress:  50%|█████     | 1000/2000 [10:59<06:32,  2.54it/s, Loss=0.0576404, Gaussian number=199368, print grad=0.002397049916908145, Depth Loss=0.0000000]
Training progress:  50%|█████     | 1000/2000 [12:08<06:32,  2.54it/s, Loss=0.0593561, Gaussian number=205419, print grad=0.00023001596855465323, Depth Loss=0.0000000]
Training progress:  50%|█████     | 1010/2000 [12:08<38:45,  2.35s/it, Loss=0.0593561, Gaussian number=205419, print grad=0.00023001596855465323, Depth Loss=0.0000000]
Training progress:  50%|█████     | 1010/2000 [12:12<38:45,  2.35s/it, Loss=0.0744480, Gaussian number=205419, print grad=0.0005188415525481105, Depth Loss=0.0000000] 
Training progress:  51%|█████     | 1020/2000 [12:12<28:47,  1.76s/it, Loss=0.0744480, Gaussian number=205419, print grad=0.0005188415525481105, Depth Loss=0.0000000]
Training progress:  51%|█████     | 1020/2000 [12:16<28:47,  1.76s/it, Loss=0.0538689, Gaussian number=205419, print grad=0.0007969258585944772, Depth Loss=0.0000000]
Training progress:  52%|█████▏    | 1030/2000 [12:16<21:50,  1.35s/it, Loss=0.0538689, Gaussian number=205419, print grad=0.0007969258585944772, Depth Loss=0.0000000]
Training progress:  52%|█████▏    | 1030/2000 [12:20<21:50,  1.35s/it, Loss=0.0600888, Gaussian number=205419, print grad=0.0010815116111189127, Depth Loss=0.0000000]
Training progress:  52%|█████▏    | 1040/2000 [12:20<17:01,  1.06s/it, Loss=0.0600888, Gaussian number=205419, print grad=0.0010815116111189127, Depth Loss=0.0000000]
Training progress:  52%|█████▏    | 1040/2000 [12:24<17:01,  1.06s/it, Loss=0.0544969, Gaussian number=205419, print grad=0.0012971608666703105, Depth Loss=0.0000000]
Training progress:  52%|█████▎    | 1050/2000 [12:24<13:39,  1.16it/s, Loss=0.0544969, Gaussian number=205419, print grad=0.0012971608666703105, Depth Loss=0.0000000]
Training progress:  52%|█████▎    | 1050/2000 [12:28<13:39,  1.16it/s, Loss=0.0465698, Gaussian number=205419, print grad=0.0015363974962383509, Depth Loss=0.0000000]
Training progress:  53%|█████▎    | 1060/2000 [12:28<11:17,  1.39it/s, Loss=0.0465698, Gaussian number=205419, print grad=0.0015363974962383509, Depth Loss=0.0000000]
Training progress:  53%|█████▎    | 1060/2000 [12:32<11:17,  1.39it/s, Loss=0.0418219, Gaussian number=205419, print grad=0.0017830076394602656, Depth Loss=0.0000000]
Training progress:  54%|█████▎    | 1070/2000 [12:32<09:38,  1.61it/s, Loss=0.0418219, Gaussian number=205419, print grad=0.0017830076394602656, Depth Loss=0.0000000]
Training progress:  54%|█████▎    | 1070/2000 [12:36<09:38,  1.61it/s, Loss=0.0422503, Gaussian number=205419, print grad=0.0020191376097500324, Depth Loss=0.0000000]
Training progress:  54%|█████▍    | 1080/2000 [12:36<08:29,  1.81it/s, Loss=0.0422503, Gaussian number=205419, print grad=0.0020191376097500324, Depth Loss=0.0000000]
Training progress:  54%|█████▍    | 1080/2000 [12:40<08:29,  1.81it/s, Loss=0.0491394, Gaussian number=205419, print grad=0.002246708143502474, Depth Loss=0.0000000] 
Training progress:  55%|█████▍    | 1090/2000 [12:40<07:40,  1.98it/s, Loss=0.0491394, Gaussian number=205419, print grad=0.002246708143502474, Depth Loss=0.0000000]
Training progress:  55%|█████▍    | 1090/2000 [12:44<07:40,  1.98it/s, Loss=0.0579313, Gaussian number=205419, print grad=0.0024780870880931616, Depth Loss=0.0000000]
Training progress:  55%|█████▌    | 1100/2000 [12:44<07:04,  2.12it/s, Loss=0.0579313, Gaussian number=205419, print grad=0.0024780870880931616, Depth Loss=0.0000000]
Training progress:  55%|█████▌    | 1100/2000 [12:48<07:04,  2.12it/s, Loss=0.0581046, Gaussian number=211854, print grad=0.0002325537207070738, Depth Loss=0.0000000]
Training progress:  56%|█████▌    | 1110/2000 [12:48<06:39,  2.23it/s, Loss=0.0581046, Gaussian number=211854, print grad=0.0002325537207070738, Depth Loss=0.0000000]
Training progress:  56%|█████▌    | 1110/2000 [12:52<06:39,  2.23it/s, Loss=0.0534675, Gaussian number=211854, print grad=0.0005118527915328741, Depth Loss=0.0000000]
Training progress:  56%|█████▌    | 1120/2000 [12:52<06:20,  2.31it/s, Loss=0.0534675, Gaussian number=211854, print grad=0.0005118527915328741, Depth Loss=0.0000000]
Training progress:  56%|█████▌    | 1120/2000 [12:56<06:20,  2.31it/s, Loss=0.0424808, Gaussian number=211854, print grad=0.0007854177965782583, Depth Loss=0.0000000]
Training progress:  56%|█████▋    | 1130/2000 [12:56<06:06,  2.38it/s, Loss=0.0424808, Gaussian number=211854, print grad=0.0007854177965782583, Depth Loss=0.0000000]
Training progress:  56%|█████▋    | 1130/2000 [13:00<06:06,  2.38it/s, Loss=0.0551348, Gaussian number=211854, print grad=0.001052548410370946, Depth Loss=0.0000000] 
Training progress:  57%|█████▋    | 1140/2000 [13:00<05:54,  2.42it/s, Loss=0.0551348, Gaussian number=211854, print grad=0.001052548410370946, Depth Loss=0.0000000]
Training progress:  57%|█████▋    | 1140/2000 [13:04<05:54,  2.42it/s, Loss=0.0362748, Gaussian number=211854, print grad=0.00130165321752429, Depth Loss=0.0000000] 
Training progress:  57%|█████▊    | 1150/2000 [13:04<05:45,  2.46it/s, Loss=0.0362748, Gaussian number=211854, print grad=0.00130165321752429, Depth Loss=0.0000000]
Training progress:  57%|█████▊    | 1150/2000 [13:07<05:45,  2.46it/s, Loss=0.0416928, Gaussian number=211854, print grad=0.0015442243311554193, Depth Loss=0.0000000]
Training progress:  58%|█████▊    | 1160/2000 [13:07<05:38,  2.48it/s, Loss=0.0416928, Gaussian number=211854, print grad=0.0015442243311554193, Depth Loss=0.0000000]
Training progress:  58%|█████▊    | 1160/2000 [13:11<05:38,  2.48it/s, Loss=0.0541220, Gaussian number=211854, print grad=0.001794253010302782, Depth Loss=0.0000000] 
Training progress:  58%|█████▊    | 1170/2000 [13:11<05:32,  2.50it/s, Loss=0.0541220, Gaussian number=211854, print grad=0.001794253010302782, Depth Loss=0.0000000]
Training progress:  58%|█████▊    | 1170/2000 [13:15<05:32,  2.50it/s, Loss=0.0543740, Gaussian number=211854, print grad=0.002021856140345335, Depth Loss=0.0000000]
Training progress:  59%|█████▉    | 1180/2000 [13:15<05:26,  2.51it/s, Loss=0.0543740, Gaussian number=211854, print grad=0.002021856140345335, Depth Loss=0.0000000]
Training progress:  59%|█████▉    | 1180/2000 [13:19<05:26,  2.51it/s, Loss=0.0451235, Gaussian number=211854, print grad=0.002280416199937463, Depth Loss=0.0000000]
Training progress:  60%|█████▉    | 1190/2000 [13:19<05:21,  2.52it/s, Loss=0.0451235, Gaussian number=211854, print grad=0.002280416199937463, Depth Loss=0.0000000]
Training progress:  60%|█████▉    | 1190/2000 [13:23<05:21,  2.52it/s, Loss=0.0550643, Gaussian number=211854, print grad=0.0024880829732865095, Depth Loss=0.0000000]
Training progress:  60%|██████    | 1200/2000 [13:23<05:16,  2.52it/s, Loss=0.0550643, Gaussian number=211854, print grad=0.0024880829732865095, Depth Loss=0.0000000]
Training progress:  60%|██████    | 1200/2000 [13:27<05:16,  2.52it/s, Loss=0.0419042, Gaussian number=218894, print grad=0.0002313837903784588, Depth Loss=0.0000000]
Training progress:  60%|██████    | 1210/2000 [13:27<05:12,  2.53it/s, Loss=0.0419042, Gaussian number=218894, print grad=0.0002313837903784588, Depth Loss=0.0000000]
Training progress:  60%|██████    | 1210/2000 [13:31<05:12,  2.53it/s, Loss=0.0348231, Gaussian number=218894, print grad=0.0004997150972485542, Depth Loss=0.0000000]
Training progress:  61%|██████    | 1220/2000 [13:31<05:07,  2.53it/s, Loss=0.0348231, Gaussian number=218894, print grad=0.0004997150972485542, Depth Loss=0.0000000]
Training progress:  61%|██████    | 1220/2000 [13:35<05:07,  2.53it/s, Loss=0.0384064, Gaussian number=218894, print grad=0.0007218475802801549, Depth Loss=0.0000000]
Training progress:  62%|██████▏   | 1230/2000 [13:35<05:03,  2.54it/s, Loss=0.0384064, Gaussian number=218894, print grad=0.0007218475802801549, Depth Loss=0.0000000]
Training progress:  62%|██████▏   | 1230/2000 [13:39<05:03,  2.54it/s, Loss=0.0382542, Gaussian number=218894, print grad=0.0009668837883509696, Depth Loss=0.0000000]
Training progress:  62%|██████▏   | 1240/2000 [13:39<04:59,  2.54it/s, Loss=0.0382542, Gaussian number=218894, print grad=0.0009668837883509696, Depth Loss=0.0000000]
Training progress:  62%|██████▏   | 1240/2000 [13:43<04:59,  2.54it/s, Loss=0.0370930, Gaussian number=218894, print grad=0.001197255216538906, Depth Loss=0.0000000] 
Training progress:  62%|██████▎   | 1250/2000 [13:43<04:54,  2.54it/s, Loss=0.0370930, Gaussian number=218894, print grad=0.001197255216538906, Depth Loss=0.0000000]
Training progress:  62%|██████▎   | 1250/2000 [13:47<04:54,  2.54it/s, Loss=0.0391924, Gaussian number=218894, print grad=0.0014162056613713503, Depth Loss=0.0000000]
Training progress:  63%|██████▎   | 1260/2000 [13:47<04:51,  2.54it/s, Loss=0.0391924, Gaussian number=218894, print grad=0.0014162056613713503, Depth Loss=0.0000000]
Training progress:  63%|██████▎   | 1260/2000 [13:51<04:51,  2.54it/s, Loss=0.0537187, Gaussian number=218894, print grad=0.0016546053811907768, Depth Loss=0.0000000]
Training progress:  64%|██████▎   | 1270/2000 [13:51<04:48,  2.53it/s, Loss=0.0537187, Gaussian number=218894, print grad=0.0016546053811907768, Depth Loss=0.0000000]
Training progress:  64%|██████▎   | 1270/2000 [13:55<04:48,  2.53it/s, Loss=0.0492009, Gaussian number=218894, print grad=0.0018885262543335557, Depth Loss=0.0000000]
Training progress:  64%|██████▍   | 1280/2000 [13:55<04:43,  2.54it/s, Loss=0.0492009, Gaussian number=218894, print grad=0.0018885262543335557, Depth Loss=0.0000000]
Training progress:  64%|██████▍   | 1280/2000 [13:59<04:43,  2.54it/s, Loss=0.0374843, Gaussian number=218894, print grad=0.00213613361120224, Depth Loss=0.0000000]  
Training progress:  64%|██████▍   | 1290/2000 [13:59<04:39,  2.54it/s, Loss=0.0374843, Gaussian number=218894, print grad=0.00213613361120224, Depth Loss=0.0000000]
Training progress:  64%|██████▍   | 1290/2000 [14:03<04:39,  2.54it/s, Loss=0.0566945, Gaussian number=218894, print grad=0.0023582905996590853, Depth Loss=0.0000000]
Training progress:  65%|██████▌   | 1300/2000 [14:03<04:35,  2.54it/s, Loss=0.0566945, Gaussian number=218894, print grad=0.0023582905996590853, Depth Loss=0.0000000]
Training progress:  65%|██████▌   | 1300/2000 [14:06<04:35,  2.54it/s, Loss=0.0583718, Gaussian number=225244, print grad=0.0002459704992361367, Depth Loss=0.0000000]
Training progress:  66%|██████▌   | 1310/2000 [14:06<04:31,  2.54it/s, Loss=0.0583718, Gaussian number=225244, print grad=0.0002459704992361367, Depth Loss=0.0000000]
Training progress:  66%|██████▌   | 1310/2000 [14:10<04:31,  2.54it/s, Loss=0.0567272, Gaussian number=225244, print grad=0.0004901063512079418, Depth Loss=0.0000000]
Training progress:  66%|██████▌   | 1320/2000 [14:10<04:28,  2.54it/s, Loss=0.0567272, Gaussian number=225244, print grad=0.0004901063512079418, Depth Loss=0.0000000]
Training progress:  66%|██████▌   | 1320/2000 [14:14<04:28,  2.54it/s, Loss=0.0428281, Gaussian number=225244, print grad=0.0007396459695883095, Depth Loss=0.0000000]
Training progress:  66%|██████▋   | 1330/2000 [14:14<04:24,  2.54it/s, Loss=0.0428281, Gaussian number=225244, print grad=0.0007396459695883095, Depth Loss=0.0000000]
Training progress:  66%|██████▋   | 1330/2000 [14:18<04:24,  2.54it/s, Loss=0.0446364, Gaussian number=225244, print grad=0.0009931334061548114, Depth Loss=0.0000000]
Training progress:  67%|██████▋   | 1340/2000 [14:18<04:20,  2.54it/s, Loss=0.0446364, Gaussian number=225244, print grad=0.0009931334061548114, Depth Loss=0.0000000]
Training progress:  67%|██████▋   | 1340/2000 [14:22<04:20,  2.54it/s, Loss=0.0651188, Gaussian number=225244, print grad=0.00122322968672961, Depth Loss=0.0000000]  
Training progress:  68%|██████▊   | 1350/2000 [14:22<04:15,  2.54it/s, Loss=0.0651188, Gaussian number=225244, print grad=0.00122322968672961, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1350/2000 [14:26<04:15,  2.54it/s, Loss=0.0383674, Gaussian number=225244, print grad=0.001448223483748734, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1360/2000 [14:26<04:12,  2.54it/s, Loss=0.0383674, Gaussian number=225244, print grad=0.001448223483748734, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1360/2000 [14:30<04:12,  2.54it/s, Loss=0.0719881, Gaussian number=225244, print grad=0.0016825484344735742, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1370/2000 [14:30<04:08,  2.54it/s, Loss=0.0719881, Gaussian number=225244, print grad=0.0016825484344735742, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1370/2000 [14:34<04:08,  2.54it/s, Loss=0.0422101, Gaussian number=225244, print grad=0.0019012342672795057, Depth Loss=0.0000000]
Training progress:  69%|██████▉   | 1380/2000 [14:34<04:04,  2.54it/s, Loss=0.0422101, Gaussian number=225244, print grad=0.0019012342672795057, Depth Loss=0.0000000]
Training progress:  69%|██████▉   | 1380/2000 [14:38<04:04,  2.54it/s, Loss=0.0380703, Gaussian number=225244, print grad=0.0021075422409921885, Depth Loss=0.0000000]
Training progress:  70%|██████▉   | 1390/2000 [14:38<04:00,  2.54it/s, Loss=0.0380703, Gaussian number=225244, print grad=0.0021075422409921885, Depth Loss=0.0000000]
Training progress:  70%|██████▉   | 1390/2000 [14:42<04:00,  2.54it/s, Loss=0.0436283, Gaussian number=225244, print grad=0.0023349912371486425, Depth Loss=0.0000000]
Training progress:  70%|███████   | 1400/2000 [14:42<03:56,  2.53it/s, Loss=0.0436283, Gaussian number=225244, print grad=0.0023349912371486425, Depth Loss=0.0000000]
Training progress:  70%|███████   | 1400/2000 [14:46<03:56,  2.53it/s, Loss=0.0550613, Gaussian number=231923, print grad=0.00023071598843671381, Depth Loss=0.0000000]
Training progress:  70%|███████   | 1410/2000 [14:46<03:53,  2.53it/s, Loss=0.0550613, Gaussian number=231923, print grad=0.00023071598843671381, Depth Loss=0.0000000]
Training progress:  70%|███████   | 1410/2000 [14:50<03:53,  2.53it/s, Loss=0.0429417, Gaussian number=231923, print grad=0.0005032045301049948, Depth Loss=0.0000000] 
Training progress:  71%|███████   | 1420/2000 [14:50<03:48,  2.53it/s, Loss=0.0429417, Gaussian number=231923, print grad=0.0005032045301049948, Depth Loss=0.0000000]
Training progress:  71%|███████   | 1420/2000 [14:54<03:48,  2.53it/s, Loss=0.0475860, Gaussian number=231923, print grad=0.0007569840527139604, Depth Loss=0.0000000]
Training progress:  72%|███████▏  | 1430/2000 [14:54<03:44,  2.53it/s, Loss=0.0475860, Gaussian number=231923, print grad=0.0007569840527139604, Depth Loss=0.0000000]
Training progress:  72%|███████▏  | 1430/2000 [14:58<03:44,  2.53it/s, Loss=0.0408054, Gaussian number=231923, print grad=0.0009945007041096687, Depth Loss=0.0000000]
Training progress:  72%|███████▏  | 1440/2000 [14:58<03:40,  2.54it/s, Loss=0.0408054, Gaussian number=231923, print grad=0.0009945007041096687, Depth Loss=0.0000000]
Training progress:  72%|███████▏  | 1440/2000 [15:02<03:40,  2.54it/s, Loss=0.0411083, Gaussian number=231923, print grad=0.001219600671902299, Depth Loss=0.0000000] 
Training progress:  72%|███████▎  | 1450/2000 [15:02<03:36,  2.54it/s, Loss=0.0411083, Gaussian number=231923, print grad=0.001219600671902299, Depth Loss=0.0000000]
Training progress:  72%|███████▎  | 1450/2000 [15:06<03:36,  2.54it/s, Loss=0.0344011, Gaussian number=231923, print grad=0.0014373904559761286, Depth Loss=0.0000000]
Training progress:  73%|███████▎  | 1460/2000 [15:06<03:32,  2.54it/s, Loss=0.0344011, Gaussian number=231923, print grad=0.0014373904559761286, Depth Loss=0.0000000]
Training progress:  73%|███████▎  | 1460/2000 [15:10<03:32,  2.54it/s, Loss=0.0464701, Gaussian number=231923, print grad=0.0016680704429745674, Depth Loss=0.0000000]
Training progress:  74%|███████▎  | 1470/2000 [15:10<03:29,  2.54it/s, Loss=0.0464701, Gaussian number=231923, print grad=0.0016680704429745674, Depth Loss=0.0000000]
Training progress:  74%|███████▎  | 1470/2000 [15:14<03:29,  2.54it/s, Loss=0.0470535, Gaussian number=231923, print grad=0.0019061350030824542, Depth Loss=0.0000000]
Training progress:  74%|███████▍  | 1480/2000 [15:14<03:25,  2.53it/s, Loss=0.0470535, Gaussian number=231923, print grad=0.0019061350030824542, Depth Loss=0.0000000]
Training progress:  74%|███████▍  | 1480/2000 [15:18<03:25,  2.53it/s, Loss=0.0479416, Gaussian number=231923, print grad=0.0021466840989887714, Depth Loss=0.0000000]
Training progress:  74%|███████▍  | 1490/2000 [15:18<03:21,  2.53it/s, Loss=0.0479416, Gaussian number=231923, print grad=0.0021466840989887714, Depth Loss=0.0000000]
Training progress:  74%|███████▍  | 1490/2000 [15:21<03:21,  2.53it/s, Loss=0.0495860, Gaussian number=231923, print grad=0.0023831233847886324, Depth Loss=0.0000000]
Training progress:  75%|███████▌  | 1500/2000 [15:21<03:17,  2.53it/s, Loss=0.0495860, Gaussian number=231923, print grad=0.0023831233847886324, Depth Loss=0.0000000]
Training progress:  75%|███████▌  | 1500/2000 [16:31<03:17,  2.53it/s, Loss=0.0523675, Gaussian number=237896, print grad=0.0002116716786986217, Depth Loss=0.0000000]
Training progress:  76%|███████▌  | 1510/2000 [16:31<19:15,  2.36s/it, Loss=0.0523675, Gaussian number=237896, print grad=0.0002116716786986217, Depth Loss=0.0000000]
Training progress:  76%|███████▌  | 1510/2000 [16:35<19:15,  2.36s/it, Loss=0.0477154, Gaussian number=237896, print grad=0.000438658898929134, Depth Loss=0.0000000] 
Training progress:  76%|███████▌  | 1520/2000 [16:35<14:09,  1.77s/it, Loss=0.0477154, Gaussian number=237896, print grad=0.000438658898929134, Depth Loss=0.0000000]
Training progress:  76%|███████▌  | 1520/2000 [16:39<14:09,  1.77s/it, Loss=0.0283537, Gaussian number=237896, print grad=0.0006786218727938831, Depth Loss=0.0000000]
Training progress:  76%|███████▋  | 1530/2000 [16:39<10:37,  1.36s/it, Loss=0.0283537, Gaussian number=237896, print grad=0.0006786218727938831, Depth Loss=0.0000000]
Training progress:  76%|███████▋  | 1530/2000 [16:43<10:37,  1.36s/it, Loss=0.0427514, Gaussian number=237896, print grad=0.0009031814988702536, Depth Loss=0.0000000]
Training progress:  77%|███████▋  | 1540/2000 [16:43<08:11,  1.07s/it, Loss=0.0427514, Gaussian number=237896, print grad=0.0009031814988702536, Depth Loss=0.0000000]
Training progress:  77%|███████▋  | 1540/2000 [16:47<08:11,  1.07s/it, Loss=0.0449891, Gaussian number=237896, print grad=0.0011596952099353075, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1550/2000 [16:47<06:29,  1.16it/s, Loss=0.0449891, Gaussian number=237896, print grad=0.0011596952099353075, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1550/2000 [16:51<06:29,  1.16it/s, Loss=0.0434321, Gaussian number=237896, print grad=0.0014098244719207287, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1560/2000 [16:51<05:18,  1.38it/s, Loss=0.0434321, Gaussian number=237896, print grad=0.0014098244719207287, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1560/2000 [16:54<05:18,  1.38it/s, Loss=0.0373338, Gaussian number=237896, print grad=0.0016333542298525572, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1570/2000 [16:54<04:28,  1.60it/s, Loss=0.0373338, Gaussian number=237896, print grad=0.0016333542298525572, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1570/2000 [16:58<04:28,  1.60it/s, Loss=0.0276109, Gaussian number=237896, print grad=0.0018148628296330571, Depth Loss=0.0000000]
Training progress:  79%|███████▉  | 1580/2000 [16:58<03:53,  1.80it/s, Loss=0.0276109, Gaussian number=237896, print grad=0.0018148628296330571, Depth Loss=0.0000000]
Training progress:  79%|███████▉  | 1580/2000 [17:02<03:53,  1.80it/s, Loss=0.0357510, Gaussian number=237896, print grad=0.0020294056739658117, Depth Loss=0.0000000]
Training progress:  80%|███████▉  | 1590/2000 [17:02<03:27,  1.97it/s, Loss=0.0357510, Gaussian number=237896, print grad=0.0020294056739658117, Depth Loss=0.0000000]
Training progress:  80%|███████▉  | 1590/2000 [17:06<03:27,  1.97it/s, Loss=0.0389800, Gaussian number=237896, print grad=0.0022534136660397053, Depth Loss=0.0000000]
Training progress:  80%|████████  | 1600/2000 [17:06<03:09,  2.12it/s, Loss=0.0389800, Gaussian number=237896, print grad=0.0022534136660397053, Depth Loss=0.0000000]
Training progress:  80%|████████  | 1600/2000 [17:10<03:09,  2.12it/s, Loss=0.0426388, Gaussian number=243155, print grad=0.00022967273253016174, Depth Loss=0.0000000]
Training progress:  80%|████████  | 1610/2000 [17:10<02:55,  2.22it/s, Loss=0.0426388, Gaussian number=243155, print grad=0.00022967273253016174, Depth Loss=0.0000000]
Training progress:  80%|████████  | 1610/2000 [17:14<02:55,  2.22it/s, Loss=0.0444484, Gaussian number=243155, print grad=0.00047600659308955073, Depth Loss=0.0000000]
Training progress:  81%|████████  | 1620/2000 [17:14<02:44,  2.31it/s, Loss=0.0444484, Gaussian number=243155, print grad=0.00047600659308955073, Depth Loss=0.0000000]
Training progress:  81%|████████  | 1620/2000 [17:18<02:44,  2.31it/s, Loss=0.0375822, Gaussian number=243155, print grad=0.0006996195297688246, Depth Loss=0.0000000] 
Training progress:  82%|████████▏ | 1630/2000 [17:18<02:36,  2.36it/s, Loss=0.0375822, Gaussian number=243155, print grad=0.0006996195297688246, Depth Loss=0.0000000]
Training progress:  82%|████████▏ | 1630/2000 [17:22<02:36,  2.36it/s, Loss=0.0274529, Gaussian number=243155, print grad=0.0009319278178736567, Depth Loss=0.0000000]
Training progress:  82%|████████▏ | 1640/2000 [17:22<02:29,  2.41it/s, Loss=0.0274529, Gaussian number=243155, print grad=0.0009319278178736567, Depth Loss=0.0000000]
Training progress:  82%|████████▏ | 1640/2000 [17:26<02:29,  2.41it/s, Loss=0.0393527, Gaussian number=243155, print grad=0.0011345320381224155, Depth Loss=0.0000000]
Training progress:  82%|████████▎ | 1650/2000 [17:26<02:23,  2.44it/s, Loss=0.0393527, Gaussian number=243155, print grad=0.0011345320381224155, Depth Loss=0.0000000]
Training progress:  82%|████████▎ | 1650/2000 [17:30<02:23,  2.44it/s, Loss=0.0379095, Gaussian number=243155, print grad=0.0013631434412673116, Depth Loss=0.0000000]
Training progress:  83%|████████▎ | 1660/2000 [17:30<02:17,  2.47it/s, Loss=0.0379095, Gaussian number=243155, print grad=0.0013631434412673116, Depth Loss=0.0000000]
Training progress:  83%|████████▎ | 1660/2000 [17:34<02:17,  2.47it/s, Loss=0.0337902, Gaussian number=243155, print grad=0.0015748062869533896, Depth Loss=0.0000000]
Training progress:  84%|████████▎ | 1670/2000 [17:34<02:12,  2.49it/s, Loss=0.0337902, Gaussian number=243155, print grad=0.0015748062869533896, Depth Loss=0.0000000]
Training progress:  84%|████████▎ | 1670/2000 [17:38<02:12,  2.49it/s, Loss=0.0335999, Gaussian number=243155, print grad=0.0018088920041918755, Depth Loss=0.0000000]
Training progress:  84%|████████▍ | 1680/2000 [17:38<02:08,  2.49it/s, Loss=0.0335999, Gaussian number=243155, print grad=0.0018088920041918755, Depth Loss=0.0000000]
Training progress:  84%|████████▍ | 1680/2000 [17:42<02:08,  2.49it/s, Loss=0.0394905, Gaussian number=243155, print grad=0.002017667517066002, Depth Loss=0.0000000] 
Training progress:  84%|████████▍ | 1690/2000 [17:42<02:03,  2.50it/s, Loss=0.0394905, Gaussian number=243155, print grad=0.002017667517066002, Depth Loss=0.0000000]
Training progress:  84%|████████▍ | 1690/2000 [17:46<02:03,  2.50it/s, Loss=0.0398089, Gaussian number=243155, print grad=0.0022055935114622116, Depth Loss=0.0000000]
Training progress:  85%|████████▌ | 1700/2000 [17:46<01:59,  2.51it/s, Loss=0.0398089, Gaussian number=243155, print grad=0.0022055935114622116, Depth Loss=0.0000000]
Training progress:  85%|████████▌ | 1700/2000 [17:50<01:59,  2.51it/s, Loss=0.0421308, Gaussian number=248600, print grad=0.00022635914501734078, Depth Loss=0.0000000]
Training progress:  86%|████████▌ | 1710/2000 [17:50<01:55,  2.51it/s, Loss=0.0421308, Gaussian number=248600, print grad=0.00022635914501734078, Depth Loss=0.0000000]
Training progress:  86%|████████▌ | 1710/2000 [17:54<01:55,  2.51it/s, Loss=0.0491588, Gaussian number=248600, print grad=0.000427376915467903, Depth Loss=0.0000000]  
Training progress:  86%|████████▌ | 1720/2000 [17:54<01:50,  2.52it/s, Loss=0.0491588, Gaussian number=248600, print grad=0.000427376915467903, Depth Loss=0.0000000]
Training progress:  86%|████████▌ | 1720/2000 [17:58<01:50,  2.52it/s, Loss=0.0391289, Gaussian number=248600, print grad=0.0006523849442601204, Depth Loss=0.0000000]
Training progress:  86%|████████▋ | 1730/2000 [17:58<01:46,  2.53it/s, Loss=0.0391289, Gaussian number=248600, print grad=0.0006523849442601204, Depth Loss=0.0000000]
Training progress:  86%|████████▋ | 1730/2000 [18:02<01:46,  2.53it/s, Loss=0.0584099, Gaussian number=248600, print grad=0.0009036727715283632, Depth Loss=0.0000000]
Training progress:  87%|████████▋ | 1740/2000 [18:02<01:42,  2.53it/s, Loss=0.0584099, Gaussian number=248600, print grad=0.0009036727715283632, Depth Loss=0.0000000]
Training progress:  87%|████████▋ | 1740/2000 [18:06<01:42,  2.53it/s, Loss=0.0535522, Gaussian number=248600, print grad=0.0011454987106844783, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1750/2000 [18:06<01:38,  2.53it/s, Loss=0.0535522, Gaussian number=248600, print grad=0.0011454987106844783, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1750/2000 [18:10<01:38,  2.53it/s, Loss=0.0406420, Gaussian number=248600, print grad=0.0013533313758671284, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1760/2000 [18:10<01:34,  2.54it/s, Loss=0.0406420, Gaussian number=248600, print grad=0.0013533313758671284, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1760/2000 [18:14<01:34,  2.54it/s, Loss=0.0319230, Gaussian number=248600, print grad=0.0015557508450001478, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1770/2000 [18:14<01:30,  2.54it/s, Loss=0.0319230, Gaussian number=248600, print grad=0.0015557508450001478, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1770/2000 [18:17<01:30,  2.54it/s, Loss=0.0387166, Gaussian number=248600, print grad=0.00175559485796839, Depth Loss=0.0000000]  
Training progress:  89%|████████▉ | 1780/2000 [18:17<01:26,  2.54it/s, Loss=0.0387166, Gaussian number=248600, print grad=0.00175559485796839, Depth Loss=0.0000000]
Training progress:  89%|████████▉ | 1780/2000 [18:21<01:26,  2.54it/s, Loss=0.0345964, Gaussian number=248600, print grad=0.0019291896605864167, Depth Loss=0.0000000]
Training progress:  90%|████████▉ | 1790/2000 [18:21<01:22,  2.54it/s, Loss=0.0345964, Gaussian number=248600, print grad=0.0019291896605864167, Depth Loss=0.0000000]
Training progress:  90%|████████▉ | 1790/2000 [18:25<01:22,  2.54it/s, Loss=0.0341773, Gaussian number=248600, print grad=0.0021489739883691072, Depth Loss=0.0000000]
Training progress:  90%|█████████ | 1800/2000 [18:25<01:18,  2.54it/s, Loss=0.0341773, Gaussian number=248600, print grad=0.0021489739883691072, Depth Loss=0.0000000]
Training progress:  90%|█████████ | 1800/2000 [18:29<01:18,  2.54it/s, Loss=0.0429875, Gaussian number=253392, print grad=0.0002384580293437466, Depth Loss=0.0000000]
Training progress:  90%|█████████ | 1810/2000 [18:29<01:14,  2.54it/s, Loss=0.0429875, Gaussian number=253392, print grad=0.0002384580293437466, Depth Loss=0.0000000]
Training progress:  90%|█████████ | 1810/2000 [18:33<01:14,  2.54it/s, Loss=0.0332370, Gaussian number=253392, print grad=0.00047380634350702167, Depth Loss=0.0000000]
Training progress:  91%|█████████ | 1820/2000 [18:33<01:10,  2.54it/s, Loss=0.0332370, Gaussian number=253392, print grad=0.00047380634350702167, Depth Loss=0.0000000]
Training progress:  91%|█████████ | 1820/2000 [18:37<01:10,  2.54it/s, Loss=0.0344486, Gaussian number=253392, print grad=0.000680661469232291, Depth Loss=0.0000000]  
Training progress:  92%|█████████▏| 1830/2000 [18:37<01:06,  2.54it/s, Loss=0.0344486, Gaussian number=253392, print grad=0.000680661469232291, Depth Loss=0.0000000]
Training progress:  92%|█████████▏| 1830/2000 [18:41<01:06,  2.54it/s, Loss=0.0308980, Gaussian number=253392, print grad=0.0009037034469656646, Depth Loss=0.0000000]
Training progress:  92%|█████████▏| 1840/2000 [18:41<01:03,  2.54it/s, Loss=0.0308980, Gaussian number=253392, print grad=0.0009037034469656646, Depth Loss=0.0000000]
Training progress:  92%|█████████▏| 1840/2000 [18:45<01:03,  2.54it/s, Loss=0.0356738, Gaussian number=253392, print grad=0.0011102731805294752, Depth Loss=0.0000000]
Training progress:  92%|█████████▎| 1850/2000 [18:45<00:59,  2.54it/s, Loss=0.0356738, Gaussian number=253392, print grad=0.0011102731805294752, Depth Loss=0.0000000]
Training progress:  92%|█████████▎| 1850/2000 [18:49<00:59,  2.54it/s, Loss=0.0414968, Gaussian number=253392, print grad=0.0012819577241316438, Depth Loss=0.0000000]
Training progress:  93%|█████████▎| 1860/2000 [18:49<00:55,  2.54it/s, Loss=0.0414968, Gaussian number=253392, print grad=0.0012819577241316438, Depth Loss=0.0000000]
Training progress:  93%|█████████▎| 1860/2000 [18:53<00:55,  2.54it/s, Loss=0.0404974, Gaussian number=253392, print grad=0.0015161240007728338, Depth Loss=0.0000000]
Training progress:  94%|█████████▎| 1870/2000 [18:53<00:51,  2.54it/s, Loss=0.0404974, Gaussian number=253392, print grad=0.0015161240007728338, Depth Loss=0.0000000]
Training progress:  94%|█████████▎| 1870/2000 [18:57<00:51,  2.54it/s, Loss=0.0292598, Gaussian number=253392, print grad=0.0017146257450804114, Depth Loss=0.0000000]
Training progress:  94%|█████████▍| 1880/2000 [18:57<00:47,  2.54it/s, Loss=0.0292598, Gaussian number=253392, print grad=0.0017146257450804114, Depth Loss=0.0000000]
Training progress:  94%|█████████▍| 1880/2000 [19:01<00:47,  2.54it/s, Loss=0.0375882, Gaussian number=253392, print grad=0.0019030902767553926, Depth Loss=0.0000000]
Training progress:  94%|█████████▍| 1890/2000 [19:01<00:43,  2.54it/s, Loss=0.0375882, Gaussian number=253392, print grad=0.0019030902767553926, Depth Loss=0.0000000]
Training progress:  94%|█████████▍| 1890/2000 [19:05<00:43,  2.54it/s, Loss=0.0510024, Gaussian number=253392, print grad=0.0021289007272571325, Depth Loss=0.0000000]
Training progress:  95%|█████████▌| 1900/2000 [19:05<00:39,  2.54it/s, Loss=0.0510024, Gaussian number=253392, print grad=0.0021289007272571325, Depth Loss=0.0000000]
Training progress:  95%|█████████▌| 1900/2000 [19:09<00:39,  2.54it/s, Loss=0.0395608, Gaussian number=259327, print grad=0.0001985850976780057, Depth Loss=0.0000000]
Training progress:  96%|█████████▌| 1910/2000 [19:09<00:35,  2.54it/s, Loss=0.0395608, Gaussian number=259327, print grad=0.0001985850976780057, Depth Loss=0.0000000]
Training progress:  96%|█████████▌| 1910/2000 [19:13<00:35,  2.54it/s, Loss=0.0306718, Gaussian number=259327, print grad=0.0004151339235249907, Depth Loss=0.0000000]
Training progress:  96%|█████████▌| 1920/2000 [19:13<00:31,  2.53it/s, Loss=0.0306718, Gaussian number=259327, print grad=0.0004151339235249907, Depth Loss=0.0000000]
Training progress:  96%|█████████▌| 1920/2000 [19:17<00:31,  2.53it/s, Loss=0.0285791, Gaussian number=259327, print grad=0.0006341959815472364, Depth Loss=0.0000000]
Training progress:  96%|█████████▋| 1930/2000 [19:17<00:27,  2.53it/s, Loss=0.0285791, Gaussian number=259327, print grad=0.0006341959815472364, Depth Loss=0.0000000]
Training progress:  96%|█████████▋| 1930/2000 [19:21<00:27,  2.53it/s, Loss=0.0420429, Gaussian number=259327, print grad=0.000836711551528424, Depth Loss=0.0000000] 
Training progress:  97%|█████████▋| 1940/2000 [19:21<00:23,  2.53it/s, Loss=0.0420429, Gaussian number=259327, print grad=0.000836711551528424, Depth Loss=0.0000000]
Training progress:  97%|█████████▋| 1940/2000 [19:25<00:23,  2.53it/s, Loss=0.0297309, Gaussian number=259327, print grad=0.0010379188461229205, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1950/2000 [19:25<00:19,  2.53it/s, Loss=0.0297309, Gaussian number=259327, print grad=0.0010379188461229205, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1950/2000 [19:28<00:19,  2.53it/s, Loss=0.0519991, Gaussian number=259327, print grad=0.0012339522363618016, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1960/2000 [19:28<00:15,  2.53it/s, Loss=0.0519991, Gaussian number=259327, print grad=0.0012339522363618016, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1960/2000 [19:32<00:15,  2.53it/s, Loss=0.0493700, Gaussian number=259327, print grad=0.001444430323317647, Depth Loss=0.0000000] 
Training progress:  98%|█████████▊| 1970/2000 [19:32<00:11,  2.53it/s, Loss=0.0493700, Gaussian number=259327, print grad=0.001444430323317647, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1970/2000 [19:36<00:11,  2.53it/s, Loss=0.0355906, Gaussian number=259327, print grad=0.0016523897647857666, Depth Loss=0.0000000]
Training progress:  99%|█████████▉| 1980/2000 [19:36<00:07,  2.53it/s, Loss=0.0355906, Gaussian number=259327, print grad=0.0016523897647857666, Depth Loss=0.0000000]
Training progress:  99%|█████████▉| 1980/2000 [19:40<00:07,  2.53it/s, Loss=0.0330191, Gaussian number=259327, print grad=0.0018951755482703447, Depth Loss=0.0000000]
Training progress: 100%|█████████▉| 1990/2000 [19:40<00:03,  2.53it/s, Loss=0.0330191, Gaussian number=259327, print grad=0.0018951755482703447, Depth Loss=0.0000000]
Training progress: 100%|█████████▉| 1990/2000 [19:44<00:03,  2.53it/s, Loss=0.0255082, Gaussian number=259327, print grad=0.0021068037021905184, Depth Loss=0.0000000]
Training progress: 100%|██████████| 2000/2000 [19:44<00:00,  2.53it/s, Loss=0.0255082, Gaussian number=259327, print grad=0.0021068037021905184, Depth Loss=0.0000000]
Training progress: 100%|██████████| 2000/2000 [19:44<00:00,  1.69it/s, Loss=0.0255082, Gaussian number=259327, print grad=0.0021068037021905184, Depth Loss=0.0000000]
Iteration 100 [03/12 19:06:09]

[ITER 100] Evaluating test: WD 0.228505, PSNR 12.4339,lpips 0.615936,ssim 0.423309 [03/12 19:07:07]

[ITER 100] Evaluating train: WD 0.238069, PSNR 12.7117,lpips 0.618083,ssim 0.441420 [03/12 19:07:15]
Gaussian number:182686,print gradients:2.501029484847095e-05 [03/12 19:07:15]
Iteration 200 [03/12 19:07:54]

[ITER 200] Evaluating test: WD 0.219055, PSNR 13.8347,lpips 0.571389,ssim 0.444812 [03/12 19:08:53]

[ITER 200] Evaluating train: WD 0.223878, PSNR 13.9958,lpips 0.561249,ssim 0.457346 [03/12 19:09:00]
Gaussian number:182686,print gradients:2.7678335754899308e-05 [03/12 19:09:00]
Iteration 300 [03/12 19:09:40]

[ITER 300] Evaluating test: WD 0.211928, PSNR 14.4099,lpips 0.542320,ssim 0.454393 [03/12 19:10:38]

[ITER 300] Evaluating train: WD 0.217308, PSNR 14.6837,lpips 0.532791,ssim 0.465460 [03/12 19:10:45]
Gaussian number:182686,print gradients:2.9147260647732764e-05 [03/12 19:10:45]
Iteration 400 [03/12 19:11:25]
Iteration 500 [03/12 19:12:04]

[ITER 500] Evaluating test: WD 0.199942, PSNR 15.0786,lpips 0.512384,ssim 0.466444 [03/12 19:13:02]

[ITER 500] Evaluating train: WD 0.213949, PSNR 15.0854,lpips 0.512151,ssim 0.472314 [03/12 19:13:10]
Gaussian number:182686,print gradients:3.089873644057661e-05 [03/12 19:13:10]
Iteration 600 [03/12 19:13:49]
Iteration 700 [03/12 19:14:28]
Iteration 800 [03/12 19:15:08]
Iteration 900 [03/12 19:15:48]
Iteration 1000 [03/12 19:16:27]

[ITER 1000] Evaluating test: WD 0.185090, PSNR 15.6452,lpips 0.465598,ssim 0.464465 [03/12 19:17:25]

[ITER 1000] Evaluating train: WD 0.199254, PSNR 15.8283,lpips 0.469917,ssim 0.470461 [03/12 19:17:32]
Gaussian number:199368,print gradients:3.82154066755902e-05 [03/12 19:17:33]
Iteration 1100 [03/12 19:18:11]
Iteration 1200 [03/12 19:18:51]
Iteration 1300 [03/12 19:19:30]
Iteration 1400 [03/12 19:20:10]
Iteration 1500 [03/12 19:20:49]

[ITER 1500] Evaluating test: WD 0.172898, PSNR 15.8686,lpips 0.435894,ssim 0.464995 [03/12 19:21:47]

[ITER 1500] Evaluating train: WD 0.185547, PSNR 16.2080,lpips 0.439244,ssim 0.465818 [03/12 19:21:55]
Gaussian number:231923,print gradients:nan [03/12 19:21:55]
Iteration 1600 [03/12 19:22:34]
Iteration 1700 [03/12 19:23:14]
Iteration 1800 [03/12 19:23:53]
Iteration 1900 [03/12 19:24:32]
Iteration 2000 [03/12 19:25:12]

[ITER 2000] Evaluating test: WD 0.163268, PSNR 16.1334,lpips 0.416565,ssim 0.472182 [03/12 19:26:10]

[ITER 2000] Evaluating train: WD 0.182673, PSNR 16.4373,lpips 0.427868,ssim 0.470132 [03/12 19:26:18]
Gaussian number:259327,print gradients:nan [03/12 19:26:18]

[ITER 2000] Saving Gaussians [03/12 19:26:18]

Training complete. [03/12 19:26:20]
