Optimizing /home/cw4287/gaussian-model/train_30k
Output folder: /home/cw4287/gaussian-model/train_30k [03/12 16:41:30]
Tensorboard not available: not logging progress [03/12 16:41:30]
------------LLFF HOLD------------- [03/12 16:41:31]

Reading camera 1/301
Reading camera 2/301
Reading camera 3/301
Reading camera 4/301
Reading camera 5/301
Reading camera 6/301
Reading camera 7/301
Reading camera 8/301
Reading camera 9/301
Reading camera 10/301
Reading camera 11/301
Reading camera 12/301
Reading camera 13/301
Reading camera 14/301
Reading camera 15/301
Reading camera 16/301
Reading camera 17/301
Reading camera 18/301
Reading camera 19/301
Reading camera 20/301
Reading camera 21/301
Reading camera 22/301
Reading camera 23/301
Reading camera 24/301
Reading camera 25/301
Reading camera 26/301
Reading camera 27/301
Reading camera 28/301
Reading camera 29/301
Reading camera 30/301
Reading camera 31/301
Reading camera 32/301
Reading camera 33/301
Reading camera 34/301
Reading camera 35/301
Reading camera 36/301
Reading camera 37/301
Reading camera 38/301
Reading camera 39/301
Reading camera 40/301
Reading camera 41/301
Reading camera 42/301
Reading camera 43/301
Reading camera 44/301
Reading camera 45/301
Reading camera 46/301
Reading camera 47/301
Reading camera 48/301
Reading camera 49/301
Reading camera 50/301
Reading camera 51/301
Reading camera 52/301
Reading camera 53/301
Reading camera 54/301
Reading camera 55/301
Reading camera 56/301
Reading camera 57/301
Reading camera 58/301
Reading camera 59/301
Reading camera 60/301
Reading camera 61/301
Reading camera 62/301
Reading camera 63/301
Reading camera 64/301
Reading camera 65/301
Reading camera 66/301
Reading camera 67/301
Reading camera 68/301
Reading camera 69/301
Reading camera 70/301
Reading camera 71/301
Reading camera 72/301
Reading camera 73/301
Reading camera 74/301
Reading camera 75/301
Reading camera 76/301
Reading camera 77/301
Reading camera 78/301
Reading camera 79/301
Reading camera 80/301
Reading camera 81/301
Reading camera 82/301
Reading camera 83/301
Reading camera 84/301
Reading camera 85/301
Reading camera 86/301
Reading camera 87/301
Reading camera 88/301
Reading camera 89/301
Reading camera 90/301
Reading camera 91/301
Reading camera 92/301
Reading camera 93/301
Reading camera 94/301
Reading camera 95/301
Reading camera 96/301
Reading camera 97/301
Reading camera 98/301
Reading camera 99/301
Reading camera 100/301
Reading camera 101/301
Reading camera 102/301
Reading camera 103/301
Reading camera 104/301
Reading camera 105/301
Reading camera 106/301
Reading camera 107/301
Reading camera 108/301
Reading camera 109/301
Reading camera 110/301
Reading camera 111/301
Reading camera 112/301
Reading camera 113/301
Reading camera 114/301
Reading camera 115/301
Reading camera 116/301
Reading camera 117/301
Reading camera 118/301
Reading camera 119/301
Reading camera 120/301
Reading camera 121/301
Reading camera 122/301
Reading camera 123/301
Reading camera 124/301
Reading camera 125/301
Reading camera 126/301
Reading camera 127/301
Reading camera 128/301
Reading camera 129/301
Reading camera 130/301
Reading camera 131/301
Reading camera 132/301
Reading camera 133/301
Reading camera 134/301
Reading camera 135/301
Reading camera 136/301
Reading camera 137/301
Reading camera 138/301
Reading camera 139/301
Reading camera 140/301
Reading camera 141/301
Reading camera 142/301
Reading camera 143/301
Reading camera 144/301
Reading camera 145/301
Reading camera 146/301
Reading camera 147/301
Reading camera 148/301
Reading camera 149/301
Reading camera 150/301
Reading camera 151/301
Reading camera 152/301
Reading camera 153/301
Reading camera 154/301
Reading camera 155/301
Reading camera 156/301
Reading camera 157/301
Reading camera 158/301
Reading camera 159/301
Reading camera 160/301
Reading camera 161/301
Reading camera 162/301
Reading camera 163/301
Reading camera 164/301
Reading camera 165/301
Reading camera 166/301
Reading camera 167/301
Reading camera 168/301
Reading camera 169/301
Reading camera 170/301
Reading camera 171/301
Reading camera 172/301
Reading camera 173/301
Reading camera 174/301
Reading camera 175/301
Reading camera 176/301
Reading camera 177/301
Reading camera 178/301
Reading camera 179/301
Reading camera 180/301
Reading camera 181/301
Reading camera 182/301
Reading camera 183/301
Reading camera 184/301
Reading camera 185/301
Reading camera 186/301
Reading camera 187/301
Reading camera 188/301
Reading camera 189/301
Reading camera 190/301
Reading camera 191/301
Reading camera 192/301
Reading camera 193/301
Reading camera 194/301
Reading camera 195/301
Reading camera 196/301
Reading camera 197/301
Reading camera 198/301
Reading camera 199/301
Reading camera 200/301
Reading camera 201/301
Reading camera 202/301
Reading camera 203/301
Reading camera 204/301
Reading camera 205/301
Reading camera 206/301
Reading camera 207/301
Reading camera 208/301
Reading camera 209/301
Reading camera 210/301
Reading camera 211/301
Reading camera 212/301
Reading camera 213/301
Reading camera 214/301
Reading camera 215/301
Reading camera 216/301
Reading camera 217/301
Reading camera 218/301
Reading camera 219/301
Reading camera 220/301
Reading camera 221/301
Reading camera 222/301
Reading camera 223/301
Reading camera 224/301
Reading camera 225/301
Reading camera 226/301
Reading camera 227/301
Reading camera 228/301
Reading camera 229/301
Reading camera 230/301
Reading camera 231/301
Reading camera 232/301
Reading camera 233/301
Reading camera 234/301
Reading camera 235/301
Reading camera 236/301
Reading camera 237/301
Reading camera 238/301
Reading camera 239/301
Reading camera 240/301
Reading camera 241/301
Reading camera 242/301
Reading camera 243/301
Reading camera 244/301
Reading camera 245/301
Reading camera 246/301
Reading camera 247/301
Reading camera 248/301
Reading camera 249/301
Reading camera 250/301
Reading camera 251/301
Reading camera 252/301
Reading camera 253/301
Reading camera 254/301
Reading camera 255/301
Reading camera 256/301
Reading camera 257/301
Reading camera 258/301
Reading camera 259/301
Reading camera 260/301
Reading camera 261/301
Reading camera 262/301
Reading camera 263/301
Reading camera 264/301
Reading camera 265/301
Reading camera 266/301
Reading camera 267/301
Reading camera 268/301
Reading camera 269/301
Reading camera 270/301
Reading camera 271/301
Reading camera 272/301
Reading camera 273/301
Reading camera 274/301
Reading camera 275/301
Reading camera 276/301
Reading camera 277/301
Reading camera 278/301
Reading camera 279/301
Reading camera 280/301
Reading camera 281/301
Reading camera 282/301
Reading camera 283/301
Reading camera 284/301
Reading camera 285/301
Reading camera 286/301
Reading camera 287/301
Reading camera 288/301
Reading camera 289/301
Reading camera 290/301
Reading camera 291/301
Reading camera 292/301
Reading camera 293/301
Reading camera 294/301
Reading camera 295/301
Reading camera 296/301
Reading camera 297/301
Reading camera 298/301
Reading camera 299/301
Reading camera 300/301
Reading camera 301/301 [03/12 16:41:31]
Loading Training Cameras [03/12 16:41:32]
Loading Test Cameras [03/12 16:41:56]
Number of points at initialisation :  182686 [03/12 16:42:00]

Training progress:   0%|          | 0/2000 [00:00<?, ?it/s]/ext3/conda/envs/3dgs/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/ext3/conda/envs/3dgs/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)

Training progress:   0%|          | 0/2000 [00:10<?, ?it/s, Loss=0.1518287, Gaussian number=182686, print grad=6.16824981989339e-05, Depth Loss=0.0000000]
Training progress:   0%|          | 10/2000 [00:10<33:14,  1.00s/it, Loss=0.1518287, Gaussian number=182686, print grad=6.16824981989339e-05, Depth Loss=0.0000000]
Training progress:   0%|          | 10/2000 [00:13<33:14,  1.00s/it, Loss=0.1470595, Gaussian number=182686, print grad=0.0001637214736547321, Depth Loss=0.0000000]
Training progress:   1%|          | 20/2000 [00:13<20:45,  1.59it/s, Loss=0.1470595, Gaussian number=182686, print grad=0.0001637214736547321, Depth Loss=0.0000000]
Training progress:   1%|          | 20/2000 [00:17<20:45,  1.59it/s, Loss=0.1459841, Gaussian number=182686, print grad=0.000259747845120728, Depth Loss=0.0000000] 
Training progress:   2%|▏         | 30/2000 [00:17<16:44,  1.96it/s, Loss=0.1459841, Gaussian number=182686, print grad=0.000259747845120728, Depth Loss=0.0000000]
Training progress:   2%|▏         | 30/2000 [00:21<16:44,  1.96it/s, Loss=0.1573320, Gaussian number=182686, print grad=0.0003625792160164565, Depth Loss=0.0000000]
Training progress:   2%|▏         | 40/2000 [00:21<14:48,  2.21it/s, Loss=0.1573320, Gaussian number=182686, print grad=0.0003625792160164565, Depth Loss=0.0000000]
Training progress:   2%|▏         | 40/2000 [00:24<14:48,  2.21it/s, Loss=0.1198988, Gaussian number=182686, print grad=0.00044180930126458406, Depth Loss=0.0000000]
Training progress:   2%|▎         | 50/2000 [00:24<13:42,  2.37it/s, Loss=0.1198988, Gaussian number=182686, print grad=0.00044180930126458406, Depth Loss=0.0000000]
Training progress:   2%|▎         | 50/2000 [00:28<13:42,  2.37it/s, Loss=0.1376891, Gaussian number=182686, print grad=0.0005655882996506989, Depth Loss=0.0000000] 
Training progress:   3%|▎         | 60/2000 [00:28<13:00,  2.49it/s, Loss=0.1376891, Gaussian number=182686, print grad=0.0005655882996506989, Depth Loss=0.0000000]
Training progress:   3%|▎         | 60/2000 [00:32<13:00,  2.49it/s, Loss=0.1240787, Gaussian number=182686, print grad=0.0007256179233081639, Depth Loss=0.0000000]
Training progress:   4%|▎         | 70/2000 [00:32<12:33,  2.56it/s, Loss=0.1240787, Gaussian number=182686, print grad=0.0007256179233081639, Depth Loss=0.0000000]
Training progress:   4%|▎         | 70/2000 [00:35<12:33,  2.56it/s, Loss=0.1436687, Gaussian number=182686, print grad=0.00084176060045138, Depth Loss=0.0000000]  
Training progress:   4%|▍         | 80/2000 [00:35<12:14,  2.61it/s, Loss=0.1436687, Gaussian number=182686, print grad=0.00084176060045138, Depth Loss=0.0000000]
Training progress:   4%|▍         | 80/2000 [00:39<12:14,  2.61it/s, Loss=0.1235215, Gaussian number=182686, print grad=0.0009620757773518562, Depth Loss=0.0000000]
Training progress:   4%|▍         | 90/2000 [00:39<12:01,  2.65it/s, Loss=0.1235215, Gaussian number=182686, print grad=0.0009620757773518562, Depth Loss=0.0000000]
Training progress:   4%|▍         | 90/2000 [00:42<12:01,  2.65it/s, Loss=0.1234972, Gaussian number=182686, print grad=0.0011080520926043391, Depth Loss=0.0000000]
Training progress:   5%|▌         | 100/2000 [00:42<11:51,  2.67it/s, Loss=0.1234972, Gaussian number=182686, print grad=0.0011080520926043391, Depth Loss=0.0000000]
Training progress:   5%|▌         | 100/2000 [01:50<11:51,  2.67it/s, Loss=0.1443236, Gaussian number=182686, print grad=0.0012692614691331983, Depth Loss=0.0000000]
Training progress:   6%|▌         | 110/2000 [01:50<1:13:31,  2.33s/it, Loss=0.1443236, Gaussian number=182686, print grad=0.0012692614691331983, Depth Loss=0.0000000]
Training progress:   6%|▌         | 110/2000 [01:54<1:13:31,  2.33s/it, Loss=0.1197369, Gaussian number=182686, print grad=0.0014255548594519496, Depth Loss=0.0000000]
Training progress:   6%|▌         | 120/2000 [01:54<54:21,  1.74s/it, Loss=0.1197369, Gaussian number=182686, print grad=0.0014255548594519496, Depth Loss=0.0000000]  
Training progress:   6%|▌         | 120/2000 [01:58<54:21,  1.74s/it, Loss=0.1397275, Gaussian number=182686, print grad=0.0016263031866401434, Depth Loss=0.0000000]
Training progress:   6%|▋         | 130/2000 [01:58<41:09,  1.32s/it, Loss=0.1397275, Gaussian number=182686, print grad=0.0016263031866401434, Depth Loss=0.0000000]
Training progress:   6%|▋         | 130/2000 [02:01<41:09,  1.32s/it, Loss=0.1270056, Gaussian number=182686, print grad=0.0018307879799976945, Depth Loss=0.0000000]
Training progress:   7%|▋         | 140/2000 [02:01<31:59,  1.03s/it, Loss=0.1270056, Gaussian number=182686, print grad=0.0018307879799976945, Depth Loss=0.0000000]
Training progress:   7%|▋         | 140/2000 [02:05<31:59,  1.03s/it, Loss=0.1099959, Gaussian number=182686, print grad=0.0020092339254915714, Depth Loss=0.0000000]
Training progress:   8%|▊         | 150/2000 [02:05<25:36,  1.20it/s, Loss=0.1099959, Gaussian number=182686, print grad=0.0020092339254915714, Depth Loss=0.0000000]
Training progress:   8%|▊         | 150/2000 [02:09<25:36,  1.20it/s, Loss=0.1173725, Gaussian number=182686, print grad=0.0022482185158878565, Depth Loss=0.0000000]
Training progress:   8%|▊         | 160/2000 [02:09<21:10,  1.45it/s, Loss=0.1173725, Gaussian number=182686, print grad=0.0022482185158878565, Depth Loss=0.0000000]
Training progress:   8%|▊         | 160/2000 [02:12<21:10,  1.45it/s, Loss=0.1160220, Gaussian number=182686, print grad=0.0024210349656641483, Depth Loss=0.0000000]
Training progress:   8%|▊         | 170/2000 [02:12<18:04,  1.69it/s, Loss=0.1160220, Gaussian number=182686, print grad=0.0024210349656641483, Depth Loss=0.0000000]
Training progress:   8%|▊         | 170/2000 [02:16<18:04,  1.69it/s, Loss=0.1022176, Gaussian number=182686, print grad=0.0026353683788329363, Depth Loss=0.0000000]
Training progress:   9%|▉         | 180/2000 [02:16<15:53,  1.91it/s, Loss=0.1022176, Gaussian number=182686, print grad=0.0026353683788329363, Depth Loss=0.0000000]
Training progress:   9%|▉         | 180/2000 [02:19<15:53,  1.91it/s, Loss=0.1286657, Gaussian number=182686, print grad=0.0028125683311372995, Depth Loss=0.0000000]
Training progress:  10%|▉         | 190/2000 [02:19<14:21,  2.10it/s, Loss=0.1286657, Gaussian number=182686, print grad=0.0028125683311372995, Depth Loss=0.0000000]
Training progress:  10%|▉         | 190/2000 [02:23<14:21,  2.10it/s, Loss=0.1155658, Gaussian number=182686, print grad=0.00303624477237463, Depth Loss=0.0000000]  
Training progress:  10%|█         | 200/2000 [02:23<13:15,  2.26it/s, Loss=0.1155658, Gaussian number=182686, print grad=0.00303624477237463, Depth Loss=0.0000000]
Training progress:  10%|█         | 200/2000 [03:30<13:15,  2.26it/s, Loss=0.1284138, Gaussian number=182686, print grad=0.0032743162009865046, Depth Loss=0.0000000]
Training progress:  10%|█         | 210/2000 [03:30<1:09:12,  2.32s/it, Loss=0.1284138, Gaussian number=182686, print grad=0.0032743162009865046, Depth Loss=0.0000000]
Training progress:  10%|█         | 210/2000 [03:34<1:09:12,  2.32s/it, Loss=0.1070961, Gaussian number=182686, print grad=0.0034832567907869816, Depth Loss=0.0000000]
Training progress:  11%|█         | 220/2000 [03:34<51:23,  1.73s/it, Loss=0.1070961, Gaussian number=182686, print grad=0.0034832567907869816, Depth Loss=0.0000000]  
Training progress:  11%|█         | 220/2000 [03:37<51:23,  1.73s/it, Loss=0.1185462, Gaussian number=182686, print grad=0.003695976221933961, Depth Loss=0.0000000] 
Training progress:  12%|█▏        | 230/2000 [03:37<38:58,  1.32s/it, Loss=0.1185462, Gaussian number=182686, print grad=0.003695976221933961, Depth Loss=0.0000000]
Training progress:  12%|█▏        | 230/2000 [03:41<38:58,  1.32s/it, Loss=0.1420878, Gaussian number=182686, print grad=0.0039031861815601587, Depth Loss=0.0000000]
Training progress:  12%|█▏        | 240/2000 [03:41<30:19,  1.03s/it, Loss=0.1420878, Gaussian number=182686, print grad=0.0039031861815601587, Depth Loss=0.0000000]
Training progress:  12%|█▏        | 240/2000 [03:45<30:19,  1.03s/it, Loss=0.1094900, Gaussian number=182686, print grad=0.004141550045460463, Depth Loss=0.0000000] 
Training progress:  12%|█▎        | 250/2000 [03:45<24:16,  1.20it/s, Loss=0.1094900, Gaussian number=182686, print grad=0.004141550045460463, Depth Loss=0.0000000]
Training progress:  12%|█▎        | 250/2000 [03:48<24:16,  1.20it/s, Loss=0.1236017, Gaussian number=182686, print grad=0.0043617133051157, Depth Loss=0.0000000]  
Training progress:  13%|█▎        | 260/2000 [03:48<20:02,  1.45it/s, Loss=0.1236017, Gaussian number=182686, print grad=0.0043617133051157, Depth Loss=0.0000000]
Training progress:  13%|█▎        | 260/2000 [03:52<20:02,  1.45it/s, Loss=0.0909889, Gaussian number=182686, print grad=0.004591086879372597, Depth Loss=0.0000000]
Training progress:  14%|█▎        | 270/2000 [03:52<17:04,  1.69it/s, Loss=0.0909889, Gaussian number=182686, print grad=0.004591086879372597, Depth Loss=0.0000000]
Training progress:  14%|█▎        | 270/2000 [03:55<17:04,  1.69it/s, Loss=0.1174697, Gaussian number=182686, print grad=0.004875320475548506, Depth Loss=0.0000000]
Training progress:  14%|█▍        | 280/2000 [03:55<14:59,  1.91it/s, Loss=0.1174697, Gaussian number=182686, print grad=0.004875320475548506, Depth Loss=0.0000000]
Training progress:  14%|█▍        | 280/2000 [03:59<14:59,  1.91it/s, Loss=0.1144443, Gaussian number=182686, print grad=0.005127909127622843, Depth Loss=0.0000000]
Training progress:  14%|█▍        | 290/2000 [03:59<13:31,  2.11it/s, Loss=0.1144443, Gaussian number=182686, print grad=0.005127909127622843, Depth Loss=0.0000000]
Training progress:  14%|█▍        | 290/2000 [04:03<13:31,  2.11it/s, Loss=0.1066400, Gaussian number=182686, print grad=0.005379339214414358, Depth Loss=0.0000000]
Training progress:  15%|█▌        | 300/2000 [04:03<12:29,  2.27it/s, Loss=0.1066400, Gaussian number=182686, print grad=0.005379339214414358, Depth Loss=0.0000000]
Training progress:  15%|█▌        | 300/2000 [05:10<12:29,  2.27it/s, Loss=0.0908122, Gaussian number=182686, print grad=0.005662406794726849, Depth Loss=0.0000000]
Training progress:  16%|█▌        | 310/2000 [05:10<1:05:25,  2.32s/it, Loss=0.0908122, Gaussian number=182686, print grad=0.005662406794726849, Depth Loss=0.0000000]
Training progress:  16%|█▌        | 310/2000 [05:13<1:05:25,  2.32s/it, Loss=0.0940953, Gaussian number=182686, print grad=0.005848534405231476, Depth Loss=0.0000000]
Training progress:  16%|█▌        | 320/2000 [05:13<48:32,  1.73s/it, Loss=0.0940953, Gaussian number=182686, print grad=0.005848534405231476, Depth Loss=0.0000000]  
Training progress:  16%|█▌        | 320/2000 [05:17<48:32,  1.73s/it, Loss=0.1224545, Gaussian number=182686, print grad=0.006090486887842417, Depth Loss=0.0000000]
Training progress:  16%|█▋        | 330/2000 [05:17<36:47,  1.32s/it, Loss=0.1224545, Gaussian number=182686, print grad=0.006090486887842417, Depth Loss=0.0000000]
Training progress:  16%|█▋        | 330/2000 [05:21<36:47,  1.32s/it, Loss=0.0920181, Gaussian number=182686, print grad=0.006356155499815941, Depth Loss=0.0000000]
Training progress:  17%|█▋        | 340/2000 [05:21<28:35,  1.03s/it, Loss=0.0920181, Gaussian number=182686, print grad=0.006356155499815941, Depth Loss=0.0000000]
Training progress:  17%|█▋        | 340/2000 [05:24<28:35,  1.03s/it, Loss=0.0950607, Gaussian number=182686, print grad=0.006615365389734507, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 350/2000 [05:24<22:51,  1.20it/s, Loss=0.0950607, Gaussian number=182686, print grad=0.006615365389734507, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 350/2000 [05:28<22:51,  1.20it/s, Loss=0.0908309, Gaussian number=182686, print grad=0.0069283368065953255, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 360/2000 [05:28<18:52,  1.45it/s, Loss=0.0908309, Gaussian number=182686, print grad=0.0069283368065953255, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 360/2000 [05:31<18:52,  1.45it/s, Loss=0.0923907, Gaussian number=182686, print grad=0.00720544159412384, Depth Loss=0.0000000]  
Training progress:  18%|█▊        | 370/2000 [05:31<16:04,  1.69it/s, Loss=0.0923907, Gaussian number=182686, print grad=0.00720544159412384, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 370/2000 [05:35<16:04,  1.69it/s, Loss=0.1178944, Gaussian number=182686, print grad=0.00742573756724596, Depth Loss=0.0000000]
Training progress:  19%|█▉        | 380/2000 [05:35<14:05,  1.92it/s, Loss=0.1178944, Gaussian number=182686, print grad=0.00742573756724596, Depth Loss=0.0000000]
Training progress:  19%|█▉        | 380/2000 [05:39<14:05,  1.92it/s, Loss=0.1083410, Gaussian number=182686, print grad=0.007697774097323418, Depth Loss=0.0000000]
Training progress:  20%|█▉        | 390/2000 [05:39<12:42,  2.11it/s, Loss=0.1083410, Gaussian number=182686, print grad=0.007697774097323418, Depth Loss=0.0000000]
Training progress:  20%|█▉        | 390/2000 [05:42<12:42,  2.11it/s, Loss=0.1269735, Gaussian number=182686, print grad=0.007945967838168144, Depth Loss=0.0000000]
Training progress:  20%|██        | 400/2000 [05:42<11:42,  2.28it/s, Loss=0.1269735, Gaussian number=182686, print grad=0.007945967838168144, Depth Loss=0.0000000]
Training progress:  20%|██        | 400/2000 [05:46<11:42,  2.28it/s, Loss=0.1085814, Gaussian number=182686, print grad=0.008260229602456093, Depth Loss=0.0000000]
Training progress:  20%|██        | 410/2000 [05:46<11:00,  2.41it/s, Loss=0.1085814, Gaussian number=182686, print grad=0.008260229602456093, Depth Loss=0.0000000]
Training progress:  20%|██        | 410/2000 [05:49<11:00,  2.41it/s, Loss=0.0975217, Gaussian number=182686, print grad=0.008553434163331985, Depth Loss=0.0000000]
Training progress:  21%|██        | 420/2000 [05:49<10:30,  2.51it/s, Loss=0.0975217, Gaussian number=182686, print grad=0.008553434163331985, Depth Loss=0.0000000]
Training progress:  21%|██        | 420/2000 [05:53<10:30,  2.51it/s, Loss=0.1200306, Gaussian number=182686, print grad=0.008857769891619682, Depth Loss=0.0000000]
Training progress:  22%|██▏       | 430/2000 [05:53<10:08,  2.58it/s, Loss=0.1200306, Gaussian number=182686, print grad=0.008857769891619682, Depth Loss=0.0000000]
Training progress:  22%|██▏       | 430/2000 [05:57<10:08,  2.58it/s, Loss=0.0959867, Gaussian number=182686, print grad=0.00914212130010128, Depth Loss=0.0000000] 
Training progress:  22%|██▏       | 440/2000 [05:57<09:50,  2.64it/s, Loss=0.0959867, Gaussian number=182686, print grad=0.00914212130010128, Depth Loss=0.0000000]
Training progress:  22%|██▏       | 440/2000 [06:00<09:50,  2.64it/s, Loss=0.1063168, Gaussian number=182686, print grad=0.009445791132748127, Depth Loss=0.0000000]
Training progress:  22%|██▎       | 450/2000 [06:00<09:38,  2.68it/s, Loss=0.1063168, Gaussian number=182686, print grad=0.009445791132748127, Depth Loss=0.0000000]
Training progress:  22%|██▎       | 450/2000 [06:04<09:38,  2.68it/s, Loss=0.1077120, Gaussian number=182686, print grad=0.009734129533171654, Depth Loss=0.0000000]
Training progress:  23%|██▎       | 460/2000 [06:04<09:29,  2.71it/s, Loss=0.1077120, Gaussian number=182686, print grad=0.009734129533171654, Depth Loss=0.0000000]
Training progress:  23%|██▎       | 460/2000 [06:07<09:29,  2.71it/s, Loss=0.1294435, Gaussian number=182686, print grad=0.010004078969359398, Depth Loss=0.0000000]
Training progress:  24%|██▎       | 470/2000 [06:07<09:21,  2.73it/s, Loss=0.1294435, Gaussian number=182686, print grad=0.010004078969359398, Depth Loss=0.0000000]
Training progress:  24%|██▎       | 470/2000 [06:11<09:21,  2.73it/s, Loss=0.0882279, Gaussian number=182686, print grad=0.010309593752026558, Depth Loss=0.0000000]
Training progress:  24%|██▍       | 480/2000 [06:11<09:14,  2.74it/s, Loss=0.0882279, Gaussian number=182686, print grad=0.010309593752026558, Depth Loss=0.0000000]
Training progress:  24%|██▍       | 480/2000 [06:15<09:14,  2.74it/s, Loss=0.0940495, Gaussian number=182686, print grad=0.010589665733277798, Depth Loss=0.0000000]
Training progress:  24%|██▍       | 490/2000 [06:15<09:09,  2.75it/s, Loss=0.0940495, Gaussian number=182686, print grad=0.010589665733277798, Depth Loss=0.0000000]
Training progress:  24%|██▍       | 490/2000 [06:18<09:09,  2.75it/s, Loss=0.0767924, Gaussian number=182686, print grad=0.010877605527639389, Depth Loss=0.0000000]
Training progress:  25%|██▌       | 500/2000 [06:18<09:03,  2.76it/s, Loss=0.0767924, Gaussian number=182686, print grad=0.010877605527639389, Depth Loss=0.0000000]
Training progress:  25%|██▌       | 500/2000 [07:25<09:03,  2.76it/s, Loss=0.0890111, Gaussian number=182686, print grad=0.01117213536053896, Depth Loss=0.0000000] 
Training progress:  26%|██▌       | 510/2000 [07:25<56:14,  2.27s/it, Loss=0.0890111, Gaussian number=182686, print grad=0.01117213536053896, Depth Loss=0.0000000]
Training progress:  26%|██▌       | 510/2000 [07:29<56:14,  2.27s/it, Loss=0.0913858, Gaussian number=182686, print grad=0.011484749615192413, Depth Loss=0.0000000]
Training progress:  26%|██▌       | 520/2000 [07:29<41:45,  1.69s/it, Loss=0.0913858, Gaussian number=182686, print grad=0.011484749615192413, Depth Loss=0.0000000]
Training progress:  26%|██▌       | 520/2000 [07:32<41:45,  1.69s/it, Loss=0.0739642, Gaussian number=182686, print grad=0.011745086871087551, Depth Loss=0.0000000]
Training progress:  26%|██▋       | 530/2000 [07:32<31:39,  1.29s/it, Loss=0.0739642, Gaussian number=182686, print grad=0.011745086871087551, Depth Loss=0.0000000]
Training progress:  26%|██▋       | 530/2000 [07:36<31:39,  1.29s/it, Loss=0.0995385, Gaussian number=182686, print grad=0.012037415988743305, Depth Loss=0.0000000]
Training progress:  27%|██▋       | 540/2000 [07:36<24:37,  1.01s/it, Loss=0.0995385, Gaussian number=182686, print grad=0.012037415988743305, Depth Loss=0.0000000]
Training progress:  27%|██▋       | 540/2000 [07:40<24:37,  1.01s/it, Loss=0.0951900, Gaussian number=182686, print grad=0.012354771606624126, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 550/2000 [07:40<19:43,  1.23it/s, Loss=0.0951900, Gaussian number=182686, print grad=0.012354771606624126, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 550/2000 [07:43<19:43,  1.23it/s, Loss=0.0773806, Gaussian number=182686, print grad=0.012657016515731812, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 560/2000 [07:43<16:17,  1.47it/s, Loss=0.0773806, Gaussian number=182686, print grad=0.012657016515731812, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 560/2000 [07:47<16:17,  1.47it/s, Loss=0.0995606, Gaussian number=182686, print grad=0.012999769300222397, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 570/2000 [07:47<13:54,  1.71it/s, Loss=0.0995606, Gaussian number=182686, print grad=0.012999769300222397, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 570/2000 [07:50<13:54,  1.71it/s, Loss=0.0858856, Gaussian number=182686, print grad=0.013299304060637951, Depth Loss=0.0000000]
Training progress:  29%|██▉       | 580/2000 [07:50<12:13,  1.94it/s, Loss=0.0858856, Gaussian number=182686, print grad=0.013299304060637951, Depth Loss=0.0000000]
Training progress:  29%|██▉       | 580/2000 [07:54<12:13,  1.94it/s, Loss=0.0972119, Gaussian number=182686, print grad=0.013613343238830566, Depth Loss=0.0000000]
Training progress:  30%|██▉       | 590/2000 [07:54<11:01,  2.13it/s, Loss=0.0972119, Gaussian number=182686, print grad=0.013613343238830566, Depth Loss=0.0000000]
Training progress:  30%|██▉       | 590/2000 [07:58<11:01,  2.13it/s, Loss=0.0995541, Gaussian number=182686, print grad=0.013903883285820484, Depth Loss=0.0000000]
Training progress:  30%|███       | 600/2000 [07:58<10:10,  2.29it/s, Loss=0.0995541, Gaussian number=182686, print grad=0.013903883285820484, Depth Loss=0.0000000]
Training progress:  30%|███       | 600/2000 [08:02<10:10,  2.29it/s, Loss=0.0877553, Gaussian number=184665, print grad=0.0003007250197697431, Depth Loss=0.0000000]
Training progress:  30%|███       | 610/2000 [08:02<09:52,  2.35it/s, Loss=0.0877553, Gaussian number=184665, print grad=0.0003007250197697431, Depth Loss=0.0000000]
Training progress:  30%|███       | 610/2000 [08:05<09:52,  2.35it/s, Loss=0.1132403, Gaussian number=184665, print grad=0.0006487988284789026, Depth Loss=0.0000000]
Training progress:  31%|███       | 620/2000 [08:05<09:19,  2.47it/s, Loss=0.1132403, Gaussian number=184665, print grad=0.0006487988284789026, Depth Loss=0.0000000]
Training progress:  31%|███       | 620/2000 [08:09<09:19,  2.47it/s, Loss=0.0816939, Gaussian number=184665, print grad=0.0009296079515479505, Depth Loss=0.0000000]
Training progress:  32%|███▏      | 630/2000 [08:09<08:56,  2.55it/s, Loss=0.0816939, Gaussian number=184665, print grad=0.0009296079515479505, Depth Loss=0.0000000]
Training progress:  32%|███▏      | 630/2000 [08:12<08:56,  2.55it/s, Loss=0.0878100, Gaussian number=184665, print grad=0.0013044646475464106, Depth Loss=0.0000000]
Training progress:  32%|███▏      | 640/2000 [08:12<08:38,  2.62it/s, Loss=0.0878100, Gaussian number=184665, print grad=0.0013044646475464106, Depth Loss=0.0000000]
Training progress:  32%|███▏      | 640/2000 [08:16<08:38,  2.62it/s, Loss=0.0992351, Gaussian number=184665, print grad=0.0015801133122295141, Depth Loss=0.0000000]
Training progress:  32%|███▎      | 650/2000 [08:16<08:25,  2.67it/s, Loss=0.0992351, Gaussian number=184665, print grad=0.0015801133122295141, Depth Loss=0.0000000]
Training progress:  32%|███▎      | 650/2000 [08:20<08:25,  2.67it/s, Loss=0.1032707, Gaussian number=184665, print grad=0.0019225929863750935, Depth Loss=0.0000000]
Training progress:  33%|███▎      | 660/2000 [08:20<08:15,  2.71it/s, Loss=0.1032707, Gaussian number=184665, print grad=0.0019225929863750935, Depth Loss=0.0000000]
Training progress:  33%|███▎      | 660/2000 [08:23<08:15,  2.71it/s, Loss=0.0887892, Gaussian number=184665, print grad=0.0022373388055711985, Depth Loss=0.0000000]
Training progress:  34%|███▎      | 670/2000 [08:23<08:06,  2.73it/s, Loss=0.0887892, Gaussian number=184665, print grad=0.0022373388055711985, Depth Loss=0.0000000]
Training progress:  34%|███▎      | 670/2000 [08:27<08:06,  2.73it/s, Loss=0.0844023, Gaussian number=184665, print grad=0.002591419732198119, Depth Loss=0.0000000] 
Training progress:  34%|███▍      | 680/2000 [08:27<07:59,  2.75it/s, Loss=0.0844023, Gaussian number=184665, print grad=0.002591419732198119, Depth Loss=0.0000000]
Training progress:  34%|███▍      | 680/2000 [08:30<07:59,  2.75it/s, Loss=0.0989832, Gaussian number=184665, print grad=0.0029003634117543697, Depth Loss=0.0000000]
Training progress:  34%|███▍      | 690/2000 [08:30<07:53,  2.76it/s, Loss=0.0989832, Gaussian number=184665, print grad=0.0029003634117543697, Depth Loss=0.0000000]
Training progress:  34%|███▍      | 690/2000 [08:34<07:53,  2.76it/s, Loss=0.0999458, Gaussian number=184665, print grad=0.003195740981027484, Depth Loss=0.0000000] 
Training progress:  35%|███▌      | 700/2000 [08:34<07:48,  2.77it/s, Loss=0.0999458, Gaussian number=184665, print grad=0.003195740981027484, Depth Loss=0.0000000]
Training progress:  35%|███▌      | 700/2000 [08:37<07:48,  2.77it/s, Loss=0.0895857, Gaussian number=191845, print grad=0.00028563421801663935, Depth Loss=0.0000000]
Training progress:  36%|███▌      | 710/2000 [08:37<07:43,  2.78it/s, Loss=0.0895857, Gaussian number=191845, print grad=0.00028563421801663935, Depth Loss=0.0000000]
Training progress:  36%|███▌      | 710/2000 [08:41<07:43,  2.78it/s, Loss=0.0811621, Gaussian number=191845, print grad=0.000623879546765238, Depth Loss=0.0000000]  
Training progress:  36%|███▌      | 720/2000 [08:41<07:39,  2.79it/s, Loss=0.0811621, Gaussian number=191845, print grad=0.000623879546765238, Depth Loss=0.0000000]
Training progress:  36%|███▌      | 720/2000 [08:45<07:39,  2.79it/s, Loss=0.1012294, Gaussian number=191845, print grad=0.0009203215595334768, Depth Loss=0.0000000]
Training progress:  36%|███▋      | 730/2000 [08:45<07:34,  2.79it/s, Loss=0.1012294, Gaussian number=191845, print grad=0.0009203215595334768, Depth Loss=0.0000000]
Training progress:  36%|███▋      | 730/2000 [08:48<07:34,  2.79it/s, Loss=0.1259208, Gaussian number=191845, print grad=0.0012973010307177901, Depth Loss=0.0000000]
Training progress:  37%|███▋      | 740/2000 [08:48<07:30,  2.79it/s, Loss=0.1259208, Gaussian number=191845, print grad=0.0012973010307177901, Depth Loss=0.0000000]
Training progress:  37%|███▋      | 740/2000 [08:52<07:30,  2.79it/s, Loss=0.0896176, Gaussian number=191845, print grad=0.0016426017973572016, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 750/2000 [08:52<07:26,  2.80it/s, Loss=0.0896176, Gaussian number=191845, print grad=0.0016426017973572016, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 750/2000 [08:55<07:26,  2.80it/s, Loss=0.0842794, Gaussian number=191845, print grad=0.0019692566711455584, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 760/2000 [08:55<07:22,  2.80it/s, Loss=0.0842794, Gaussian number=191845, print grad=0.0019692566711455584, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 760/2000 [08:59<07:22,  2.80it/s, Loss=0.0785793, Gaussian number=191845, print grad=0.0023105137515813112, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 770/2000 [08:59<07:19,  2.80it/s, Loss=0.0785793, Gaussian number=191845, print grad=0.0023105137515813112, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 770/2000 [09:02<07:19,  2.80it/s, Loss=0.1003693, Gaussian number=191845, print grad=0.002618404570966959, Depth Loss=0.0000000] 
Training progress:  39%|███▉      | 780/2000 [09:02<07:15,  2.80it/s, Loss=0.1003693, Gaussian number=191845, print grad=0.002618404570966959, Depth Loss=0.0000000]
Training progress:  39%|███▉      | 780/2000 [09:06<07:15,  2.80it/s, Loss=0.1144647, Gaussian number=191845, print grad=0.0029368542600423098, Depth Loss=0.0000000]
Training progress:  40%|███▉      | 790/2000 [09:06<07:12,  2.80it/s, Loss=0.1144647, Gaussian number=191845, print grad=0.0029368542600423098, Depth Loss=0.0000000]
Training progress:  40%|███▉      | 790/2000 [09:10<07:12,  2.80it/s, Loss=0.0990773, Gaussian number=191845, print grad=0.003293718909844756, Depth Loss=0.0000000] 
Training progress:  40%|████      | 800/2000 [09:10<07:08,  2.80it/s, Loss=0.0990773, Gaussian number=191845, print grad=0.003293718909844756, Depth Loss=0.0000000]
Training progress:  40%|████      | 800/2000 [09:13<07:08,  2.80it/s, Loss=0.1019205, Gaussian number=199684, print grad=0.00032113329507410526, Depth Loss=0.0000000]
Training progress:  40%|████      | 810/2000 [09:13<07:05,  2.80it/s, Loss=0.1019205, Gaussian number=199684, print grad=0.00032113329507410526, Depth Loss=0.0000000]
Training progress:  40%|████      | 810/2000 [09:17<07:05,  2.80it/s, Loss=0.0966601, Gaussian number=199684, print grad=0.0006454135873354971, Depth Loss=0.0000000] 
Training progress:  41%|████      | 820/2000 [09:17<07:01,  2.80it/s, Loss=0.0966601, Gaussian number=199684, print grad=0.0006454135873354971, Depth Loss=0.0000000]
Training progress:  41%|████      | 820/2000 [09:20<07:01,  2.80it/s, Loss=0.0796029, Gaussian number=199684, print grad=0.0010555406333878636, Depth Loss=0.0000000]
Training progress:  42%|████▏     | 830/2000 [09:20<06:57,  2.80it/s, Loss=0.0796029, Gaussian number=199684, print grad=0.0010555406333878636, Depth Loss=0.0000000]
Training progress:  42%|████▏     | 830/2000 [09:24<06:57,  2.80it/s, Loss=0.0820796, Gaussian number=199684, print grad=0.0013999918010085821, Depth Loss=0.0000000]
Training progress:  42%|████▏     | 840/2000 [09:24<06:53,  2.81it/s, Loss=0.0820796, Gaussian number=199684, print grad=0.0013999918010085821, Depth Loss=0.0000000]
Training progress:  42%|████▏     | 840/2000 [09:27<06:53,  2.81it/s, Loss=0.0901782, Gaussian number=199684, print grad=0.001764975138939917, Depth Loss=0.0000000] 
Training progress:  42%|████▎     | 850/2000 [09:27<06:49,  2.81it/s, Loss=0.0901782, Gaussian number=199684, print grad=0.001764975138939917, Depth Loss=0.0000000]
Training progress:  42%|████▎     | 850/2000 [09:31<06:49,  2.81it/s, Loss=0.0847662, Gaussian number=199684, print grad=0.0020922229159623384, Depth Loss=0.0000000]
Training progress:  43%|████▎     | 860/2000 [09:31<06:46,  2.81it/s, Loss=0.0847662, Gaussian number=199684, print grad=0.0020922229159623384, Depth Loss=0.0000000]
Training progress:  43%|████▎     | 860/2000 [09:34<06:46,  2.81it/s, Loss=0.1015763, Gaussian number=199684, print grad=0.0024193902499973774, Depth Loss=0.0000000]
Training progress:  44%|████▎     | 870/2000 [09:34<06:42,  2.81it/s, Loss=0.1015763, Gaussian number=199684, print grad=0.0024193902499973774, Depth Loss=0.0000000]
Training progress:  44%|████▎     | 870/2000 [09:38<06:42,  2.81it/s, Loss=0.0962970, Gaussian number=199684, print grad=0.002734872279688716, Depth Loss=0.0000000] 
Training progress:  44%|████▍     | 880/2000 [09:38<06:38,  2.81it/s, Loss=0.0962970, Gaussian number=199684, print grad=0.002734872279688716, Depth Loss=0.0000000]
Training progress:  44%|████▍     | 880/2000 [09:42<06:38,  2.81it/s, Loss=0.0750145, Gaussian number=199684, print grad=0.0030832430347800255, Depth Loss=0.0000000]
Training progress:  44%|████▍     | 890/2000 [09:42<06:35,  2.81it/s, Loss=0.0750145, Gaussian number=199684, print grad=0.0030832430347800255, Depth Loss=0.0000000]
Training progress:  44%|████▍     | 890/2000 [09:45<06:35,  2.81it/s, Loss=0.0942388, Gaussian number=199684, print grad=0.0034011618699878454, Depth Loss=0.0000000]
Training progress:  45%|████▌     | 900/2000 [09:45<06:31,  2.81it/s, Loss=0.0942388, Gaussian number=199684, print grad=0.0034011618699878454, Depth Loss=0.0000000]
Training progress:  45%|████▌     | 900/2000 [09:49<06:31,  2.81it/s, Loss=0.0790191, Gaussian number=208544, print grad=0.00030488939955830574, Depth Loss=0.0000000]
Training progress:  46%|████▌     | 910/2000 [09:49<06:27,  2.81it/s, Loss=0.0790191, Gaussian number=208544, print grad=0.00030488939955830574, Depth Loss=0.0000000]
Training progress:  46%|████▌     | 910/2000 [09:52<06:27,  2.81it/s, Loss=0.0921643, Gaussian number=208544, print grad=0.0005890416796319187, Depth Loss=0.0000000] 
Training progress:  46%|████▌     | 920/2000 [09:52<06:23,  2.82it/s, Loss=0.0921643, Gaussian number=208544, print grad=0.0005890416796319187, Depth Loss=0.0000000]
Training progress:  46%|████▌     | 920/2000 [09:56<06:23,  2.82it/s, Loss=0.0984251, Gaussian number=208544, print grad=0.0009770896285772324, Depth Loss=0.0000000]
Training progress:  46%|████▋     | 930/2000 [09:56<06:19,  2.82it/s, Loss=0.0984251, Gaussian number=208544, print grad=0.0009770896285772324, Depth Loss=0.0000000]
Training progress:  46%|████▋     | 930/2000 [09:59<06:19,  2.82it/s, Loss=0.0885311, Gaussian number=208544, print grad=0.0012920503504574299, Depth Loss=0.0000000]
Training progress:  47%|████▋     | 940/2000 [09:59<06:16,  2.82it/s, Loss=0.0885311, Gaussian number=208544, print grad=0.0012920503504574299, Depth Loss=0.0000000]
Training progress:  47%|████▋     | 940/2000 [10:03<06:16,  2.82it/s, Loss=0.0832523, Gaussian number=208544, print grad=0.0016428397502750158, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 950/2000 [10:03<06:12,  2.82it/s, Loss=0.0832523, Gaussian number=208544, print grad=0.0016428397502750158, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 950/2000 [10:06<06:12,  2.82it/s, Loss=0.0855477, Gaussian number=208544, print grad=0.001961448695510626, Depth Loss=0.0000000] 
Training progress:  48%|████▊     | 960/2000 [10:06<06:08,  2.82it/s, Loss=0.0855477, Gaussian number=208544, print grad=0.001961448695510626, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 960/2000 [10:10<06:08,  2.82it/s, Loss=0.1065138, Gaussian number=208544, print grad=0.002310664625838399, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 970/2000 [10:10<06:05,  2.82it/s, Loss=0.1065138, Gaussian number=208544, print grad=0.002310664625838399, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 970/2000 [10:14<06:05,  2.82it/s, Loss=0.0726007, Gaussian number=208544, print grad=0.00263784802518785, Depth Loss=0.0000000] 
Training progress:  49%|████▉     | 980/2000 [10:14<06:01,  2.82it/s, Loss=0.0726007, Gaussian number=208544, print grad=0.00263784802518785, Depth Loss=0.0000000]
Training progress:  49%|████▉     | 980/2000 [10:17<06:01,  2.82it/s, Loss=0.0734214, Gaussian number=208544, print grad=0.0029260527808219194, Depth Loss=0.0000000]
Training progress:  50%|████▉     | 990/2000 [10:17<05:58,  2.82it/s, Loss=0.0734214, Gaussian number=208544, print grad=0.0029260527808219194, Depth Loss=0.0000000]
Training progress:  50%|████▉     | 990/2000 [10:21<05:58,  2.82it/s, Loss=0.0960465, Gaussian number=208544, print grad=0.003199262311682105, Depth Loss=0.0000000] 
Training progress:  50%|█████     | 1000/2000 [10:21<05:54,  2.82it/s, Loss=0.0960465, Gaussian number=208544, print grad=0.003199262311682105, Depth Loss=0.0000000]
Training progress:  50%|█████     | 1000/2000 [11:27<05:54,  2.82it/s, Loss=0.0905184, Gaussian number=217154, print grad=0.0002778818306978792, Depth Loss=0.0000000]
Training progress:  50%|█████     | 1010/2000 [11:27<37:12,  2.25s/it, Loss=0.0905184, Gaussian number=217154, print grad=0.0002778818306978792, Depth Loss=0.0000000]
Training progress:  50%|█████     | 1010/2000 [11:31<37:12,  2.25s/it, Loss=0.1125396, Gaussian number=217154, print grad=0.0006600001361221075, Depth Loss=0.0000000]
Training progress:  51%|█████     | 1020/2000 [11:31<27:31,  1.69s/it, Loss=0.1125396, Gaussian number=217154, print grad=0.0006600001361221075, Depth Loss=0.0000000]
Training progress:  51%|█████     | 1020/2000 [11:35<27:31,  1.69s/it, Loss=0.0928112, Gaussian number=217154, print grad=0.0009959585731849074, Depth Loss=0.0000000]
Training progress:  52%|█████▏    | 1030/2000 [11:35<20:48,  1.29s/it, Loss=0.0928112, Gaussian number=217154, print grad=0.0009959585731849074, Depth Loss=0.0000000]
Training progress:  52%|█████▏    | 1030/2000 [11:38<20:48,  1.29s/it, Loss=0.0944378, Gaussian number=217154, print grad=0.0013675241498276591, Depth Loss=0.0000000]
Training progress:  52%|█████▏    | 1040/2000 [11:38<16:08,  1.01s/it, Loss=0.0944378, Gaussian number=217154, print grad=0.0013675241498276591, Depth Loss=0.0000000]
Training progress:  52%|█████▏    | 1040/2000 [11:42<16:08,  1.01s/it, Loss=0.0848187, Gaussian number=217154, print grad=0.0016556549817323685, Depth Loss=0.0000000]
Training progress:  52%|█████▎    | 1050/2000 [11:42<12:52,  1.23it/s, Loss=0.0848187, Gaussian number=217154, print grad=0.0016556549817323685, Depth Loss=0.0000000]
Training progress:  52%|█████▎    | 1050/2000 [11:45<12:52,  1.23it/s, Loss=0.0844874, Gaussian number=217154, print grad=0.0019766492769122124, Depth Loss=0.0000000]
Training progress:  53%|█████▎    | 1060/2000 [11:45<10:36,  1.48it/s, Loss=0.0844874, Gaussian number=217154, print grad=0.0019766492769122124, Depth Loss=0.0000000]
Training progress:  53%|█████▎    | 1060/2000 [11:49<10:36,  1.48it/s, Loss=0.0693288, Gaussian number=217154, print grad=0.002343387808650732, Depth Loss=0.0000000] 
Training progress:  54%|█████▎    | 1070/2000 [11:49<09:00,  1.72it/s, Loss=0.0693288, Gaussian number=217154, print grad=0.002343387808650732, Depth Loss=0.0000000]
Training progress:  54%|█████▎    | 1070/2000 [11:53<09:00,  1.72it/s, Loss=0.0727877, Gaussian number=217154, print grad=0.0026474366895854473, Depth Loss=0.0000000]
Training progress:  54%|█████▍    | 1080/2000 [11:53<07:53,  1.94it/s, Loss=0.0727877, Gaussian number=217154, print grad=0.0026474366895854473, Depth Loss=0.0000000]
Training progress:  54%|█████▍    | 1080/2000 [11:56<07:53,  1.94it/s, Loss=0.0903000, Gaussian number=217154, print grad=0.0029825244564563036, Depth Loss=0.0000000]
Training progress:  55%|█████▍    | 1090/2000 [11:56<07:05,  2.14it/s, Loss=0.0903000, Gaussian number=217154, print grad=0.0029825244564563036, Depth Loss=0.0000000]
Training progress:  55%|█████▍    | 1090/2000 [12:00<07:05,  2.14it/s, Loss=0.0901801, Gaussian number=217154, print grad=0.00330745754763484, Depth Loss=0.0000000]  
Training progress:  55%|█████▌    | 1100/2000 [12:00<06:31,  2.30it/s, Loss=0.0901801, Gaussian number=217154, print grad=0.00330745754763484, Depth Loss=0.0000000]
Training progress:  55%|█████▌    | 1100/2000 [12:03<06:31,  2.30it/s, Loss=0.0990732, Gaussian number=226547, print grad=0.00028524198569357395, Depth Loss=0.0000000]
Training progress:  56%|█████▌    | 1110/2000 [12:03<06:05,  2.43it/s, Loss=0.0990732, Gaussian number=226547, print grad=0.00028524198569357395, Depth Loss=0.0000000]
Training progress:  56%|█████▌    | 1110/2000 [12:07<06:05,  2.43it/s, Loss=0.0944604, Gaussian number=226547, print grad=0.0006281884852796793, Depth Loss=0.0000000] 
Training progress:  56%|█████▌    | 1120/2000 [12:07<05:47,  2.54it/s, Loss=0.0944604, Gaussian number=226547, print grad=0.0006281884852796793, Depth Loss=0.0000000]
Training progress:  56%|█████▌    | 1120/2000 [12:10<05:47,  2.54it/s, Loss=0.0753292, Gaussian number=226547, print grad=0.0009947814978659153, Depth Loss=0.0000000]
Training progress:  56%|█████▋    | 1130/2000 [12:10<05:32,  2.62it/s, Loss=0.0753292, Gaussian number=226547, print grad=0.0009947814978659153, Depth Loss=0.0000000]
Training progress:  56%|█████▋    | 1130/2000 [12:14<05:32,  2.62it/s, Loss=0.0895200, Gaussian number=226547, print grad=0.0013343211030587554, Depth Loss=0.0000000]
Training progress:  57%|█████▋    | 1140/2000 [12:14<05:21,  2.67it/s, Loss=0.0895200, Gaussian number=226547, print grad=0.0013343211030587554, Depth Loss=0.0000000]
Training progress:  57%|█████▋    | 1140/2000 [12:17<05:21,  2.67it/s, Loss=0.0668196, Gaussian number=226547, print grad=0.0016861606854945421, Depth Loss=0.0000000]
Training progress:  57%|█████▊    | 1150/2000 [12:17<05:13,  2.71it/s, Loss=0.0668196, Gaussian number=226547, print grad=0.0016861606854945421, Depth Loss=0.0000000]
Training progress:  57%|█████▊    | 1150/2000 [12:21<05:13,  2.71it/s, Loss=0.0706648, Gaussian number=226547, print grad=0.0019707914907485247, Depth Loss=0.0000000]
Training progress:  58%|█████▊    | 1160/2000 [12:21<05:06,  2.74it/s, Loss=0.0706648, Gaussian number=226547, print grad=0.0019707914907485247, Depth Loss=0.0000000]
Training progress:  58%|█████▊    | 1160/2000 [12:25<05:06,  2.74it/s, Loss=0.0864783, Gaussian number=226547, print grad=0.0022967492695897818, Depth Loss=0.0000000]
Training progress:  58%|█████▊    | 1170/2000 [12:25<05:00,  2.76it/s, Loss=0.0864783, Gaussian number=226547, print grad=0.0022967492695897818, Depth Loss=0.0000000]
Training progress:  58%|█████▊    | 1170/2000 [12:28<05:00,  2.76it/s, Loss=0.0867433, Gaussian number=226547, print grad=0.002632704097777605, Depth Loss=0.0000000] 
Training progress:  59%|█████▉    | 1180/2000 [12:28<04:55,  2.78it/s, Loss=0.0867433, Gaussian number=226547, print grad=0.002632704097777605, Depth Loss=0.0000000]
Training progress:  59%|█████▉    | 1180/2000 [12:32<04:55,  2.78it/s, Loss=0.0850659, Gaussian number=226547, print grad=0.0029688458889722824, Depth Loss=0.0000000]
Training progress:  60%|█████▉    | 1190/2000 [12:32<04:50,  2.79it/s, Loss=0.0850659, Gaussian number=226547, print grad=0.0029688458889722824, Depth Loss=0.0000000]
Training progress:  60%|█████▉    | 1190/2000 [12:35<04:50,  2.79it/s, Loss=0.0925350, Gaussian number=226547, print grad=0.0032453613821417093, Depth Loss=0.0000000]
Training progress:  60%|██████    | 1200/2000 [12:35<04:45,  2.80it/s, Loss=0.0925350, Gaussian number=226547, print grad=0.0032453613821417093, Depth Loss=0.0000000]
Training progress:  60%|██████    | 1200/2000 [12:39<04:45,  2.80it/s, Loss=0.0776658, Gaussian number=236287, print grad=0.0003137169114779681, Depth Loss=0.0000000]
Training progress:  60%|██████    | 1210/2000 [12:39<04:41,  2.81it/s, Loss=0.0776658, Gaussian number=236287, print grad=0.0003137169114779681, Depth Loss=0.0000000]
Training progress:  60%|██████    | 1210/2000 [12:42<04:41,  2.81it/s, Loss=0.0697152, Gaussian number=236287, print grad=0.0006834551459178329, Depth Loss=0.0000000]
Training progress:  61%|██████    | 1220/2000 [12:42<04:37,  2.81it/s, Loss=0.0697152, Gaussian number=236287, print grad=0.0006834551459178329, Depth Loss=0.0000000]
Training progress:  61%|██████    | 1220/2000 [12:46<04:37,  2.81it/s, Loss=0.0724764, Gaussian number=236287, print grad=0.0010066060349345207, Depth Loss=0.0000000]
Training progress:  62%|██████▏   | 1230/2000 [12:46<04:33,  2.81it/s, Loss=0.0724764, Gaussian number=236287, print grad=0.0010066060349345207, Depth Loss=0.0000000]
Training progress:  62%|██████▏   | 1230/2000 [12:49<04:33,  2.81it/s, Loss=0.0690163, Gaussian number=236287, print grad=0.001359466346912086, Depth Loss=0.0000000] 
Training progress:  62%|██████▏   | 1240/2000 [12:49<04:29,  2.82it/s, Loss=0.0690163, Gaussian number=236287, print grad=0.001359466346912086, Depth Loss=0.0000000]
Training progress:  62%|██████▏   | 1240/2000 [12:53<04:29,  2.82it/s, Loss=0.0692057, Gaussian number=236287, print grad=0.001646467950195074, Depth Loss=0.0000000]
Training progress:  62%|██████▎   | 1250/2000 [12:53<04:26,  2.82it/s, Loss=0.0692057, Gaussian number=236287, print grad=0.001646467950195074, Depth Loss=0.0000000]
Training progress:  62%|██████▎   | 1250/2000 [12:56<04:26,  2.82it/s, Loss=0.0721476, Gaussian number=236287, print grad=0.0019240747205913067, Depth Loss=0.0000000]
Training progress:  63%|██████▎   | 1260/2000 [12:56<04:22,  2.82it/s, Loss=0.0721476, Gaussian number=236287, print grad=0.0019240747205913067, Depth Loss=0.0000000]
Training progress:  63%|██████▎   | 1260/2000 [13:00<04:22,  2.82it/s, Loss=0.0850516, Gaussian number=236287, print grad=0.002251324011012912, Depth Loss=0.0000000] 
Training progress:  64%|██████▎   | 1270/2000 [13:00<04:19,  2.82it/s, Loss=0.0850516, Gaussian number=236287, print grad=0.002251324011012912, Depth Loss=0.0000000]
Training progress:  64%|██████▎   | 1270/2000 [13:04<04:19,  2.82it/s, Loss=0.0869415, Gaussian number=236287, print grad=0.002536170417442918, Depth Loss=0.0000000]
Training progress:  64%|██████▍   | 1280/2000 [13:04<04:15,  2.82it/s, Loss=0.0869415, Gaussian number=236287, print grad=0.002536170417442918, Depth Loss=0.0000000]
Training progress:  64%|██████▍   | 1280/2000 [13:07<04:15,  2.82it/s, Loss=0.0674846, Gaussian number=236287, print grad=0.0028717906679958105, Depth Loss=0.0000000]
Training progress:  64%|██████▍   | 1290/2000 [13:07<04:12,  2.82it/s, Loss=0.0674846, Gaussian number=236287, print grad=0.0028717906679958105, Depth Loss=0.0000000]
Training progress:  64%|██████▍   | 1290/2000 [13:11<04:12,  2.82it/s, Loss=0.1015550, Gaussian number=236287, print grad=0.003170281182974577, Depth Loss=0.0000000] 
Training progress:  65%|██████▌   | 1300/2000 [13:11<04:08,  2.81it/s, Loss=0.1015550, Gaussian number=236287, print grad=0.003170281182974577, Depth Loss=0.0000000]
Training progress:  65%|██████▌   | 1300/2000 [13:14<04:08,  2.81it/s, Loss=0.0977261, Gaussian number=246609, print grad=0.00033900546259246767, Depth Loss=0.0000000]
Training progress:  66%|██████▌   | 1310/2000 [13:14<04:05,  2.81it/s, Loss=0.0977261, Gaussian number=246609, print grad=0.00033900546259246767, Depth Loss=0.0000000]
Training progress:  66%|██████▌   | 1310/2000 [13:18<04:05,  2.81it/s, Loss=0.0980671, Gaussian number=246609, print grad=0.000654773146379739, Depth Loss=0.0000000]  
Training progress:  66%|██████▌   | 1320/2000 [13:18<04:02,  2.80it/s, Loss=0.0980671, Gaussian number=246609, print grad=0.000654773146379739, Depth Loss=0.0000000]
Training progress:  66%|██████▌   | 1320/2000 [13:21<04:02,  2.80it/s, Loss=0.0787739, Gaussian number=246609, print grad=0.0009957058355212212, Depth Loss=0.0000000]
Training progress:  66%|██████▋   | 1330/2000 [13:21<03:59,  2.80it/s, Loss=0.0787739, Gaussian number=246609, print grad=0.0009957058355212212, Depth Loss=0.0000000]
Training progress:  66%|██████▋   | 1330/2000 [13:25<03:59,  2.80it/s, Loss=0.0820935, Gaussian number=246609, print grad=0.001320422044955194, Depth Loss=0.0000000] 
Training progress:  67%|██████▋   | 1340/2000 [13:25<03:55,  2.80it/s, Loss=0.0820935, Gaussian number=246609, print grad=0.001320422044955194, Depth Loss=0.0000000]
Training progress:  67%|██████▋   | 1340/2000 [13:29<03:55,  2.80it/s, Loss=0.1065051, Gaussian number=246609, print grad=0.001589520717971027, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1350/2000 [13:29<03:52,  2.80it/s, Loss=0.1065051, Gaussian number=246609, print grad=0.001589520717971027, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1350/2000 [13:32<03:52,  2.80it/s, Loss=0.0649679, Gaussian number=246609, print grad=0.001878700451925397, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1360/2000 [13:32<03:48,  2.80it/s, Loss=0.0649679, Gaussian number=246609, print grad=0.001878700451925397, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1360/2000 [13:36<03:48,  2.80it/s, Loss=0.1172303, Gaussian number=246609, print grad=0.002222237177193165, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1370/2000 [13:36<03:45,  2.80it/s, Loss=0.1172303, Gaussian number=246609, print grad=0.002222237177193165, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1370/2000 [13:39<03:45,  2.80it/s, Loss=0.0788570, Gaussian number=246609, print grad=0.0025069592520594597, Depth Loss=0.0000000]
Training progress:  69%|██████▉   | 1380/2000 [13:39<03:41,  2.80it/s, Loss=0.0788570, Gaussian number=246609, print grad=0.0025069592520594597, Depth Loss=0.0000000]
Training progress:  69%|██████▉   | 1380/2000 [13:43<03:41,  2.80it/s, Loss=0.0729762, Gaussian number=246609, print grad=0.0027969428338110447, Depth Loss=0.0000000]
Training progress:  70%|██████▉   | 1390/2000 [13:43<03:37,  2.80it/s, Loss=0.0729762, Gaussian number=246609, print grad=0.0027969428338110447, Depth Loss=0.0000000]
Training progress:  70%|██████▉   | 1390/2000 [13:46<03:37,  2.80it/s, Loss=0.0803762, Gaussian number=246609, print grad=0.0030956906266510487, Depth Loss=0.0000000]
Training progress:  70%|███████   | 1400/2000 [13:46<03:34,  2.80it/s, Loss=0.0803762, Gaussian number=246609, print grad=0.0030956906266510487, Depth Loss=0.0000000]
Training progress:  70%|███████   | 1400/2000 [13:50<03:34,  2.80it/s, Loss=0.0932315, Gaussian number=256684, print grad=0.00033166081993840635, Depth Loss=0.0000000]
Training progress:  70%|███████   | 1410/2000 [13:50<03:30,  2.80it/s, Loss=0.0932315, Gaussian number=256684, print grad=0.00033166081993840635, Depth Loss=0.0000000]
Training progress:  70%|███████   | 1410/2000 [13:54<03:30,  2.80it/s, Loss=0.0806923, Gaussian number=256684, print grad=0.0006598511827178299, Depth Loss=0.0000000] 
Training progress:  71%|███████   | 1420/2000 [13:54<03:26,  2.80it/s, Loss=0.0806923, Gaussian number=256684, print grad=0.0006598511827178299, Depth Loss=0.0000000]
Training progress:  71%|███████   | 1420/2000 [13:57<03:26,  2.80it/s, Loss=0.0804024, Gaussian number=256684, print grad=0.001015002140775323, Depth Loss=0.0000000] 
Training progress:  72%|███████▏  | 1430/2000 [13:57<03:23,  2.80it/s, Loss=0.0804024, Gaussian number=256684, print grad=0.001015002140775323, Depth Loss=0.0000000]
Training progress:  72%|███████▏  | 1430/2000 [14:01<03:23,  2.80it/s, Loss=0.0768583, Gaussian number=256684, print grad=0.0012957199942320585, Depth Loss=0.0000000]
Training progress:  72%|███████▏  | 1440/2000 [14:01<03:19,  2.81it/s, Loss=0.0768583, Gaussian number=256684, print grad=0.0012957199942320585, Depth Loss=0.0000000]
Training progress:  72%|███████▏  | 1440/2000 [14:04<03:19,  2.81it/s, Loss=0.0664210, Gaussian number=256684, print grad=0.0015825465088710189, Depth Loss=0.0000000]
Training progress:  72%|███████▎  | 1450/2000 [14:04<03:15,  2.81it/s, Loss=0.0664210, Gaussian number=256684, print grad=0.0015825465088710189, Depth Loss=0.0000000]
Training progress:  72%|███████▎  | 1450/2000 [14:08<03:15,  2.81it/s, Loss=0.0611985, Gaussian number=256684, print grad=0.0018808775348588824, Depth Loss=0.0000000]
Training progress:  73%|███████▎  | 1460/2000 [14:08<03:12,  2.80it/s, Loss=0.0611985, Gaussian number=256684, print grad=0.0018808775348588824, Depth Loss=0.0000000]
Training progress:  73%|███████▎  | 1460/2000 [14:11<03:12,  2.80it/s, Loss=0.0832970, Gaussian number=256684, print grad=0.00218900921754539, Depth Loss=0.0000000]  
Training progress:  74%|███████▎  | 1470/2000 [14:11<03:08,  2.81it/s, Loss=0.0832970, Gaussian number=256684, print grad=0.00218900921754539, Depth Loss=0.0000000]
Training progress:  74%|███████▎  | 1470/2000 [14:15<03:08,  2.81it/s, Loss=0.0840251, Gaussian number=256684, print grad=0.0025117213372141123, Depth Loss=0.0000000]
Training progress:  74%|███████▍  | 1480/2000 [14:15<03:05,  2.81it/s, Loss=0.0840251, Gaussian number=256684, print grad=0.0025117213372141123, Depth Loss=0.0000000]
Training progress:  74%|███████▍  | 1480/2000 [14:19<03:05,  2.81it/s, Loss=0.0874477, Gaussian number=256684, print grad=0.002820492722094059, Depth Loss=0.0000000] 
Training progress:  74%|███████▍  | 1490/2000 [14:19<03:01,  2.81it/s, Loss=0.0874477, Gaussian number=256684, print grad=0.002820492722094059, Depth Loss=0.0000000]
Training progress:  74%|███████▍  | 1490/2000 [14:22<03:01,  2.81it/s, Loss=0.0832093, Gaussian number=256684, print grad=0.0031341922003775835, Depth Loss=0.0000000]
Training progress:  75%|███████▌  | 1500/2000 [14:22<02:58,  2.81it/s, Loss=0.0832093, Gaussian number=256684, print grad=0.0031341922003775835, Depth Loss=0.0000000]
Training progress:  75%|███████▌  | 1500/2000 [15:29<02:58,  2.81it/s, Loss=0.0977559, Gaussian number=266587, print grad=0.0002959308330900967, Depth Loss=0.0000000]
Training progress:  76%|███████▌  | 1510/2000 [15:29<18:27,  2.26s/it, Loss=0.0977559, Gaussian number=266587, print grad=0.0002959308330900967, Depth Loss=0.0000000]
Training progress:  76%|███████▌  | 1510/2000 [15:33<18:27,  2.26s/it, Loss=0.0879494, Gaussian number=266587, print grad=0.0005884216516278684, Depth Loss=0.0000000]
Training progress:  76%|███████▌  | 1520/2000 [15:33<13:30,  1.69s/it, Loss=0.0879494, Gaussian number=266587, print grad=0.0005884216516278684, Depth Loss=0.0000000]
Training progress:  76%|███████▌  | 1520/2000 [15:36<13:30,  1.69s/it, Loss=0.0527372, Gaussian number=266587, print grad=0.0009401277056895196, Depth Loss=0.0000000]
Training progress:  76%|███████▋  | 1530/2000 [15:36<10:04,  1.29s/it, Loss=0.0527372, Gaussian number=266587, print grad=0.0009401277056895196, Depth Loss=0.0000000]
Training progress:  76%|███████▋  | 1530/2000 [15:40<10:04,  1.29s/it, Loss=0.0699401, Gaussian number=266587, print grad=0.0012597147142514586, Depth Loss=0.0000000]
Training progress:  77%|███████▋  | 1540/2000 [15:40<07:43,  1.01s/it, Loss=0.0699401, Gaussian number=266587, print grad=0.0012597147142514586, Depth Loss=0.0000000]
Training progress:  77%|███████▋  | 1540/2000 [15:43<07:43,  1.01s/it, Loss=0.0798128, Gaussian number=266587, print grad=0.0015781846595928073, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1550/2000 [15:43<06:04,  1.23it/s, Loss=0.0798128, Gaussian number=266587, print grad=0.0015781846595928073, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1550/2000 [15:47<06:04,  1.23it/s, Loss=0.0830516, Gaussian number=266587, print grad=0.0019213373307138681, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1560/2000 [15:47<04:56,  1.49it/s, Loss=0.0830516, Gaussian number=266587, print grad=0.0019213373307138681, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1560/2000 [15:50<04:56,  1.49it/s, Loss=0.0726240, Gaussian number=266587, print grad=0.002245980780571699, Depth Loss=0.0000000] 
Training progress:  78%|███████▊  | 1570/2000 [15:50<04:08,  1.73it/s, Loss=0.0726240, Gaussian number=266587, print grad=0.002245980780571699, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1570/2000 [15:54<04:08,  1.73it/s, Loss=0.0545384, Gaussian number=266587, print grad=0.002499702852219343, Depth Loss=0.0000000]
Training progress:  79%|███████▉  | 1580/2000 [15:54<03:34,  1.96it/s, Loss=0.0545384, Gaussian number=266587, print grad=0.002499702852219343, Depth Loss=0.0000000]
Training progress:  79%|███████▉  | 1580/2000 [15:57<03:34,  1.96it/s, Loss=0.0771318, Gaussian number=266587, print grad=0.0027869802433997393, Depth Loss=0.0000000]
Training progress:  80%|███████▉  | 1590/2000 [15:57<03:09,  2.16it/s, Loss=0.0771318, Gaussian number=266587, print grad=0.0027869802433997393, Depth Loss=0.0000000]
Training progress:  80%|███████▉  | 1590/2000 [16:01<03:09,  2.16it/s, Loss=0.0704866, Gaussian number=266587, print grad=0.0031080131884664297, Depth Loss=0.0000000]
Training progress:  80%|████████  | 1600/2000 [16:01<02:51,  2.33it/s, Loss=0.0704866, Gaussian number=266587, print grad=0.0031080131884664297, Depth Loss=0.0000000]
Training progress:  80%|████████  | 1600/2000 [16:04<02:51,  2.33it/s, Loss=0.0855289, Gaussian number=276673, print grad=0.00031095551094040275, Depth Loss=0.0000000]
Training progress:  80%|████████  | 1610/2000 [16:04<02:38,  2.46it/s, Loss=0.0855289, Gaussian number=276673, print grad=0.00031095551094040275, Depth Loss=0.0000000]
Training progress:  80%|████████  | 1610/2000 [16:08<02:38,  2.46it/s, Loss=0.0831123, Gaussian number=276673, print grad=0.0006782337441109121, Depth Loss=0.0000000] 
Training progress:  81%|████████  | 1620/2000 [16:08<02:28,  2.56it/s, Loss=0.0831123, Gaussian number=276673, print grad=0.0006782337441109121, Depth Loss=0.0000000]
Training progress:  81%|████████  | 1620/2000 [16:11<02:28,  2.56it/s, Loss=0.0721484, Gaussian number=276673, print grad=0.000986733241006732, Depth Loss=0.0000000] 
Training progress:  82%|████████▏ | 1630/2000 [16:11<02:20,  2.64it/s, Loss=0.0721484, Gaussian number=276673, print grad=0.000986733241006732, Depth Loss=0.0000000]
Training progress:  82%|████████▏ | 1630/2000 [16:15<02:20,  2.64it/s, Loss=0.0571019, Gaussian number=276673, print grad=0.0012896922416985035, Depth Loss=0.0000000]
Training progress:  82%|████████▏ | 1640/2000 [16:15<02:13,  2.70it/s, Loss=0.0571019, Gaussian number=276673, print grad=0.0012896922416985035, Depth Loss=0.0000000]
Training progress:  82%|████████▏ | 1640/2000 [16:18<02:13,  2.70it/s, Loss=0.0715407, Gaussian number=276673, print grad=0.001589929684996605, Depth Loss=0.0000000] 
Training progress:  82%|████████▎ | 1650/2000 [16:18<02:07,  2.74it/s, Loss=0.0715407, Gaussian number=276673, print grad=0.001589929684996605, Depth Loss=0.0000000]
Training progress:  82%|████████▎ | 1650/2000 [16:22<02:07,  2.74it/s, Loss=0.0705758, Gaussian number=276673, print grad=0.0018667104886844754, Depth Loss=0.0000000]
Training progress:  83%|████████▎ | 1660/2000 [16:22<02:02,  2.77it/s, Loss=0.0705758, Gaussian number=276673, print grad=0.0018667104886844754, Depth Loss=0.0000000]
Training progress:  83%|████████▎ | 1660/2000 [16:25<02:02,  2.77it/s, Loss=0.0664790, Gaussian number=276673, print grad=0.0021546194329857826, Depth Loss=0.0000000]
Training progress:  84%|████████▎ | 1670/2000 [16:25<01:58,  2.79it/s, Loss=0.0664790, Gaussian number=276673, print grad=0.0021546194329857826, Depth Loss=0.0000000]
Training progress:  84%|████████▎ | 1670/2000 [16:29<01:58,  2.79it/s, Loss=0.0621471, Gaussian number=276673, print grad=0.002443220466375351, Depth Loss=0.0000000] 
Training progress:  84%|████████▍ | 1680/2000 [16:29<01:53,  2.81it/s, Loss=0.0621471, Gaussian number=276673, print grad=0.002443220466375351, Depth Loss=0.0000000]
Training progress:  84%|████████▍ | 1680/2000 [16:32<01:53,  2.81it/s, Loss=0.0713036, Gaussian number=276673, print grad=0.0027516481932252645, Depth Loss=0.0000000]
Training progress:  84%|████████▍ | 1690/2000 [16:32<01:50,  2.82it/s, Loss=0.0713036, Gaussian number=276673, print grad=0.0027516481932252645, Depth Loss=0.0000000]
Training progress:  84%|████████▍ | 1690/2000 [16:36<01:50,  2.82it/s, Loss=0.0782367, Gaussian number=276673, print grad=0.0030278966296464205, Depth Loss=0.0000000]
Training progress:  85%|████████▌ | 1700/2000 [16:36<01:46,  2.82it/s, Loss=0.0782367, Gaussian number=276673, print grad=0.0030278966296464205, Depth Loss=0.0000000]
Training progress:  85%|████████▌ | 1700/2000 [16:40<01:46,  2.82it/s, Loss=0.0829572, Gaussian number=286485, print grad=0.00032843733788467944, Depth Loss=0.0000000]
Training progress:  86%|████████▌ | 1710/2000 [16:40<01:42,  2.83it/s, Loss=0.0829572, Gaussian number=286485, print grad=0.00032843733788467944, Depth Loss=0.0000000]
Training progress:  86%|████████▌ | 1710/2000 [16:43<01:42,  2.83it/s, Loss=0.0880183, Gaussian number=286485, print grad=0.0006006060284562409, Depth Loss=0.0000000] 
Training progress:  86%|████████▌ | 1720/2000 [16:43<01:38,  2.83it/s, Loss=0.0880183, Gaussian number=286485, print grad=0.0006006060284562409, Depth Loss=0.0000000]
Training progress:  86%|████████▌ | 1720/2000 [16:47<01:38,  2.83it/s, Loss=0.0804797, Gaussian number=286485, print grad=0.0008936440572142601, Depth Loss=0.0000000]
Training progress:  86%|████████▋ | 1730/2000 [16:47<01:35,  2.83it/s, Loss=0.0804797, Gaussian number=286485, print grad=0.0008936440572142601, Depth Loss=0.0000000]
Training progress:  86%|████████▋ | 1730/2000 [16:50<01:35,  2.83it/s, Loss=0.0985287, Gaussian number=286485, print grad=0.0012109903618693352, Depth Loss=0.0000000]
Training progress:  87%|████████▋ | 1740/2000 [16:50<01:31,  2.84it/s, Loss=0.0985287, Gaussian number=286485, print grad=0.0012109903618693352, Depth Loss=0.0000000]
Training progress:  87%|████████▋ | 1740/2000 [16:54<01:31,  2.84it/s, Loss=0.0926391, Gaussian number=286485, print grad=0.0015248713316395879, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1750/2000 [16:54<01:28,  2.84it/s, Loss=0.0926391, Gaussian number=286485, print grad=0.0015248713316395879, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1750/2000 [16:57<01:28,  2.84it/s, Loss=0.0776055, Gaussian number=286485, print grad=0.0018139625899493694, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1760/2000 [16:57<01:24,  2.83it/s, Loss=0.0776055, Gaussian number=286485, print grad=0.0018139625899493694, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1760/2000 [17:01<01:24,  2.83it/s, Loss=0.0634446, Gaussian number=286485, print grad=0.002083568135276437, Depth Loss=0.0000000] 
Training progress:  88%|████████▊ | 1770/2000 [17:01<01:21,  2.83it/s, Loss=0.0634446, Gaussian number=286485, print grad=0.002083568135276437, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1770/2000 [17:04<01:21,  2.83it/s, Loss=0.0729974, Gaussian number=286485, print grad=0.0023578861728310585, Depth Loss=0.0000000]
Training progress:  89%|████████▉ | 1780/2000 [17:04<01:17,  2.83it/s, Loss=0.0729974, Gaussian number=286485, print grad=0.0023578861728310585, Depth Loss=0.0000000]
Training progress:  89%|████████▉ | 1780/2000 [17:08<01:17,  2.83it/s, Loss=0.0687426, Gaussian number=286485, print grad=0.0025890592951327562, Depth Loss=0.0000000]
Training progress:  90%|████████▉ | 1790/2000 [17:08<01:14,  2.84it/s, Loss=0.0687426, Gaussian number=286485, print grad=0.0025890592951327562, Depth Loss=0.0000000]
Training progress:  90%|████████▉ | 1790/2000 [17:11<01:14,  2.84it/s, Loss=0.0698205, Gaussian number=286485, print grad=0.002894060220569372, Depth Loss=0.0000000] 
Training progress:  90%|█████████ | 1800/2000 [17:11<01:10,  2.84it/s, Loss=0.0698205, Gaussian number=286485, print grad=0.002894060220569372, Depth Loss=0.0000000]
Training progress:  90%|█████████ | 1800/2000 [17:15<01:10,  2.84it/s, Loss=0.0783895, Gaussian number=296536, print grad=0.000285480753518641, Depth Loss=0.0000000]
Training progress:  90%|█████████ | 1810/2000 [17:15<01:06,  2.84it/s, Loss=0.0783895, Gaussian number=296536, print grad=0.000285480753518641, Depth Loss=0.0000000]
Training progress:  90%|█████████ | 1810/2000 [17:18<01:06,  2.84it/s, Loss=0.0708750, Gaussian number=296536, print grad=0.0006222085212357342, Depth Loss=0.0000000]
Training progress:  91%|█████████ | 1820/2000 [17:18<01:03,  2.84it/s, Loss=0.0708750, Gaussian number=296536, print grad=0.0006222085212357342, Depth Loss=0.0000000]
Training progress:  91%|█████████ | 1820/2000 [17:22<01:03,  2.84it/s, Loss=0.0600857, Gaussian number=296536, print grad=0.0008576972759328783, Depth Loss=0.0000000]
Training progress:  92%|█████████▏| 1830/2000 [17:22<00:59,  2.85it/s, Loss=0.0600857, Gaussian number=296536, print grad=0.0008576972759328783, Depth Loss=0.0000000]
Training progress:  92%|█████████▏| 1830/2000 [17:25<00:59,  2.85it/s, Loss=0.0642051, Gaussian number=296536, print grad=0.0011693051783367991, Depth Loss=0.0000000]
Training progress:  92%|█████████▏| 1840/2000 [17:25<00:56,  2.85it/s, Loss=0.0642051, Gaussian number=296536, print grad=0.0011693051783367991, Depth Loss=0.0000000]
Training progress:  92%|█████████▏| 1840/2000 [17:29<00:56,  2.85it/s, Loss=0.0685714, Gaussian number=296536, print grad=0.0014493661001324654, Depth Loss=0.0000000]
Training progress:  92%|█████████▎| 1850/2000 [17:29<00:52,  2.85it/s, Loss=0.0685714, Gaussian number=296536, print grad=0.0014493661001324654, Depth Loss=0.0000000]
Training progress:  92%|█████████▎| 1850/2000 [17:32<00:52,  2.85it/s, Loss=0.0717588, Gaussian number=296536, print grad=0.0017048867885023355, Depth Loss=0.0000000]
Training progress:  93%|█████████▎| 1860/2000 [17:32<00:49,  2.85it/s, Loss=0.0717588, Gaussian number=296536, print grad=0.0017048867885023355, Depth Loss=0.0000000]
Training progress:  93%|█████████▎| 1860/2000 [17:36<00:49,  2.85it/s, Loss=0.0814210, Gaussian number=296536, print grad=0.002031629905104637, Depth Loss=0.0000000] 
Training progress:  94%|█████████▎| 1870/2000 [17:36<00:45,  2.85it/s, Loss=0.0814210, Gaussian number=296536, print grad=0.002031629905104637, Depth Loss=0.0000000]
Training progress:  94%|█████████▎| 1870/2000 [17:39<00:45,  2.85it/s, Loss=0.0625654, Gaussian number=296536, print grad=0.002321569947525859, Depth Loss=0.0000000]
Training progress:  94%|█████████▍| 1880/2000 [17:39<00:42,  2.85it/s, Loss=0.0625654, Gaussian number=296536, print grad=0.002321569947525859, Depth Loss=0.0000000]
Training progress:  94%|█████████▍| 1880/2000 [17:43<00:42,  2.85it/s, Loss=0.0696923, Gaussian number=296536, print grad=0.0026112522464245558, Depth Loss=0.0000000]
Training progress:  94%|█████████▍| 1890/2000 [17:43<00:38,  2.85it/s, Loss=0.0696923, Gaussian number=296536, print grad=0.0026112522464245558, Depth Loss=0.0000000]
Training progress:  94%|█████████▍| 1890/2000 [17:46<00:38,  2.85it/s, Loss=0.0833339, Gaussian number=296536, print grad=0.0029003142844885588, Depth Loss=0.0000000]
Training progress:  95%|█████████▌| 1900/2000 [17:46<00:35,  2.85it/s, Loss=0.0833339, Gaussian number=296536, print grad=0.0029003142844885588, Depth Loss=0.0000000]
Training progress:  95%|█████████▌| 1900/2000 [17:50<00:35,  2.85it/s, Loss=0.0782534, Gaussian number=307300, print grad=0.0002449904568493366, Depth Loss=0.0000000]
Training progress:  96%|█████████▌| 1910/2000 [17:50<00:31,  2.85it/s, Loss=0.0782534, Gaussian number=307300, print grad=0.0002449904568493366, Depth Loss=0.0000000]
Training progress:  96%|█████████▌| 1910/2000 [17:53<00:31,  2.85it/s, Loss=0.0710746, Gaussian number=307300, print grad=0.0005375020555220544, Depth Loss=0.0000000]
Training progress:  96%|█████████▌| 1920/2000 [17:53<00:28,  2.85it/s, Loss=0.0710746, Gaussian number=307300, print grad=0.0005375020555220544, Depth Loss=0.0000000]
Training progress:  96%|█████████▌| 1920/2000 [17:57<00:28,  2.85it/s, Loss=0.0575431, Gaussian number=307300, print grad=0.0008316735620610416, Depth Loss=0.0000000]
Training progress:  96%|█████████▋| 1930/2000 [17:57<00:24,  2.85it/s, Loss=0.0575431, Gaussian number=307300, print grad=0.0008316735620610416, Depth Loss=0.0000000]
Training progress:  96%|█████████▋| 1930/2000 [18:00<00:24,  2.85it/s, Loss=0.0764680, Gaussian number=307300, print grad=0.001113230362534523, Depth Loss=0.0000000] 
Training progress:  97%|█████████▋| 1940/2000 [18:00<00:21,  2.84it/s, Loss=0.0764680, Gaussian number=307300, print grad=0.001113230362534523, Depth Loss=0.0000000]
Training progress:  97%|█████████▋| 1940/2000 [18:04<00:21,  2.84it/s, Loss=0.0626994, Gaussian number=307300, print grad=0.001384046976454556, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1950/2000 [18:04<00:17,  2.84it/s, Loss=0.0626994, Gaussian number=307300, print grad=0.001384046976454556, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1950/2000 [18:07<00:17,  2.84it/s, Loss=0.0930450, Gaussian number=307300, print grad=0.001643601106479764, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1960/2000 [18:07<00:14,  2.84it/s, Loss=0.0930450, Gaussian number=307300, print grad=0.001643601106479764, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1960/2000 [18:11<00:14,  2.84it/s, Loss=0.0789484, Gaussian number=307300, print grad=0.0019145385595038533, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1970/2000 [18:11<00:10,  2.84it/s, Loss=0.0789484, Gaussian number=307300, print grad=0.0019145385595038533, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1970/2000 [18:14<00:10,  2.84it/s, Loss=0.0678496, Gaussian number=307300, print grad=0.00220160442404449, Depth Loss=0.0000000]  
Training progress:  99%|█████████▉| 1980/2000 [18:14<00:07,  2.84it/s, Loss=0.0678496, Gaussian number=307300, print grad=0.00220160442404449, Depth Loss=0.0000000]
Training progress:  99%|█████████▉| 1980/2000 [18:18<00:07,  2.84it/s, Loss=0.0663490, Gaussian number=307300, print grad=0.0024962176103144884, Depth Loss=0.0000000]
Training progress: 100%|█████████▉| 1990/2000 [18:18<00:03,  2.84it/s, Loss=0.0663490, Gaussian number=307300, print grad=0.0024962176103144884, Depth Loss=0.0000000]
Training progress: 100%|█████████▉| 1990/2000 [18:21<00:03,  2.84it/s, Loss=0.0534935, Gaussian number=307300, print grad=0.002813945524394512, Depth Loss=0.0000000] 
Training progress: 100%|██████████| 2000/2000 [18:21<00:00,  2.84it/s, Loss=0.0534935, Gaussian number=307300, print grad=0.002813945524394512, Depth Loss=0.0000000]
Training progress: 100%|██████████| 2000/2000 [18:21<00:00,  1.81it/s, Loss=0.0534935, Gaussian number=307300, print grad=0.002813945524394512, Depth Loss=0.0000000]
Iteration 100 [03/12 16:42:43]

[ITER 100] Evaluating test: WD 0.131948, PSNR 12.8688,lpips 0.586645,ssim 0.453427 [03/12 16:43:40]

[ITER 100] Evaluating train: WD 0.134558, PSNR 13.2669,lpips 0.589651,ssim 0.472937 [03/12 16:43:47]
Gaussian number:182686,print gradients:1.5951271052472293e-05 [03/12 16:43:47]
Iteration 200 [03/12 16:44:24]

[ITER 200] Evaluating test: WD 0.118808, PSNR 14.1788,lpips 0.536125,ssim 0.488046 [03/12 16:45:20]

[ITER 200] Evaluating train: WD 0.118979, PSNR 14.6056,lpips 0.531850,ssim 0.505853 [03/12 16:45:27]
Gaussian number:182686,print gradients:2.1422692952910438e-05 [03/12 16:45:27]
Iteration 300 [03/12 16:46:03]

[ITER 300] Evaluating test: WD 0.109660, PSNR 14.9739,lpips 0.501081,ssim 0.510800 [03/12 16:47:00]

[ITER 300] Evaluating train: WD 0.109669, PSNR 15.5079,lpips 0.490239,ssim 0.528817 [03/12 16:47:07]
Gaussian number:182686,print gradients:2.528378536226228e-05 [03/12 16:47:07]
Iteration 400 [03/12 16:47:43]
Iteration 500 [03/12 16:48:19]

[ITER 500] Evaluating test: WD 0.099316, PSNR 15.9503,lpips 0.461971,ssim 0.537766 [03/12 16:49:15]

[ITER 500] Evaluating train: WD 0.104773, PSNR 16.1846,lpips 0.462173,ssim 0.547732 [03/12 16:49:23]
Gaussian number:182686,print gradients:3.088205266976729e-05 [03/12 16:49:23]
Iteration 600 [03/12 16:49:58]
Iteration 700 [03/12 16:50:34]
Iteration 800 [03/12 16:51:10]
Iteration 900 [03/12 16:51:46]
Iteration 1000 [03/12 16:52:21]

[ITER 1000] Evaluating test: WD 0.086694, PSNR 16.9177,lpips 0.409038,ssim 0.569622 [03/12 16:53:17]

[ITER 1000] Evaluating train: WD 0.091915, PSNR 17.1346,lpips 0.414162,ssim 0.573543 [03/12 16:53:25]
Gaussian number:208544,print gradients:4.920634819427505e-05 [03/12 16:53:25]
Iteration 1100 [03/12 16:54:00]
Iteration 1200 [03/12 16:54:36]
Iteration 1300 [03/12 16:55:11]
Iteration 1400 [03/12 16:55:47]
Iteration 1500 [03/12 16:56:23]

[ITER 1500] Evaluating test: WD 0.078077, PSNR 17.4321,lpips 0.372749,ssim 0.590719 [03/12 16:57:19]

[ITER 1500] Evaluating train: WD 0.081709, PSNR 17.8255,lpips 0.372604,ssim 0.596731 [03/12 16:57:26]
Gaussian number:256684,print gradients:4.905732930637896e-05 [03/12 16:57:26]
Iteration 1600 [03/12 16:58:01]
Iteration 1700 [03/12 16:58:36]
Iteration 1800 [03/12 16:59:12]
Iteration 1900 [03/12 16:59:47]
Iteration 2000 [03/12 17:00:22]

[ITER 2000] Evaluating test: WD 0.071871, PSNR 17.8661,lpips 0.349971,ssim 0.605185 [03/12 17:01:18]

[ITER 2000] Evaluating train: WD 0.079525, PSNR 18.1330,lpips 0.358653,ssim 0.602415 [03/12 17:01:26]
Gaussian number:307300,print gradients:4.5092005166225135e-05 [03/12 17:01:26]

[ITER 2000] Saving Gaussians [03/12 17:01:26]

Training complete. [03/12 17:01:28]
