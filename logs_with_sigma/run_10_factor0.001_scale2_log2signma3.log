Optimizing /home/cw4287/gaussian-model/train_30k
Output folder: /home/cw4287/gaussian-model/train_30k [03/12 19:46:15]
Tensorboard not available: not logging progress [03/12 19:46:15]
------------LLFF HOLD------------- [03/12 19:46:16]

Reading camera 1/301
Reading camera 2/301
Reading camera 3/301
Reading camera 4/301
Reading camera 5/301
Reading camera 6/301
Reading camera 7/301
Reading camera 8/301
Reading camera 9/301
Reading camera 10/301
Reading camera 11/301
Reading camera 12/301
Reading camera 13/301
Reading camera 14/301
Reading camera 15/301
Reading camera 16/301
Reading camera 17/301
Reading camera 18/301
Reading camera 19/301
Reading camera 20/301
Reading camera 21/301
Reading camera 22/301
Reading camera 23/301
Reading camera 24/301
Reading camera 25/301
Reading camera 26/301
Reading camera 27/301
Reading camera 28/301
Reading camera 29/301
Reading camera 30/301
Reading camera 31/301
Reading camera 32/301
Reading camera 33/301
Reading camera 34/301
Reading camera 35/301
Reading camera 36/301
Reading camera 37/301
Reading camera 38/301
Reading camera 39/301
Reading camera 40/301
Reading camera 41/301
Reading camera 42/301
Reading camera 43/301
Reading camera 44/301
Reading camera 45/301
Reading camera 46/301
Reading camera 47/301
Reading camera 48/301
Reading camera 49/301
Reading camera 50/301
Reading camera 51/301
Reading camera 52/301
Reading camera 53/301
Reading camera 54/301
Reading camera 55/301
Reading camera 56/301
Reading camera 57/301
Reading camera 58/301
Reading camera 59/301
Reading camera 60/301
Reading camera 61/301
Reading camera 62/301
Reading camera 63/301
Reading camera 64/301
Reading camera 65/301
Reading camera 66/301
Reading camera 67/301
Reading camera 68/301
Reading camera 69/301
Reading camera 70/301
Reading camera 71/301
Reading camera 72/301
Reading camera 73/301
Reading camera 74/301
Reading camera 75/301
Reading camera 76/301
Reading camera 77/301
Reading camera 78/301
Reading camera 79/301
Reading camera 80/301
Reading camera 81/301
Reading camera 82/301
Reading camera 83/301
Reading camera 84/301
Reading camera 85/301
Reading camera 86/301
Reading camera 87/301
Reading camera 88/301
Reading camera 89/301
Reading camera 90/301
Reading camera 91/301
Reading camera 92/301
Reading camera 93/301
Reading camera 94/301
Reading camera 95/301
Reading camera 96/301
Reading camera 97/301
Reading camera 98/301
Reading camera 99/301
Reading camera 100/301
Reading camera 101/301
Reading camera 102/301
Reading camera 103/301
Reading camera 104/301
Reading camera 105/301
Reading camera 106/301
Reading camera 107/301
Reading camera 108/301
Reading camera 109/301
Reading camera 110/301
Reading camera 111/301
Reading camera 112/301
Reading camera 113/301
Reading camera 114/301
Reading camera 115/301
Reading camera 116/301
Reading camera 117/301
Reading camera 118/301
Reading camera 119/301
Reading camera 120/301
Reading camera 121/301
Reading camera 122/301
Reading camera 123/301
Reading camera 124/301
Reading camera 125/301
Reading camera 126/301
Reading camera 127/301
Reading camera 128/301
Reading camera 129/301
Reading camera 130/301
Reading camera 131/301
Reading camera 132/301
Reading camera 133/301
Reading camera 134/301
Reading camera 135/301
Reading camera 136/301
Reading camera 137/301
Reading camera 138/301
Reading camera 139/301
Reading camera 140/301
Reading camera 141/301
Reading camera 142/301
Reading camera 143/301
Reading camera 144/301
Reading camera 145/301
Reading camera 146/301
Reading camera 147/301
Reading camera 148/301
Reading camera 149/301
Reading camera 150/301
Reading camera 151/301
Reading camera 152/301
Reading camera 153/301
Reading camera 154/301
Reading camera 155/301
Reading camera 156/301
Reading camera 157/301
Reading camera 158/301
Reading camera 159/301
Reading camera 160/301
Reading camera 161/301
Reading camera 162/301
Reading camera 163/301
Reading camera 164/301
Reading camera 165/301
Reading camera 166/301
Reading camera 167/301
Reading camera 168/301
Reading camera 169/301
Reading camera 170/301
Reading camera 171/301
Reading camera 172/301
Reading camera 173/301
Reading camera 174/301
Reading camera 175/301
Reading camera 176/301
Reading camera 177/301
Reading camera 178/301
Reading camera 179/301
Reading camera 180/301
Reading camera 181/301
Reading camera 182/301
Reading camera 183/301
Reading camera 184/301
Reading camera 185/301
Reading camera 186/301
Reading camera 187/301
Reading camera 188/301
Reading camera 189/301
Reading camera 190/301
Reading camera 191/301
Reading camera 192/301
Reading camera 193/301
Reading camera 194/301
Reading camera 195/301
Reading camera 196/301
Reading camera 197/301
Reading camera 198/301
Reading camera 199/301
Reading camera 200/301
Reading camera 201/301
Reading camera 202/301
Reading camera 203/301
Reading camera 204/301
Reading camera 205/301
Reading camera 206/301
Reading camera 207/301
Reading camera 208/301
Reading camera 209/301
Reading camera 210/301
Reading camera 211/301
Reading camera 212/301
Reading camera 213/301
Reading camera 214/301
Reading camera 215/301
Reading camera 216/301
Reading camera 217/301
Reading camera 218/301
Reading camera 219/301
Reading camera 220/301
Reading camera 221/301
Reading camera 222/301
Reading camera 223/301
Reading camera 224/301
Reading camera 225/301
Reading camera 226/301
Reading camera 227/301
Reading camera 228/301
Reading camera 229/301
Reading camera 230/301
Reading camera 231/301
Reading camera 232/301
Reading camera 233/301
Reading camera 234/301
Reading camera 235/301
Reading camera 236/301
Reading camera 237/301
Reading camera 238/301
Reading camera 239/301
Reading camera 240/301
Reading camera 241/301
Reading camera 242/301
Reading camera 243/301
Reading camera 244/301
Reading camera 245/301
Reading camera 246/301
Reading camera 247/301
Reading camera 248/301
Reading camera 249/301
Reading camera 250/301
Reading camera 251/301
Reading camera 252/301
Reading camera 253/301
Reading camera 254/301
Reading camera 255/301
Reading camera 256/301
Reading camera 257/301
Reading camera 258/301
Reading camera 259/301
Reading camera 260/301
Reading camera 261/301
Reading camera 262/301
Reading camera 263/301
Reading camera 264/301
Reading camera 265/301
Reading camera 266/301
Reading camera 267/301
Reading camera 268/301
Reading camera 269/301
Reading camera 270/301
Reading camera 271/301
Reading camera 272/301
Reading camera 273/301
Reading camera 274/301
Reading camera 275/301
Reading camera 276/301
Reading camera 277/301
Reading camera 278/301
Reading camera 279/301
Reading camera 280/301
Reading camera 281/301
Reading camera 282/301
Reading camera 283/301
Reading camera 284/301
Reading camera 285/301
Reading camera 286/301
Reading camera 287/301
Reading camera 288/301
Reading camera 289/301
Reading camera 290/301
Reading camera 291/301
Reading camera 292/301
Reading camera 293/301
Reading camera 294/301
Reading camera 295/301
Reading camera 296/301
Reading camera 297/301
Reading camera 298/301
Reading camera 299/301
Reading camera 300/301
Reading camera 301/301 [03/12 19:46:16]
Loading Training Cameras [03/12 19:46:16]
Loading Test Cameras [03/12 19:46:33]
Number of points at initialisation :  182686 [03/12 19:46:34]

Training progress:   0%|          | 0/2000 [00:00<?, ?it/s]/ext3/conda/envs/3dgs/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/ext3/conda/envs/3dgs/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)

Training progress:   0%|          | 0/2000 [00:05<?, ?it/s, Loss=0.0146933, Gaussian number=182686, print grad=6.436834155465476e-06, Depth Loss=0.0000000]
Training progress:   0%|          | 10/2000 [00:05<17:23,  1.91it/s, Loss=0.0146933, Gaussian number=182686, print grad=6.436834155465476e-06, Depth Loss=0.0000000]
Training progress:   0%|          | 10/2000 [00:08<17:23,  1.91it/s, Loss=0.0140355, Gaussian number=182686, print grad=1.6771085938671604e-05, Depth Loss=0.0000000]
Training progress:   1%|          | 20/2000 [00:08<14:19,  2.30it/s, Loss=0.0140355, Gaussian number=182686, print grad=1.6771085938671604e-05, Depth Loss=0.0000000]
Training progress:   1%|          | 20/2000 [00:12<14:19,  2.30it/s, Loss=0.0139362, Gaussian number=182686, print grad=2.6643221644917503e-05, Depth Loss=0.0000000]
Training progress:   2%|▏         | 30/2000 [00:12<13:17,  2.47it/s, Loss=0.0139362, Gaussian number=182686, print grad=2.6643221644917503e-05, Depth Loss=0.0000000]
Training progress:   2%|▏         | 30/2000 [00:16<13:17,  2.47it/s, Loss=0.0148519, Gaussian number=182686, print grad=3.695222403621301e-05, Depth Loss=0.0000000] 
Training progress:   2%|▏         | 40/2000 [00:16<12:46,  2.56it/s, Loss=0.0148519, Gaussian number=182686, print grad=3.695222403621301e-05, Depth Loss=0.0000000]
Training progress:   2%|▏         | 40/2000 [00:20<12:46,  2.56it/s, Loss=0.0113420, Gaussian number=182686, print grad=4.529299258138053e-05, Depth Loss=0.0000000]
Training progress:   2%|▎         | 50/2000 [00:20<12:27,  2.61it/s, Loss=0.0113420, Gaussian number=182686, print grad=4.529299258138053e-05, Depth Loss=0.0000000]
Training progress:   2%|▎         | 50/2000 [00:23<12:27,  2.61it/s, Loss=0.0127559, Gaussian number=182686, print grad=5.8028170315083116e-05, Depth Loss=0.0000000]
Training progress:   3%|▎         | 60/2000 [00:23<12:12,  2.65it/s, Loss=0.0127559, Gaussian number=182686, print grad=5.8028170315083116e-05, Depth Loss=0.0000000]
Training progress:   3%|▎         | 60/2000 [00:27<12:12,  2.65it/s, Loss=0.0114228, Gaussian number=182686, print grad=7.358606671914458e-05, Depth Loss=0.0000000] 
Training progress:   4%|▎         | 70/2000 [00:27<12:03,  2.67it/s, Loss=0.0114228, Gaussian number=182686, print grad=7.358606671914458e-05, Depth Loss=0.0000000]
Training progress:   4%|▎         | 70/2000 [00:31<12:03,  2.67it/s, Loss=0.0136138, Gaussian number=182686, print grad=8.571359649067745e-05, Depth Loss=0.0000000]
Training progress:   4%|▍         | 80/2000 [00:31<11:55,  2.68it/s, Loss=0.0136138, Gaussian number=182686, print grad=8.571359649067745e-05, Depth Loss=0.0000000]
Training progress:   4%|▍         | 80/2000 [00:34<11:55,  2.68it/s, Loss=0.0116846, Gaussian number=182686, print grad=9.843843872658908e-05, Depth Loss=0.0000000]
Training progress:   4%|▍         | 90/2000 [00:34<11:48,  2.69it/s, Loss=0.0116846, Gaussian number=182686, print grad=9.843843872658908e-05, Depth Loss=0.0000000]
Training progress:   4%|▍         | 90/2000 [00:38<11:48,  2.69it/s, Loss=0.0112768, Gaussian number=182686, print grad=0.00011357526091160253, Depth Loss=0.0000000]
Training progress:   5%|▌         | 100/2000 [00:38<11:43,  2.70it/s, Loss=0.0112768, Gaussian number=182686, print grad=0.00011357526091160253, Depth Loss=0.0000000]
Training progress:   5%|▌         | 100/2000 [01:46<11:43,  2.70it/s, Loss=0.0133198, Gaussian number=182686, print grad=0.00012983690248802304, Depth Loss=0.0000000]
Training progress:   6%|▌         | 110/2000 [01:46<1:13:48,  2.34s/it, Loss=0.0133198, Gaussian number=182686, print grad=0.00012983690248802304, Depth Loss=0.0000000]
Training progress:   6%|▌         | 110/2000 [01:50<1:13:48,  2.34s/it, Loss=0.0108390, Gaussian number=182686, print grad=0.00014563783770427108, Depth Loss=0.0000000]
Training progress:   6%|▌         | 120/2000 [01:50<54:34,  1.74s/it, Loss=0.0108390, Gaussian number=182686, print grad=0.00014563783770427108, Depth Loss=0.0000000]  
Training progress:   6%|▌         | 120/2000 [01:53<54:34,  1.74s/it, Loss=0.0126264, Gaussian number=182686, print grad=0.00016510984278284013, Depth Loss=0.0000000]
Training progress:   6%|▋         | 130/2000 [01:53<41:19,  1.33s/it, Loss=0.0126264, Gaussian number=182686, print grad=0.00016510984278284013, Depth Loss=0.0000000]
Training progress:   6%|▋         | 130/2000 [01:57<41:19,  1.33s/it, Loss=0.0112489, Gaussian number=182686, print grad=0.00018523770268075168, Depth Loss=0.0000000]
Training progress:   7%|▋         | 140/2000 [01:57<32:08,  1.04s/it, Loss=0.0112489, Gaussian number=182686, print grad=0.00018523770268075168, Depth Loss=0.0000000]
Training progress:   7%|▋         | 140/2000 [02:01<32:08,  1.04s/it, Loss=0.0098114, Gaussian number=182686, print grad=0.00020280794706195593, Depth Loss=0.0000000]
Training progress:   8%|▊         | 150/2000 [02:01<25:44,  1.20it/s, Loss=0.0098114, Gaussian number=182686, print grad=0.00020280794706195593, Depth Loss=0.0000000]
Training progress:   8%|▊         | 150/2000 [02:04<25:44,  1.20it/s, Loss=0.0106268, Gaussian number=182686, print grad=0.00022553691815119237, Depth Loss=0.0000000]
Training progress:   8%|▊         | 160/2000 [02:04<21:15,  1.44it/s, Loss=0.0106268, Gaussian number=182686, print grad=0.00022553691815119237, Depth Loss=0.0000000]
Training progress:   8%|▊         | 160/2000 [02:08<21:15,  1.44it/s, Loss=0.0105959, Gaussian number=182686, print grad=0.00024309880973305553, Depth Loss=0.0000000]
Training progress:   8%|▊         | 170/2000 [02:08<18:09,  1.68it/s, Loss=0.0105959, Gaussian number=182686, print grad=0.00024309880973305553, Depth Loss=0.0000000]
Training progress:   8%|▊         | 170/2000 [02:12<18:09,  1.68it/s, Loss=0.0089891, Gaussian number=182686, print grad=0.00026355014415457845, Depth Loss=0.0000000]
Training progress:   9%|▉         | 180/2000 [02:12<15:58,  1.90it/s, Loss=0.0089891, Gaussian number=182686, print grad=0.00026355014415457845, Depth Loss=0.0000000]
Training progress:   9%|▉         | 180/2000 [02:15<15:58,  1.90it/s, Loss=0.0115086, Gaussian number=182686, print grad=0.0002816621563397348, Depth Loss=0.0000000] 
Training progress:  10%|▉         | 190/2000 [02:15<14:25,  2.09it/s, Loss=0.0115086, Gaussian number=182686, print grad=0.0002816621563397348, Depth Loss=0.0000000]
Training progress:  10%|▉         | 190/2000 [02:19<14:25,  2.09it/s, Loss=0.0101424, Gaussian number=182686, print grad=0.00030297486227937043, Depth Loss=0.0000000]
Training progress:  10%|█         | 200/2000 [02:19<13:18,  2.25it/s, Loss=0.0101424, Gaussian number=182686, print grad=0.00030297486227937043, Depth Loss=0.0000000]
Training progress:  10%|█         | 200/2000 [03:27<13:18,  2.25it/s, Loss=0.0111725, Gaussian number=182686, print grad=0.00032564770663157105, Depth Loss=0.0000000]
Training progress:  10%|█         | 210/2000 [03:27<1:10:14,  2.35s/it, Loss=0.0111725, Gaussian number=182686, print grad=0.00032564770663157105, Depth Loss=0.0000000]
Training progress:  10%|█         | 210/2000 [03:31<1:10:14,  2.35s/it, Loss=0.0092428, Gaussian number=182686, print grad=0.00034619859070517123, Depth Loss=0.0000000]
Training progress:  11%|█         | 220/2000 [03:31<52:08,  1.76s/it, Loss=0.0092428, Gaussian number=182686, print grad=0.00034619859070517123, Depth Loss=0.0000000]  
Training progress:  11%|█         | 220/2000 [03:34<52:08,  1.76s/it, Loss=0.0101872, Gaussian number=182686, print grad=0.0003672996535897255, Depth Loss=0.0000000] 
Training progress:  12%|█▏        | 230/2000 [03:34<39:31,  1.34s/it, Loss=0.0101872, Gaussian number=182686, print grad=0.0003672996535897255, Depth Loss=0.0000000]
Training progress:  12%|█▏        | 230/2000 [03:38<39:31,  1.34s/it, Loss=0.0127105, Gaussian number=182686, print grad=0.0003871435474138707, Depth Loss=0.0000000]
Training progress:  12%|█▏        | 240/2000 [03:38<30:43,  1.05s/it, Loss=0.0127105, Gaussian number=182686, print grad=0.0003871435474138707, Depth Loss=0.0000000]
Training progress:  12%|█▏        | 240/2000 [03:42<30:43,  1.05s/it, Loss=0.0096135, Gaussian number=182686, print grad=0.0004100463120266795, Depth Loss=0.0000000]
Training progress:  12%|█▎        | 250/2000 [03:42<24:34,  1.19it/s, Loss=0.0096135, Gaussian number=182686, print grad=0.0004100463120266795, Depth Loss=0.0000000]
Training progress:  12%|█▎        | 250/2000 [03:45<24:34,  1.19it/s, Loss=0.0108096, Gaussian number=182686, print grad=0.0004308911447878927, Depth Loss=0.0000000]
Training progress:  13%|█▎        | 260/2000 [03:45<20:15,  1.43it/s, Loss=0.0108096, Gaussian number=182686, print grad=0.0004308911447878927, Depth Loss=0.0000000]
Training progress:  13%|█▎        | 260/2000 [03:49<20:15,  1.43it/s, Loss=0.0076469, Gaussian number=182686, print grad=0.0004530680598691106, Depth Loss=0.0000000]
Training progress:  14%|█▎        | 270/2000 [03:49<17:15,  1.67it/s, Loss=0.0076469, Gaussian number=182686, print grad=0.0004530680598691106, Depth Loss=0.0000000]
Training progress:  14%|█▎        | 270/2000 [03:53<17:15,  1.67it/s, Loss=0.0100770, Gaussian number=182686, print grad=0.00047855128650553524, Depth Loss=0.0000000]
Training progress:  14%|█▍        | 280/2000 [03:53<15:07,  1.89it/s, Loss=0.0100770, Gaussian number=182686, print grad=0.00047855128650553524, Depth Loss=0.0000000]
Training progress:  14%|█▍        | 280/2000 [03:56<15:07,  1.89it/s, Loss=0.0098294, Gaussian number=182686, print grad=0.0005024629645049572, Depth Loss=0.0000000] 
Training progress:  14%|█▍        | 290/2000 [03:56<13:38,  2.09it/s, Loss=0.0098294, Gaussian number=182686, print grad=0.0005024629645049572, Depth Loss=0.0000000]
Training progress:  14%|█▍        | 290/2000 [04:00<13:38,  2.09it/s, Loss=0.0092207, Gaussian number=182686, print grad=0.000526588293723762, Depth Loss=0.0000000] 
Training progress:  15%|█▌        | 300/2000 [04:00<12:35,  2.25it/s, Loss=0.0092207, Gaussian number=182686, print grad=0.000526588293723762, Depth Loss=0.0000000]
Training progress:  15%|█▌        | 300/2000 [05:08<12:35,  2.25it/s, Loss=0.0077581, Gaussian number=182686, print grad=0.0005522910505533218, Depth Loss=0.0000000]
Training progress:  16%|█▌        | 310/2000 [05:08<1:06:18,  2.35s/it, Loss=0.0077581, Gaussian number=182686, print grad=0.0005522910505533218, Depth Loss=0.0000000]
Training progress:  16%|█▌        | 310/2000 [05:12<1:06:18,  2.35s/it, Loss=0.0079468, Gaussian number=182686, print grad=0.0005706975935027003, Depth Loss=0.0000000]
Training progress:  16%|█▌        | 320/2000 [05:12<49:11,  1.76s/it, Loss=0.0079468, Gaussian number=182686, print grad=0.0005706975935027003, Depth Loss=0.0000000]  
Training progress:  16%|█▌        | 320/2000 [05:15<49:11,  1.76s/it, Loss=0.0104499, Gaussian number=182686, print grad=0.0005927069578319788, Depth Loss=0.0000000]
Training progress:  16%|█▋        | 330/2000 [05:15<37:15,  1.34s/it, Loss=0.0104499, Gaussian number=182686, print grad=0.0005927069578319788, Depth Loss=0.0000000]
Training progress:  16%|█▋        | 330/2000 [05:19<37:15,  1.34s/it, Loss=0.0077671, Gaussian number=182686, print grad=0.00061756931245327, Depth Loss=0.0000000]  
Training progress:  17%|█▋        | 340/2000 [05:19<28:55,  1.05s/it, Loss=0.0077671, Gaussian number=182686, print grad=0.00061756931245327, Depth Loss=0.0000000]
Training progress:  17%|█▋        | 340/2000 [05:23<28:55,  1.05s/it, Loss=0.0080664, Gaussian number=182686, print grad=0.0006410283967852592, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 350/2000 [05:23<23:07,  1.19it/s, Loss=0.0080664, Gaussian number=182686, print grad=0.0006410283967852592, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 350/2000 [05:26<23:07,  1.19it/s, Loss=0.0077355, Gaussian number=182686, print grad=0.0006688341964036226, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 360/2000 [05:26<19:03,  1.43it/s, Loss=0.0077355, Gaussian number=182686, print grad=0.0006688341964036226, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 360/2000 [05:30<19:03,  1.43it/s, Loss=0.0075839, Gaussian number=182686, print grad=0.0006934120901860297, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 370/2000 [05:30<16:13,  1.67it/s, Loss=0.0075839, Gaussian number=182686, print grad=0.0006934120901860297, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 370/2000 [05:33<16:13,  1.67it/s, Loss=0.0101567, Gaussian number=182686, print grad=0.0007139857625588775, Depth Loss=0.0000000]
Training progress:  19%|█▉        | 380/2000 [05:33<14:12,  1.90it/s, Loss=0.0101567, Gaussian number=182686, print grad=0.0007139857625588775, Depth Loss=0.0000000]
Training progress:  19%|█▉        | 380/2000 [05:37<14:12,  1.90it/s, Loss=0.0090637, Gaussian number=182686, print grad=0.0007389780948869884, Depth Loss=0.0000000]
Training progress:  20%|█▉        | 390/2000 [05:37<12:47,  2.10it/s, Loss=0.0090637, Gaussian number=182686, print grad=0.0007389780948869884, Depth Loss=0.0000000]
Training progress:  20%|█▉        | 390/2000 [05:41<12:47,  2.10it/s, Loss=0.0109638, Gaussian number=182686, print grad=0.0007622950943186879, Depth Loss=0.0000000]
Training progress:  20%|██        | 400/2000 [05:41<11:47,  2.26it/s, Loss=0.0109638, Gaussian number=182686, print grad=0.0007622950943186879, Depth Loss=0.0000000]
Training progress:  20%|██        | 400/2000 [05:44<11:47,  2.26it/s, Loss=0.0092975, Gaussian number=182686, print grad=0.0007906457176432014, Depth Loss=0.0000000]
Training progress:  20%|██        | 410/2000 [05:44<11:04,  2.39it/s, Loss=0.0092975, Gaussian number=182686, print grad=0.0007906457176432014, Depth Loss=0.0000000]
Training progress:  20%|██        | 410/2000 [05:48<11:04,  2.39it/s, Loss=0.0081604, Gaussian number=182686, print grad=0.0008179485448636115, Depth Loss=0.0000000]
Training progress:  21%|██        | 420/2000 [05:48<10:33,  2.49it/s, Loss=0.0081604, Gaussian number=182686, print grad=0.0008179485448636115, Depth Loss=0.0000000]
Training progress:  21%|██        | 420/2000 [05:52<10:33,  2.49it/s, Loss=0.0102422, Gaussian number=182686, print grad=0.0008459484088234603, Depth Loss=0.0000000]
Training progress:  22%|██▏       | 430/2000 [05:52<10:11,  2.57it/s, Loss=0.0102422, Gaussian number=182686, print grad=0.0008459484088234603, Depth Loss=0.0000000]
Training progress:  22%|██▏       | 430/2000 [05:55<10:11,  2.57it/s, Loss=0.0080754, Gaussian number=182686, print grad=0.0008715811418369412, Depth Loss=0.0000000]
Training progress:  22%|██▏       | 440/2000 [05:55<09:54,  2.62it/s, Loss=0.0080754, Gaussian number=182686, print grad=0.0008715811418369412, Depth Loss=0.0000000]
Training progress:  22%|██▏       | 440/2000 [05:59<09:54,  2.62it/s, Loss=0.0090504, Gaussian number=182686, print grad=0.0008985929889604449, Depth Loss=0.0000000]
Training progress:  22%|██▎       | 450/2000 [05:59<09:41,  2.67it/s, Loss=0.0090504, Gaussian number=182686, print grad=0.0008985929889604449, Depth Loss=0.0000000]
Training progress:  22%|██▎       | 450/2000 [06:02<09:41,  2.67it/s, Loss=0.0094231, Gaussian number=182686, print grad=0.0009244311950169504, Depth Loss=0.0000000]
Training progress:  23%|██▎       | 460/2000 [06:02<09:31,  2.69it/s, Loss=0.0094231, Gaussian number=182686, print grad=0.0009244311950169504, Depth Loss=0.0000000]
Training progress:  23%|██▎       | 460/2000 [06:06<09:31,  2.69it/s, Loss=0.0110806, Gaussian number=182686, print grad=0.0009492072276771069, Depth Loss=0.0000000]
Training progress:  24%|██▎       | 470/2000 [06:06<09:23,  2.72it/s, Loss=0.0110806, Gaussian number=182686, print grad=0.0009492072276771069, Depth Loss=0.0000000]
Training progress:  24%|██▎       | 470/2000 [06:10<09:23,  2.72it/s, Loss=0.0074710, Gaussian number=182686, print grad=0.0009771505137905478, Depth Loss=0.0000000]
Training progress:  24%|██▍       | 480/2000 [06:10<09:16,  2.73it/s, Loss=0.0074710, Gaussian number=182686, print grad=0.0009771505137905478, Depth Loss=0.0000000]
Training progress:  24%|██▍       | 480/2000 [06:13<09:16,  2.73it/s, Loss=0.0080039, Gaussian number=182686, print grad=0.0010025810915976763, Depth Loss=0.0000000]
Training progress:  24%|██▍       | 490/2000 [06:13<09:10,  2.74it/s, Loss=0.0080039, Gaussian number=182686, print grad=0.0010025810915976763, Depth Loss=0.0000000]
Training progress:  24%|██▍       | 490/2000 [06:17<09:10,  2.74it/s, Loss=0.0062269, Gaussian number=182686, print grad=0.0010284055024385452, Depth Loss=0.0000000]
Training progress:  25%|██▌       | 500/2000 [06:17<09:05,  2.75it/s, Loss=0.0062269, Gaussian number=182686, print grad=0.0010284055024385452, Depth Loss=0.0000000]
Training progress:  25%|██▌       | 500/2000 [07:25<09:05,  2.75it/s, Loss=0.0074819, Gaussian number=182686, print grad=0.0010548175778239965, Depth Loss=0.0000000]
Training progress:  26%|██▌       | 510/2000 [07:25<57:04,  2.30s/it, Loss=0.0074819, Gaussian number=182686, print grad=0.0010548175778239965, Depth Loss=0.0000000]
Training progress:  26%|██▌       | 510/2000 [07:29<57:04,  2.30s/it, Loss=0.0077245, Gaussian number=182686, print grad=0.0010824031196534634, Depth Loss=0.0000000]
Training progress:  26%|██▌       | 520/2000 [07:29<42:21,  1.72s/it, Loss=0.0077245, Gaussian number=182686, print grad=0.0010824031196534634, Depth Loss=0.0000000]
Training progress:  26%|██▌       | 520/2000 [07:32<42:21,  1.72s/it, Loss=0.0060092, Gaussian number=182686, print grad=0.001105619827285409, Depth Loss=0.0000000] 
Training progress:  26%|██▋       | 530/2000 [07:32<32:05,  1.31s/it, Loss=0.0060092, Gaussian number=182686, print grad=0.001105619827285409, Depth Loss=0.0000000]
Training progress:  26%|██▋       | 530/2000 [07:36<32:05,  1.31s/it, Loss=0.0082202, Gaussian number=182686, print grad=0.0011314083822071552, Depth Loss=0.0000000]
Training progress:  27%|██▋       | 540/2000 [07:36<24:56,  1.02s/it, Loss=0.0082202, Gaussian number=182686, print grad=0.0011314083822071552, Depth Loss=0.0000000]
Training progress:  27%|██▋       | 540/2000 [07:39<24:56,  1.02s/it, Loss=0.0076715, Gaussian number=182686, print grad=0.001159562380053103, Depth Loss=0.0000000] 
Training progress:  28%|██▊       | 550/2000 [07:39<19:57,  1.21it/s, Loss=0.0076715, Gaussian number=182686, print grad=0.001159562380053103, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 550/2000 [07:43<19:57,  1.21it/s, Loss=0.0061499, Gaussian number=182686, print grad=0.0011856190394610167, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 560/2000 [07:43<16:28,  1.46it/s, Loss=0.0061499, Gaussian number=182686, print grad=0.0011856190394610167, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 560/2000 [07:47<16:28,  1.46it/s, Loss=0.0082211, Gaussian number=182686, print grad=0.0012147017987444997, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 570/2000 [07:47<14:02,  1.70it/s, Loss=0.0082211, Gaussian number=182686, print grad=0.0012147017987444997, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 570/2000 [07:50<14:02,  1.70it/s, Loss=0.0070732, Gaussian number=182686, print grad=0.0012420580023899674, Depth Loss=0.0000000]
Training progress:  29%|██▉       | 580/2000 [07:50<12:18,  1.92it/s, Loss=0.0070732, Gaussian number=182686, print grad=0.0012420580023899674, Depth Loss=0.0000000]
Training progress:  29%|██▉       | 580/2000 [07:54<12:18,  1.92it/s, Loss=0.0081535, Gaussian number=182686, print grad=0.0012700045481324196, Depth Loss=0.0000000]
Training progress:  30%|██▉       | 590/2000 [07:54<11:06,  2.12it/s, Loss=0.0081535, Gaussian number=182686, print grad=0.0012700045481324196, Depth Loss=0.0000000]
Training progress:  30%|██▉       | 590/2000 [07:57<11:06,  2.12it/s, Loss=0.0083684, Gaussian number=182686, print grad=0.0012956393184140325, Depth Loss=0.0000000]
Training progress:  30%|███       | 600/2000 [07:57<10:14,  2.28it/s, Loss=0.0083684, Gaussian number=182686, print grad=0.0012956393184140325, Depth Loss=0.0000000]
Training progress:  30%|███       | 600/2000 [08:01<10:14,  2.28it/s, Loss=0.0069057, Gaussian number=182665, print grad=2.4724588001845405e-05, Depth Loss=0.0000000]
Training progress:  30%|███       | 610/2000 [08:01<09:37,  2.41it/s, Loss=0.0069057, Gaussian number=182665, print grad=2.4724588001845405e-05, Depth Loss=0.0000000]
Training progress:  30%|███       | 610/2000 [08:05<09:37,  2.41it/s, Loss=0.0089625, Gaussian number=182665, print grad=5.304021397023462e-05, Depth Loss=0.0000000] 
Training progress:  31%|███       | 620/2000 [08:05<09:10,  2.51it/s, Loss=0.0089625, Gaussian number=182665, print grad=5.304021397023462e-05, Depth Loss=0.0000000]
Training progress:  31%|███       | 620/2000 [08:08<09:10,  2.51it/s, Loss=0.0063814, Gaussian number=182665, print grad=7.808079681126401e-05, Depth Loss=0.0000000]
Training progress:  32%|███▏      | 630/2000 [08:08<08:50,  2.58it/s, Loss=0.0063814, Gaussian number=182665, print grad=7.808079681126401e-05, Depth Loss=0.0000000]
Training progress:  32%|███▏      | 630/2000 [08:12<08:50,  2.58it/s, Loss=0.0070388, Gaussian number=182665, print grad=0.00010873481369344518, Depth Loss=0.0000000]
Training progress:  32%|███▏      | 640/2000 [08:12<08:35,  2.64it/s, Loss=0.0070388, Gaussian number=182665, print grad=0.00010873481369344518, Depth Loss=0.0000000]
Training progress:  32%|███▏      | 640/2000 [08:15<08:35,  2.64it/s, Loss=0.0080286, Gaussian number=182665, print grad=0.00013356162526179105, Depth Loss=0.0000000]
Training progress:  32%|███▎      | 650/2000 [08:15<08:24,  2.68it/s, Loss=0.0080286, Gaussian number=182665, print grad=0.00013356162526179105, Depth Loss=0.0000000]
Training progress:  32%|███▎      | 650/2000 [08:19<08:24,  2.68it/s, Loss=0.0081679, Gaussian number=182665, print grad=0.0001628051686566323, Depth Loss=0.0000000] 
Training progress:  33%|███▎      | 660/2000 [08:19<08:14,  2.71it/s, Loss=0.0081679, Gaussian number=182665, print grad=0.0001628051686566323, Depth Loss=0.0000000]
Training progress:  33%|███▎      | 660/2000 [08:23<08:14,  2.71it/s, Loss=0.0072254, Gaussian number=182665, print grad=0.00018890819046646357, Depth Loss=0.0000000]
Training progress:  34%|███▎      | 670/2000 [08:23<08:06,  2.73it/s, Loss=0.0072254, Gaussian number=182665, print grad=0.00018890819046646357, Depth Loss=0.0000000]
Training progress:  34%|███▎      | 670/2000 [08:26<08:06,  2.73it/s, Loss=0.0066885, Gaussian number=182665, print grad=0.00021823757560923696, Depth Loss=0.0000000]
Training progress:  34%|███▍      | 680/2000 [08:26<08:00,  2.74it/s, Loss=0.0066885, Gaussian number=182665, print grad=0.00021823757560923696, Depth Loss=0.0000000]
Training progress:  34%|███▍      | 680/2000 [08:30<08:00,  2.74it/s, Loss=0.0082443, Gaussian number=182665, print grad=0.00024539572768844664, Depth Loss=0.0000000]
Training progress:  34%|███▍      | 690/2000 [08:30<07:55,  2.76it/s, Loss=0.0082443, Gaussian number=182665, print grad=0.00024539572768844664, Depth Loss=0.0000000]
Training progress:  34%|███▍      | 690/2000 [08:33<07:55,  2.76it/s, Loss=0.0081545, Gaussian number=182665, print grad=0.00027179636526852846, Depth Loss=0.0000000]
Training progress:  35%|███▌      | 700/2000 [08:33<07:50,  2.77it/s, Loss=0.0081545, Gaussian number=182665, print grad=0.00027179636526852846, Depth Loss=0.0000000]
Training progress:  35%|███▌      | 700/2000 [08:37<07:50,  2.77it/s, Loss=0.0069245, Gaussian number=182684, print grad=2.3443581085302867e-05, Depth Loss=0.0000000]
Training progress:  36%|███▌      | 710/2000 [08:37<07:45,  2.77it/s, Loss=0.0069245, Gaussian number=182684, print grad=2.3443581085302867e-05, Depth Loss=0.0000000]
Training progress:  36%|███▌      | 710/2000 [08:41<07:45,  2.77it/s, Loss=0.0064340, Gaussian number=182684, print grad=5.050297113484703e-05, Depth Loss=0.0000000] 
Training progress:  36%|███▌      | 720/2000 [08:41<07:41,  2.77it/s, Loss=0.0064340, Gaussian number=182684, print grad=5.050297113484703e-05, Depth Loss=0.0000000]
Training progress:  36%|███▌      | 720/2000 [08:44<07:41,  2.77it/s, Loss=0.0081964, Gaussian number=182684, print grad=7.573634502477944e-05, Depth Loss=0.0000000]
Training progress:  36%|███▋      | 730/2000 [08:44<07:37,  2.78it/s, Loss=0.0081964, Gaussian number=182684, print grad=7.573634502477944e-05, Depth Loss=0.0000000]
Training progress:  36%|███▋      | 730/2000 [08:48<07:37,  2.78it/s, Loss=0.0098399, Gaussian number=182684, print grad=0.00010562584066065028, Depth Loss=0.0000000]
Training progress:  37%|███▋      | 740/2000 [08:48<07:33,  2.78it/s, Loss=0.0098399, Gaussian number=182684, print grad=0.00010562584066065028, Depth Loss=0.0000000]
Training progress:  37%|███▋      | 740/2000 [08:51<07:33,  2.78it/s, Loss=0.0070636, Gaussian number=182684, print grad=0.00013415982539299875, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 750/2000 [08:51<07:29,  2.78it/s, Loss=0.0070636, Gaussian number=182684, print grad=0.00013415982539299875, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 750/2000 [08:55<07:29,  2.78it/s, Loss=0.0067486, Gaussian number=182684, print grad=0.0001613687927601859, Depth Loss=0.0000000] 
Training progress:  38%|███▊      | 760/2000 [08:55<07:25,  2.78it/s, Loss=0.0067486, Gaussian number=182684, print grad=0.0001613687927601859, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 760/2000 [08:59<07:25,  2.78it/s, Loss=0.0060450, Gaussian number=182684, print grad=0.0001901926298160106, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 770/2000 [08:59<07:22,  2.78it/s, Loss=0.0060450, Gaussian number=182684, print grad=0.0001901926298160106, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 770/2000 [09:02<07:22,  2.78it/s, Loss=0.0080714, Gaussian number=182684, print grad=0.0002167512575397268, Depth Loss=0.0000000]
Training progress:  39%|███▉      | 780/2000 [09:02<07:18,  2.78it/s, Loss=0.0080714, Gaussian number=182684, print grad=0.0002167512575397268, Depth Loss=0.0000000]
Training progress:  39%|███▉      | 780/2000 [09:06<07:18,  2.78it/s, Loss=0.0096636, Gaussian number=182684, print grad=0.0002446798316668719, Depth Loss=0.0000000]
Training progress:  40%|███▉      | 790/2000 [09:06<07:15,  2.78it/s, Loss=0.0096636, Gaussian number=182684, print grad=0.0002446798316668719, Depth Loss=0.0000000]
Training progress:  40%|███▉      | 790/2000 [09:09<07:15,  2.78it/s, Loss=0.0078950, Gaussian number=182684, print grad=0.00027408532332628965, Depth Loss=0.0000000]
Training progress:  40%|████      | 800/2000 [09:09<07:11,  2.78it/s, Loss=0.0078950, Gaussian number=182684, print grad=0.00027408532332628965, Depth Loss=0.0000000]
Training progress:  40%|████      | 800/2000 [09:13<07:11,  2.78it/s, Loss=0.0075613, Gaussian number=182689, print grad=2.501619928807486e-05, Depth Loss=0.0000000] 
Training progress:  40%|████      | 810/2000 [09:13<07:08,  2.78it/s, Loss=0.0075613, Gaussian number=182689, print grad=2.501619928807486e-05, Depth Loss=0.0000000]
Training progress:  40%|████      | 810/2000 [09:17<07:08,  2.78it/s, Loss=0.0075506, Gaussian number=182689, print grad=5.214917109697126e-05, Depth Loss=0.0000000]
Training progress:  41%|████      | 820/2000 [09:17<07:05,  2.77it/s, Loss=0.0075506, Gaussian number=182689, print grad=5.214917109697126e-05, Depth Loss=0.0000000]
Training progress:  41%|████      | 820/2000 [09:20<07:05,  2.77it/s, Loss=0.0058904, Gaussian number=182689, print grad=8.381844963878393e-05, Depth Loss=0.0000000]
Training progress:  42%|████▏     | 830/2000 [09:20<07:01,  2.77it/s, Loss=0.0058904, Gaussian number=182689, print grad=8.381844963878393e-05, Depth Loss=0.0000000]
Training progress:  42%|████▏     | 830/2000 [09:24<07:01,  2.77it/s, Loss=0.0064940, Gaussian number=182689, print grad=0.00011225753405597061, Depth Loss=0.0000000]
Training progress:  42%|████▏     | 840/2000 [09:24<06:57,  2.78it/s, Loss=0.0064940, Gaussian number=182689, print grad=0.00011225753405597061, Depth Loss=0.0000000]
Training progress:  42%|████▏     | 840/2000 [09:27<06:57,  2.78it/s, Loss=0.0069903, Gaussian number=182689, print grad=0.00014171037764754146, Depth Loss=0.0000000]
Training progress:  42%|████▎     | 850/2000 [09:27<06:54,  2.78it/s, Loss=0.0069903, Gaussian number=182689, print grad=0.00014171037764754146, Depth Loss=0.0000000]
Training progress:  42%|████▎     | 850/2000 [09:31<06:54,  2.78it/s, Loss=0.0066102, Gaussian number=182689, print grad=0.00016882168711163104, Depth Loss=0.0000000]
Training progress:  43%|████▎     | 860/2000 [09:31<06:50,  2.77it/s, Loss=0.0066102, Gaussian number=182689, print grad=0.00016882168711163104, Depth Loss=0.0000000]
Training progress:  43%|████▎     | 860/2000 [09:35<06:50,  2.77it/s, Loss=0.0078904, Gaussian number=182689, print grad=0.00019620064995251596, Depth Loss=0.0000000]
Training progress:  44%|████▎     | 870/2000 [09:35<06:47,  2.78it/s, Loss=0.0078904, Gaussian number=182689, print grad=0.00019620064995251596, Depth Loss=0.0000000]
Training progress:  44%|████▎     | 870/2000 [09:38<06:47,  2.78it/s, Loss=0.0076411, Gaussian number=182689, print grad=0.00022414735576603562, Depth Loss=0.0000000]
Training progress:  44%|████▍     | 880/2000 [09:38<06:43,  2.78it/s, Loss=0.0076411, Gaussian number=182689, print grad=0.00022414735576603562, Depth Loss=0.0000000]
Training progress:  44%|████▍     | 880/2000 [09:42<06:43,  2.78it/s, Loss=0.0060060, Gaussian number=182689, print grad=0.0002527993347030133, Depth Loss=0.0000000] 
Training progress:  44%|████▍     | 890/2000 [09:42<06:39,  2.78it/s, Loss=0.0060060, Gaussian number=182689, print grad=0.0002527993347030133, Depth Loss=0.0000000]
Training progress:  44%|████▍     | 890/2000 [09:45<06:39,  2.78it/s, Loss=0.0077497, Gaussian number=182689, print grad=0.0002810157893691212, Depth Loss=0.0000000]
Training progress:  45%|████▌     | 900/2000 [09:45<06:36,  2.78it/s, Loss=0.0077497, Gaussian number=182689, print grad=0.0002810157893691212, Depth Loss=0.0000000]
Training progress:  45%|████▌     | 900/2000 [09:49<06:36,  2.78it/s, Loss=0.0057365, Gaussian number=182696, print grad=2.449744897603523e-05, Depth Loss=0.0000000]
Training progress:  46%|████▌     | 910/2000 [09:49<06:31,  2.78it/s, Loss=0.0057365, Gaussian number=182696, print grad=2.449744897603523e-05, Depth Loss=0.0000000]
Training progress:  46%|████▌     | 910/2000 [09:53<06:31,  2.78it/s, Loss=0.0073220, Gaussian number=182696, print grad=4.8458794481121004e-05, Depth Loss=0.0000000]
Training progress:  46%|████▌     | 920/2000 [09:53<06:27,  2.78it/s, Loss=0.0073220, Gaussian number=182696, print grad=4.8458794481121004e-05, Depth Loss=0.0000000]
Training progress:  46%|████▌     | 920/2000 [09:56<06:27,  2.78it/s, Loss=0.0074645, Gaussian number=182696, print grad=7.849198300391436e-05, Depth Loss=0.0000000] 
Training progress:  46%|████▋     | 930/2000 [09:56<06:23,  2.79it/s, Loss=0.0074645, Gaussian number=182696, print grad=7.849198300391436e-05, Depth Loss=0.0000000]
Training progress:  46%|████▋     | 930/2000 [10:00<06:23,  2.79it/s, Loss=0.0069248, Gaussian number=182696, print grad=0.00010572253086138517, Depth Loss=0.0000000]
Training progress:  47%|████▋     | 940/2000 [10:00<06:20,  2.79it/s, Loss=0.0069248, Gaussian number=182696, print grad=0.00010572253086138517, Depth Loss=0.0000000]
Training progress:  47%|████▋     | 940/2000 [10:03<06:20,  2.79it/s, Loss=0.0064883, Gaussian number=182696, print grad=0.00013341952580958605, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 950/2000 [10:03<06:16,  2.79it/s, Loss=0.0064883, Gaussian number=182696, print grad=0.00013341952580958605, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 950/2000 [10:07<06:16,  2.79it/s, Loss=0.0066574, Gaussian number=182696, print grad=0.00016025778313633054, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 960/2000 [10:07<06:13,  2.79it/s, Loss=0.0066574, Gaussian number=182696, print grad=0.00016025778313633054, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 960/2000 [10:10<06:13,  2.79it/s, Loss=0.0084914, Gaussian number=182696, print grad=0.00019018325838260353, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 970/2000 [10:10<06:09,  2.79it/s, Loss=0.0084914, Gaussian number=182696, print grad=0.00019018325838260353, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 970/2000 [10:14<06:09,  2.79it/s, Loss=0.0055759, Gaussian number=182696, print grad=0.00021800163085572422, Depth Loss=0.0000000]
Training progress:  49%|████▉     | 980/2000 [10:14<06:05,  2.79it/s, Loss=0.0055759, Gaussian number=182696, print grad=0.00021800163085572422, Depth Loss=0.0000000]
Training progress:  49%|████▉     | 980/2000 [10:18<06:05,  2.79it/s, Loss=0.0058120, Gaussian number=182696, print grad=0.00024238771584350616, Depth Loss=0.0000000]
Training progress:  50%|████▉     | 990/2000 [10:18<06:02,  2.79it/s, Loss=0.0058120, Gaussian number=182696, print grad=0.00024238771584350616, Depth Loss=0.0000000]
Training progress:  50%|████▉     | 990/2000 [10:21<06:02,  2.79it/s, Loss=0.0074858, Gaussian number=182696, print grad=0.00026591739151626825, Depth Loss=0.0000000]
Training progress:  50%|█████     | 1000/2000 [10:21<05:58,  2.79it/s, Loss=0.0074858, Gaussian number=182696, print grad=0.00026591739151626825, Depth Loss=0.0000000]
Training progress:  50%|█████     | 1000/2000 [11:29<05:58,  2.79it/s, Loss=0.0067527, Gaussian number=182709, print grad=2.3743268684484065e-05, Depth Loss=0.0000000]
Training progress:  50%|█████     | 1010/2000 [11:29<37:48,  2.29s/it, Loss=0.0067527, Gaussian number=182709, print grad=2.3743268684484065e-05, Depth Loss=0.0000000]
Training progress:  50%|█████     | 1010/2000 [11:33<37:48,  2.29s/it, Loss=0.0082876, Gaussian number=182709, print grad=5.5039130529621616e-05, Depth Loss=0.0000000]
Training progress:  51%|█████     | 1020/2000 [11:33<27:56,  1.71s/it, Loss=0.0082876, Gaussian number=182709, print grad=5.5039130529621616e-05, Depth Loss=0.0000000]
Training progress:  51%|█████     | 1020/2000 [11:36<27:56,  1.71s/it, Loss=0.0068638, Gaussian number=182709, print grad=8.521882409695536e-05, Depth Loss=0.0000000] 
Training progress:  52%|█████▏    | 1030/2000 [11:36<21:05,  1.30s/it, Loss=0.0068638, Gaussian number=182709, print grad=8.521882409695536e-05, Depth Loss=0.0000000]
Training progress:  52%|█████▏    | 1030/2000 [11:40<21:05,  1.30s/it, Loss=0.0072430, Gaussian number=182709, print grad=0.00011668838851619512, Depth Loss=0.0000000]
Training progress:  52%|█████▏    | 1040/2000 [11:40<16:19,  1.02s/it, Loss=0.0072430, Gaussian number=182709, print grad=0.00011668838851619512, Depth Loss=0.0000000]
Training progress:  52%|█████▏    | 1040/2000 [11:43<16:19,  1.02s/it, Loss=0.0066038, Gaussian number=182709, print grad=0.00014126749010756612, Depth Loss=0.0000000]
Training progress:  52%|█████▎    | 1050/2000 [11:43<12:59,  1.22it/s, Loss=0.0066038, Gaussian number=182709, print grad=0.00014126749010756612, Depth Loss=0.0000000]
Training progress:  52%|█████▎    | 1050/2000 [11:47<12:59,  1.22it/s, Loss=0.0061955, Gaussian number=182709, print grad=0.0001685283932602033, Depth Loss=0.0000000] 
Training progress:  53%|█████▎    | 1060/2000 [11:47<10:40,  1.47it/s, Loss=0.0061955, Gaussian number=182709, print grad=0.0001685283932602033, Depth Loss=0.0000000]
Training progress:  53%|█████▎    | 1060/2000 [11:51<10:40,  1.47it/s, Loss=0.0051175, Gaussian number=182709, print grad=0.000198485009605065, Depth Loss=0.0000000] 
Training progress:  54%|█████▎    | 1070/2000 [11:51<09:02,  1.71it/s, Loss=0.0051175, Gaussian number=182709, print grad=0.000198485009605065, Depth Loss=0.0000000]
Training progress:  54%|█████▎    | 1070/2000 [11:54<09:02,  1.71it/s, Loss=0.0057956, Gaussian number=182709, print grad=0.0002256058360217139, Depth Loss=0.0000000]
Training progress:  54%|█████▍    | 1080/2000 [11:54<07:54,  1.94it/s, Loss=0.0057956, Gaussian number=182709, print grad=0.0002256058360217139, Depth Loss=0.0000000]
Training progress:  54%|█████▍    | 1080/2000 [11:58<07:54,  1.94it/s, Loss=0.0069580, Gaussian number=182709, print grad=0.0002540640707593411, Depth Loss=0.0000000]
Training progress:  55%|█████▍    | 1090/2000 [11:58<07:06,  2.14it/s, Loss=0.0069580, Gaussian number=182709, print grad=0.0002540640707593411, Depth Loss=0.0000000]
Training progress:  55%|█████▍    | 1090/2000 [12:01<07:06,  2.14it/s, Loss=0.0071647, Gaussian number=182709, print grad=0.00028244106215424836, Depth Loss=0.0000000]
Training progress:  55%|█████▌    | 1100/2000 [12:01<06:31,  2.30it/s, Loss=0.0071647, Gaussian number=182709, print grad=0.00028244106215424836, Depth Loss=0.0000000]
Training progress:  55%|█████▌    | 1100/2000 [12:05<06:31,  2.30it/s, Loss=0.0074222, Gaussian number=182703, print grad=2.520179441489745e-05, Depth Loss=0.0000000] 
Training progress:  56%|█████▌    | 1110/2000 [12:05<06:06,  2.43it/s, Loss=0.0074222, Gaussian number=182703, print grad=2.520179441489745e-05, Depth Loss=0.0000000]
Training progress:  56%|█████▌    | 1110/2000 [12:08<06:06,  2.43it/s, Loss=0.0066733, Gaussian number=182703, print grad=5.45483453606721e-05, Depth Loss=0.0000000] 
Training progress:  56%|█████▌    | 1120/2000 [12:08<05:47,  2.53it/s, Loss=0.0066733, Gaussian number=182703, print grad=5.45483453606721e-05, Depth Loss=0.0000000]
Training progress:  56%|█████▌    | 1120/2000 [12:12<05:47,  2.53it/s, Loss=0.0055728, Gaussian number=182703, print grad=8.528519538231194e-05, Depth Loss=0.0000000]
Training progress:  56%|█████▋    | 1130/2000 [12:12<05:33,  2.61it/s, Loss=0.0055728, Gaussian number=182703, print grad=8.528519538231194e-05, Depth Loss=0.0000000]
Training progress:  56%|█████▋    | 1130/2000 [12:16<05:33,  2.61it/s, Loss=0.0068931, Gaussian number=182703, print grad=0.00011565625027287751, Depth Loss=0.0000000]
Training progress:  57%|█████▋    | 1140/2000 [12:16<05:22,  2.67it/s, Loss=0.0068931, Gaussian number=182703, print grad=0.00011565625027287751, Depth Loss=0.0000000]
Training progress:  57%|█████▋    | 1140/2000 [12:19<05:22,  2.67it/s, Loss=0.0049060, Gaussian number=182703, print grad=0.00014491798356175423, Depth Loss=0.0000000]
Training progress:  57%|█████▊    | 1150/2000 [12:19<05:14,  2.71it/s, Loss=0.0049060, Gaussian number=182703, print grad=0.00014491798356175423, Depth Loss=0.0000000]
Training progress:  57%|█████▊    | 1150/2000 [12:23<05:14,  2.71it/s, Loss=0.0055312, Gaussian number=182703, print grad=0.0001711031363811344, Depth Loss=0.0000000] 
Training progress:  58%|█████▊    | 1160/2000 [12:23<05:07,  2.73it/s, Loss=0.0055312, Gaussian number=182703, print grad=0.0001711031363811344, Depth Loss=0.0000000]
Training progress:  58%|█████▊    | 1160/2000 [12:26<05:07,  2.73it/s, Loss=0.0066391, Gaussian number=182703, print grad=0.00019952384172938764, Depth Loss=0.0000000]
Training progress:  58%|█████▊    | 1170/2000 [12:26<05:01,  2.75it/s, Loss=0.0066391, Gaussian number=182703, print grad=0.00019952384172938764, Depth Loss=0.0000000]
Training progress:  58%|█████▊    | 1170/2000 [12:30<05:01,  2.75it/s, Loss=0.0067236, Gaussian number=182703, print grad=0.00022784338216297328, Depth Loss=0.0000000]
Training progress:  59%|█████▉    | 1180/2000 [12:30<04:56,  2.77it/s, Loss=0.0067236, Gaussian number=182703, print grad=0.00022784338216297328, Depth Loss=0.0000000]
Training progress:  59%|█████▉    | 1180/2000 [12:33<04:56,  2.77it/s, Loss=0.0064261, Gaussian number=182703, print grad=0.00025775734684430063, Depth Loss=0.0000000]
Training progress:  60%|█████▉    | 1190/2000 [12:33<04:51,  2.78it/s, Loss=0.0064261, Gaussian number=182703, print grad=0.00025775734684430063, Depth Loss=0.0000000]
Training progress:  60%|█████▉    | 1190/2000 [12:37<04:51,  2.78it/s, Loss=0.0072118, Gaussian number=182703, print grad=0.0002823931572493166, Depth Loss=0.0000000] 
Training progress:  60%|██████    | 1200/2000 [12:37<04:47,  2.79it/s, Loss=0.0072118, Gaussian number=182703, print grad=0.0002823931572493166, Depth Loss=0.0000000]
Training progress:  60%|██████    | 1200/2000 [12:41<04:47,  2.79it/s, Loss=0.0056699, Gaussian number=182712, print grad=2.714885340537876e-05, Depth Loss=0.0000000]
Training progress:  60%|██████    | 1210/2000 [12:41<04:43,  2.79it/s, Loss=0.0056699, Gaussian number=182712, print grad=2.714885340537876e-05, Depth Loss=0.0000000]
Training progress:  60%|██████    | 1210/2000 [12:44<04:43,  2.79it/s, Loss=0.0046746, Gaussian number=182712, print grad=5.767402399214916e-05, Depth Loss=0.0000000]
Training progress:  61%|██████    | 1220/2000 [12:44<04:39,  2.79it/s, Loss=0.0046746, Gaussian number=182712, print grad=5.767402399214916e-05, Depth Loss=0.0000000]
Training progress:  61%|██████    | 1220/2000 [12:48<04:39,  2.79it/s, Loss=0.0052353, Gaussian number=182712, print grad=8.464104030281305e-05, Depth Loss=0.0000000]
Training progress:  62%|██████▏   | 1230/2000 [12:48<04:35,  2.80it/s, Loss=0.0052353, Gaussian number=182712, print grad=8.464104030281305e-05, Depth Loss=0.0000000]
Training progress:  62%|██████▏   | 1230/2000 [12:51<04:35,  2.80it/s, Loss=0.0049443, Gaussian number=182712, print grad=0.00011415420158300549, Depth Loss=0.0000000]
Training progress:  62%|██████▏   | 1240/2000 [12:51<04:31,  2.79it/s, Loss=0.0049443, Gaussian number=182712, print grad=0.00011415420158300549, Depth Loss=0.0000000]
Training progress:  62%|██████▏   | 1240/2000 [12:55<04:31,  2.79it/s, Loss=0.0050897, Gaussian number=182712, print grad=0.00013988910359330475, Depth Loss=0.0000000]
Training progress:  62%|██████▎   | 1250/2000 [12:55<04:28,  2.80it/s, Loss=0.0050897, Gaussian number=182712, print grad=0.00013988910359330475, Depth Loss=0.0000000]
Training progress:  62%|██████▎   | 1250/2000 [12:58<04:28,  2.80it/s, Loss=0.0053562, Gaussian number=182712, print grad=0.00016532494919374585, Depth Loss=0.0000000]
Training progress:  63%|██████▎   | 1260/2000 [12:58<04:24,  2.80it/s, Loss=0.0053562, Gaussian number=182712, print grad=0.00016532494919374585, Depth Loss=0.0000000]
Training progress:  63%|██████▎   | 1260/2000 [13:02<04:24,  2.80it/s, Loss=0.0066247, Gaussian number=182712, print grad=0.00019419603631831706, Depth Loss=0.0000000]
Training progress:  64%|██████▎   | 1270/2000 [13:02<04:21,  2.80it/s, Loss=0.0066247, Gaussian number=182712, print grad=0.00019419603631831706, Depth Loss=0.0000000]
Training progress:  64%|██████▎   | 1270/2000 [13:06<04:21,  2.80it/s, Loss=0.0068215, Gaussian number=182712, print grad=0.00022109202109277248, Depth Loss=0.0000000]
Training progress:  64%|██████▍   | 1280/2000 [13:06<04:17,  2.80it/s, Loss=0.0068215, Gaussian number=182712, print grad=0.00022109202109277248, Depth Loss=0.0000000]
Training progress:  64%|██████▍   | 1280/2000 [13:09<04:17,  2.80it/s, Loss=0.0051699, Gaussian number=182712, print grad=0.00025136058684438467, Depth Loss=0.0000000]
Training progress:  64%|██████▍   | 1290/2000 [13:09<04:13,  2.80it/s, Loss=0.0051699, Gaussian number=182712, print grad=0.00025136058684438467, Depth Loss=0.0000000]
Training progress:  64%|██████▍   | 1290/2000 [13:13<04:13,  2.80it/s, Loss=0.0077332, Gaussian number=182712, print grad=0.0002780614304356277, Depth Loss=0.0000000] 
Training progress:  65%|██████▌   | 1300/2000 [13:13<04:10,  2.80it/s, Loss=0.0077332, Gaussian number=182712, print grad=0.0002780614304356277, Depth Loss=0.0000000]
Training progress:  65%|██████▌   | 1300/2000 [13:16<04:10,  2.80it/s, Loss=0.0073678, Gaussian number=182698, print grad=2.8230331736267544e-05, Depth Loss=0.0000000]
Training progress:  66%|██████▌   | 1310/2000 [13:16<04:06,  2.80it/s, Loss=0.0073678, Gaussian number=182698, print grad=2.8230331736267544e-05, Depth Loss=0.0000000]
Training progress:  66%|██████▌   | 1310/2000 [13:20<04:06,  2.80it/s, Loss=0.0070932, Gaussian number=182698, print grad=5.536495154956356e-05, Depth Loss=0.0000000] 
Training progress:  66%|██████▌   | 1320/2000 [13:20<04:03,  2.79it/s, Loss=0.0070932, Gaussian number=182698, print grad=5.536495154956356e-05, Depth Loss=0.0000000]
Training progress:  66%|██████▌   | 1320/2000 [13:23<04:03,  2.79it/s, Loss=0.0054438, Gaussian number=182698, print grad=8.399634680245072e-05, Depth Loss=0.0000000]
Training progress:  66%|██████▋   | 1330/2000 [13:23<03:59,  2.79it/s, Loss=0.0054438, Gaussian number=182698, print grad=8.399634680245072e-05, Depth Loss=0.0000000]
Training progress:  66%|██████▋   | 1330/2000 [13:27<03:59,  2.79it/s, Loss=0.0060216, Gaussian number=182698, print grad=0.00011350285058142617, Depth Loss=0.0000000]
Training progress:  67%|██████▋   | 1340/2000 [13:27<03:55,  2.80it/s, Loss=0.0060216, Gaussian number=182698, print grad=0.00011350285058142617, Depth Loss=0.0000000]
Training progress:  67%|██████▋   | 1340/2000 [13:31<03:55,  2.80it/s, Loss=0.0082026, Gaussian number=182698, print grad=0.00013864181528333575, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1350/2000 [13:31<03:52,  2.80it/s, Loss=0.0082026, Gaussian number=182698, print grad=0.00013864181528333575, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1350/2000 [13:34<03:52,  2.80it/s, Loss=0.0049527, Gaussian number=182698, print grad=0.0001651360944379121, Depth Loss=0.0000000] 
Training progress:  68%|██████▊   | 1360/2000 [13:34<03:48,  2.80it/s, Loss=0.0049527, Gaussian number=182698, print grad=0.0001651360944379121, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1360/2000 [13:38<03:48,  2.80it/s, Loss=0.0089878, Gaussian number=182698, print grad=0.00019495772721711546, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1370/2000 [13:38<03:45,  2.80it/s, Loss=0.0089878, Gaussian number=182698, print grad=0.00019495772721711546, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1370/2000 [13:41<03:45,  2.80it/s, Loss=0.0059378, Gaussian number=182698, print grad=0.00022176926722750068, Depth Loss=0.0000000]
Training progress:  69%|██████▉   | 1380/2000 [13:41<03:41,  2.80it/s, Loss=0.0059378, Gaussian number=182698, print grad=0.00022176926722750068, Depth Loss=0.0000000]
Training progress:  69%|██████▉   | 1380/2000 [13:45<03:41,  2.80it/s, Loss=0.0053960, Gaussian number=182698, print grad=0.00024771399330347776, Depth Loss=0.0000000]
Training progress:  70%|██████▉   | 1390/2000 [13:45<03:37,  2.80it/s, Loss=0.0053960, Gaussian number=182698, print grad=0.00024771399330347776, Depth Loss=0.0000000]
Training progress:  70%|██████▉   | 1390/2000 [13:48<03:37,  2.80it/s, Loss=0.0060400, Gaussian number=182698, print grad=0.0002759729977697134, Depth Loss=0.0000000] 
Training progress:  70%|███████   | 1400/2000 [13:48<03:34,  2.80it/s, Loss=0.0060400, Gaussian number=182698, print grad=0.0002759729977697134, Depth Loss=0.0000000]
Training progress:  70%|███████   | 1400/2000 [13:52<03:34,  2.80it/s, Loss=0.0066258, Gaussian number=182713, print grad=2.8171472877147608e-05, Depth Loss=0.0000000]
Training progress:  70%|███████   | 1410/2000 [13:52<03:31,  2.80it/s, Loss=0.0066258, Gaussian number=182713, print grad=2.8171472877147608e-05, Depth Loss=0.0000000]
Training progress:  70%|███████   | 1410/2000 [13:56<03:31,  2.80it/s, Loss=0.0058688, Gaussian number=182713, print grad=5.812486415379681e-05, Depth Loss=0.0000000] 
Training progress:  71%|███████   | 1420/2000 [13:56<03:27,  2.80it/s, Loss=0.0058688, Gaussian number=182713, print grad=5.812486415379681e-05, Depth Loss=0.0000000]
Training progress:  71%|███████   | 1420/2000 [13:59<03:27,  2.80it/s, Loss=0.0060043, Gaussian number=182713, print grad=9.02387109817937e-05, Depth Loss=0.0000000] 
Training progress:  72%|███████▏  | 1430/2000 [13:59<03:23,  2.80it/s, Loss=0.0060043, Gaussian number=182713, print grad=9.02387109817937e-05, Depth Loss=0.0000000]
Training progress:  72%|███████▏  | 1430/2000 [14:03<03:23,  2.80it/s, Loss=0.0058616, Gaussian number=182713, print grad=0.00011725505464710295, Depth Loss=0.0000000]
Training progress:  72%|███████▏  | 1440/2000 [14:03<03:20,  2.80it/s, Loss=0.0058616, Gaussian number=182713, print grad=0.00011725505464710295, Depth Loss=0.0000000]
Training progress:  72%|███████▏  | 1440/2000 [14:06<03:20,  2.80it/s, Loss=0.0051181, Gaussian number=182713, print grad=0.0001447658723918721, Depth Loss=0.0000000] 
Training progress:  72%|███████▎  | 1450/2000 [14:06<03:16,  2.80it/s, Loss=0.0051181, Gaussian number=182713, print grad=0.0001447658723918721, Depth Loss=0.0000000]
Training progress:  72%|███████▎  | 1450/2000 [14:10<03:16,  2.80it/s, Loss=0.0047349, Gaussian number=182713, print grad=0.0001729530922602862, Depth Loss=0.0000000]
Training progress:  73%|███████▎  | 1460/2000 [14:10<03:13,  2.80it/s, Loss=0.0047349, Gaussian number=182713, print grad=0.0001729530922602862, Depth Loss=0.0000000]
Training progress:  73%|███████▎  | 1460/2000 [14:14<03:13,  2.80it/s, Loss=0.0062405, Gaussian number=182713, print grad=0.00020141103595960885, Depth Loss=0.0000000]
Training progress:  74%|███████▎  | 1470/2000 [14:14<03:09,  2.79it/s, Loss=0.0062405, Gaussian number=182713, print grad=0.00020141103595960885, Depth Loss=0.0000000]
Training progress:  74%|███████▎  | 1470/2000 [14:17<03:09,  2.79it/s, Loss=0.0062420, Gaussian number=182713, print grad=0.0002310265408596024, Depth Loss=0.0000000] 
Training progress:  74%|███████▍  | 1480/2000 [14:17<03:06,  2.79it/s, Loss=0.0062420, Gaussian number=182713, print grad=0.0002310265408596024, Depth Loss=0.0000000]
Training progress:  74%|███████▍  | 1480/2000 [14:21<03:06,  2.79it/s, Loss=0.0066475, Gaussian number=182713, print grad=0.00026022540987469256, Depth Loss=0.0000000]
Training progress:  74%|███████▍  | 1490/2000 [14:21<03:02,  2.79it/s, Loss=0.0066475, Gaussian number=182713, print grad=0.00026022540987469256, Depth Loss=0.0000000]
Training progress:  74%|███████▍  | 1490/2000 [14:24<03:02,  2.79it/s, Loss=0.0064591, Gaussian number=182713, print grad=0.00028972228756174445, Depth Loss=0.0000000]
Training progress:  75%|███████▌  | 1500/2000 [14:24<02:59,  2.79it/s, Loss=0.0064591, Gaussian number=182713, print grad=0.00028972228756174445, Depth Loss=0.0000000]
Training progress:  75%|███████▌  | 1500/2000 [15:32<02:59,  2.79it/s, Loss=0.0070539, Gaussian number=182722, print grad=2.560986285971012e-05, Depth Loss=0.0000000] 
Training progress:  76%|███████▌  | 1510/2000 [15:32<18:43,  2.29s/it, Loss=0.0070539, Gaussian number=182722, print grad=2.560986285971012e-05, Depth Loss=0.0000000]
Training progress:  76%|███████▌  | 1510/2000 [15:36<18:43,  2.29s/it, Loss=0.0060827, Gaussian number=182722, print grad=5.197511927690357e-05, Depth Loss=0.0000000]
Training progress:  76%|███████▌  | 1520/2000 [15:36<13:41,  1.71s/it, Loss=0.0060827, Gaussian number=182722, print grad=5.197511927690357e-05, Depth Loss=0.0000000]
Training progress:  76%|███████▌  | 1520/2000 [15:39<13:41,  1.71s/it, Loss=0.0038395, Gaussian number=182722, print grad=8.240013994509354e-05, Depth Loss=0.0000000]
Training progress:  76%|███████▋  | 1530/2000 [15:39<10:13,  1.31s/it, Loss=0.0038395, Gaussian number=182722, print grad=8.240013994509354e-05, Depth Loss=0.0000000]
Training progress:  76%|███████▋  | 1530/2000 [15:43<10:13,  1.31s/it, Loss=0.0053280, Gaussian number=182722, print grad=0.00011089966574218124, Depth Loss=0.0000000]
Training progress:  77%|███████▋  | 1540/2000 [15:43<07:49,  1.02s/it, Loss=0.0053280, Gaussian number=182722, print grad=0.00011089966574218124, Depth Loss=0.0000000]
Training progress:  77%|███████▋  | 1540/2000 [15:47<07:49,  1.02s/it, Loss=0.0058076, Gaussian number=182722, print grad=0.0001409582473570481, Depth Loss=0.0000000] 
Training progress:  78%|███████▊  | 1550/2000 [15:47<06:09,  1.22it/s, Loss=0.0058076, Gaussian number=182722, print grad=0.0001409582473570481, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1550/2000 [15:50<06:09,  1.22it/s, Loss=0.0060254, Gaussian number=182722, print grad=0.00017201362061314285, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1560/2000 [15:50<05:00,  1.46it/s, Loss=0.0060254, Gaussian number=182722, print grad=0.00017201362061314285, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1560/2000 [15:54<05:00,  1.46it/s, Loss=0.0052983, Gaussian number=182722, print grad=0.0002021482214331627, Depth Loss=0.0000000] 
Training progress:  78%|███████▊  | 1570/2000 [15:54<04:11,  1.71it/s, Loss=0.0052983, Gaussian number=182722, print grad=0.0002021482214331627, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1570/2000 [15:57<04:11,  1.71it/s, Loss=0.0039976, Gaussian number=182722, print grad=0.0002259537868667394, Depth Loss=0.0000000]
Training progress:  79%|███████▉  | 1580/2000 [15:57<03:37,  1.93it/s, Loss=0.0039976, Gaussian number=182722, print grad=0.0002259537868667394, Depth Loss=0.0000000]
Training progress:  79%|███████▉  | 1580/2000 [16:01<03:37,  1.93it/s, Loss=0.0056391, Gaussian number=182722, print grad=0.00025266222655773163, Depth Loss=0.0000000]
Training progress:  80%|███████▉  | 1590/2000 [16:01<03:12,  2.13it/s, Loss=0.0056391, Gaussian number=182722, print grad=0.00025266222655773163, Depth Loss=0.0000000]
Training progress:  80%|███████▉  | 1590/2000 [16:04<03:12,  2.13it/s, Loss=0.0052738, Gaussian number=182722, print grad=0.00028235549689270556, Depth Loss=0.0000000]
Training progress:  80%|████████  | 1600/2000 [16:04<02:54,  2.30it/s, Loss=0.0052738, Gaussian number=182722, print grad=0.00028235549689270556, Depth Loss=0.0000000]
Training progress:  80%|████████  | 1600/2000 [16:08<02:54,  2.30it/s, Loss=0.0056775, Gaussian number=182700, print grad=2.813184619299136e-05, Depth Loss=0.0000000] 
Training progress:  80%|████████  | 1610/2000 [16:08<02:40,  2.42it/s, Loss=0.0056775, Gaussian number=182700, print grad=2.813184619299136e-05, Depth Loss=0.0000000]
Training progress:  80%|████████  | 1610/2000 [16:12<02:40,  2.42it/s, Loss=0.0060736, Gaussian number=182700, print grad=5.96783502260223e-05, Depth Loss=0.0000000] 
Training progress:  81%|████████  | 1620/2000 [16:12<02:30,  2.53it/s, Loss=0.0060736, Gaussian number=182700, print grad=5.96783502260223e-05, Depth Loss=0.0000000]
Training progress:  81%|████████  | 1620/2000 [16:15<02:30,  2.53it/s, Loss=0.0053240, Gaussian number=182700, print grad=8.795040048426017e-05, Depth Loss=0.0000000]
Training progress:  82%|████████▏ | 1630/2000 [16:15<02:22,  2.60it/s, Loss=0.0053240, Gaussian number=182700, print grad=8.795040048426017e-05, Depth Loss=0.0000000]
Training progress:  82%|████████▏ | 1630/2000 [16:19<02:22,  2.60it/s, Loss=0.0039037, Gaussian number=182700, print grad=0.00011679733142955229, Depth Loss=0.0000000]
Training progress:  82%|████████▏ | 1640/2000 [16:19<02:15,  2.66it/s, Loss=0.0039037, Gaussian number=182700, print grad=0.00011679733142955229, Depth Loss=0.0000000]
Training progress:  82%|████████▏ | 1640/2000 [16:22<02:15,  2.66it/s, Loss=0.0053610, Gaussian number=182700, print grad=0.00014379835920408368, Depth Loss=0.0000000]
Training progress:  82%|████████▎ | 1650/2000 [16:22<02:09,  2.70it/s, Loss=0.0053610, Gaussian number=182700, print grad=0.00014379835920408368, Depth Loss=0.0000000]
Training progress:  82%|████████▎ | 1650/2000 [16:26<02:09,  2.70it/s, Loss=0.0052293, Gaussian number=182700, print grad=0.00017128698527812958, Depth Loss=0.0000000]
Training progress:  83%|████████▎ | 1660/2000 [16:26<02:04,  2.73it/s, Loss=0.0052293, Gaussian number=182700, print grad=0.00017128698527812958, Depth Loss=0.0000000]
Training progress:  83%|████████▎ | 1660/2000 [16:30<02:04,  2.73it/s, Loss=0.0050123, Gaussian number=182700, print grad=0.00019915189477615058, Depth Loss=0.0000000]
Training progress:  84%|████████▎ | 1670/2000 [16:30<01:59,  2.75it/s, Loss=0.0050123, Gaussian number=182700, print grad=0.00019915189477615058, Depth Loss=0.0000000]
Training progress:  84%|████████▎ | 1670/2000 [16:33<01:59,  2.75it/s, Loss=0.0045370, Gaussian number=182700, print grad=0.00022802084276918322, Depth Loss=0.0000000]
Training progress:  84%|████████▍ | 1680/2000 [16:33<01:55,  2.77it/s, Loss=0.0045370, Gaussian number=182700, print grad=0.00022802084276918322, Depth Loss=0.0000000]
Training progress:  84%|████████▍ | 1680/2000 [16:37<01:55,  2.77it/s, Loss=0.0054315, Gaussian number=182700, print grad=0.00025662832194939256, Depth Loss=0.0000000]
Training progress:  84%|████████▍ | 1690/2000 [16:37<01:51,  2.78it/s, Loss=0.0054315, Gaussian number=182700, print grad=0.00025662832194939256, Depth Loss=0.0000000]
Training progress:  84%|████████▍ | 1690/2000 [16:40<01:51,  2.78it/s, Loss=0.0057629, Gaussian number=182700, print grad=0.00028246460715308785, Depth Loss=0.0000000]
Training progress:  85%|████████▌ | 1700/2000 [16:40<01:47,  2.78it/s, Loss=0.0057629, Gaussian number=182700, print grad=0.00028246460715308785, Depth Loss=0.0000000]
Training progress:  85%|████████▌ | 1700/2000 [16:44<01:47,  2.78it/s, Loss=0.0059518, Gaussian number=182717, print grad=2.927575224020984e-05, Depth Loss=0.0000000] 
Training progress:  86%|████████▌ | 1710/2000 [16:44<01:44,  2.78it/s, Loss=0.0059518, Gaussian number=182717, print grad=2.927575224020984e-05, Depth Loss=0.0000000]
Training progress:  86%|████████▌ | 1710/2000 [16:47<01:44,  2.78it/s, Loss=0.0060359, Gaussian number=182717, print grad=5.464076457428746e-05, Depth Loss=0.0000000]
Training progress:  86%|████████▌ | 1720/2000 [16:47<01:40,  2.79it/s, Loss=0.0060359, Gaussian number=182717, print grad=5.464076457428746e-05, Depth Loss=0.0000000]
Training progress:  86%|████████▌ | 1720/2000 [16:51<01:40,  2.79it/s, Loss=0.0054941, Gaussian number=182717, print grad=8.320028427988291e-05, Depth Loss=0.0000000]
Training progress:  86%|████████▋ | 1730/2000 [16:51<01:36,  2.79it/s, Loss=0.0054941, Gaussian number=182717, print grad=8.320028427988291e-05, Depth Loss=0.0000000]
Training progress:  86%|████████▋ | 1730/2000 [16:55<01:36,  2.79it/s, Loss=0.0069939, Gaussian number=182717, print grad=0.00011348442785674706, Depth Loss=0.0000000]
Training progress:  87%|████████▋ | 1740/2000 [16:55<01:33,  2.79it/s, Loss=0.0069939, Gaussian number=182717, print grad=0.00011348442785674706, Depth Loss=0.0000000]
Training progress:  87%|████████▋ | 1740/2000 [16:58<01:33,  2.79it/s, Loss=0.0068504, Gaussian number=182717, print grad=0.00014449657464865595, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1750/2000 [16:58<01:29,  2.79it/s, Loss=0.0068504, Gaussian number=182717, print grad=0.00014449657464865595, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1750/2000 [17:02<01:29,  2.79it/s, Loss=0.0056530, Gaussian number=182717, print grad=0.00017334816220682114, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1760/2000 [17:02<01:25,  2.79it/s, Loss=0.0056530, Gaussian number=182717, print grad=0.00017334816220682114, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1760/2000 [17:05<01:25,  2.79it/s, Loss=0.0046410, Gaussian number=182717, print grad=0.00019991901353932917, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1770/2000 [17:05<01:22,  2.79it/s, Loss=0.0046410, Gaussian number=182717, print grad=0.00019991901353932917, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1770/2000 [17:09<01:22,  2.79it/s, Loss=0.0056700, Gaussian number=182717, print grad=0.00022680229449179024, Depth Loss=0.0000000]
Training progress:  89%|████████▉ | 1780/2000 [17:09<01:18,  2.79it/s, Loss=0.0056700, Gaussian number=182717, print grad=0.00022680229449179024, Depth Loss=0.0000000]
Training progress:  89%|████████▉ | 1780/2000 [17:12<01:18,  2.79it/s, Loss=0.0050773, Gaussian number=182717, print grad=0.0002511299098841846, Depth Loss=0.0000000] 
Training progress:  90%|████████▉ | 1790/2000 [17:12<01:15,  2.79it/s, Loss=0.0050773, Gaussian number=182717, print grad=0.0002511299098841846, Depth Loss=0.0000000]
Training progress:  90%|████████▉ | 1790/2000 [17:16<01:15,  2.79it/s, Loss=0.0050936, Gaussian number=182717, print grad=0.0002810054284054786, Depth Loss=0.0000000]
Training progress:  90%|█████████ | 1800/2000 [17:16<01:11,  2.79it/s, Loss=0.0050936, Gaussian number=182717, print grad=0.0002810054284054786, Depth Loss=0.0000000]
Training progress:  90%|█████████ | 1800/2000 [17:20<01:11,  2.79it/s, Loss=0.0055537, Gaussian number=182711, print grad=2.8516082238638774e-05, Depth Loss=0.0000000]
Training progress:  90%|█████████ | 1810/2000 [17:20<01:08,  2.79it/s, Loss=0.0055537, Gaussian number=182711, print grad=2.8516082238638774e-05, Depth Loss=0.0000000]
Training progress:  90%|█████████ | 1810/2000 [17:23<01:08,  2.79it/s, Loss=0.0050255, Gaussian number=182711, print grad=5.912362030358054e-05, Depth Loss=0.0000000] 
Training progress:  91%|█████████ | 1820/2000 [17:23<01:04,  2.79it/s, Loss=0.0050255, Gaussian number=182711, print grad=5.912362030358054e-05, Depth Loss=0.0000000]
Training progress:  91%|█████████ | 1820/2000 [17:27<01:04,  2.79it/s, Loss=0.0041329, Gaussian number=182711, print grad=8.389922004425898e-05, Depth Loss=0.0000000]
Training progress:  92%|█████████▏| 1830/2000 [17:27<01:00,  2.79it/s, Loss=0.0041329, Gaussian number=182711, print grad=8.389922004425898e-05, Depth Loss=0.0000000]
Training progress:  92%|█████████▏| 1830/2000 [17:30<01:00,  2.79it/s, Loss=0.0047408, Gaussian number=182711, print grad=0.00011480421380838379, Depth Loss=0.0000000]
Training progress:  92%|█████████▏| 1840/2000 [17:30<00:57,  2.79it/s, Loss=0.0047408, Gaussian number=182711, print grad=0.00011480421380838379, Depth Loss=0.0000000]
Training progress:  92%|█████████▏| 1840/2000 [17:34<00:57,  2.79it/s, Loss=0.0050390, Gaussian number=182711, print grad=0.0001429175172233954, Depth Loss=0.0000000] 
Training progress:  92%|█████████▎| 1850/2000 [17:34<00:53,  2.79it/s, Loss=0.0050390, Gaussian number=182711, print grad=0.0001429175172233954, Depth Loss=0.0000000]
Training progress:  92%|█████████▎| 1850/2000 [17:38<00:53,  2.79it/s, Loss=0.0051758, Gaussian number=182711, print grad=0.00016780140867922455, Depth Loss=0.0000000]
Training progress:  93%|█████████▎| 1860/2000 [17:38<00:50,  2.79it/s, Loss=0.0051758, Gaussian number=182711, print grad=0.00016780140867922455, Depth Loss=0.0000000]
Training progress:  93%|█████████▎| 1860/2000 [17:41<00:50,  2.79it/s, Loss=0.0057778, Gaussian number=182711, print grad=0.00020029937149956822, Depth Loss=0.0000000]
Training progress:  94%|█████████▎| 1870/2000 [17:41<00:46,  2.79it/s, Loss=0.0057778, Gaussian number=182711, print grad=0.00020029937149956822, Depth Loss=0.0000000]
Training progress:  94%|█████████▎| 1870/2000 [17:45<00:46,  2.79it/s, Loss=0.0045531, Gaussian number=182711, print grad=0.00022908289975021034, Depth Loss=0.0000000]
Training progress:  94%|█████████▍| 1880/2000 [17:45<00:43,  2.79it/s, Loss=0.0045531, Gaussian number=182711, print grad=0.00022908289975021034, Depth Loss=0.0000000]
Training progress:  94%|█████████▍| 1880/2000 [17:48<00:43,  2.79it/s, Loss=0.0051540, Gaussian number=182711, print grad=0.0002567482879385352, Depth Loss=0.0000000] 
Training progress:  94%|█████████▍| 1890/2000 [17:48<00:39,  2.79it/s, Loss=0.0051540, Gaussian number=182711, print grad=0.0002567482879385352, Depth Loss=0.0000000]
Training progress:  94%|█████████▍| 1890/2000 [17:52<00:39,  2.79it/s, Loss=0.0060991, Gaussian number=182711, print grad=0.0002859215601347387, Depth Loss=0.0000000]
Training progress:  95%|█████████▌| 1900/2000 [17:52<00:35,  2.79it/s, Loss=0.0060991, Gaussian number=182711, print grad=0.0002859215601347387, Depth Loss=0.0000000]
Training progress:  95%|█████████▌| 1900/2000 [17:56<00:35,  2.79it/s, Loss=0.0057132, Gaussian number=182744, print grad=2.511296588636469e-05, Depth Loss=0.0000000]
Training progress:  96%|█████████▌| 1910/2000 [17:56<00:32,  2.79it/s, Loss=0.0057132, Gaussian number=182744, print grad=2.511296588636469e-05, Depth Loss=0.0000000]
Training progress:  96%|█████████▌| 1910/2000 [17:59<00:32,  2.79it/s, Loss=0.0042476, Gaussian number=182744, print grad=5.350301944417879e-05, Depth Loss=0.0000000]
Training progress:  96%|█████████▌| 1920/2000 [17:59<00:28,  2.79it/s, Loss=0.0042476, Gaussian number=182744, print grad=5.350301944417879e-05, Depth Loss=0.0000000]
Training progress:  96%|█████████▌| 1920/2000 [18:03<00:28,  2.79it/s, Loss=0.0039626, Gaussian number=182744, print grad=8.17592881503515e-05, Depth Loss=0.0000000] 
Training progress:  96%|█████████▋| 1930/2000 [18:03<00:25,  2.79it/s, Loss=0.0039626, Gaussian number=182744, print grad=8.17592881503515e-05, Depth Loss=0.0000000]
Training progress:  96%|█████████▋| 1930/2000 [18:06<00:25,  2.79it/s, Loss=0.0056036, Gaussian number=182744, print grad=0.00010952063166769221, Depth Loss=0.0000000]
Training progress:  97%|█████████▋| 1940/2000 [18:06<00:21,  2.79it/s, Loss=0.0056036, Gaussian number=182744, print grad=0.00010952063166769221, Depth Loss=0.0000000]
Training progress:  97%|█████████▋| 1940/2000 [18:10<00:21,  2.79it/s, Loss=0.0043720, Gaussian number=182744, print grad=0.00013732342631556094, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1950/2000 [18:10<00:17,  2.78it/s, Loss=0.0043720, Gaussian number=182744, print grad=0.00013732342631556094, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1950/2000 [18:13<00:17,  2.78it/s, Loss=0.0069266, Gaussian number=182744, print grad=0.00016449733811896294, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1960/2000 [18:13<00:14,  2.79it/s, Loss=0.0069266, Gaussian number=182744, print grad=0.00016449733811896294, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1960/2000 [18:17<00:14,  2.79it/s, Loss=0.0057093, Gaussian number=182744, print grad=0.00019229837926104665, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1970/2000 [18:17<00:10,  2.79it/s, Loss=0.0057093, Gaussian number=182744, print grad=0.00019229837926104665, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1970/2000 [18:21<00:10,  2.79it/s, Loss=0.0048875, Gaussian number=182744, print grad=0.00022131216246634722, Depth Loss=0.0000000]
Training progress:  99%|█████████▉| 1980/2000 [18:21<00:07,  2.79it/s, Loss=0.0048875, Gaussian number=182744, print grad=0.00022131216246634722, Depth Loss=0.0000000]
Training progress:  99%|█████████▉| 1980/2000 [18:24<00:07,  2.79it/s, Loss=0.0048849, Gaussian number=182744, print grad=0.0002527644101064652, Depth Loss=0.0000000] 
Training progress: 100%|█████████▉| 1990/2000 [18:24<00:03,  2.79it/s, Loss=0.0048849, Gaussian number=182744, print grad=0.0002527644101064652, Depth Loss=0.0000000]
Training progress: 100%|█████████▉| 1990/2000 [18:28<00:03,  2.79it/s, Loss=0.0041327, Gaussian number=182744, print grad=0.0002841346140485257, Depth Loss=0.0000000]
Training progress: 100%|██████████| 2000/2000 [18:28<00:00,  2.79it/s, Loss=0.0041327, Gaussian number=182744, print grad=0.0002841346140485257, Depth Loss=0.0000000]
Training progress: 100%|██████████| 2000/2000 [18:28<00:00,  1.80it/s, Loss=0.0041327, Gaussian number=182744, print grad=0.0002841346140485257, Depth Loss=0.0000000]
Iteration 100 [03/12 19:47:12]

[ITER 100] Evaluating test: WD 0.013368, PSNR 12.9172,lpips 0.588337,ssim 0.451427 [03/12 19:48:10]

[ITER 100] Evaluating train: WD 0.013711, PSNR 13.3678,lpips 0.590115,ssim 0.470408 [03/12 19:48:17]
Gaussian number:182686,print gradients:1.6507194686710136e-06 [03/12 19:48:17]
Iteration 200 [03/12 19:48:53]

[ITER 200] Evaluating test: WD 0.012124, PSNR 14.2899,lpips 0.535520,ssim 0.486246 [03/12 19:49:51]

[ITER 200] Evaluating train: WD 0.012095, PSNR 14.7889,lpips 0.525325,ssim 0.505395 [03/12 19:49:58]
Gaussian number:182686,print gradients:2.1648975234711543e-06 [03/12 19:49:58]
Iteration 300 [03/12 19:50:34]

[ITER 300] Evaluating test: WD 0.011254, PSNR 15.0563,lpips 0.498704,ssim 0.507006 [03/12 19:51:32]

[ITER 300] Evaluating train: WD 0.011255, PSNR 15.5662,lpips 0.485333,ssim 0.523826 [03/12 19:51:39]
Gaussian number:182686,print gradients:2.5091535462706815e-06 [03/12 19:51:39]
Iteration 400 [03/12 19:52:15]
Iteration 500 [03/12 19:52:51]

[ITER 500] Evaluating test: WD 0.010341, PSNR 15.9721,lpips 0.460557,ssim 0.529287 [03/12 19:53:48]

[ITER 500] Evaluating train: WD 0.010926, PSNR 16.2430,lpips 0.459259,ssim 0.539229 [03/12 19:53:56]
Gaussian number:182686,print gradients:2.958026925625745e-06 [03/12 19:53:56]
Iteration 600 [03/12 19:54:32]
Iteration 700 [03/12 19:55:08]
Iteration 800 [03/12 19:55:44]
Iteration 900 [03/12 19:56:20]
Iteration 1000 [03/12 19:56:56]

[ITER 1000] Evaluating test: WD 0.009003, PSNR 16.7978,lpips 0.405582,ssim 0.556549 [03/12 19:57:53]

[ITER 1000] Evaluating train: WD 0.009452, PSNR 17.1320,lpips 0.407105,ssim 0.565028 [03/12 19:58:00]
Gaussian number:182696,print gradients:4.062236712343292e-06 [03/12 19:58:00]
Iteration 1100 [03/12 19:58:36]
Iteration 1200 [03/12 19:59:11]
Iteration 1300 [03/12 19:59:47]
Iteration 1400 [03/12 20:00:23]
Iteration 1500 [03/12 20:00:59]

[ITER 1500] Evaluating test: WD 0.008155, PSNR 17.2546,lpips 0.373626,ssim 0.573938 [03/12 20:01:56]

[ITER 1500] Evaluating train: WD 0.008431, PSNR 17.7316,lpips 0.368238,ssim 0.584869 [03/12 20:02:03]
Gaussian number:182713,print gradients:4.362530034995871e-06 [03/12 20:02:03]
Iteration 1600 [03/12 20:02:39]
Iteration 1700 [03/12 20:03:15]
Iteration 1800 [03/12 20:03:50]
Iteration 1900 [03/12 20:04:26]
Iteration 2000 [03/12 20:05:02]

[ITER 2000] Evaluating test: WD 0.007620, PSNR 17.6190,lpips 0.355925,ssim 0.586133 [03/12 20:05:58]

[ITER 2000] Evaluating train: WD 0.008204, PSNR 18.0206,lpips 0.355097,ssim 0.589659 [03/12 20:06:06]
Gaussian number:182744,print gradients:4.3369650484237354e-06 [03/12 20:06:06]

[ITER 2000] Saving Gaussians [03/12 20:06:06]

Training complete. [03/12 20:06:07]
