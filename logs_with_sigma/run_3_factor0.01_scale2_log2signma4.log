Optimizing /home/cw4287/gaussian-model/train_30k
Output folder: /home/cw4287/gaussian-model/train_30k [03/12 17:21:18]
Tensorboard not available: not logging progress [03/12 17:21:18]
------------LLFF HOLD------------- [03/12 17:21:20]

Reading camera 1/301
Reading camera 2/301
Reading camera 3/301
Reading camera 4/301
Reading camera 5/301
Reading camera 6/301
Reading camera 7/301
Reading camera 8/301
Reading camera 9/301
Reading camera 10/301
Reading camera 11/301
Reading camera 12/301
Reading camera 13/301
Reading camera 14/301
Reading camera 15/301
Reading camera 16/301
Reading camera 17/301
Reading camera 18/301
Reading camera 19/301
Reading camera 20/301
Reading camera 21/301
Reading camera 22/301
Reading camera 23/301
Reading camera 24/301
Reading camera 25/301
Reading camera 26/301
Reading camera 27/301
Reading camera 28/301
Reading camera 29/301
Reading camera 30/301
Reading camera 31/301
Reading camera 32/301
Reading camera 33/301
Reading camera 34/301
Reading camera 35/301
Reading camera 36/301
Reading camera 37/301
Reading camera 38/301
Reading camera 39/301
Reading camera 40/301
Reading camera 41/301
Reading camera 42/301
Reading camera 43/301
Reading camera 44/301
Reading camera 45/301
Reading camera 46/301
Reading camera 47/301
Reading camera 48/301
Reading camera 49/301
Reading camera 50/301
Reading camera 51/301
Reading camera 52/301
Reading camera 53/301
Reading camera 54/301
Reading camera 55/301
Reading camera 56/301
Reading camera 57/301
Reading camera 58/301
Reading camera 59/301
Reading camera 60/301
Reading camera 61/301
Reading camera 62/301
Reading camera 63/301
Reading camera 64/301
Reading camera 65/301
Reading camera 66/301
Reading camera 67/301
Reading camera 68/301
Reading camera 69/301
Reading camera 70/301
Reading camera 71/301
Reading camera 72/301
Reading camera 73/301
Reading camera 74/301
Reading camera 75/301
Reading camera 76/301
Reading camera 77/301
Reading camera 78/301
Reading camera 79/301
Reading camera 80/301
Reading camera 81/301
Reading camera 82/301
Reading camera 83/301
Reading camera 84/301
Reading camera 85/301
Reading camera 86/301
Reading camera 87/301
Reading camera 88/301
Reading camera 89/301
Reading camera 90/301
Reading camera 91/301
Reading camera 92/301
Reading camera 93/301
Reading camera 94/301
Reading camera 95/301
Reading camera 96/301
Reading camera 97/301
Reading camera 98/301
Reading camera 99/301
Reading camera 100/301
Reading camera 101/301
Reading camera 102/301
Reading camera 103/301
Reading camera 104/301
Reading camera 105/301
Reading camera 106/301
Reading camera 107/301
Reading camera 108/301
Reading camera 109/301
Reading camera 110/301
Reading camera 111/301
Reading camera 112/301
Reading camera 113/301
Reading camera 114/301
Reading camera 115/301
Reading camera 116/301
Reading camera 117/301
Reading camera 118/301
Reading camera 119/301
Reading camera 120/301
Reading camera 121/301
Reading camera 122/301
Reading camera 123/301
Reading camera 124/301
Reading camera 125/301
Reading camera 126/301
Reading camera 127/301
Reading camera 128/301
Reading camera 129/301
Reading camera 130/301
Reading camera 131/301
Reading camera 132/301
Reading camera 133/301
Reading camera 134/301
Reading camera 135/301
Reading camera 136/301
Reading camera 137/301
Reading camera 138/301
Reading camera 139/301
Reading camera 140/301
Reading camera 141/301
Reading camera 142/301
Reading camera 143/301
Reading camera 144/301
Reading camera 145/301
Reading camera 146/301
Reading camera 147/301
Reading camera 148/301
Reading camera 149/301
Reading camera 150/301
Reading camera 151/301
Reading camera 152/301
Reading camera 153/301
Reading camera 154/301
Reading camera 155/301
Reading camera 156/301
Reading camera 157/301
Reading camera 158/301
Reading camera 159/301
Reading camera 160/301
Reading camera 161/301
Reading camera 162/301
Reading camera 163/301
Reading camera 164/301
Reading camera 165/301
Reading camera 166/301
Reading camera 167/301
Reading camera 168/301
Reading camera 169/301
Reading camera 170/301
Reading camera 171/301
Reading camera 172/301
Reading camera 173/301
Reading camera 174/301
Reading camera 175/301
Reading camera 176/301
Reading camera 177/301
Reading camera 178/301
Reading camera 179/301
Reading camera 180/301
Reading camera 181/301
Reading camera 182/301
Reading camera 183/301
Reading camera 184/301
Reading camera 185/301
Reading camera 186/301
Reading camera 187/301
Reading camera 188/301
Reading camera 189/301
Reading camera 190/301
Reading camera 191/301
Reading camera 192/301
Reading camera 193/301
Reading camera 194/301
Reading camera 195/301
Reading camera 196/301
Reading camera 197/301
Reading camera 198/301
Reading camera 199/301
Reading camera 200/301
Reading camera 201/301
Reading camera 202/301
Reading camera 203/301
Reading camera 204/301
Reading camera 205/301
Reading camera 206/301
Reading camera 207/301
Reading camera 208/301
Reading camera 209/301
Reading camera 210/301
Reading camera 211/301
Reading camera 212/301
Reading camera 213/301
Reading camera 214/301
Reading camera 215/301
Reading camera 216/301
Reading camera 217/301
Reading camera 218/301
Reading camera 219/301
Reading camera 220/301
Reading camera 221/301
Reading camera 222/301
Reading camera 223/301
Reading camera 224/301
Reading camera 225/301
Reading camera 226/301
Reading camera 227/301
Reading camera 228/301
Reading camera 229/301
Reading camera 230/301
Reading camera 231/301
Reading camera 232/301
Reading camera 233/301
Reading camera 234/301
Reading camera 235/301
Reading camera 236/301
Reading camera 237/301
Reading camera 238/301
Reading camera 239/301
Reading camera 240/301
Reading camera 241/301
Reading camera 242/301
Reading camera 243/301
Reading camera 244/301
Reading camera 245/301
Reading camera 246/301
Reading camera 247/301
Reading camera 248/301
Reading camera 249/301
Reading camera 250/301
Reading camera 251/301
Reading camera 252/301
Reading camera 253/301
Reading camera 254/301
Reading camera 255/301
Reading camera 256/301
Reading camera 257/301
Reading camera 258/301
Reading camera 259/301
Reading camera 260/301
Reading camera 261/301
Reading camera 262/301
Reading camera 263/301
Reading camera 264/301
Reading camera 265/301
Reading camera 266/301
Reading camera 267/301
Reading camera 268/301
Reading camera 269/301
Reading camera 270/301
Reading camera 271/301
Reading camera 272/301
Reading camera 273/301
Reading camera 274/301
Reading camera 275/301
Reading camera 276/301
Reading camera 277/301
Reading camera 278/301
Reading camera 279/301
Reading camera 280/301
Reading camera 281/301
Reading camera 282/301
Reading camera 283/301
Reading camera 284/301
Reading camera 285/301
Reading camera 286/301
Reading camera 287/301
Reading camera 288/301
Reading camera 289/301
Reading camera 290/301
Reading camera 291/301
Reading camera 292/301
Reading camera 293/301
Reading camera 294/301
Reading camera 295/301
Reading camera 296/301
Reading camera 297/301
Reading camera 298/301
Reading camera 299/301
Reading camera 300/301
Reading camera 301/301 [03/12 17:21:20]
Loading Training Cameras [03/12 17:21:20]
Loading Test Cameras [03/12 17:21:32]
Number of points at initialisation :  182686 [03/12 17:21:35]

Training progress:   0%|          | 0/2000 [00:00<?, ?it/s]/ext3/conda/envs/3dgs/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/ext3/conda/envs/3dgs/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)

Training progress:   0%|          | 0/2000 [00:05<?, ?it/s, Loss=0.1368336, Gaussian number=182686, print grad=7.03999976394698e-05, Depth Loss=0.0000000]
Training progress:   0%|          | 10/2000 [00:05<17:21,  1.91it/s, Loss=0.1368336, Gaussian number=182686, print grad=7.03999976394698e-05, Depth Loss=0.0000000]
Training progress:   0%|          | 10/2000 [00:08<17:21,  1.91it/s, Loss=0.1288446, Gaussian number=182686, print grad=0.00017397836199961603, Depth Loss=0.0000000]
Training progress:   1%|          | 20/2000 [00:08<14:14,  2.32it/s, Loss=0.1288446, Gaussian number=182686, print grad=0.00017397836199961603, Depth Loss=0.0000000]
Training progress:   1%|          | 20/2000 [00:12<14:14,  2.32it/s, Loss=0.1274938, Gaussian number=182686, print grad=0.00027270111604593694, Depth Loss=0.0000000]
Training progress:   2%|▏         | 30/2000 [00:12<13:12,  2.49it/s, Loss=0.1274938, Gaussian number=182686, print grad=0.00027270111604593694, Depth Loss=0.0000000]
Training progress:   2%|▏         | 30/2000 [00:16<13:12,  2.49it/s, Loss=0.1333096, Gaussian number=182686, print grad=0.0003714062331710011, Depth Loss=0.0000000] 
Training progress:   2%|▏         | 40/2000 [00:16<12:41,  2.57it/s, Loss=0.1333096, Gaussian number=182686, print grad=0.0003714062331710011, Depth Loss=0.0000000]
Training progress:   2%|▏         | 40/2000 [00:19<12:41,  2.57it/s, Loss=0.1014442, Gaussian number=182686, print grad=0.0004521989030763507, Depth Loss=0.0000000]
Training progress:   2%|▎         | 50/2000 [00:19<12:21,  2.63it/s, Loss=0.1014442, Gaussian number=182686, print grad=0.0004521989030763507, Depth Loss=0.0000000]
Training progress:   2%|▎         | 50/2000 [00:23<12:21,  2.63it/s, Loss=0.1113111, Gaussian number=182686, print grad=0.0005719046457670629, Depth Loss=0.0000000]
Training progress:   3%|▎         | 60/2000 [00:23<12:07,  2.67it/s, Loss=0.1113111, Gaussian number=182686, print grad=0.0005719046457670629, Depth Loss=0.0000000]
Training progress:   3%|▎         | 60/2000 [00:27<12:07,  2.67it/s, Loss=0.0981993, Gaussian number=182686, print grad=0.0007087711710482836, Depth Loss=0.0000000]
Training progress:   4%|▎         | 70/2000 [00:27<11:58,  2.69it/s, Loss=0.0981993, Gaussian number=182686, print grad=0.0007087711710482836, Depth Loss=0.0000000]
Training progress:   4%|▎         | 70/2000 [00:30<11:58,  2.69it/s, Loss=0.1203945, Gaussian number=182686, print grad=0.0008202587487176061, Depth Loss=0.0000000]
Training progress:   4%|▍         | 80/2000 [00:30<11:50,  2.70it/s, Loss=0.1203945, Gaussian number=182686, print grad=0.0008202587487176061, Depth Loss=0.0000000]
Training progress:   4%|▍         | 80/2000 [00:34<11:50,  2.70it/s, Loss=0.1033317, Gaussian number=182686, print grad=0.0009394047665409744, Depth Loss=0.0000000]
Training progress:   4%|▍         | 90/2000 [00:34<11:44,  2.71it/s, Loss=0.1033317, Gaussian number=182686, print grad=0.0009394047665409744, Depth Loss=0.0000000]
Training progress:   4%|▍         | 90/2000 [00:38<11:44,  2.71it/s, Loss=0.0962541, Gaussian number=182686, print grad=0.001079169800505042, Depth Loss=0.0000000] 
Training progress:   5%|▌         | 100/2000 [00:38<11:38,  2.72it/s, Loss=0.0962541, Gaussian number=182686, print grad=0.001079169800505042, Depth Loss=0.0000000]
Training progress:   5%|▌         | 100/2000 [01:45<11:38,  2.72it/s, Loss=0.1155519, Gaussian number=182686, print grad=0.001225590007379651, Depth Loss=0.0000000]
Training progress:   6%|▌         | 110/2000 [01:45<1:12:48,  2.31s/it, Loss=0.1155519, Gaussian number=182686, print grad=0.001225590007379651, Depth Loss=0.0000000]
Training progress:   6%|▌         | 110/2000 [01:49<1:12:48,  2.31s/it, Loss=0.0917130, Gaussian number=182686, print grad=0.0013671625638380647, Depth Loss=0.0000000]
Training progress:   6%|▌         | 120/2000 [01:49<53:51,  1.72s/it, Loss=0.0917130, Gaussian number=182686, print grad=0.0013671625638380647, Depth Loss=0.0000000]  
Training progress:   6%|▌         | 120/2000 [01:52<53:51,  1.72s/it, Loss=0.1051898, Gaussian number=182686, print grad=0.001533476752229035, Depth Loss=0.0000000] 
Training progress:   6%|▋         | 130/2000 [01:52<40:46,  1.31s/it, Loss=0.1051898, Gaussian number=182686, print grad=0.001533476752229035, Depth Loss=0.0000000]
Training progress:   6%|▋         | 130/2000 [01:56<40:46,  1.31s/it, Loss=0.0934656, Gaussian number=182686, print grad=0.0017059368547052145, Depth Loss=0.0000000]
Training progress:   7%|▋         | 140/2000 [01:56<31:43,  1.02s/it, Loss=0.0934656, Gaussian number=182686, print grad=0.0017059368547052145, Depth Loss=0.0000000]
Training progress:   7%|▋         | 140/2000 [01:59<31:43,  1.02s/it, Loss=0.0808674, Gaussian number=182686, print grad=0.0018559208838269114, Depth Loss=0.0000000]
Training progress:   8%|▊         | 150/2000 [01:59<25:24,  1.21it/s, Loss=0.0808674, Gaussian number=182686, print grad=0.0018559208838269114, Depth Loss=0.0000000]
Training progress:   8%|▊         | 150/2000 [02:03<25:24,  1.21it/s, Loss=0.0889675, Gaussian number=182686, print grad=0.002047654241323471, Depth Loss=0.0000000] 
Training progress:   8%|▊         | 160/2000 [02:03<21:00,  1.46it/s, Loss=0.0889675, Gaussian number=182686, print grad=0.002047654241323471, Depth Loss=0.0000000]
Training progress:   8%|▊         | 160/2000 [02:07<21:00,  1.46it/s, Loss=0.0882236, Gaussian number=182686, print grad=0.0022026568185538054, Depth Loss=0.0000000]
Training progress:   8%|▊         | 170/2000 [02:07<17:57,  1.70it/s, Loss=0.0882236, Gaussian number=182686, print grad=0.0022026568185538054, Depth Loss=0.0000000]
Training progress:   8%|▊         | 170/2000 [02:10<17:57,  1.70it/s, Loss=0.0728581, Gaussian number=182686, print grad=0.0023749845568090677, Depth Loss=0.0000000]
Training progress:   9%|▉         | 180/2000 [02:10<15:47,  1.92it/s, Loss=0.0728581, Gaussian number=182686, print grad=0.0023749845568090677, Depth Loss=0.0000000]
Training progress:   9%|▉         | 180/2000 [02:14<15:47,  1.92it/s, Loss=0.0927999, Gaussian number=182686, print grad=0.002534620463848114, Depth Loss=0.0000000] 
Training progress:  10%|▉         | 190/2000 [02:14<14:16,  2.11it/s, Loss=0.0927999, Gaussian number=182686, print grad=0.002534620463848114, Depth Loss=0.0000000]
Training progress:  10%|▉         | 190/2000 [02:18<14:16,  2.11it/s, Loss=0.0817186, Gaussian number=182686, print grad=0.0027081503067165613, Depth Loss=0.0000000]
Training progress:  10%|█         | 200/2000 [02:18<13:11,  2.27it/s, Loss=0.0817186, Gaussian number=182686, print grad=0.0027081503067165613, Depth Loss=0.0000000]
Training progress:  10%|█         | 200/2000 [03:25<13:11,  2.27it/s, Loss=0.0890515, Gaussian number=182686, print grad=0.0028915994334965944, Depth Loss=0.0000000]
Training progress:  10%|█         | 210/2000 [03:25<1:10:00,  2.35s/it, Loss=0.0890515, Gaussian number=182686, print grad=0.0028915994334965944, Depth Loss=0.0000000]
Training progress:  10%|█         | 210/2000 [03:29<1:10:00,  2.35s/it, Loss=0.0730438, Gaussian number=182686, print grad=0.0030633434653282166, Depth Loss=0.0000000]
Training progress:  11%|█         | 220/2000 [03:29<51:57,  1.75s/it, Loss=0.0730438, Gaussian number=182686, print grad=0.0030633434653282166, Depth Loss=0.0000000]  
Training progress:  11%|█         | 220/2000 [03:33<51:57,  1.75s/it, Loss=0.0813273, Gaussian number=182686, print grad=0.0032411140855401754, Depth Loss=0.0000000]
Training progress:  12%|█▏        | 230/2000 [03:33<39:21,  1.33s/it, Loss=0.0813273, Gaussian number=182686, print grad=0.0032411140855401754, Depth Loss=0.0000000]
Training progress:  12%|█▏        | 230/2000 [03:36<39:21,  1.33s/it, Loss=0.1022819, Gaussian number=182686, print grad=0.003407704411074519, Depth Loss=0.0000000] 
Training progress:  12%|█▏        | 240/2000 [03:36<30:34,  1.04s/it, Loss=0.1022819, Gaussian number=182686, print grad=0.003407704411074519, Depth Loss=0.0000000]
Training progress:  12%|█▏        | 240/2000 [03:40<30:34,  1.04s/it, Loss=0.0779802, Gaussian number=182686, print grad=0.0036007012240588665, Depth Loss=0.0000000]
Training progress:  12%|█▎        | 250/2000 [03:40<24:25,  1.19it/s, Loss=0.0779802, Gaussian number=182686, print grad=0.0036007012240588665, Depth Loss=0.0000000]
Training progress:  12%|█▎        | 250/2000 [03:44<24:25,  1.19it/s, Loss=0.0855119, Gaussian number=182686, print grad=0.0037752625066787004, Depth Loss=0.0000000]
Training progress:  13%|█▎        | 260/2000 [03:44<20:08,  1.44it/s, Loss=0.0855119, Gaussian number=182686, print grad=0.0037752625066787004, Depth Loss=0.0000000]
Training progress:  13%|█▎        | 260/2000 [03:47<20:08,  1.44it/s, Loss=0.0593996, Gaussian number=182686, print grad=0.00395954679697752, Depth Loss=0.0000000]  
Training progress:  14%|█▎        | 270/2000 [03:47<17:07,  1.68it/s, Loss=0.0593996, Gaussian number=182686, print grad=0.00395954679697752, Depth Loss=0.0000000]
Training progress:  14%|█▎        | 270/2000 [03:51<17:07,  1.68it/s, Loss=0.0789894, Gaussian number=182686, print grad=0.004159971140325069, Depth Loss=0.0000000]
Training progress:  14%|█▍        | 280/2000 [03:51<15:01,  1.91it/s, Loss=0.0789894, Gaussian number=182686, print grad=0.004159971140325069, Depth Loss=0.0000000]
Training progress:  14%|█▍        | 280/2000 [03:54<15:01,  1.91it/s, Loss=0.0766712, Gaussian number=182686, print grad=0.004356694407761097, Depth Loss=0.0000000]
Training progress:  14%|█▍        | 290/2000 [03:54<13:31,  2.11it/s, Loss=0.0766712, Gaussian number=182686, print grad=0.004356694407761097, Depth Loss=0.0000000]
Training progress:  14%|█▍        | 290/2000 [03:58<13:31,  2.11it/s, Loss=0.0717473, Gaussian number=182686, print grad=0.004553061909973621, Depth Loss=0.0000000]
Training progress:  15%|█▌        | 300/2000 [03:58<12:28,  2.27it/s, Loss=0.0717473, Gaussian number=182686, print grad=0.004553061909973621, Depth Loss=0.0000000]
Training progress:  15%|█▌        | 300/2000 [05:06<12:28,  2.27it/s, Loss=0.0607991, Gaussian number=182686, print grad=0.004757758695632219, Depth Loss=0.0000000]
Training progress:  16%|█▌        | 310/2000 [05:06<1:06:09,  2.35s/it, Loss=0.0607991, Gaussian number=182686, print grad=0.004757758695632219, Depth Loss=0.0000000]
Training progress:  16%|█▌        | 310/2000 [05:10<1:06:09,  2.35s/it, Loss=0.0613188, Gaussian number=182686, print grad=0.004913396202027798, Depth Loss=0.0000000]
Training progress:  16%|█▌        | 320/2000 [05:10<49:02,  1.75s/it, Loss=0.0613188, Gaussian number=182686, print grad=0.004913396202027798, Depth Loss=0.0000000]  
Training progress:  16%|█▌        | 320/2000 [05:13<49:02,  1.75s/it, Loss=0.0810737, Gaussian number=182686, print grad=0.005087999161332846, Depth Loss=0.0000000]
Training progress:  16%|█▋        | 330/2000 [05:13<37:08,  1.33s/it, Loss=0.0810737, Gaussian number=182686, print grad=0.005087999161332846, Depth Loss=0.0000000]
Training progress:  16%|█▋        | 330/2000 [05:17<37:08,  1.33s/it, Loss=0.0612024, Gaussian number=182686, print grad=0.005285835359245539, Depth Loss=0.0000000]
Training progress:  17%|█▋        | 340/2000 [05:17<28:50,  1.04s/it, Loss=0.0612024, Gaussian number=182686, print grad=0.005285835359245539, Depth Loss=0.0000000]
Training progress:  17%|█▋        | 340/2000 [05:20<28:50,  1.04s/it, Loss=0.0626059, Gaussian number=182686, print grad=0.0054786414839327335, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 350/2000 [05:20<23:01,  1.19it/s, Loss=0.0626059, Gaussian number=182686, print grad=0.0054786414839327335, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 350/2000 [05:24<23:01,  1.19it/s, Loss=0.0605490, Gaussian number=182686, print grad=0.005693383980542421, Depth Loss=0.0000000] 
Training progress:  18%|█▊        | 360/2000 [05:24<18:57,  1.44it/s, Loss=0.0605490, Gaussian number=182686, print grad=0.005693383980542421, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 360/2000 [05:28<18:57,  1.44it/s, Loss=0.0578373, Gaussian number=182686, print grad=0.005885252729058266, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 370/2000 [05:28<16:07,  1.68it/s, Loss=0.0578373, Gaussian number=182686, print grad=0.005885252729058266, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 370/2000 [05:31<16:07,  1.68it/s, Loss=0.0793129, Gaussian number=182686, print grad=0.0060500092804431915, Depth Loss=0.0000000]
Training progress:  19%|█▉        | 380/2000 [05:31<14:07,  1.91it/s, Loss=0.0793129, Gaussian number=182686, print grad=0.0060500092804431915, Depth Loss=0.0000000]
Training progress:  19%|█▉        | 380/2000 [05:35<14:07,  1.91it/s, Loss=0.0679891, Gaussian number=182686, print grad=0.006246933247894049, Depth Loss=0.0000000] 
Training progress:  20%|█▉        | 390/2000 [05:35<12:43,  2.11it/s, Loss=0.0679891, Gaussian number=182686, print grad=0.006246933247894049, Depth Loss=0.0000000]
Training progress:  20%|█▉        | 390/2000 [05:38<12:43,  2.11it/s, Loss=0.0858379, Gaussian number=182686, print grad=0.0064313034527003765, Depth Loss=0.0000000]
Training progress:  20%|██        | 400/2000 [05:38<11:42,  2.28it/s, Loss=0.0858379, Gaussian number=182686, print grad=0.0064313034527003765, Depth Loss=0.0000000]
Training progress:  20%|██        | 400/2000 [05:42<11:42,  2.28it/s, Loss=0.0714640, Gaussian number=182686, print grad=0.006655471865087748, Depth Loss=0.0000000] 
Training progress:  20%|██        | 410/2000 [05:42<11:00,  2.41it/s, Loss=0.0714640, Gaussian number=182686, print grad=0.006655471865087748, Depth Loss=0.0000000]
Training progress:  20%|██        | 410/2000 [05:45<11:00,  2.41it/s, Loss=0.0621956, Gaussian number=182686, print grad=0.006875872611999512, Depth Loss=0.0000000]
Training progress:  21%|██        | 420/2000 [05:45<10:29,  2.51it/s, Loss=0.0621956, Gaussian number=182686, print grad=0.006875872611999512, Depth Loss=0.0000000]
Training progress:  21%|██        | 420/2000 [05:49<10:29,  2.51it/s, Loss=0.0779159, Gaussian number=182686, print grad=0.007096706423908472, Depth Loss=0.0000000]
Training progress:  22%|██▏       | 430/2000 [05:49<10:06,  2.59it/s, Loss=0.0779159, Gaussian number=182686, print grad=0.007096706423908472, Depth Loss=0.0000000]
Training progress:  22%|██▏       | 430/2000 [05:53<10:06,  2.59it/s, Loss=0.0617700, Gaussian number=182686, print grad=0.007293774746358395, Depth Loss=0.0000000]
Training progress:  22%|██▏       | 440/2000 [05:53<09:49,  2.65it/s, Loss=0.0617700, Gaussian number=182686, print grad=0.007293774746358395, Depth Loss=0.0000000]
Training progress:  22%|██▏       | 440/2000 [05:56<09:49,  2.65it/s, Loss=0.0688664, Gaussian number=182686, print grad=0.007503232453018427, Depth Loss=0.0000000]
Training progress:  22%|██▎       | 450/2000 [05:56<09:35,  2.69it/s, Loss=0.0688664, Gaussian number=182686, print grad=0.007503232453018427, Depth Loss=0.0000000]
Training progress:  22%|██▎       | 450/2000 [06:00<09:35,  2.69it/s, Loss=0.0720931, Gaussian number=182686, print grad=0.007703493814915419, Depth Loss=0.0000000]
Training progress:  23%|██▎       | 460/2000 [06:00<09:26,  2.72it/s, Loss=0.0720931, Gaussian number=182686, print grad=0.007703493814915419, Depth Loss=0.0000000]
Training progress:  23%|██▎       | 460/2000 [06:03<09:26,  2.72it/s, Loss=0.0839320, Gaussian number=182686, print grad=0.007899370975792408, Depth Loss=0.0000000]
Training progress:  24%|██▎       | 470/2000 [06:03<09:18,  2.74it/s, Loss=0.0839320, Gaussian number=182686, print grad=0.007899370975792408, Depth Loss=0.0000000]
Training progress:  24%|██▎       | 470/2000 [06:07<09:18,  2.74it/s, Loss=0.0565233, Gaussian number=182686, print grad=0.00811626948416233, Depth Loss=0.0000000] 
Training progress:  24%|██▍       | 480/2000 [06:07<09:11,  2.75it/s, Loss=0.0565233, Gaussian number=182686, print grad=0.00811626948416233, Depth Loss=0.0000000]
Training progress:  24%|██▍       | 480/2000 [06:11<09:11,  2.75it/s, Loss=0.0600580, Gaussian number=182686, print grad=0.008315657265484333, Depth Loss=0.0000000]
Training progress:  24%|██▍       | 490/2000 [06:11<09:06,  2.76it/s, Loss=0.0600580, Gaussian number=182686, print grad=0.008315657265484333, Depth Loss=0.0000000]
Training progress:  24%|██▍       | 490/2000 [06:14<09:06,  2.76it/s, Loss=0.0461892, Gaussian number=182686, print grad=0.00851707998663187, Depth Loss=0.0000000] 
Training progress:  25%|██▌       | 500/2000 [06:14<09:01,  2.77it/s, Loss=0.0461892, Gaussian number=182686, print grad=0.00851707998663187, Depth Loss=0.0000000]
Training progress:  25%|██▌       | 500/2000 [07:22<09:01,  2.77it/s, Loss=0.0553567, Gaussian number=182686, print grad=0.008726377040147781, Depth Loss=0.0000000]
Training progress:  26%|██▌       | 510/2000 [07:22<56:52,  2.29s/it, Loss=0.0553567, Gaussian number=182686, print grad=0.008726377040147781, Depth Loss=0.0000000]
Training progress:  26%|██▌       | 510/2000 [07:26<56:52,  2.29s/it, Loss=0.0596675, Gaussian number=182686, print grad=0.008935708552598953, Depth Loss=0.0000000]
Training progress:  26%|██▌       | 520/2000 [07:26<42:11,  1.71s/it, Loss=0.0596675, Gaussian number=182686, print grad=0.008935708552598953, Depth Loss=0.0000000]
Training progress:  26%|██▌       | 520/2000 [07:29<42:11,  1.71s/it, Loss=0.0440525, Gaussian number=182686, print grad=0.009112555533647537, Depth Loss=0.0000000]
Training progress:  26%|██▋       | 530/2000 [07:29<31:56,  1.30s/it, Loss=0.0440525, Gaussian number=182686, print grad=0.009112555533647537, Depth Loss=0.0000000]
Training progress:  26%|██▋       | 530/2000 [07:33<31:56,  1.30s/it, Loss=0.0609930, Gaussian number=182686, print grad=0.009309914894402027, Depth Loss=0.0000000]
Training progress:  27%|██▋       | 540/2000 [07:33<24:49,  1.02s/it, Loss=0.0609930, Gaussian number=182686, print grad=0.009309914894402027, Depth Loss=0.0000000]
Training progress:  27%|██▋       | 540/2000 [07:36<24:49,  1.02s/it, Loss=0.0560346, Gaussian number=182686, print grad=0.00952757429331541, Depth Loss=0.0000000] 
Training progress:  28%|██▊       | 550/2000 [07:36<19:51,  1.22it/s, Loss=0.0560346, Gaussian number=182686, print grad=0.00952757429331541, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 550/2000 [07:40<19:51,  1.22it/s, Loss=0.0451900, Gaussian number=182686, print grad=0.009727233089506626, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 560/2000 [07:40<16:22,  1.47it/s, Loss=0.0451900, Gaussian number=182686, print grad=0.009727233089506626, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 560/2000 [07:44<16:22,  1.47it/s, Loss=0.0597306, Gaussian number=182686, print grad=0.009945024736225605, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 570/2000 [07:44<13:56,  1.71it/s, Loss=0.0597306, Gaussian number=182686, print grad=0.009945024736225605, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 570/2000 [07:47<13:56,  1.71it/s, Loss=0.0530614, Gaussian number=182686, print grad=0.010157938115298748, Depth Loss=0.0000000]
Training progress:  29%|██▉       | 580/2000 [07:47<12:14,  1.93it/s, Loss=0.0530614, Gaussian number=182686, print grad=0.010157938115298748, Depth Loss=0.0000000]
Training progress:  29%|██▉       | 580/2000 [07:51<12:14,  1.93it/s, Loss=0.0589899, Gaussian number=182686, print grad=0.010366438888013363, Depth Loss=0.0000000]
Training progress:  30%|██▉       | 590/2000 [07:51<11:01,  2.13it/s, Loss=0.0589899, Gaussian number=182686, print grad=0.010366438888013363, Depth Loss=0.0000000]
Training progress:  30%|██▉       | 590/2000 [07:54<11:01,  2.13it/s, Loss=0.0647391, Gaussian number=182686, print grad=0.010563395917415619, Depth Loss=0.0000000]
Training progress:  30%|███       | 600/2000 [07:54<10:09,  2.30it/s, Loss=0.0647391, Gaussian number=182686, print grad=0.010563395917415619, Depth Loss=0.0000000]
Training progress:  30%|███       | 600/2000 [07:58<10:09,  2.30it/s, Loss=0.0529241, Gaussian number=183483, print grad=0.00019113157759420574, Depth Loss=0.0000000]
Training progress:  30%|███       | 610/2000 [07:58<09:33,  2.43it/s, Loss=0.0529241, Gaussian number=183483, print grad=0.00019113157759420574, Depth Loss=0.0000000]
Training progress:  30%|███       | 610/2000 [08:01<09:33,  2.43it/s, Loss=0.0663710, Gaussian number=183483, print grad=0.00040928920498117805, Depth Loss=0.0000000]
Training progress:  31%|███       | 620/2000 [08:01<09:06,  2.53it/s, Loss=0.0663710, Gaussian number=183483, print grad=0.00040928920498117805, Depth Loss=0.0000000]
Training progress:  31%|███       | 620/2000 [08:05<09:06,  2.53it/s, Loss=0.0474781, Gaussian number=183483, print grad=0.0006058831932023168, Depth Loss=0.0000000] 
Training progress:  32%|███▏      | 630/2000 [08:05<08:46,  2.60it/s, Loss=0.0474781, Gaussian number=183483, print grad=0.0006058831932023168, Depth Loss=0.0000000]
Training progress:  32%|███▏      | 630/2000 [08:09<08:46,  2.60it/s, Loss=0.0532661, Gaussian number=183483, print grad=0.0008393688476644456, Depth Loss=0.0000000]
Training progress:  32%|███▏      | 640/2000 [08:09<08:30,  2.66it/s, Loss=0.0532661, Gaussian number=183483, print grad=0.0008393688476644456, Depth Loss=0.0000000]
Training progress:  32%|███▏      | 640/2000 [08:12<08:30,  2.66it/s, Loss=0.0592484, Gaussian number=183483, print grad=0.0010348532814532518, Depth Loss=0.0000000]
Training progress:  32%|███▎      | 650/2000 [08:12<08:19,  2.70it/s, Loss=0.0592484, Gaussian number=183483, print grad=0.0010348532814532518, Depth Loss=0.0000000]
Training progress:  32%|███▎      | 650/2000 [08:16<08:19,  2.70it/s, Loss=0.0574353, Gaussian number=183483, print grad=0.0012558035086840391, Depth Loss=0.0000000]
Training progress:  33%|███▎      | 660/2000 [08:16<08:10,  2.73it/s, Loss=0.0574353, Gaussian number=183483, print grad=0.0012558035086840391, Depth Loss=0.0000000]
Training progress:  33%|███▎      | 660/2000 [08:19<08:10,  2.73it/s, Loss=0.0538551, Gaussian number=183483, print grad=0.0014501074329018593, Depth Loss=0.0000000]
Training progress:  34%|███▎      | 670/2000 [08:19<08:02,  2.75it/s, Loss=0.0538551, Gaussian number=183483, print grad=0.0014501074329018593, Depth Loss=0.0000000]
Training progress:  34%|███▎      | 670/2000 [08:23<08:02,  2.75it/s, Loss=0.0479999, Gaussian number=183483, print grad=0.001671561854891479, Depth Loss=0.0000000] 
Training progress:  34%|███▍      | 680/2000 [08:23<07:56,  2.77it/s, Loss=0.0479999, Gaussian number=183483, print grad=0.001671561854891479, Depth Loss=0.0000000]
Training progress:  34%|███▍      | 680/2000 [08:26<07:56,  2.77it/s, Loss=0.0629642, Gaussian number=183483, print grad=0.001878954702988267, Depth Loss=0.0000000]
Training progress:  34%|███▍      | 690/2000 [08:26<07:51,  2.78it/s, Loss=0.0629642, Gaussian number=183483, print grad=0.001878954702988267, Depth Loss=0.0000000]
Training progress:  34%|███▍      | 690/2000 [08:30<07:51,  2.78it/s, Loss=0.0613139, Gaussian number=183483, print grad=0.0020773974247276783, Depth Loss=0.0000000]
Training progress:  35%|███▌      | 700/2000 [08:30<07:46,  2.79it/s, Loss=0.0613139, Gaussian number=183483, print grad=0.0020773974247276783, Depth Loss=0.0000000]
Training progress:  35%|███▌      | 700/2000 [08:33<07:46,  2.79it/s, Loss=0.0514046, Gaussian number=186599, print grad=0.0001863553625298664, Depth Loss=0.0000000]
Training progress:  36%|███▌      | 710/2000 [08:33<07:41,  2.79it/s, Loss=0.0514046, Gaussian number=186599, print grad=0.0001863553625298664, Depth Loss=0.0000000]
Training progress:  36%|███▌      | 710/2000 [08:37<07:41,  2.79it/s, Loss=0.0493259, Gaussian number=186599, print grad=0.00041288143256679177, Depth Loss=0.0000000]
Training progress:  36%|███▌      | 720/2000 [08:37<07:37,  2.80it/s, Loss=0.0493259, Gaussian number=186599, print grad=0.00041288143256679177, Depth Loss=0.0000000]
Training progress:  36%|███▌      | 720/2000 [08:41<07:37,  2.80it/s, Loss=0.0624195, Gaussian number=186599, print grad=0.0006139210308901966, Depth Loss=0.0000000] 
Training progress:  36%|███▋      | 730/2000 [08:41<07:32,  2.81it/s, Loss=0.0624195, Gaussian number=186599, print grad=0.0006139210308901966, Depth Loss=0.0000000]
Training progress:  36%|███▋      | 730/2000 [08:44<07:32,  2.81it/s, Loss=0.0714399, Gaussian number=186599, print grad=0.0008481019758619368, Depth Loss=0.0000000]
Training progress:  37%|███▋      | 740/2000 [08:44<07:28,  2.81it/s, Loss=0.0714399, Gaussian number=186599, print grad=0.0008481019758619368, Depth Loss=0.0000000]
Training progress:  37%|███▋      | 740/2000 [08:48<07:28,  2.81it/s, Loss=0.0514876, Gaussian number=186599, print grad=0.001067046308889985, Depth Loss=0.0000000] 
Training progress:  38%|███▊      | 750/2000 [08:48<07:24,  2.81it/s, Loss=0.0514876, Gaussian number=186599, print grad=0.001067046308889985, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 750/2000 [08:51<07:24,  2.81it/s, Loss=0.0504228, Gaussian number=186599, print grad=0.0012811367632821202, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 760/2000 [08:51<07:20,  2.81it/s, Loss=0.0504228, Gaussian number=186599, print grad=0.0012811367632821202, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 760/2000 [08:55<07:20,  2.81it/s, Loss=0.0433960, Gaussian number=186599, print grad=0.0015052419621497393, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 770/2000 [08:55<07:17,  2.81it/s, Loss=0.0433960, Gaussian number=186599, print grad=0.0015052419621497393, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 770/2000 [08:58<07:17,  2.81it/s, Loss=0.0601209, Gaussian number=186599, print grad=0.0017109233886003494, Depth Loss=0.0000000]
Training progress:  39%|███▉      | 780/2000 [08:58<07:13,  2.81it/s, Loss=0.0601209, Gaussian number=186599, print grad=0.0017109233886003494, Depth Loss=0.0000000]
Training progress:  39%|███▉      | 780/2000 [09:02<07:13,  2.81it/s, Loss=0.0713028, Gaussian number=186599, print grad=0.0019290696363896132, Depth Loss=0.0000000]
Training progress:  40%|███▉      | 790/2000 [09:02<07:10,  2.81it/s, Loss=0.0713028, Gaussian number=186599, print grad=0.0019290696363896132, Depth Loss=0.0000000]
Training progress:  40%|███▉      | 790/2000 [09:05<07:10,  2.81it/s, Loss=0.0560323, Gaussian number=186599, print grad=0.0021565365605056286, Depth Loss=0.0000000]
Training progress:  40%|████      | 800/2000 [09:05<07:06,  2.81it/s, Loss=0.0560323, Gaussian number=186599, print grad=0.0021565365605056286, Depth Loss=0.0000000]
Training progress:  40%|████      | 800/2000 [09:09<07:06,  2.81it/s, Loss=0.0562157, Gaussian number=190229, print grad=0.0001989983138628304, Depth Loss=0.0000000]
Training progress:  40%|████      | 810/2000 [09:09<07:03,  2.81it/s, Loss=0.0562157, Gaussian number=190229, print grad=0.0001989983138628304, Depth Loss=0.0000000]
Training progress:  40%|████      | 810/2000 [09:13<07:03,  2.81it/s, Loss=0.0553571, Gaussian number=190229, print grad=0.0004171195614617318, Depth Loss=0.0000000]
Training progress:  41%|████      | 820/2000 [09:13<07:00,  2.81it/s, Loss=0.0553571, Gaussian number=190229, print grad=0.0004171195614617318, Depth Loss=0.0000000]
Training progress:  41%|████      | 820/2000 [09:16<07:00,  2.81it/s, Loss=0.0433305, Gaussian number=190229, print grad=0.0006610653945244849, Depth Loss=0.0000000]
Training progress:  42%|████▏     | 830/2000 [09:16<06:56,  2.81it/s, Loss=0.0433305, Gaussian number=190229, print grad=0.0006610653945244849, Depth Loss=0.0000000]
Training progress:  42%|████▏     | 830/2000 [09:20<06:56,  2.81it/s, Loss=0.0485265, Gaussian number=190229, print grad=0.0008841035305522382, Depth Loss=0.0000000]
Training progress:  42%|████▏     | 840/2000 [09:20<06:53,  2.81it/s, Loss=0.0485265, Gaussian number=190229, print grad=0.0008841035305522382, Depth Loss=0.0000000]
Training progress:  42%|████▏     | 840/2000 [09:23<06:53,  2.81it/s, Loss=0.0507992, Gaussian number=190229, print grad=0.0011096963426098228, Depth Loss=0.0000000]
Training progress:  42%|████▎     | 850/2000 [09:23<06:50,  2.80it/s, Loss=0.0507992, Gaussian number=190229, print grad=0.0011096963426098228, Depth Loss=0.0000000]
Training progress:  42%|████▎     | 850/2000 [09:27<06:50,  2.80it/s, Loss=0.0474515, Gaussian number=190229, print grad=0.0013189016608521342, Depth Loss=0.0000000]
Training progress:  43%|████▎     | 860/2000 [09:27<06:46,  2.80it/s, Loss=0.0474515, Gaussian number=190229, print grad=0.0013189016608521342, Depth Loss=0.0000000]
Training progress:  43%|████▎     | 860/2000 [09:30<06:46,  2.80it/s, Loss=0.0558293, Gaussian number=190229, print grad=0.0015262726228684187, Depth Loss=0.0000000]
Training progress:  44%|████▎     | 870/2000 [09:30<06:43,  2.80it/s, Loss=0.0558293, Gaussian number=190229, print grad=0.0015262726228684187, Depth Loss=0.0000000]
Training progress:  44%|████▎     | 870/2000 [09:34<06:43,  2.80it/s, Loss=0.0548631, Gaussian number=190229, print grad=0.0017487052828073502, Depth Loss=0.0000000]
Training progress:  44%|████▍     | 880/2000 [09:34<06:39,  2.80it/s, Loss=0.0548631, Gaussian number=190229, print grad=0.0017487052828073502, Depth Loss=0.0000000]
Training progress:  44%|████▍     | 880/2000 [09:38<06:39,  2.80it/s, Loss=0.0433166, Gaussian number=190229, print grad=0.0019737863913178444, Depth Loss=0.0000000]
Training progress:  44%|████▍     | 890/2000 [09:38<06:35,  2.81it/s, Loss=0.0433166, Gaussian number=190229, print grad=0.0019737863913178444, Depth Loss=0.0000000]
Training progress:  44%|████▍     | 890/2000 [09:41<06:35,  2.81it/s, Loss=0.0547416, Gaussian number=190229, print grad=0.0021932560484856367, Depth Loss=0.0000000]
Training progress:  45%|████▌     | 900/2000 [09:41<06:32,  2.81it/s, Loss=0.0547416, Gaussian number=190229, print grad=0.0021932560484856367, Depth Loss=0.0000000]
Training progress:  45%|████▌     | 900/2000 [09:45<06:32,  2.81it/s, Loss=0.0432226, Gaussian number=194257, print grad=0.0001969473814824596, Depth Loss=0.0000000]
Training progress:  46%|████▌     | 910/2000 [09:45<06:28,  2.81it/s, Loss=0.0432226, Gaussian number=194257, print grad=0.0001969473814824596, Depth Loss=0.0000000]
Training progress:  46%|████▌     | 910/2000 [09:48<06:28,  2.81it/s, Loss=0.0538311, Gaussian number=194257, print grad=0.0003995021397713572, Depth Loss=0.0000000]
Training progress:  46%|████▌     | 920/2000 [09:48<06:24,  2.81it/s, Loss=0.0538311, Gaussian number=194257, print grad=0.0003995021397713572, Depth Loss=0.0000000]
Training progress:  46%|████▌     | 920/2000 [09:52<06:24,  2.81it/s, Loss=0.0534665, Gaussian number=194257, print grad=0.0006503327167592943, Depth Loss=0.0000000]
Training progress:  46%|████▋     | 930/2000 [09:52<06:20,  2.81it/s, Loss=0.0534665, Gaussian number=194257, print grad=0.0006503327167592943, Depth Loss=0.0000000]
Training progress:  46%|████▋     | 930/2000 [09:55<06:20,  2.81it/s, Loss=0.0500145, Gaussian number=194257, print grad=0.0008757046307437122, Depth Loss=0.0000000]
Training progress:  47%|████▋     | 940/2000 [09:55<06:16,  2.81it/s, Loss=0.0500145, Gaussian number=194257, print grad=0.0008757046307437122, Depth Loss=0.0000000]
Training progress:  47%|████▋     | 940/2000 [09:59<06:16,  2.81it/s, Loss=0.0483614, Gaussian number=194257, print grad=0.0010897103929892182, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 950/2000 [09:59<06:13,  2.81it/s, Loss=0.0483614, Gaussian number=194257, print grad=0.0010897103929892182, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 950/2000 [10:02<06:13,  2.81it/s, Loss=0.0466469, Gaussian number=194257, print grad=0.0012988628586754203, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 960/2000 [10:02<06:09,  2.81it/s, Loss=0.0466469, Gaussian number=194257, print grad=0.0012988628586754203, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 960/2000 [10:06<06:09,  2.81it/s, Loss=0.0612419, Gaussian number=194257, print grad=0.0015409074258059263, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 970/2000 [10:06<06:05,  2.81it/s, Loss=0.0612419, Gaussian number=194257, print grad=0.0015409074258059263, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 970/2000 [10:10<06:05,  2.81it/s, Loss=0.0378929, Gaussian number=194257, print grad=0.0017530007753521204, Depth Loss=0.0000000]
Training progress:  49%|████▉     | 980/2000 [10:10<06:02,  2.81it/s, Loss=0.0378929, Gaussian number=194257, print grad=0.0017530007753521204, Depth Loss=0.0000000]
Training progress:  49%|████▉     | 980/2000 [10:13<06:02,  2.81it/s, Loss=0.0419098, Gaussian number=194257, print grad=0.0019384927581995726, Depth Loss=0.0000000]
Training progress:  50%|████▉     | 990/2000 [10:13<05:58,  2.81it/s, Loss=0.0419098, Gaussian number=194257, print grad=0.0019384927581995726, Depth Loss=0.0000000]
Training progress:  50%|████▉     | 990/2000 [10:17<05:58,  2.81it/s, Loss=0.0502044, Gaussian number=194257, print grad=0.0021166126243770123, Depth Loss=0.0000000]
Training progress:  50%|█████     | 1000/2000 [10:17<05:55,  2.81it/s, Loss=0.0502044, Gaussian number=194257, print grad=0.0021166126243770123, Depth Loss=0.0000000]
Training progress:  50%|█████     | 1000/2000 [11:25<05:55,  2.81it/s, Loss=0.0500086, Gaussian number=198448, print grad=0.00019852264085784554, Depth Loss=0.0000000]
Training progress:  50%|█████     | 1010/2000 [11:25<37:43,  2.29s/it, Loss=0.0500086, Gaussian number=198448, print grad=0.00019852264085784554, Depth Loss=0.0000000]
Training progress:  50%|█████     | 1010/2000 [11:28<37:43,  2.29s/it, Loss=0.0618937, Gaussian number=198448, print grad=0.0004539642541203648, Depth Loss=0.0000000] 
Training progress:  51%|█████     | 1020/2000 [11:28<27:52,  1.71s/it, Loss=0.0618937, Gaussian number=198448, print grad=0.0004539642541203648, Depth Loss=0.0000000]
Training progress:  51%|█████     | 1020/2000 [11:32<27:52,  1.71s/it, Loss=0.0482560, Gaussian number=198448, print grad=0.0006946034845896065, Depth Loss=0.0000000]
Training progress:  52%|█████▏    | 1030/2000 [11:32<21:02,  1.30s/it, Loss=0.0482560, Gaussian number=198448, print grad=0.0006946034845896065, Depth Loss=0.0000000]
Training progress:  52%|█████▏    | 1030/2000 [11:35<21:02,  1.30s/it, Loss=0.0514673, Gaussian number=198448, print grad=0.0009441028232686222, Depth Loss=0.0000000]
Training progress:  52%|█████▏    | 1040/2000 [11:35<16:16,  1.02s/it, Loss=0.0514673, Gaussian number=198448, print grad=0.0009441028232686222, Depth Loss=0.0000000]
Training progress:  52%|█████▏    | 1040/2000 [11:39<16:16,  1.02s/it, Loss=0.0464411, Gaussian number=198448, print grad=0.001134632620960474, Depth Loss=0.0000000] 
Training progress:  52%|█████▎    | 1050/2000 [11:39<12:57,  1.22it/s, Loss=0.0464411, Gaussian number=198448, print grad=0.001134632620960474, Depth Loss=0.0000000]
Training progress:  52%|█████▎    | 1050/2000 [11:42<12:57,  1.22it/s, Loss=0.0424477, Gaussian number=198448, print grad=0.001350240665487945, Depth Loss=0.0000000]
Training progress:  53%|█████▎    | 1060/2000 [11:42<10:38,  1.47it/s, Loss=0.0424477, Gaussian number=198448, print grad=0.001350240665487945, Depth Loss=0.0000000]
Training progress:  53%|█████▎    | 1060/2000 [11:46<10:38,  1.47it/s, Loss=0.0353710, Gaussian number=198448, print grad=0.0015712515451014042, Depth Loss=0.0000000]
Training progress:  54%|█████▎    | 1070/2000 [11:46<09:00,  1.72it/s, Loss=0.0353710, Gaussian number=198448, print grad=0.0015712515451014042, Depth Loss=0.0000000]
Training progress:  54%|█████▎    | 1070/2000 [11:49<09:00,  1.72it/s, Loss=0.0389309, Gaussian number=198448, print grad=0.001779443002305925, Depth Loss=0.0000000] 
Training progress:  54%|█████▍    | 1080/2000 [11:49<07:52,  1.95it/s, Loss=0.0389309, Gaussian number=198448, print grad=0.001779443002305925, Depth Loss=0.0000000]
Training progress:  54%|█████▍    | 1080/2000 [11:53<07:52,  1.95it/s, Loss=0.0439066, Gaussian number=198448, print grad=0.001988393487408757, Depth Loss=0.0000000]
Training progress:  55%|█████▍    | 1090/2000 [11:53<07:03,  2.15it/s, Loss=0.0439066, Gaussian number=198448, print grad=0.001988393487408757, Depth Loss=0.0000000]
Training progress:  55%|█████▍    | 1090/2000 [11:56<07:03,  2.15it/s, Loss=0.0507922, Gaussian number=198448, print grad=0.002201244467869401, Depth Loss=0.0000000]
Training progress:  55%|█████▌    | 1100/2000 [11:56<06:29,  2.31it/s, Loss=0.0507922, Gaussian number=198448, print grad=0.002201244467869401, Depth Loss=0.0000000]
Training progress:  55%|█████▌    | 1100/2000 [12:00<06:29,  2.31it/s, Loss=0.0513573, Gaussian number=202949, print grad=0.00020525979925878346, Depth Loss=0.0000000]
Training progress:  56%|█████▌    | 1110/2000 [12:00<06:03,  2.45it/s, Loss=0.0513573, Gaussian number=202949, print grad=0.00020525979925878346, Depth Loss=0.0000000]
Training progress:  56%|█████▌    | 1110/2000 [12:04<06:03,  2.45it/s, Loss=0.0476282, Gaussian number=202949, print grad=0.0004449190164450556, Depth Loss=0.0000000] 
Training progress:  56%|█████▌    | 1120/2000 [12:04<05:45,  2.55it/s, Loss=0.0476282, Gaussian number=202949, print grad=0.0004449190164450556, Depth Loss=0.0000000]
Training progress:  56%|█████▌    | 1120/2000 [12:07<05:45,  2.55it/s, Loss=0.0383120, Gaussian number=202949, print grad=0.0006886369665153325, Depth Loss=0.0000000]
Training progress:  56%|█████▋    | 1130/2000 [12:07<05:30,  2.63it/s, Loss=0.0383120, Gaussian number=202949, print grad=0.0006886369665153325, Depth Loss=0.0000000]
Training progress:  56%|█████▋    | 1130/2000 [12:11<05:30,  2.63it/s, Loss=0.0490546, Gaussian number=202949, print grad=0.0009255373734049499, Depth Loss=0.0000000]
Training progress:  57%|█████▋    | 1140/2000 [12:11<05:19,  2.69it/s, Loss=0.0490546, Gaussian number=202949, print grad=0.0009255373734049499, Depth Loss=0.0000000]
Training progress:  57%|█████▋    | 1140/2000 [12:14<05:19,  2.69it/s, Loss=0.0334423, Gaussian number=202949, print grad=0.001151396776549518, Depth Loss=0.0000000] 
Training progress:  57%|█████▊    | 1150/2000 [12:14<05:11,  2.73it/s, Loss=0.0334423, Gaussian number=202949, print grad=0.001151396776549518, Depth Loss=0.0000000]
Training progress:  57%|█████▊    | 1150/2000 [12:18<05:11,  2.73it/s, Loss=0.0374499, Gaussian number=202949, print grad=0.0013637248193845153, Depth Loss=0.0000000]
Training progress:  58%|█████▊    | 1160/2000 [12:18<05:04,  2.76it/s, Loss=0.0374499, Gaussian number=202949, print grad=0.0013637248193845153, Depth Loss=0.0000000]
Training progress:  58%|█████▊    | 1160/2000 [12:21<05:04,  2.76it/s, Loss=0.0468954, Gaussian number=202949, print grad=0.0015861248830333352, Depth Loss=0.0000000]
Training progress:  58%|█████▊    | 1170/2000 [12:21<04:59,  2.77it/s, Loss=0.0468954, Gaussian number=202949, print grad=0.0015861248830333352, Depth Loss=0.0000000]
Training progress:  58%|█████▊    | 1170/2000 [12:25<04:59,  2.77it/s, Loss=0.0458088, Gaussian number=202949, print grad=0.0017989035695791245, Depth Loss=0.0000000]
Training progress:  59%|█████▉    | 1180/2000 [12:25<04:53,  2.79it/s, Loss=0.0458088, Gaussian number=202949, print grad=0.0017989035695791245, Depth Loss=0.0000000]
Training progress:  59%|█████▉    | 1180/2000 [12:28<04:53,  2.79it/s, Loss=0.0421574, Gaussian number=202949, print grad=0.0020287074148654938, Depth Loss=0.0000000]
Training progress:  60%|█████▉    | 1190/2000 [12:28<04:48,  2.80it/s, Loss=0.0421574, Gaussian number=202949, print grad=0.0020287074148654938, Depth Loss=0.0000000]
Training progress:  60%|█████▉    | 1190/2000 [12:32<04:48,  2.80it/s, Loss=0.0488517, Gaussian number=202949, print grad=0.0022156662307679653, Depth Loss=0.0000000]
Training progress:  60%|██████    | 1200/2000 [12:32<04:44,  2.81it/s, Loss=0.0488517, Gaussian number=202949, print grad=0.0022156662307679653, Depth Loss=0.0000000]
Training progress:  60%|██████    | 1200/2000 [12:35<04:44,  2.81it/s, Loss=0.0383313, Gaussian number=207721, print grad=0.0002107358304783702, Depth Loss=0.0000000]
Training progress:  60%|██████    | 1210/2000 [12:35<04:40,  2.82it/s, Loss=0.0383313, Gaussian number=207721, print grad=0.0002107358304783702, Depth Loss=0.0000000]
Training progress:  60%|██████    | 1210/2000 [12:39<04:40,  2.82it/s, Loss=0.0322538, Gaussian number=207721, print grad=0.0004513072199188173, Depth Loss=0.0000000]
Training progress:  61%|██████    | 1220/2000 [12:39<04:36,  2.82it/s, Loss=0.0322538, Gaussian number=207721, print grad=0.0004513072199188173, Depth Loss=0.0000000]
Training progress:  61%|██████    | 1220/2000 [12:42<04:36,  2.82it/s, Loss=0.0363113, Gaussian number=207721, print grad=0.0006577098392881453, Depth Loss=0.0000000]
Training progress:  62%|██████▏   | 1230/2000 [12:42<04:32,  2.82it/s, Loss=0.0363113, Gaussian number=207721, print grad=0.0006577098392881453, Depth Loss=0.0000000]
Training progress:  62%|██████▏   | 1230/2000 [12:46<04:32,  2.82it/s, Loss=0.0338321, Gaussian number=207721, print grad=0.0008789973217062652, Depth Loss=0.0000000]
Training progress:  62%|██████▏   | 1240/2000 [12:46<04:29,  2.82it/s, Loss=0.0338321, Gaussian number=207721, print grad=0.0008789973217062652, Depth Loss=0.0000000]
Training progress:  62%|██████▏   | 1240/2000 [12:49<04:29,  2.82it/s, Loss=0.0339356, Gaussian number=207721, print grad=0.0010799411684274673, Depth Loss=0.0000000]
Training progress:  62%|██████▎   | 1250/2000 [12:49<04:25,  2.82it/s, Loss=0.0339356, Gaussian number=207721, print grad=0.0010799411684274673, Depth Loss=0.0000000]
Training progress:  62%|██████▎   | 1250/2000 [12:53<04:25,  2.82it/s, Loss=0.0358953, Gaussian number=207721, print grad=0.0012774588540196419, Depth Loss=0.0000000]
Training progress:  63%|██████▎   | 1260/2000 [12:53<04:21,  2.82it/s, Loss=0.0358953, Gaussian number=207721, print grad=0.0012774588540196419, Depth Loss=0.0000000]
Training progress:  63%|██████▎   | 1260/2000 [12:57<04:21,  2.82it/s, Loss=0.0482707, Gaussian number=207721, print grad=0.0014935517683625221, Depth Loss=0.0000000]
Training progress:  64%|██████▎   | 1270/2000 [12:57<04:18,  2.82it/s, Loss=0.0482707, Gaussian number=207721, print grad=0.0014935517683625221, Depth Loss=0.0000000]
Training progress:  64%|██████▎   | 1270/2000 [13:00<04:18,  2.82it/s, Loss=0.0460046, Gaussian number=207721, print grad=0.0017048368463292718, Depth Loss=0.0000000]
Training progress:  64%|██████▍   | 1280/2000 [13:00<04:14,  2.83it/s, Loss=0.0460046, Gaussian number=207721, print grad=0.0017048368463292718, Depth Loss=0.0000000]
Training progress:  64%|██████▍   | 1280/2000 [13:04<04:14,  2.83it/s, Loss=0.0336843, Gaussian number=207721, print grad=0.0019339952850714326, Depth Loss=0.0000000]
Training progress:  64%|██████▍   | 1290/2000 [13:04<04:11,  2.83it/s, Loss=0.0336843, Gaussian number=207721, print grad=0.0019339952850714326, Depth Loss=0.0000000]
Training progress:  64%|██████▍   | 1290/2000 [13:07<04:11,  2.83it/s, Loss=0.0518497, Gaussian number=207721, print grad=0.0021350057795643806, Depth Loss=0.0000000]
Training progress:  65%|██████▌   | 1300/2000 [13:07<04:07,  2.82it/s, Loss=0.0518497, Gaussian number=207721, print grad=0.0021350057795643806, Depth Loss=0.0000000]
Training progress:  65%|██████▌   | 1300/2000 [13:11<04:07,  2.82it/s, Loss=0.0515061, Gaussian number=212294, print grad=0.00022426315990742296, Depth Loss=0.0000000]
Training progress:  66%|██████▌   | 1310/2000 [13:11<04:03,  2.83it/s, Loss=0.0515061, Gaussian number=212294, print grad=0.00022426315990742296, Depth Loss=0.0000000]
Training progress:  66%|██████▌   | 1310/2000 [13:14<04:03,  2.83it/s, Loss=0.0511189, Gaussian number=212294, print grad=0.0004455700109247118, Depth Loss=0.0000000] 
Training progress:  66%|██████▌   | 1320/2000 [13:14<03:59,  2.84it/s, Loss=0.0511189, Gaussian number=212294, print grad=0.0004455700109247118, Depth Loss=0.0000000]
Training progress:  66%|██████▌   | 1320/2000 [13:18<03:59,  2.84it/s, Loss=0.0390140, Gaussian number=212294, print grad=0.000675510847941041, Depth Loss=0.0000000] 
Training progress:  66%|██████▋   | 1330/2000 [13:18<03:55,  2.84it/s, Loss=0.0390140, Gaussian number=212294, print grad=0.000675510847941041, Depth Loss=0.0000000]
Training progress:  66%|██████▋   | 1330/2000 [13:21<03:55,  2.84it/s, Loss=0.0408962, Gaussian number=212294, print grad=0.0009021017467603087, Depth Loss=0.0000000]
Training progress:  67%|██████▋   | 1340/2000 [13:21<03:52,  2.84it/s, Loss=0.0408962, Gaussian number=212294, print grad=0.0009021017467603087, Depth Loss=0.0000000]
Training progress:  67%|██████▋   | 1340/2000 [13:25<03:52,  2.84it/s, Loss=0.0576538, Gaussian number=212294, print grad=0.0011040953686460853, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1350/2000 [13:25<03:48,  2.85it/s, Loss=0.0576538, Gaussian number=212294, print grad=0.0011040953686460853, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1350/2000 [13:28<03:48,  2.85it/s, Loss=0.0343547, Gaussian number=212294, print grad=0.0013055176241323352, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1360/2000 [13:28<03:44,  2.85it/s, Loss=0.0343547, Gaussian number=212294, print grad=0.0013055176241323352, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1360/2000 [13:32<03:44,  2.85it/s, Loss=0.0613870, Gaussian number=212294, print grad=0.0015272919554263353, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1370/2000 [13:32<03:41,  2.85it/s, Loss=0.0613870, Gaussian number=212294, print grad=0.0015272919554263353, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1370/2000 [13:35<03:41,  2.85it/s, Loss=0.0386205, Gaussian number=212294, print grad=0.0017278383020311594, Depth Loss=0.0000000]
Training progress:  69%|██████▉   | 1380/2000 [13:35<03:37,  2.85it/s, Loss=0.0386205, Gaussian number=212294, print grad=0.0017278383020311594, Depth Loss=0.0000000]
Training progress:  69%|██████▉   | 1380/2000 [13:39<03:37,  2.85it/s, Loss=0.0357788, Gaussian number=212294, print grad=0.0019205686403438449, Depth Loss=0.0000000]
Training progress:  70%|██████▉   | 1390/2000 [13:39<03:34,  2.85it/s, Loss=0.0357788, Gaussian number=212294, print grad=0.0019205686403438449, Depth Loss=0.0000000]
Training progress:  70%|██████▉   | 1390/2000 [13:42<03:34,  2.85it/s, Loss=0.0393578, Gaussian number=212294, print grad=0.0021259731147438288, Depth Loss=0.0000000]
Training progress:  70%|███████   | 1400/2000 [13:42<03:30,  2.85it/s, Loss=0.0393578, Gaussian number=212294, print grad=0.0021259731147438288, Depth Loss=0.0000000]
Training progress:  70%|███████   | 1400/2000 [13:46<03:30,  2.85it/s, Loss=0.0473785, Gaussian number=217163, print grad=0.00021071135415695608, Depth Loss=0.0000000]
Training progress:  70%|███████   | 1410/2000 [13:46<03:27,  2.85it/s, Loss=0.0473785, Gaussian number=217163, print grad=0.00021071135415695608, Depth Loss=0.0000000]
Training progress:  70%|███████   | 1410/2000 [13:49<03:27,  2.85it/s, Loss=0.0396460, Gaussian number=217163, print grad=0.00045318290358409286, Depth Loss=0.0000000]
Training progress:  71%|███████   | 1420/2000 [13:49<03:23,  2.85it/s, Loss=0.0396460, Gaussian number=217163, print grad=0.00045318290358409286, Depth Loss=0.0000000]
Training progress:  71%|███████   | 1420/2000 [13:53<03:23,  2.85it/s, Loss=0.0418651, Gaussian number=217163, print grad=0.0006950694369152188, Depth Loss=0.0000000] 
Training progress:  72%|███████▏  | 1430/2000 [13:53<03:20,  2.85it/s, Loss=0.0418651, Gaussian number=217163, print grad=0.0006950694369152188, Depth Loss=0.0000000]
Training progress:  72%|███████▏  | 1430/2000 [13:56<03:20,  2.85it/s, Loss=0.0386766, Gaussian number=217163, print grad=0.000909169262740761, Depth Loss=0.0000000] 
Training progress:  72%|███████▏  | 1440/2000 [13:56<03:16,  2.85it/s, Loss=0.0386766, Gaussian number=217163, print grad=0.000909169262740761, Depth Loss=0.0000000]
Training progress:  72%|███████▏  | 1440/2000 [14:00<03:16,  2.85it/s, Loss=0.0368097, Gaussian number=217163, print grad=0.001117270439863205, Depth Loss=0.0000000]
Training progress:  72%|███████▎  | 1450/2000 [14:00<03:12,  2.85it/s, Loss=0.0368097, Gaussian number=217163, print grad=0.001117270439863205, Depth Loss=0.0000000]
Training progress:  72%|███████▎  | 1450/2000 [14:03<03:12,  2.85it/s, Loss=0.0309898, Gaussian number=217163, print grad=0.0013202582485973835, Depth Loss=0.0000000]
Training progress:  73%|███████▎  | 1460/2000 [14:03<03:09,  2.85it/s, Loss=0.0309898, Gaussian number=217163, print grad=0.0013202582485973835, Depth Loss=0.0000000]
Training progress:  73%|███████▎  | 1460/2000 [14:07<03:09,  2.85it/s, Loss=0.0424715, Gaussian number=217163, print grad=0.001536661759018898, Depth Loss=0.0000000] 
Training progress:  74%|███████▎  | 1470/2000 [14:07<03:06,  2.85it/s, Loss=0.0424715, Gaussian number=217163, print grad=0.001536661759018898, Depth Loss=0.0000000]
Training progress:  74%|███████▎  | 1470/2000 [14:10<03:06,  2.85it/s, Loss=0.0418267, Gaussian number=217163, print grad=0.001752918236888945, Depth Loss=0.0000000]
Training progress:  74%|███████▍  | 1480/2000 [14:10<03:02,  2.85it/s, Loss=0.0418267, Gaussian number=217163, print grad=0.001752918236888945, Depth Loss=0.0000000]
Training progress:  74%|███████▍  | 1480/2000 [14:14<03:02,  2.85it/s, Loss=0.0439699, Gaussian number=217163, print grad=0.001969106262549758, Depth Loss=0.0000000]
Training progress:  74%|███████▍  | 1490/2000 [14:14<02:58,  2.85it/s, Loss=0.0439699, Gaussian number=217163, print grad=0.001969106262549758, Depth Loss=0.0000000]
Training progress:  74%|███████▍  | 1490/2000 [14:17<02:58,  2.85it/s, Loss=0.0447512, Gaussian number=217163, print grad=0.0021879293490201235, Depth Loss=0.0000000]
Training progress:  75%|███████▌  | 1500/2000 [14:17<02:55,  2.85it/s, Loss=0.0447512, Gaussian number=217163, print grad=0.0021879293490201235, Depth Loss=0.0000000]
Training progress:  75%|███████▌  | 1500/2000 [15:25<02:55,  2.85it/s, Loss=0.0486290, Gaussian number=221571, print grad=0.00019765131582971662, Depth Loss=0.0000000]
Training progress:  76%|███████▌  | 1510/2000 [15:25<18:38,  2.28s/it, Loss=0.0486290, Gaussian number=221571, print grad=0.00019765131582971662, Depth Loss=0.0000000]
Training progress:  76%|███████▌  | 1510/2000 [15:29<18:38,  2.28s/it, Loss=0.0428317, Gaussian number=221571, print grad=0.00040010194061324, Depth Loss=0.0000000]   
Training progress:  76%|███████▌  | 1520/2000 [15:29<13:37,  1.70s/it, Loss=0.0428317, Gaussian number=221571, print grad=0.00040010194061324, Depth Loss=0.0000000]
Training progress:  76%|███████▌  | 1520/2000 [15:32<13:37,  1.70s/it, Loss=0.0255391, Gaussian number=221571, print grad=0.0006320812390185893, Depth Loss=0.0000000]
Training progress:  76%|███████▋  | 1530/2000 [15:32<10:10,  1.30s/it, Loss=0.0255391, Gaussian number=221571, print grad=0.0006320812390185893, Depth Loss=0.0000000]
Training progress:  76%|███████▋  | 1530/2000 [15:36<10:10,  1.30s/it, Loss=0.0376358, Gaussian number=221571, print grad=0.0008472573244944215, Depth Loss=0.0000000]
Training progress:  77%|███████▋  | 1540/2000 [15:36<07:47,  1.02s/it, Loss=0.0376358, Gaussian number=221571, print grad=0.0008472573244944215, Depth Loss=0.0000000]
Training progress:  77%|███████▋  | 1540/2000 [15:39<07:47,  1.02s/it, Loss=0.0393613, Gaussian number=221571, print grad=0.0010760778095573187, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1550/2000 [15:39<06:07,  1.22it/s, Loss=0.0393613, Gaussian number=221571, print grad=0.0010760778095573187, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1550/2000 [15:43<06:07,  1.22it/s, Loss=0.0398838, Gaussian number=221571, print grad=0.0013045337982475758, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1560/2000 [15:43<04:58,  1.48it/s, Loss=0.0398838, Gaussian number=221571, print grad=0.0013045337982475758, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1560/2000 [15:46<04:58,  1.48it/s, Loss=0.0355247, Gaussian number=221571, print grad=0.001519812154583633, Depth Loss=0.0000000] 
Training progress:  78%|███████▊  | 1570/2000 [15:46<04:09,  1.72it/s, Loss=0.0355247, Gaussian number=221571, print grad=0.001519812154583633, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1570/2000 [15:50<04:09,  1.72it/s, Loss=0.0259497, Gaussian number=221571, print grad=0.0016888052923604846, Depth Loss=0.0000000]
Training progress:  79%|███████▉  | 1580/2000 [15:50<03:35,  1.95it/s, Loss=0.0259497, Gaussian number=221571, print grad=0.0016888052923604846, Depth Loss=0.0000000]
Training progress:  79%|███████▉  | 1580/2000 [15:54<03:35,  1.95it/s, Loss=0.0354935, Gaussian number=221571, print grad=0.001890283077955246, Depth Loss=0.0000000] 
Training progress:  80%|███████▉  | 1590/2000 [15:54<03:10,  2.15it/s, Loss=0.0354935, Gaussian number=221571, print grad=0.001890283077955246, Depth Loss=0.0000000]
Training progress:  80%|███████▉  | 1590/2000 [15:57<03:10,  2.15it/s, Loss=0.0351397, Gaussian number=221571, print grad=0.0021046504843980074, Depth Loss=0.0000000]
Training progress:  80%|████████  | 1600/2000 [15:57<02:52,  2.32it/s, Loss=0.0351397, Gaussian number=221571, print grad=0.0021046504843980074, Depth Loss=0.0000000]
Training progress:  80%|████████  | 1600/2000 [16:01<02:52,  2.32it/s, Loss=0.0381115, Gaussian number=225531, print grad=0.0002138531272066757, Depth Loss=0.0000000]
Training progress:  80%|████████  | 1610/2000 [16:01<02:39,  2.45it/s, Loss=0.0381115, Gaussian number=225531, print grad=0.0002138531272066757, Depth Loss=0.0000000]
Training progress:  80%|████████  | 1610/2000 [16:04<02:39,  2.45it/s, Loss=0.0416634, Gaussian number=225531, print grad=0.0004522073140833527, Depth Loss=0.0000000]
Training progress:  81%|████████  | 1620/2000 [16:04<02:28,  2.55it/s, Loss=0.0416634, Gaussian number=225531, print grad=0.0004522073140833527, Depth Loss=0.0000000]
Training progress:  81%|████████  | 1620/2000 [16:08<02:28,  2.55it/s, Loss=0.0356752, Gaussian number=225531, print grad=0.0006639983039349318, Depth Loss=0.0000000]
Training progress:  82%|████████▏ | 1630/2000 [16:08<02:20,  2.63it/s, Loss=0.0356752, Gaussian number=225531, print grad=0.0006639983039349318, Depth Loss=0.0000000]
Training progress:  82%|████████▏ | 1630/2000 [16:11<02:20,  2.63it/s, Loss=0.0259888, Gaussian number=225531, print grad=0.0008792056469246745, Depth Loss=0.0000000]
Training progress:  82%|████████▏ | 1640/2000 [16:11<02:14,  2.68it/s, Loss=0.0259888, Gaussian number=225531, print grad=0.0008792056469246745, Depth Loss=0.0000000]
Training progress:  82%|████████▏ | 1640/2000 [16:15<02:14,  2.68it/s, Loss=0.0364802, Gaussian number=225531, print grad=0.0010733861709013581, Depth Loss=0.0000000]
Training progress:  82%|████████▎ | 1650/2000 [16:15<02:08,  2.72it/s, Loss=0.0364802, Gaussian number=225531, print grad=0.0010733861709013581, Depth Loss=0.0000000]
Training progress:  82%|████████▎ | 1650/2000 [16:18<02:08,  2.72it/s, Loss=0.0345403, Gaussian number=225531, print grad=0.0012812193017452955, Depth Loss=0.0000000]
Training progress:  83%|████████▎ | 1660/2000 [16:18<02:03,  2.75it/s, Loss=0.0345403, Gaussian number=225531, print grad=0.0012812193017452955, Depth Loss=0.0000000]
Training progress:  83%|████████▎ | 1660/2000 [16:22<02:03,  2.75it/s, Loss=0.0322066, Gaussian number=225531, print grad=0.0014835657784715295, Depth Loss=0.0000000]
Training progress:  84%|████████▎ | 1670/2000 [16:22<01:58,  2.77it/s, Loss=0.0322066, Gaussian number=225531, print grad=0.0014835657784715295, Depth Loss=0.0000000]
Training progress:  84%|████████▎ | 1670/2000 [16:25<01:58,  2.77it/s, Loss=0.0295839, Gaussian number=225531, print grad=0.0016944643575698137, Depth Loss=0.0000000]
Training progress:  84%|████████▍ | 1680/2000 [16:25<01:54,  2.79it/s, Loss=0.0295839, Gaussian number=225531, print grad=0.0016944643575698137, Depth Loss=0.0000000]
Training progress:  84%|████████▍ | 1680/2000 [16:29<01:54,  2.79it/s, Loss=0.0362179, Gaussian number=225531, print grad=0.001894728047773242, Depth Loss=0.0000000] 
Training progress:  84%|████████▍ | 1690/2000 [16:29<01:50,  2.79it/s, Loss=0.0362179, Gaussian number=225531, print grad=0.001894728047773242, Depth Loss=0.0000000]
Training progress:  84%|████████▍ | 1690/2000 [16:33<01:50,  2.79it/s, Loss=0.0358000, Gaussian number=225531, print grad=0.0020714271813631058, Depth Loss=0.0000000]
Training progress:  85%|████████▌ | 1700/2000 [16:33<01:47,  2.80it/s, Loss=0.0358000, Gaussian number=225531, print grad=0.0020714271813631058, Depth Loss=0.0000000]
Training progress:  85%|████████▌ | 1700/2000 [16:36<01:47,  2.80it/s, Loss=0.0398855, Gaussian number=229622, print grad=0.00021808412566315383, Depth Loss=0.0000000]
Training progress:  86%|████████▌ | 1710/2000 [16:36<01:42,  2.82it/s, Loss=0.0398855, Gaussian number=229622, print grad=0.00021808412566315383, Depth Loss=0.0000000]
Training progress:  86%|████████▌ | 1710/2000 [16:40<01:42,  2.82it/s, Loss=0.0420289, Gaussian number=229622, print grad=0.00040332775097340345, Depth Loss=0.0000000]
Training progress:  86%|████████▌ | 1720/2000 [16:40<01:38,  2.83it/s, Loss=0.0420289, Gaussian number=229622, print grad=0.00040332775097340345, Depth Loss=0.0000000]
Training progress:  86%|████████▌ | 1720/2000 [16:43<01:38,  2.83it/s, Loss=0.0353811, Gaussian number=229622, print grad=0.0006167364190332592, Depth Loss=0.0000000] 
Training progress:  86%|████████▋ | 1730/2000 [16:43<01:35,  2.84it/s, Loss=0.0353811, Gaussian number=229622, print grad=0.0006167364190332592, Depth Loss=0.0000000]
Training progress:  86%|████████▋ | 1730/2000 [16:47<01:35,  2.84it/s, Loss=0.0493297, Gaussian number=229622, print grad=0.000841562170535326, Depth Loss=0.0000000] 
Training progress:  87%|████████▋ | 1740/2000 [16:47<01:31,  2.84it/s, Loss=0.0493297, Gaussian number=229622, print grad=0.000841562170535326, Depth Loss=0.0000000]
Training progress:  87%|████████▋ | 1740/2000 [16:50<01:31,  2.84it/s, Loss=0.0476797, Gaussian number=229622, print grad=0.0010690633207559586, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1750/2000 [16:50<01:27,  2.84it/s, Loss=0.0476797, Gaussian number=229622, print grad=0.0010690633207559586, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1750/2000 [16:54<01:27,  2.84it/s, Loss=0.0372270, Gaussian number=229622, print grad=0.0012662914814427495, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1760/2000 [16:54<01:24,  2.85it/s, Loss=0.0372270, Gaussian number=229622, print grad=0.0012662914814427495, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1760/2000 [16:57<01:24,  2.85it/s, Loss=0.0300007, Gaussian number=229622, print grad=0.001457749167457223, Depth Loss=0.0000000] 
Training progress:  88%|████████▊ | 1770/2000 [16:57<01:20,  2.85it/s, Loss=0.0300007, Gaussian number=229622, print grad=0.001457749167457223, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1770/2000 [17:01<01:20,  2.85it/s, Loss=0.0359309, Gaussian number=229622, print grad=0.0016454723663628101, Depth Loss=0.0000000]
Training progress:  89%|████████▉ | 1780/2000 [17:01<01:17,  2.85it/s, Loss=0.0359309, Gaussian number=229622, print grad=0.0016454723663628101, Depth Loss=0.0000000]
Training progress:  89%|████████▉ | 1780/2000 [17:04<01:17,  2.85it/s, Loss=0.0321608, Gaussian number=229622, print grad=0.001810935907997191, Depth Loss=0.0000000] 
Training progress:  90%|████████▉ | 1790/2000 [17:04<01:13,  2.85it/s, Loss=0.0321608, Gaussian number=229622, print grad=0.001810935907997191, Depth Loss=0.0000000]
Training progress:  90%|████████▉ | 1790/2000 [17:08<01:13,  2.85it/s, Loss=0.0329372, Gaussian number=229622, print grad=0.002014476340264082, Depth Loss=0.0000000]
Training progress:  90%|█████████ | 1800/2000 [17:08<01:10,  2.85it/s, Loss=0.0329372, Gaussian number=229622, print grad=0.002014476340264082, Depth Loss=0.0000000]
Training progress:  90%|█████████ | 1800/2000 [17:11<01:10,  2.85it/s, Loss=0.0385711, Gaussian number=233238, print grad=0.00021787197329103947, Depth Loss=0.0000000]
Training progress:  90%|█████████ | 1810/2000 [17:11<01:06,  2.85it/s, Loss=0.0385711, Gaussian number=233238, print grad=0.00021787197329103947, Depth Loss=0.0000000]
Training progress:  90%|█████████ | 1810/2000 [17:15<01:06,  2.85it/s, Loss=0.0326827, Gaussian number=233238, print grad=0.00043923614430241287, Depth Loss=0.0000000]
Training progress:  91%|█████████ | 1820/2000 [17:15<01:03,  2.86it/s, Loss=0.0326827, Gaussian number=233238, print grad=0.00043923614430241287, Depth Loss=0.0000000]
Training progress:  91%|█████████ | 1820/2000 [17:18<01:03,  2.86it/s, Loss=0.0292523, Gaussian number=233238, print grad=0.0006288316217251122, Depth Loss=0.0000000] 
Training progress:  92%|█████████▏| 1830/2000 [17:18<00:59,  2.86it/s, Loss=0.0292523, Gaussian number=233238, print grad=0.0006288316217251122, Depth Loss=0.0000000]
Training progress:  92%|█████████▏| 1830/2000 [17:22<00:59,  2.86it/s, Loss=0.0298662, Gaussian number=233238, print grad=0.0008446176652796566, Depth Loss=0.0000000]
Training progress:  92%|█████████▏| 1840/2000 [17:22<00:55,  2.86it/s, Loss=0.0298662, Gaussian number=233238, print grad=0.0008446176652796566, Depth Loss=0.0000000]
Training progress:  92%|█████████▏| 1840/2000 [17:25<00:55,  2.86it/s, Loss=0.0331623, Gaussian number=233238, print grad=0.001040786737576127, Depth Loss=0.0000000] 
Training progress:  92%|█████████▎| 1850/2000 [17:25<00:52,  2.86it/s, Loss=0.0331623, Gaussian number=233238, print grad=0.001040786737576127, Depth Loss=0.0000000]
Training progress:  92%|█████████▎| 1850/2000 [17:29<00:52,  2.86it/s, Loss=0.0348951, Gaussian number=233238, print grad=0.0012127821100875735, Depth Loss=0.0000000]
Training progress:  93%|█████████▎| 1860/2000 [17:29<00:48,  2.86it/s, Loss=0.0348951, Gaussian number=233238, print grad=0.0012127821100875735, Depth Loss=0.0000000]
Training progress:  93%|█████████▎| 1860/2000 [17:32<00:48,  2.86it/s, Loss=0.0377587, Gaussian number=233238, print grad=0.001437869854271412, Depth Loss=0.0000000] 
Training progress:  94%|█████████▎| 1870/2000 [17:32<00:45,  2.86it/s, Loss=0.0377587, Gaussian number=233238, print grad=0.001437869854271412, Depth Loss=0.0000000]
Training progress:  94%|█████████▎| 1870/2000 [17:36<00:45,  2.86it/s, Loss=0.0289211, Gaussian number=233238, print grad=0.00163318554405123, Depth Loss=0.0000000] 
Training progress:  94%|█████████▍| 1880/2000 [17:36<00:41,  2.86it/s, Loss=0.0289211, Gaussian number=233238, print grad=0.00163318554405123, Depth Loss=0.0000000]
Training progress:  94%|█████████▍| 1880/2000 [17:39<00:41,  2.86it/s, Loss=0.0338356, Gaussian number=233238, print grad=0.0018166539957746863, Depth Loss=0.0000000]
Training progress:  94%|█████████▍| 1890/2000 [17:39<00:38,  2.86it/s, Loss=0.0338356, Gaussian number=233238, print grad=0.0018166539957746863, Depth Loss=0.0000000]
Training progress:  94%|█████████▍| 1890/2000 [17:43<00:38,  2.86it/s, Loss=0.0416917, Gaussian number=233238, print grad=0.002026916015893221, Depth Loss=0.0000000] 
Training progress:  95%|█████████▌| 1900/2000 [17:43<00:34,  2.86it/s, Loss=0.0416917, Gaussian number=233238, print grad=0.002026916015893221, Depth Loss=0.0000000]
Training progress:  95%|█████████▌| 1900/2000 [17:46<00:34,  2.86it/s, Loss=0.0373179, Gaussian number=237800, print grad=0.00018810505571309477, Depth Loss=0.0000000]
Training progress:  96%|█████████▌| 1910/2000 [17:46<00:31,  2.85it/s, Loss=0.0373179, Gaussian number=237800, print grad=0.00018810505571309477, Depth Loss=0.0000000]
Training progress:  96%|█████████▌| 1910/2000 [17:50<00:31,  2.85it/s, Loss=0.0296839, Gaussian number=237800, print grad=0.0004011582932434976, Depth Loss=0.0000000] 
Training progress:  96%|█████████▌| 1920/2000 [17:50<00:28,  2.84it/s, Loss=0.0296839, Gaussian number=237800, print grad=0.0004011582932434976, Depth Loss=0.0000000]
Training progress:  96%|█████████▌| 1920/2000 [17:53<00:28,  2.84it/s, Loss=0.0262991, Gaussian number=237800, print grad=0.0006078627775423229, Depth Loss=0.0000000]
Training progress:  96%|█████████▋| 1930/2000 [17:53<00:24,  2.84it/s, Loss=0.0262991, Gaussian number=237800, print grad=0.0006078627775423229, Depth Loss=0.0000000]
Training progress:  96%|█████████▋| 1930/2000 [17:57<00:24,  2.84it/s, Loss=0.0380119, Gaussian number=237800, print grad=0.0008012347389012575, Depth Loss=0.0000000]
Training progress:  97%|█████████▋| 1940/2000 [17:57<00:21,  2.84it/s, Loss=0.0380119, Gaussian number=237800, print grad=0.0008012347389012575, Depth Loss=0.0000000]
Training progress:  97%|█████████▋| 1940/2000 [18:00<00:21,  2.84it/s, Loss=0.0289433, Gaussian number=237800, print grad=0.0009932952234521508, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1950/2000 [18:00<00:17,  2.83it/s, Loss=0.0289433, Gaussian number=237800, print grad=0.0009932952234521508, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1950/2000 [18:04<00:17,  2.83it/s, Loss=0.0456312, Gaussian number=237800, print grad=0.0011809822171926498, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1960/2000 [18:04<00:14,  2.83it/s, Loss=0.0456312, Gaussian number=237800, print grad=0.0011809822171926498, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1960/2000 [18:07<00:14,  2.83it/s, Loss=0.0396284, Gaussian number=237800, print grad=0.0013776080450043082, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1970/2000 [18:07<00:10,  2.83it/s, Loss=0.0396284, Gaussian number=237800, print grad=0.0013776080450043082, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1970/2000 [18:11<00:10,  2.83it/s, Loss=0.0320753, Gaussian number=237800, print grad=0.001577979070134461, Depth Loss=0.0000000] 
Training progress:  99%|█████████▉| 1980/2000 [18:11<00:07,  2.83it/s, Loss=0.0320753, Gaussian number=237800, print grad=0.001577979070134461, Depth Loss=0.0000000]
Training progress:  99%|█████████▉| 1980/2000 [18:14<00:07,  2.83it/s, Loss=0.0312283, Gaussian number=237800, print grad=0.0018091854872182012, Depth Loss=0.0000000]
Training progress: 100%|█████████▉| 1990/2000 [18:14<00:03,  2.83it/s, Loss=0.0312283, Gaussian number=237800, print grad=0.0018091854872182012, Depth Loss=0.0000000]
Training progress: 100%|█████████▉| 1990/2000 [18:18<00:03,  2.83it/s, Loss=0.0250206, Gaussian number=237800, print grad=0.0020234985277056694, Depth Loss=0.0000000]
Training progress: 100%|██████████| 2000/2000 [18:18<00:00,  2.83it/s, Loss=0.0250206, Gaussian number=237800, print grad=0.0020234985277056694, Depth Loss=0.0000000]
Training progress: 100%|██████████| 2000/2000 [18:18<00:00,  1.82it/s, Loss=0.0250206, Gaussian number=237800, print grad=0.0020234985277056694, Depth Loss=0.0000000]
Iteration 100 [03/12 17:22:13]

[ITER 100] Evaluating test: WD 0.141937, PSNR 12.8084,lpips 0.600272,ssim 0.437186 [03/12 17:23:09]

[ITER 100] Evaluating train: WD 0.145433, PSNR 13.2327,lpips 0.604696,ssim 0.456218 [03/12 17:23:16]
Gaussian number:182686,print gradients:1.592680928297341e-05 [03/12 17:23:17]
Iteration 200 [03/12 17:23:52]

[ITER 200] Evaluating test: WD 0.132624, PSNR 14.1837,lpips 0.547822,ssim 0.464488 [03/12 17:24:50]

[ITER 200] Evaluating train: WD 0.133102, PSNR 14.5995,lpips 0.537009,ssim 0.480126 [03/12 17:24:57]
Gaussian number:182686,print gradients:1.9614313714555465e-05 [03/12 17:24:57]
Iteration 300 [03/12 17:25:33]

[ITER 300] Evaluating test: WD 0.126227, PSNR 14.8605,lpips 0.513278,ssim 0.479482 [03/12 17:26:30]

[ITER 300] Evaluating train: WD 0.127506, PSNR 15.3828,lpips 0.500082,ssim 0.493520 [03/12 17:26:38]
Gaussian number:182686,print gradients:2.193803265981842e-05 [03/12 17:26:38]
Iteration 400 [03/12 17:27:13]
Iteration 500 [03/12 17:27:49]

[ITER 500] Evaluating test: WD 0.118159, PSNR 15.7028,lpips 0.475818,ssim 0.495390 [03/12 17:28:46]

[ITER 500] Evaluating train: WD 0.124931, PSNR 15.9642,lpips 0.475147,ssim 0.503475 [03/12 17:28:54]
Gaussian number:182686,print gradients:2.470849904057104e-05 [03/12 17:28:54]
Iteration 600 [03/12 17:29:29]
Iteration 700 [03/12 17:30:05]
Iteration 800 [03/12 17:30:40]
Iteration 900 [03/12 17:31:16]
Iteration 1000 [03/12 17:31:52]

[ITER 1000] Evaluating test: WD 0.106144, PSNR 16.4471,lpips 0.424121,ssim 0.505122 [03/12 17:32:49]

[ITER 1000] Evaluating train: WD 0.111809, PSNR 17.0944,lpips 0.423828,ssim 0.515043 [03/12 17:32:56]
Gaussian number:194257,print gradients:3.304555139038712e-05 [03/12 17:32:56]
Iteration 1100 [03/12 17:33:31]
Iteration 1200 [03/12 17:34:07]
Iteration 1300 [03/12 17:34:42]
Iteration 1400 [03/12 17:35:17]
Iteration 1500 [03/12 17:35:52]

[ITER 1500] Evaluating test: WD 0.097540, PSNR 16.6413,lpips 0.392613,ssim 0.510642 [03/12 17:36:49]

[ITER 1500] Evaluating train: WD 0.102780, PSNR 17.4215,lpips 0.390848,ssim 0.517907 [03/12 17:36:57]
Gaussian number:217163,print gradients:nan [03/12 17:36:57]
Iteration 1600 [03/12 17:37:32]
Iteration 1700 [03/12 17:38:07]
Iteration 1800 [03/12 17:38:42]
Iteration 1900 [03/12 17:39:17]
Iteration 2000 [03/12 17:39:53]

[ITER 2000] Evaluating test: WD 0.092035, PSNR 17.0001,lpips 0.374319,ssim 0.518851 [03/12 17:40:50]

[ITER 2000] Evaluating train: WD 0.099910, PSNR 17.5848,lpips 0.381585,ssim 0.518813 [03/12 17:40:57]
Gaussian number:237800,print gradients:3.242941966163926e-05 [03/12 17:40:57]

[ITER 2000] Saving Gaussians [03/12 17:40:57]

Training complete. [03/12 17:40:59]
