Optimizing /home/cw4287/gaussian-model/train_30k
Output folder: /home/cw4287/gaussian-model/train_30k [03/12 17:01:33]
Tensorboard not available: not logging progress [03/12 17:01:33]
------------LLFF HOLD------------- [03/12 17:01:35]

Reading camera 1/301
Reading camera 2/301
Reading camera 3/301
Reading camera 4/301
Reading camera 5/301
Reading camera 6/301
Reading camera 7/301
Reading camera 8/301
Reading camera 9/301
Reading camera 10/301
Reading camera 11/301
Reading camera 12/301
Reading camera 13/301
Reading camera 14/301
Reading camera 15/301
Reading camera 16/301
Reading camera 17/301
Reading camera 18/301
Reading camera 19/301
Reading camera 20/301
Reading camera 21/301
Reading camera 22/301
Reading camera 23/301
Reading camera 24/301
Reading camera 25/301
Reading camera 26/301
Reading camera 27/301
Reading camera 28/301
Reading camera 29/301
Reading camera 30/301
Reading camera 31/301
Reading camera 32/301
Reading camera 33/301
Reading camera 34/301
Reading camera 35/301
Reading camera 36/301
Reading camera 37/301
Reading camera 38/301
Reading camera 39/301
Reading camera 40/301
Reading camera 41/301
Reading camera 42/301
Reading camera 43/301
Reading camera 44/301
Reading camera 45/301
Reading camera 46/301
Reading camera 47/301
Reading camera 48/301
Reading camera 49/301
Reading camera 50/301
Reading camera 51/301
Reading camera 52/301
Reading camera 53/301
Reading camera 54/301
Reading camera 55/301
Reading camera 56/301
Reading camera 57/301
Reading camera 58/301
Reading camera 59/301
Reading camera 60/301
Reading camera 61/301
Reading camera 62/301
Reading camera 63/301
Reading camera 64/301
Reading camera 65/301
Reading camera 66/301
Reading camera 67/301
Reading camera 68/301
Reading camera 69/301
Reading camera 70/301
Reading camera 71/301
Reading camera 72/301
Reading camera 73/301
Reading camera 74/301
Reading camera 75/301
Reading camera 76/301
Reading camera 77/301
Reading camera 78/301
Reading camera 79/301
Reading camera 80/301
Reading camera 81/301
Reading camera 82/301
Reading camera 83/301
Reading camera 84/301
Reading camera 85/301
Reading camera 86/301
Reading camera 87/301
Reading camera 88/301
Reading camera 89/301
Reading camera 90/301
Reading camera 91/301
Reading camera 92/301
Reading camera 93/301
Reading camera 94/301
Reading camera 95/301
Reading camera 96/301
Reading camera 97/301
Reading camera 98/301
Reading camera 99/301
Reading camera 100/301
Reading camera 101/301
Reading camera 102/301
Reading camera 103/301
Reading camera 104/301
Reading camera 105/301
Reading camera 106/301
Reading camera 107/301
Reading camera 108/301
Reading camera 109/301
Reading camera 110/301
Reading camera 111/301
Reading camera 112/301
Reading camera 113/301
Reading camera 114/301
Reading camera 115/301
Reading camera 116/301
Reading camera 117/301
Reading camera 118/301
Reading camera 119/301
Reading camera 120/301
Reading camera 121/301
Reading camera 122/301
Reading camera 123/301
Reading camera 124/301
Reading camera 125/301
Reading camera 126/301
Reading camera 127/301
Reading camera 128/301
Reading camera 129/301
Reading camera 130/301
Reading camera 131/301
Reading camera 132/301
Reading camera 133/301
Reading camera 134/301
Reading camera 135/301
Reading camera 136/301
Reading camera 137/301
Reading camera 138/301
Reading camera 139/301
Reading camera 140/301
Reading camera 141/301
Reading camera 142/301
Reading camera 143/301
Reading camera 144/301
Reading camera 145/301
Reading camera 146/301
Reading camera 147/301
Reading camera 148/301
Reading camera 149/301
Reading camera 150/301
Reading camera 151/301
Reading camera 152/301
Reading camera 153/301
Reading camera 154/301
Reading camera 155/301
Reading camera 156/301
Reading camera 157/301
Reading camera 158/301
Reading camera 159/301
Reading camera 160/301
Reading camera 161/301
Reading camera 162/301
Reading camera 163/301
Reading camera 164/301
Reading camera 165/301
Reading camera 166/301
Reading camera 167/301
Reading camera 168/301
Reading camera 169/301
Reading camera 170/301
Reading camera 171/301
Reading camera 172/301
Reading camera 173/301
Reading camera 174/301
Reading camera 175/301
Reading camera 176/301
Reading camera 177/301
Reading camera 178/301
Reading camera 179/301
Reading camera 180/301
Reading camera 181/301
Reading camera 182/301
Reading camera 183/301
Reading camera 184/301
Reading camera 185/301
Reading camera 186/301
Reading camera 187/301
Reading camera 188/301
Reading camera 189/301
Reading camera 190/301
Reading camera 191/301
Reading camera 192/301
Reading camera 193/301
Reading camera 194/301
Reading camera 195/301
Reading camera 196/301
Reading camera 197/301
Reading camera 198/301
Reading camera 199/301
Reading camera 200/301
Reading camera 201/301
Reading camera 202/301
Reading camera 203/301
Reading camera 204/301
Reading camera 205/301
Reading camera 206/301
Reading camera 207/301
Reading camera 208/301
Reading camera 209/301
Reading camera 210/301
Reading camera 211/301
Reading camera 212/301
Reading camera 213/301
Reading camera 214/301
Reading camera 215/301
Reading camera 216/301
Reading camera 217/301
Reading camera 218/301
Reading camera 219/301
Reading camera 220/301
Reading camera 221/301
Reading camera 222/301
Reading camera 223/301
Reading camera 224/301
Reading camera 225/301
Reading camera 226/301
Reading camera 227/301
Reading camera 228/301
Reading camera 229/301
Reading camera 230/301
Reading camera 231/301
Reading camera 232/301
Reading camera 233/301
Reading camera 234/301
Reading camera 235/301
Reading camera 236/301
Reading camera 237/301
Reading camera 238/301
Reading camera 239/301
Reading camera 240/301
Reading camera 241/301
Reading camera 242/301
Reading camera 243/301
Reading camera 244/301
Reading camera 245/301
Reading camera 246/301
Reading camera 247/301
Reading camera 248/301
Reading camera 249/301
Reading camera 250/301
Reading camera 251/301
Reading camera 252/301
Reading camera 253/301
Reading camera 254/301
Reading camera 255/301
Reading camera 256/301
Reading camera 257/301
Reading camera 258/301
Reading camera 259/301
Reading camera 260/301
Reading camera 261/301
Reading camera 262/301
Reading camera 263/301
Reading camera 264/301
Reading camera 265/301
Reading camera 266/301
Reading camera 267/301
Reading camera 268/301
Reading camera 269/301
Reading camera 270/301
Reading camera 271/301
Reading camera 272/301
Reading camera 273/301
Reading camera 274/301
Reading camera 275/301
Reading camera 276/301
Reading camera 277/301
Reading camera 278/301
Reading camera 279/301
Reading camera 280/301
Reading camera 281/301
Reading camera 282/301
Reading camera 283/301
Reading camera 284/301
Reading camera 285/301
Reading camera 286/301
Reading camera 287/301
Reading camera 288/301
Reading camera 289/301
Reading camera 290/301
Reading camera 291/301
Reading camera 292/301
Reading camera 293/301
Reading camera 294/301
Reading camera 295/301
Reading camera 296/301
Reading camera 297/301
Reading camera 298/301
Reading camera 299/301
Reading camera 300/301
Reading camera 301/301 [03/12 17:01:35]
Loading Training Cameras [03/12 17:01:35]
Loading Test Cameras [03/12 17:01:51]
Number of points at initialisation :  182686 [03/12 17:01:53]

Training progress:   0%|          | 0/2000 [00:00<?, ?it/s]/ext3/conda/envs/3dgs/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/ext3/conda/envs/3dgs/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)

Training progress:   0%|          | 0/2000 [00:05<?, ?it/s, Loss=0.1469337, Gaussian number=182686, print grad=6.437119009206071e-05, Depth Loss=0.0000000]
Training progress:   0%|          | 10/2000 [00:05<18:13,  1.82it/s, Loss=0.1469337, Gaussian number=182686, print grad=6.437119009206071e-05, Depth Loss=0.0000000]
Training progress:   0%|          | 10/2000 [00:09<18:13,  1.82it/s, Loss=0.1403549, Gaussian number=182686, print grad=0.0001677191030466929, Depth Loss=0.0000000]
Training progress:   1%|          | 20/2000 [00:09<14:36,  2.26it/s, Loss=0.1403549, Gaussian number=182686, print grad=0.0001677191030466929, Depth Loss=0.0000000]
Training progress:   1%|          | 20/2000 [00:12<14:36,  2.26it/s, Loss=0.1393629, Gaussian number=182686, print grad=0.0002664330240804702, Depth Loss=0.0000000]
Training progress:   2%|▏         | 30/2000 [00:12<13:25,  2.45it/s, Loss=0.1393629, Gaussian number=182686, print grad=0.0002664330240804702, Depth Loss=0.0000000]
Training progress:   2%|▏         | 30/2000 [00:16<13:25,  2.45it/s, Loss=0.1485177, Gaussian number=182686, print grad=0.0003695731284096837, Depth Loss=0.0000000]
Training progress:   2%|▏         | 40/2000 [00:16<12:48,  2.55it/s, Loss=0.1485177, Gaussian number=182686, print grad=0.0003695731284096837, Depth Loss=0.0000000]
Training progress:   2%|▏         | 40/2000 [00:20<12:48,  2.55it/s, Loss=0.1134170, Gaussian number=182686, print grad=0.0004529787693172693, Depth Loss=0.0000000]
Training progress:   2%|▎         | 50/2000 [00:20<12:26,  2.61it/s, Loss=0.1134170, Gaussian number=182686, print grad=0.0004529787693172693, Depth Loss=0.0000000]
Training progress:   2%|▎         | 50/2000 [00:23<12:26,  2.61it/s, Loss=0.1275646, Gaussian number=182686, print grad=0.0005802737432532012, Depth Loss=0.0000000]
Training progress:   3%|▎         | 60/2000 [00:23<12:11,  2.65it/s, Loss=0.1275646, Gaussian number=182686, print grad=0.0005802737432532012, Depth Loss=0.0000000]
Training progress:   3%|▎         | 60/2000 [00:27<12:11,  2.65it/s, Loss=0.1142139, Gaussian number=182686, print grad=0.0007358842995017767, Depth Loss=0.0000000]
Training progress:   4%|▎         | 70/2000 [00:27<12:01,  2.67it/s, Loss=0.1142139, Gaussian number=182686, print grad=0.0007358842995017767, Depth Loss=0.0000000]
Training progress:   4%|▎         | 70/2000 [00:31<12:01,  2.67it/s, Loss=0.1361333, Gaussian number=182686, print grad=0.0008572529186494648, Depth Loss=0.0000000]
Training progress:   4%|▍         | 80/2000 [00:31<11:52,  2.69it/s, Loss=0.1361333, Gaussian number=182686, print grad=0.0008572529186494648, Depth Loss=0.0000000]
Training progress:   4%|▍         | 80/2000 [00:34<11:52,  2.69it/s, Loss=0.1168601, Gaussian number=182686, print grad=0.0009844976011663675, Depth Loss=0.0000000]
Training progress:   4%|▍         | 90/2000 [00:34<11:45,  2.71it/s, Loss=0.1168601, Gaussian number=182686, print grad=0.0009844976011663675, Depth Loss=0.0000000]
Training progress:   4%|▍         | 90/2000 [00:38<11:45,  2.71it/s, Loss=0.1127588, Gaussian number=182686, print grad=0.0011362088844180107, Depth Loss=0.0000000]
Training progress:   5%|▌         | 100/2000 [00:38<11:39,  2.72it/s, Loss=0.1127588, Gaussian number=182686, print grad=0.0011362088844180107, Depth Loss=0.0000000]
Training progress:   5%|▌         | 100/2000 [01:45<11:39,  2.72it/s, Loss=0.1332237, Gaussian number=182686, print grad=0.0012988464441150427, Depth Loss=0.0000000]
Training progress:   6%|▌         | 110/2000 [01:45<1:12:47,  2.31s/it, Loss=0.1332237, Gaussian number=182686, print grad=0.0012988464441150427, Depth Loss=0.0000000]
Training progress:   6%|▌         | 110/2000 [01:49<1:12:47,  2.31s/it, Loss=0.1083470, Gaussian number=182686, print grad=0.0014569825725629926, Depth Loss=0.0000000]
Training progress:   6%|▌         | 120/2000 [01:49<53:50,  1.72s/it, Loss=0.1083470, Gaussian number=182686, print grad=0.0014569825725629926, Depth Loss=0.0000000]  
Training progress:   6%|▌         | 120/2000 [01:52<53:50,  1.72s/it, Loss=0.1262780, Gaussian number=182686, print grad=0.0016518887132406235, Depth Loss=0.0000000]
Training progress:   6%|▋         | 130/2000 [01:52<40:46,  1.31s/it, Loss=0.1262780, Gaussian number=182686, print grad=0.0016518887132406235, Depth Loss=0.0000000]
Training progress:   6%|▋         | 130/2000 [01:56<40:46,  1.31s/it, Loss=0.1125019, Gaussian number=182686, print grad=0.0018532373942434788, Depth Loss=0.0000000]
Training progress:   7%|▋         | 140/2000 [01:56<31:43,  1.02s/it, Loss=0.1125019, Gaussian number=182686, print grad=0.0018532373942434788, Depth Loss=0.0000000]
Training progress:   7%|▋         | 140/2000 [02:00<31:43,  1.02s/it, Loss=0.0981763, Gaussian number=182686, print grad=0.0020299451425671577, Depth Loss=0.0000000]
Training progress:   8%|▊         | 150/2000 [02:00<25:25,  1.21it/s, Loss=0.0981763, Gaussian number=182686, print grad=0.0020299451425671577, Depth Loss=0.0000000]
Training progress:   8%|▊         | 150/2000 [02:03<25:25,  1.21it/s, Loss=0.1063537, Gaussian number=182686, print grad=0.0022577745839953423, Depth Loss=0.0000000]
Training progress:   8%|▊         | 160/2000 [02:03<21:02,  1.46it/s, Loss=0.1063537, Gaussian number=182686, print grad=0.0022577745839953423, Depth Loss=0.0000000]
Training progress:   8%|▊         | 160/2000 [02:07<21:02,  1.46it/s, Loss=0.1059944, Gaussian number=182686, print grad=0.002433853456750512, Depth Loss=0.0000000] 
Training progress:   8%|▊         | 170/2000 [02:07<17:58,  1.70it/s, Loss=0.1059944, Gaussian number=182686, print grad=0.002433853456750512, Depth Loss=0.0000000]
Training progress:   8%|▊         | 170/2000 [02:11<17:58,  1.70it/s, Loss=0.0898815, Gaussian number=182686, print grad=0.0026384054217487574, Depth Loss=0.0000000]
Training progress:   9%|▉         | 180/2000 [02:11<15:49,  1.92it/s, Loss=0.0898815, Gaussian number=182686, print grad=0.0026384054217487574, Depth Loss=0.0000000]
Training progress:   9%|▉         | 180/2000 [02:14<15:49,  1.92it/s, Loss=0.1150809, Gaussian number=182686, print grad=0.00281974277459085, Depth Loss=0.0000000]  
Training progress:  10%|▉         | 190/2000 [02:14<14:17,  2.11it/s, Loss=0.1150809, Gaussian number=182686, print grad=0.00281974277459085, Depth Loss=0.0000000]
Training progress:  10%|▉         | 190/2000 [02:18<14:17,  2.11it/s, Loss=0.1014107, Gaussian number=182686, print grad=0.0030330976005643606, Depth Loss=0.0000000]
Training progress:  10%|█         | 200/2000 [02:18<13:12,  2.27it/s, Loss=0.1014107, Gaussian number=182686, print grad=0.0030330976005643606, Depth Loss=0.0000000]
Training progress:  10%|█         | 200/2000 [03:25<13:12,  2.27it/s, Loss=0.1116738, Gaussian number=182686, print grad=0.0032602762803435326, Depth Loss=0.0000000]
Training progress:  10%|█         | 210/2000 [03:25<1:09:15,  2.32s/it, Loss=0.1116738, Gaussian number=182686, print grad=0.0032602762803435326, Depth Loss=0.0000000]
Training progress:  10%|█         | 210/2000 [03:29<1:09:15,  2.32s/it, Loss=0.0925729, Gaussian number=182686, print grad=0.003466507187113166, Depth Loss=0.0000000] 
Training progress:  11%|█         | 220/2000 [03:29<51:25,  1.73s/it, Loss=0.0925729, Gaussian number=182686, print grad=0.003466507187113166, Depth Loss=0.0000000]  
Training progress:  11%|█         | 220/2000 [03:32<51:25,  1.73s/it, Loss=0.1019473, Gaussian number=182686, print grad=0.0036786431446671486, Depth Loss=0.0000000]
Training progress:  12%|█▏        | 230/2000 [03:32<38:59,  1.32s/it, Loss=0.1019473, Gaussian number=182686, print grad=0.0036786431446671486, Depth Loss=0.0000000]
Training progress:  12%|█▏        | 230/2000 [03:36<38:59,  1.32s/it, Loss=0.1271857, Gaussian number=182686, print grad=0.003877464681863785, Depth Loss=0.0000000] 
Training progress:  12%|█▏        | 240/2000 [03:36<30:20,  1.03s/it, Loss=0.1271857, Gaussian number=182686, print grad=0.003877464681863785, Depth Loss=0.0000000]
Training progress:  12%|█▏        | 240/2000 [03:39<30:20,  1.03s/it, Loss=0.0960780, Gaussian number=182686, print grad=0.004107318352907896, Depth Loss=0.0000000]
Training progress:  12%|█▎        | 250/2000 [03:39<24:15,  1.20it/s, Loss=0.0960780, Gaussian number=182686, print grad=0.004107318352907896, Depth Loss=0.0000000]
Training progress:  12%|█▎        | 250/2000 [03:43<24:15,  1.20it/s, Loss=0.1081274, Gaussian number=182686, print grad=0.004316443577408791, Depth Loss=0.0000000]
Training progress:  13%|█▎        | 260/2000 [03:43<20:02,  1.45it/s, Loss=0.1081274, Gaussian number=182686, print grad=0.004316443577408791, Depth Loss=0.0000000]
Training progress:  13%|█▎        | 260/2000 [03:47<20:02,  1.45it/s, Loss=0.0765238, Gaussian number=182686, print grad=0.004539069719612598, Depth Loss=0.0000000]
Training progress:  14%|█▎        | 270/2000 [03:47<17:04,  1.69it/s, Loss=0.0765238, Gaussian number=182686, print grad=0.004539069719612598, Depth Loss=0.0000000]
Training progress:  14%|█▎        | 270/2000 [03:50<17:04,  1.69it/s, Loss=0.1008934, Gaussian number=182686, print grad=0.00479474663734436, Depth Loss=0.0000000] 
Training progress:  14%|█▍        | 280/2000 [03:50<14:59,  1.91it/s, Loss=0.1008934, Gaussian number=182686, print grad=0.00479474663734436, Depth Loss=0.0000000]
Training progress:  14%|█▍        | 280/2000 [03:54<14:59,  1.91it/s, Loss=0.0983928, Gaussian number=182686, print grad=0.005034739151597023, Depth Loss=0.0000000]
Training progress:  14%|█▍        | 290/2000 [03:54<13:31,  2.11it/s, Loss=0.0983928, Gaussian number=182686, print grad=0.005034739151597023, Depth Loss=0.0000000]
Training progress:  14%|█▍        | 290/2000 [03:58<13:31,  2.11it/s, Loss=0.0924132, Gaussian number=182686, print grad=0.005274657160043716, Depth Loss=0.0000000]
Training progress:  15%|█▌        | 300/2000 [03:58<12:29,  2.27it/s, Loss=0.0924132, Gaussian number=182686, print grad=0.005274657160043716, Depth Loss=0.0000000]
Training progress:  15%|█▌        | 300/2000 [05:05<12:29,  2.27it/s, Loss=0.0777350, Gaussian number=182686, print grad=0.0055317324586212635, Depth Loss=0.0000000]
Training progress:  16%|█▌        | 310/2000 [05:05<1:05:30,  2.33s/it, Loss=0.0777350, Gaussian number=182686, print grad=0.0055317324586212635, Depth Loss=0.0000000]
Training progress:  16%|█▌        | 310/2000 [05:08<1:05:30,  2.33s/it, Loss=0.0795255, Gaussian number=182686, print grad=0.005716064013540745, Depth Loss=0.0000000] 
Training progress:  16%|█▌        | 320/2000 [05:08<48:35,  1.74s/it, Loss=0.0795255, Gaussian number=182686, print grad=0.005716064013540745, Depth Loss=0.0000000]  
Training progress:  16%|█▌        | 320/2000 [05:12<48:35,  1.74s/it, Loss=0.1049554, Gaussian number=182686, print grad=0.005936980713158846, Depth Loss=0.0000000]
Training progress:  16%|█▋        | 330/2000 [05:12<36:49,  1.32s/it, Loss=0.1049554, Gaussian number=182686, print grad=0.005936980713158846, Depth Loss=0.0000000]
Training progress:  16%|█▋        | 330/2000 [05:16<36:49,  1.32s/it, Loss=0.0777365, Gaussian number=182686, print grad=0.006184074096381664, Depth Loss=0.0000000]
Training progress:  17%|█▋        | 340/2000 [05:16<28:36,  1.03s/it, Loss=0.0777365, Gaussian number=182686, print grad=0.006184074096381664, Depth Loss=0.0000000]
Training progress:  17%|█▋        | 340/2000 [05:19<28:36,  1.03s/it, Loss=0.0797582, Gaussian number=182686, print grad=0.006421254016458988, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 350/2000 [05:19<22:52,  1.20it/s, Loss=0.0797582, Gaussian number=182686, print grad=0.006421254016458988, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 350/2000 [05:23<22:52,  1.20it/s, Loss=0.0778692, Gaussian number=182686, print grad=0.006699460558593273, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 360/2000 [05:23<18:51,  1.45it/s, Loss=0.0778692, Gaussian number=182686, print grad=0.006699460558593273, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 360/2000 [05:26<18:51,  1.45it/s, Loss=0.0757534, Gaussian number=182686, print grad=0.006945568602532148, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 370/2000 [05:26<16:03,  1.69it/s, Loss=0.0757534, Gaussian number=182686, print grad=0.006945568602532148, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 370/2000 [05:30<16:03,  1.69it/s, Loss=0.1017453, Gaussian number=182686, print grad=0.0071523976512253284, Depth Loss=0.0000000]
Training progress:  19%|█▉        | 380/2000 [05:30<14:04,  1.92it/s, Loss=0.1017453, Gaussian number=182686, print grad=0.0071523976512253284, Depth Loss=0.0000000]
Training progress:  19%|█▉        | 380/2000 [05:34<14:04,  1.92it/s, Loss=0.0911040, Gaussian number=182686, print grad=0.007403922267258167, Depth Loss=0.0000000] 
Training progress:  20%|█▉        | 390/2000 [05:34<12:41,  2.11it/s, Loss=0.0911040, Gaussian number=182686, print grad=0.007403922267258167, Depth Loss=0.0000000]
Training progress:  20%|█▉        | 390/2000 [05:37<12:41,  2.11it/s, Loss=0.1093001, Gaussian number=182686, print grad=0.007637629751116037, Depth Loss=0.0000000]
Training progress:  20%|██        | 400/2000 [05:37<11:41,  2.28it/s, Loss=0.1093001, Gaussian number=182686, print grad=0.007637629751116037, Depth Loss=0.0000000]
Training progress:  20%|██        | 400/2000 [05:41<11:41,  2.28it/s, Loss=0.0928888, Gaussian number=182686, print grad=0.007921685464680195, Depth Loss=0.0000000]
Training progress:  20%|██        | 410/2000 [05:41<11:00,  2.41it/s, Loss=0.0928888, Gaussian number=182686, print grad=0.007921685464680195, Depth Loss=0.0000000]
Training progress:  20%|██        | 410/2000 [05:44<11:00,  2.41it/s, Loss=0.0816380, Gaussian number=182686, print grad=0.008194820955395699, Depth Loss=0.0000000]
Training progress:  21%|██        | 420/2000 [05:44<10:29,  2.51it/s, Loss=0.0816380, Gaussian number=182686, print grad=0.008194820955395699, Depth Loss=0.0000000]
Training progress:  21%|██        | 420/2000 [05:48<10:29,  2.51it/s, Loss=0.1024519, Gaussian number=182686, print grad=0.00847377348691225, Depth Loss=0.0000000] 
Training progress:  22%|██▏       | 430/2000 [05:48<10:06,  2.59it/s, Loss=0.1024519, Gaussian number=182686, print grad=0.00847377348691225, Depth Loss=0.0000000]
Training progress:  22%|██▏       | 430/2000 [05:51<10:06,  2.59it/s, Loss=0.0807593, Gaussian number=182686, print grad=0.008728730492293835, Depth Loss=0.0000000]
Training progress:  22%|██▏       | 440/2000 [05:51<09:49,  2.64it/s, Loss=0.0807593, Gaussian number=182686, print grad=0.008728730492293835, Depth Loss=0.0000000]
Training progress:  22%|██▏       | 440/2000 [05:55<09:49,  2.64it/s, Loss=0.0899331, Gaussian number=182686, print grad=0.008997117169201374, Depth Loss=0.0000000]
Training progress:  22%|██▎       | 450/2000 [05:55<09:36,  2.69it/s, Loss=0.0899331, Gaussian number=182686, print grad=0.008997117169201374, Depth Loss=0.0000000]
Training progress:  22%|██▎       | 450/2000 [05:59<09:36,  2.69it/s, Loss=0.0940311, Gaussian number=182686, print grad=0.00925584975630045, Depth Loss=0.0000000] 
Training progress:  23%|██▎       | 460/2000 [05:59<09:27,  2.72it/s, Loss=0.0940311, Gaussian number=182686, print grad=0.00925584975630045, Depth Loss=0.0000000]
Training progress:  23%|██▎       | 460/2000 [06:02<09:27,  2.72it/s, Loss=0.1109656, Gaussian number=182686, print grad=0.009501629509031773, Depth Loss=0.0000000]
Training progress:  24%|██▎       | 470/2000 [06:02<09:19,  2.74it/s, Loss=0.1109656, Gaussian number=182686, print grad=0.009501629509031773, Depth Loss=0.0000000]
Training progress:  24%|██▎       | 470/2000 [06:06<09:19,  2.74it/s, Loss=0.0744258, Gaussian number=182686, print grad=0.00977841205894947, Depth Loss=0.0000000] 
Training progress:  24%|██▍       | 480/2000 [06:06<09:12,  2.75it/s, Loss=0.0744258, Gaussian number=182686, print grad=0.00977841205894947, Depth Loss=0.0000000]
Training progress:  24%|██▍       | 480/2000 [06:09<09:12,  2.75it/s, Loss=0.0798232, Gaussian number=182686, print grad=0.010031476616859436, Depth Loss=0.0000000]
Training progress:  24%|██▍       | 490/2000 [06:09<09:06,  2.76it/s, Loss=0.0798232, Gaussian number=182686, print grad=0.010031476616859436, Depth Loss=0.0000000]
Training progress:  24%|██▍       | 490/2000 [06:13<09:06,  2.76it/s, Loss=0.0621615, Gaussian number=182686, print grad=0.010289005935192108, Depth Loss=0.0000000]
Training progress:  25%|██▌       | 500/2000 [06:13<09:00,  2.77it/s, Loss=0.0621615, Gaussian number=182686, print grad=0.010289005935192108, Depth Loss=0.0000000]
Training progress:  25%|██▌       | 500/2000 [07:20<09:00,  2.77it/s, Loss=0.0746052, Gaussian number=182686, print grad=0.010552776046097279, Depth Loss=0.0000000]
Training progress:  26%|██▌       | 510/2000 [07:20<56:11,  2.26s/it, Loss=0.0746052, Gaussian number=182686, print grad=0.010552776046097279, Depth Loss=0.0000000]
Training progress:  26%|██▌       | 510/2000 [07:24<56:11,  2.26s/it, Loss=0.0769516, Gaussian number=182686, print grad=0.01082866732031107, Depth Loss=0.0000000] 
Training progress:  26%|██▌       | 520/2000 [07:24<41:43,  1.69s/it, Loss=0.0769516, Gaussian number=182686, print grad=0.01082866732031107, Depth Loss=0.0000000]
Training progress:  26%|██▌       | 520/2000 [07:27<41:43,  1.69s/it, Loss=0.0603154, Gaussian number=182686, print grad=0.011059996671974659, Depth Loss=0.0000000]
Training progress:  26%|██▋       | 530/2000 [07:27<31:37,  1.29s/it, Loss=0.0603154, Gaussian number=182686, print grad=0.011059996671974659, Depth Loss=0.0000000]
Training progress:  26%|██▋       | 530/2000 [07:31<31:37,  1.29s/it, Loss=0.0822035, Gaussian number=182686, print grad=0.011318087577819824, Depth Loss=0.0000000]
Training progress:  27%|██▋       | 540/2000 [07:31<24:36,  1.01s/it, Loss=0.0822035, Gaussian number=182686, print grad=0.011318087577819824, Depth Loss=0.0000000]
Training progress:  27%|██▋       | 540/2000 [07:34<24:36,  1.01s/it, Loss=0.0779517, Gaussian number=182686, print grad=0.011598099954426289, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 550/2000 [07:34<19:41,  1.23it/s, Loss=0.0779517, Gaussian number=182686, print grad=0.011598099954426289, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 550/2000 [07:38<19:41,  1.23it/s, Loss=0.0612002, Gaussian number=182686, print grad=0.011858358979225159, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 560/2000 [07:38<16:16,  1.48it/s, Loss=0.0612002, Gaussian number=182686, print grad=0.011858358979225159, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 560/2000 [07:41<16:16,  1.48it/s, Loss=0.0817572, Gaussian number=182686, print grad=0.012148239649832249, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 570/2000 [07:41<13:52,  1.72it/s, Loss=0.0817572, Gaussian number=182686, print grad=0.012148239649832249, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 570/2000 [07:45<13:52,  1.72it/s, Loss=0.0705961, Gaussian number=182686, print grad=0.012421123683452606, Depth Loss=0.0000000]
Training progress:  29%|██▉       | 580/2000 [07:45<12:11,  1.94it/s, Loss=0.0705961, Gaussian number=182686, print grad=0.012421123683452606, Depth Loss=0.0000000]
Training progress:  29%|██▉       | 580/2000 [07:49<12:11,  1.94it/s, Loss=0.0811564, Gaussian number=182686, print grad=0.012699954211711884, Depth Loss=0.0000000]
Training progress:  30%|██▉       | 590/2000 [07:49<11:00,  2.14it/s, Loss=0.0811564, Gaussian number=182686, print grad=0.012699954211711884, Depth Loss=0.0000000]
Training progress:  30%|██▉       | 590/2000 [07:52<11:00,  2.14it/s, Loss=0.0836218, Gaussian number=182686, print grad=0.012955164536833763, Depth Loss=0.0000000]
Training progress:  30%|███       | 600/2000 [07:52<10:08,  2.30it/s, Loss=0.0836218, Gaussian number=182686, print grad=0.012955164536833763, Depth Loss=0.0000000]
Training progress:  30%|███       | 600/2000 [07:56<10:08,  2.30it/s, Loss=0.0713882, Gaussian number=184204, print grad=0.00025439352612011135, Depth Loss=0.0000000]
Training progress:  30%|███       | 610/2000 [07:56<09:32,  2.43it/s, Loss=0.0713882, Gaussian number=184204, print grad=0.00025439352612011135, Depth Loss=0.0000000]
Training progress:  30%|███       | 610/2000 [07:59<09:32,  2.43it/s, Loss=0.0936940, Gaussian number=184204, print grad=0.0005482505657710135, Depth Loss=0.0000000] 
Training progress:  31%|███       | 620/2000 [07:59<09:06,  2.53it/s, Loss=0.0936940, Gaussian number=184204, print grad=0.0005482505657710135, Depth Loss=0.0000000]
Training progress:  31%|███       | 620/2000 [08:03<09:06,  2.53it/s, Loss=0.0653380, Gaussian number=184204, print grad=0.0008079253020696342, Depth Loss=0.0000000]
Training progress:  32%|███▏      | 630/2000 [08:03<08:47,  2.60it/s, Loss=0.0653380, Gaussian number=184204, print grad=0.0008079253020696342, Depth Loss=0.0000000]
Training progress:  32%|███▏      | 630/2000 [08:07<08:47,  2.60it/s, Loss=0.0714049, Gaussian number=184204, print grad=0.0011196746490895748, Depth Loss=0.0000000]
Training progress:  32%|███▏      | 640/2000 [08:07<08:32,  2.65it/s, Loss=0.0714049, Gaussian number=184204, print grad=0.0011196746490895748, Depth Loss=0.0000000]
Training progress:  32%|███▏      | 640/2000 [08:10<08:32,  2.65it/s, Loss=0.0818400, Gaussian number=184204, print grad=0.0013695035595446825, Depth Loss=0.0000000]
Training progress:  32%|███▎      | 650/2000 [08:10<08:20,  2.70it/s, Loss=0.0818400, Gaussian number=184204, print grad=0.0013695035595446825, Depth Loss=0.0000000]
Training progress:  32%|███▎      | 650/2000 [08:14<08:20,  2.70it/s, Loss=0.0818656, Gaussian number=184204, print grad=0.001666013733483851, Depth Loss=0.0000000] 
Training progress:  33%|███▎      | 660/2000 [08:14<08:11,  2.72it/s, Loss=0.0818656, Gaussian number=184204, print grad=0.001666013733483851, Depth Loss=0.0000000]
Training progress:  33%|███▎      | 660/2000 [08:17<08:11,  2.72it/s, Loss=0.0724028, Gaussian number=184204, print grad=0.0019261445850133896, Depth Loss=0.0000000]
Training progress:  34%|███▎      | 670/2000 [08:17<08:04,  2.75it/s, Loss=0.0724028, Gaussian number=184204, print grad=0.0019261445850133896, Depth Loss=0.0000000]
Training progress:  34%|███▎      | 670/2000 [08:21<08:04,  2.75it/s, Loss=0.0669946, Gaussian number=184204, print grad=0.0022223133128136396, Depth Loss=0.0000000]
Training progress:  34%|███▍      | 680/2000 [08:21<07:57,  2.76it/s, Loss=0.0669946, Gaussian number=184204, print grad=0.0022223133128136396, Depth Loss=0.0000000]
Training progress:  34%|███▍      | 680/2000 [08:24<07:57,  2.76it/s, Loss=0.0824088, Gaussian number=184204, print grad=0.002494621556252241, Depth Loss=0.0000000] 
Training progress:  34%|███▍      | 690/2000 [08:24<07:52,  2.77it/s, Loss=0.0824088, Gaussian number=184204, print grad=0.002494621556252241, Depth Loss=0.0000000]
Training progress:  34%|███▍      | 690/2000 [08:28<07:52,  2.77it/s, Loss=0.0827011, Gaussian number=184204, print grad=0.002760122297331691, Depth Loss=0.0000000]
Training progress:  35%|███▌      | 700/2000 [08:28<07:47,  2.78it/s, Loss=0.0827011, Gaussian number=184204, print grad=0.002760122297331691, Depth Loss=0.0000000]
Training progress:  35%|███▌      | 700/2000 [08:32<07:47,  2.78it/s, Loss=0.0727819, Gaussian number=189664, print grad=0.00025313044898211956, Depth Loss=0.0000000]
Training progress:  36%|███▌      | 710/2000 [08:32<07:42,  2.79it/s, Loss=0.0727819, Gaussian number=189664, print grad=0.00025313044898211956, Depth Loss=0.0000000]
Training progress:  36%|███▌      | 710/2000 [08:35<07:42,  2.79it/s, Loss=0.0660005, Gaussian number=189664, print grad=0.0005497555248439312, Depth Loss=0.0000000] 
Training progress:  36%|███▌      | 720/2000 [08:35<07:38,  2.79it/s, Loss=0.0660005, Gaussian number=189664, print grad=0.0005497555248439312, Depth Loss=0.0000000]
Training progress:  36%|███▌      | 720/2000 [08:39<07:38,  2.79it/s, Loss=0.0853609, Gaussian number=189664, print grad=0.0008112312061712146, Depth Loss=0.0000000]
Training progress:  36%|███▋      | 730/2000 [08:39<07:34,  2.79it/s, Loss=0.0853609, Gaussian number=189664, print grad=0.0008112312061712146, Depth Loss=0.0000000]
Training progress:  36%|███▋      | 730/2000 [08:42<07:34,  2.79it/s, Loss=0.0999731, Gaussian number=189664, print grad=0.0011303550563752651, Depth Loss=0.0000000]
Training progress:  37%|███▋      | 740/2000 [08:42<07:30,  2.80it/s, Loss=0.0999731, Gaussian number=189664, print grad=0.0011303550563752651, Depth Loss=0.0000000]
Training progress:  37%|███▋      | 740/2000 [08:46<07:30,  2.80it/s, Loss=0.0710972, Gaussian number=189664, print grad=0.0014209224609658122, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 750/2000 [08:46<07:25,  2.80it/s, Loss=0.0710972, Gaussian number=189664, print grad=0.0014209224609658122, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 750/2000 [08:49<07:25,  2.80it/s, Loss=0.0692505, Gaussian number=189664, print grad=0.0017017823411151767, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 760/2000 [08:49<07:22,  2.80it/s, Loss=0.0692505, Gaussian number=189664, print grad=0.0017017823411151767, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 760/2000 [08:53<07:22,  2.80it/s, Loss=0.0614699, Gaussian number=189664, print grad=0.001997568178921938, Depth Loss=0.0000000] 
Training progress:  38%|███▊      | 770/2000 [08:53<07:18,  2.80it/s, Loss=0.0614699, Gaussian number=189664, print grad=0.001997568178921938, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 770/2000 [08:56<07:18,  2.80it/s, Loss=0.0830226, Gaussian number=189664, print grad=0.002269948599860072, Depth Loss=0.0000000]
Training progress:  39%|███▉      | 780/2000 [08:56<07:14,  2.81it/s, Loss=0.0830226, Gaussian number=189664, print grad=0.002269948599860072, Depth Loss=0.0000000]
Training progress:  39%|███▉      | 780/2000 [09:00<07:14,  2.81it/s, Loss=0.0966078, Gaussian number=189664, print grad=0.0025542450603097677, Depth Loss=0.0000000]
Training progress:  40%|███▉      | 790/2000 [09:00<07:11,  2.80it/s, Loss=0.0966078, Gaussian number=189664, print grad=0.0025542450603097677, Depth Loss=0.0000000]
Training progress:  40%|███▉      | 790/2000 [09:04<07:11,  2.80it/s, Loss=0.0805736, Gaussian number=189664, print grad=0.0028562576044350863, Depth Loss=0.0000000]
Training progress:  40%|████      | 800/2000 [09:04<07:07,  2.80it/s, Loss=0.0805736, Gaussian number=189664, print grad=0.0028562576044350863, Depth Loss=0.0000000]
Training progress:  40%|████      | 800/2000 [09:07<07:07,  2.80it/s, Loss=0.0809597, Gaussian number=195862, print grad=0.0002704984217416495, Depth Loss=0.0000000]
Training progress:  40%|████      | 810/2000 [09:07<07:04,  2.80it/s, Loss=0.0809597, Gaussian number=195862, print grad=0.0002704984217416495, Depth Loss=0.0000000]
Training progress:  40%|████      | 810/2000 [09:11<07:04,  2.80it/s, Loss=0.0781920, Gaussian number=195862, print grad=0.0005634796107187867, Depth Loss=0.0000000]
Training progress:  41%|████      | 820/2000 [09:11<07:00,  2.80it/s, Loss=0.0781920, Gaussian number=195862, print grad=0.0005634796107187867, Depth Loss=0.0000000]
Training progress:  41%|████      | 820/2000 [09:14<07:00,  2.80it/s, Loss=0.0631361, Gaussian number=195862, print grad=0.0009062712197192013, Depth Loss=0.0000000]
Training progress:  42%|████▏     | 830/2000 [09:14<06:56,  2.81it/s, Loss=0.0631361, Gaussian number=195862, print grad=0.0009062712197192013, Depth Loss=0.0000000]
Training progress:  42%|████▏     | 830/2000 [09:18<06:56,  2.81it/s, Loss=0.0678241, Gaussian number=195862, print grad=0.0012066476047039032, Depth Loss=0.0000000]
Training progress:  42%|████▏     | 840/2000 [09:18<06:52,  2.81it/s, Loss=0.0678241, Gaussian number=195862, print grad=0.0012066476047039032, Depth Loss=0.0000000]
Training progress:  42%|████▏     | 840/2000 [09:21<06:52,  2.81it/s, Loss=0.0706714, Gaussian number=195862, print grad=0.0015132313128560781, Depth Loss=0.0000000]
Training progress:  42%|████▎     | 850/2000 [09:21<06:49,  2.81it/s, Loss=0.0706714, Gaussian number=195862, print grad=0.0015132313128560781, Depth Loss=0.0000000]
Training progress:  42%|████▎     | 850/2000 [09:25<06:49,  2.81it/s, Loss=0.0684762, Gaussian number=195862, print grad=0.0017948334570974112, Depth Loss=0.0000000]
Training progress:  43%|████▎     | 860/2000 [09:25<06:45,  2.81it/s, Loss=0.0684762, Gaussian number=195862, print grad=0.0017948334570974112, Depth Loss=0.0000000]
Training progress:  43%|████▎     | 860/2000 [09:29<06:45,  2.81it/s, Loss=0.0793652, Gaussian number=195862, print grad=0.002077102428302169, Depth Loss=0.0000000] 
Training progress:  44%|████▎     | 870/2000 [09:29<06:42,  2.81it/s, Loss=0.0793652, Gaussian number=195862, print grad=0.002077102428302169, Depth Loss=0.0000000]
Training progress:  44%|████▎     | 870/2000 [09:32<06:42,  2.81it/s, Loss=0.0766310, Gaussian number=195862, print grad=0.0023660382721573114, Depth Loss=0.0000000]
Training progress:  44%|████▍     | 880/2000 [09:32<06:38,  2.81it/s, Loss=0.0766310, Gaussian number=195862, print grad=0.0023660382721573114, Depth Loss=0.0000000]
Training progress:  44%|████▍     | 880/2000 [09:36<06:38,  2.81it/s, Loss=0.0598493, Gaussian number=195862, print grad=0.002662454964593053, Depth Loss=0.0000000] 
Training progress:  44%|████▍     | 890/2000 [09:36<06:35,  2.81it/s, Loss=0.0598493, Gaussian number=195862, print grad=0.002662454964593053, Depth Loss=0.0000000]
Training progress:  44%|████▍     | 890/2000 [09:39<06:35,  2.81it/s, Loss=0.0777513, Gaussian number=195862, print grad=0.0029495395720005035, Depth Loss=0.0000000]
Training progress:  45%|████▌     | 900/2000 [09:39<06:31,  2.81it/s, Loss=0.0777513, Gaussian number=195862, print grad=0.0029495395720005035, Depth Loss=0.0000000]
Training progress:  45%|████▌     | 900/2000 [09:43<06:31,  2.81it/s, Loss=0.0626496, Gaussian number=202682, print grad=0.0002636390854604542, Depth Loss=0.0000000]
Training progress:  46%|████▌     | 910/2000 [09:43<06:27,  2.82it/s, Loss=0.0626496, Gaussian number=202682, print grad=0.0002636390854604542, Depth Loss=0.0000000]
Training progress:  46%|████▌     | 910/2000 [09:46<06:27,  2.82it/s, Loss=0.0746644, Gaussian number=202682, print grad=0.0005228094523772597, Depth Loss=0.0000000]
Training progress:  46%|████▌     | 920/2000 [09:46<06:22,  2.82it/s, Loss=0.0746644, Gaussian number=202682, print grad=0.0005228094523772597, Depth Loss=0.0000000]
Training progress:  46%|████▌     | 920/2000 [09:50<06:22,  2.82it/s, Loss=0.0775553, Gaussian number=202682, print grad=0.0008557939436286688, Depth Loss=0.0000000]
Training progress:  46%|████▋     | 930/2000 [09:50<06:18,  2.83it/s, Loss=0.0775553, Gaussian number=202682, print grad=0.0008557939436286688, Depth Loss=0.0000000]
Training progress:  46%|████▋     | 930/2000 [09:53<06:18,  2.83it/s, Loss=0.0707381, Gaussian number=202682, print grad=0.0011405367404222488, Depth Loss=0.0000000]
Training progress:  47%|████▋     | 940/2000 [09:53<06:14,  2.83it/s, Loss=0.0707381, Gaussian number=202682, print grad=0.0011405367404222488, Depth Loss=0.0000000]
Training progress:  47%|████▋     | 940/2000 [09:57<06:14,  2.83it/s, Loss=0.0673951, Gaussian number=202682, print grad=0.0014369257260113955, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 950/2000 [09:57<06:11,  2.83it/s, Loss=0.0673951, Gaussian number=202682, print grad=0.0014369257260113955, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 950/2000 [10:00<06:11,  2.83it/s, Loss=0.0669299, Gaussian number=202682, print grad=0.0017142064170911908, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 960/2000 [10:00<06:07,  2.83it/s, Loss=0.0669299, Gaussian number=202682, print grad=0.0017142064170911908, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 960/2000 [10:04<06:07,  2.83it/s, Loss=0.0869595, Gaussian number=202682, print grad=0.0020260235760360956, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 970/2000 [10:04<06:03,  2.83it/s, Loss=0.0869595, Gaussian number=202682, print grad=0.0020260235760360956, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 970/2000 [10:07<06:03,  2.83it/s, Loss=0.0550241, Gaussian number=202682, print grad=0.0023108015302568674, Depth Loss=0.0000000]
Training progress:  49%|████▉     | 980/2000 [10:07<05:59,  2.83it/s, Loss=0.0550241, Gaussian number=202682, print grad=0.0023108015302568674, Depth Loss=0.0000000]
Training progress:  49%|████▉     | 980/2000 [10:11<05:59,  2.83it/s, Loss=0.0587858, Gaussian number=202682, print grad=0.0025581493973731995, Depth Loss=0.0000000]
Training progress:  50%|████▉     | 990/2000 [10:11<05:56,  2.83it/s, Loss=0.0587858, Gaussian number=202682, print grad=0.0025581493973731995, Depth Loss=0.0000000]
Training progress:  50%|████▉     | 990/2000 [10:15<05:56,  2.83it/s, Loss=0.0738800, Gaussian number=202682, print grad=0.002794725587591529, Depth Loss=0.0000000] 
Training progress:  50%|█████     | 1000/2000 [10:15<05:52,  2.84it/s, Loss=0.0738800, Gaussian number=202682, print grad=0.002794725587591529, Depth Loss=0.0000000]
Training progress:  50%|█████     | 1000/2000 [11:21<05:52,  2.84it/s, Loss=0.0726094, Gaussian number=209430, print grad=0.0002555169921834022, Depth Loss=0.0000000]
Training progress:  50%|█████     | 1010/2000 [11:21<37:13,  2.26s/it, Loss=0.0726094, Gaussian number=209430, print grad=0.0002555169921834022, Depth Loss=0.0000000]
Training progress:  50%|█████     | 1010/2000 [11:25<37:13,  2.26s/it, Loss=0.0896521, Gaussian number=209430, print grad=0.0005923369899392128, Depth Loss=0.0000000]
Training progress:  51%|█████     | 1020/2000 [11:25<27:31,  1.68s/it, Loss=0.0896521, Gaussian number=209430, print grad=0.0005923369899392128, Depth Loss=0.0000000]
Training progress:  51%|█████     | 1020/2000 [11:29<27:31,  1.68s/it, Loss=0.0715704, Gaussian number=209430, print grad=0.0009069279185496271, Depth Loss=0.0000000]
Training progress:  52%|█████▏    | 1030/2000 [11:29<20:46,  1.29s/it, Loss=0.0715704, Gaussian number=209430, print grad=0.0009069279185496271, Depth Loss=0.0000000]
Training progress:  52%|█████▏    | 1030/2000 [11:32<20:46,  1.29s/it, Loss=0.0753609, Gaussian number=209430, print grad=0.0012374777579680085, Depth Loss=0.0000000]
Training progress:  52%|█████▏    | 1040/2000 [11:32<16:05,  1.01s/it, Loss=0.0753609, Gaussian number=209430, print grad=0.0012374777579680085, Depth Loss=0.0000000]
Training progress:  52%|█████▏    | 1040/2000 [11:36<16:05,  1.01s/it, Loss=0.0665838, Gaussian number=209430, print grad=0.0014903582632541656, Depth Loss=0.0000000]
Training progress:  52%|█████▎    | 1050/2000 [11:36<12:49,  1.23it/s, Loss=0.0665838, Gaussian number=209430, print grad=0.0014903582632541656, Depth Loss=0.0000000]
Training progress:  52%|█████▎    | 1050/2000 [11:39<12:49,  1.23it/s, Loss=0.0627933, Gaussian number=209430, print grad=0.0017737752059474587, Depth Loss=0.0000000]
Training progress:  53%|█████▎    | 1060/2000 [11:39<10:32,  1.49it/s, Loss=0.0627933, Gaussian number=209430, print grad=0.0017737752059474587, Depth Loss=0.0000000]
Training progress:  53%|█████▎    | 1060/2000 [11:43<10:32,  1.49it/s, Loss=0.0520721, Gaussian number=209430, print grad=0.002080269157886505, Depth Loss=0.0000000] 
Training progress:  54%|█████▎    | 1070/2000 [11:43<08:56,  1.73it/s, Loss=0.0520721, Gaussian number=209430, print grad=0.002080269157886505, Depth Loss=0.0000000]
Training progress:  54%|█████▎    | 1070/2000 [11:46<08:56,  1.73it/s, Loss=0.0566682, Gaussian number=209430, print grad=0.002355588600039482, Depth Loss=0.0000000]
Training progress:  54%|█████▍    | 1080/2000 [11:46<07:49,  1.96it/s, Loss=0.0566682, Gaussian number=209430, print grad=0.002355588600039482, Depth Loss=0.0000000]
Training progress:  54%|█████▍    | 1080/2000 [11:50<07:49,  1.96it/s, Loss=0.0681868, Gaussian number=209430, print grad=0.002639931393787265, Depth Loss=0.0000000]
Training progress:  55%|█████▍    | 1090/2000 [11:50<07:01,  2.16it/s, Loss=0.0681868, Gaussian number=209430, print grad=0.002639931393787265, Depth Loss=0.0000000]
Training progress:  55%|█████▍    | 1090/2000 [11:53<07:01,  2.16it/s, Loss=0.0718380, Gaussian number=209430, print grad=0.0029224648606032133, Depth Loss=0.0000000]
Training progress:  55%|█████▌    | 1100/2000 [11:53<06:27,  2.32it/s, Loss=0.0718380, Gaussian number=209430, print grad=0.0029224648606032133, Depth Loss=0.0000000]
Training progress:  55%|█████▌    | 1100/2000 [11:57<06:27,  2.32it/s, Loss=0.0771417, Gaussian number=216861, print grad=0.00026606020401231945, Depth Loss=0.0000000]
Training progress:  56%|█████▌    | 1110/2000 [11:57<06:02,  2.45it/s, Loss=0.0771417, Gaussian number=216861, print grad=0.00026606020401231945, Depth Loss=0.0000000]
Training progress:  56%|█████▌    | 1110/2000 [12:00<06:02,  2.45it/s, Loss=0.0716717, Gaussian number=216861, print grad=0.0005825956468470395, Depth Loss=0.0000000] 
Training progress:  56%|█████▌    | 1120/2000 [12:00<05:45,  2.55it/s, Loss=0.0716717, Gaussian number=216861, print grad=0.0005825956468470395, Depth Loss=0.0000000]
Training progress:  56%|█████▌    | 1120/2000 [12:04<05:45,  2.55it/s, Loss=0.0574185, Gaussian number=216861, print grad=0.0009097435977309942, Depth Loss=0.0000000]
Training progress:  56%|█████▋    | 1130/2000 [12:04<05:32,  2.62it/s, Loss=0.0574185, Gaussian number=216861, print grad=0.0009097435977309942, Depth Loss=0.0000000]
Training progress:  56%|█████▋    | 1130/2000 [12:08<05:32,  2.62it/s, Loss=0.0704351, Gaussian number=216861, print grad=0.0012185296509414911, Depth Loss=0.0000000]
Training progress:  57%|█████▋    | 1140/2000 [12:08<05:21,  2.68it/s, Loss=0.0704351, Gaussian number=216861, print grad=0.0012185296509414911, Depth Loss=0.0000000]
Training progress:  57%|█████▋    | 1140/2000 [12:11<05:21,  2.68it/s, Loss=0.0499283, Gaussian number=216861, print grad=0.0015189474215731025, Depth Loss=0.0000000]
Training progress:  57%|█████▊    | 1150/2000 [12:11<05:13,  2.71it/s, Loss=0.0499283, Gaussian number=216861, print grad=0.0015189474215731025, Depth Loss=0.0000000]
Training progress:  57%|█████▊    | 1150/2000 [12:15<05:13,  2.71it/s, Loss=0.0549748, Gaussian number=216861, print grad=0.0017868222203105688, Depth Loss=0.0000000]
Training progress:  58%|█████▊    | 1160/2000 [12:15<05:06,  2.74it/s, Loss=0.0549748, Gaussian number=216861, print grad=0.0017868222203105688, Depth Loss=0.0000000]
Training progress:  58%|█████▊    | 1160/2000 [12:18<05:06,  2.74it/s, Loss=0.0664986, Gaussian number=216861, print grad=0.0020772332791239023, Depth Loss=0.0000000]
Training progress:  58%|█████▊    | 1170/2000 [12:18<05:00,  2.76it/s, Loss=0.0664986, Gaussian number=216861, print grad=0.0020772332791239023, Depth Loss=0.0000000]
Training progress:  58%|█████▊    | 1170/2000 [12:22<05:00,  2.76it/s, Loss=0.0671049, Gaussian number=216861, print grad=0.002361136022955179, Depth Loss=0.0000000] 
Training progress:  59%|█████▉    | 1180/2000 [12:22<04:55,  2.78it/s, Loss=0.0671049, Gaussian number=216861, print grad=0.002361136022955179, Depth Loss=0.0000000]
Training progress:  59%|█████▉    | 1180/2000 [12:25<04:55,  2.78it/s, Loss=0.0642935, Gaussian number=216861, print grad=0.002662062179297209, Depth Loss=0.0000000]
Training progress:  60%|█████▉    | 1190/2000 [12:25<04:50,  2.79it/s, Loss=0.0642935, Gaussian number=216861, print grad=0.002662062179297209, Depth Loss=0.0000000]
Training progress:  60%|█████▉    | 1190/2000 [12:29<04:50,  2.79it/s, Loss=0.0729825, Gaussian number=216861, print grad=0.002908071968704462, Depth Loss=0.0000000]
Training progress:  60%|██████    | 1200/2000 [12:29<04:46,  2.79it/s, Loss=0.0729825, Gaussian number=216861, print grad=0.002908071968704462, Depth Loss=0.0000000]
Training progress:  60%|██████    | 1200/2000 [12:32<04:46,  2.79it/s, Loss=0.0584608, Gaussian number=224652, print grad=0.00028020914760418236, Depth Loss=0.0000000]
Training progress:  60%|██████    | 1210/2000 [12:32<04:41,  2.80it/s, Loss=0.0584608, Gaussian number=224652, print grad=0.00028020914760418236, Depth Loss=0.0000000]
Training progress:  60%|██████    | 1210/2000 [12:36<04:41,  2.80it/s, Loss=0.0499168, Gaussian number=224652, print grad=0.0006056192796677351, Depth Loss=0.0000000] 
Training progress:  61%|██████    | 1220/2000 [12:36<04:37,  2.81it/s, Loss=0.0499168, Gaussian number=224652, print grad=0.0006056192796677351, Depth Loss=0.0000000]
Training progress:  61%|██████    | 1220/2000 [12:39<04:37,  2.81it/s, Loss=0.0539697, Gaussian number=224652, print grad=0.0008784004021435976, Depth Loss=0.0000000]
Training progress:  62%|██████▏   | 1230/2000 [12:39<04:33,  2.82it/s, Loss=0.0539697, Gaussian number=224652, print grad=0.0008784004021435976, Depth Loss=0.0000000]
Training progress:  62%|██████▏   | 1230/2000 [12:43<04:33,  2.82it/s, Loss=0.0508138, Gaussian number=224652, print grad=0.0011791259748861194, Depth Loss=0.0000000]
Training progress:  62%|██████▏   | 1240/2000 [12:43<04:29,  2.82it/s, Loss=0.0508138, Gaussian number=224652, print grad=0.0011791259748861194, Depth Loss=0.0000000]
Training progress:  62%|██████▏   | 1240/2000 [12:47<04:29,  2.82it/s, Loss=0.0514888, Gaussian number=224652, print grad=0.0014395221369341016, Depth Loss=0.0000000]
Training progress:  62%|██████▎   | 1250/2000 [12:47<04:25,  2.83it/s, Loss=0.0514888, Gaussian number=224652, print grad=0.0014395221369341016, Depth Loss=0.0000000]
Training progress:  62%|██████▎   | 1250/2000 [12:50<04:25,  2.83it/s, Loss=0.0544410, Gaussian number=224652, print grad=0.0016952470177784562, Depth Loss=0.0000000]
Training progress:  63%|██████▎   | 1260/2000 [12:50<04:21,  2.83it/s, Loss=0.0544410, Gaussian number=224652, print grad=0.0016952470177784562, Depth Loss=0.0000000]
Training progress:  63%|██████▎   | 1260/2000 [12:54<04:21,  2.83it/s, Loss=0.0676741, Gaussian number=224652, print grad=0.001981118693947792, Depth Loss=0.0000000] 
Training progress:  64%|██████▎   | 1270/2000 [12:54<04:18,  2.83it/s, Loss=0.0676741, Gaussian number=224652, print grad=0.001981118693947792, Depth Loss=0.0000000]
Training progress:  64%|██████▎   | 1270/2000 [12:57<04:18,  2.83it/s, Loss=0.0668962, Gaussian number=224652, print grad=0.0022491414565593004, Depth Loss=0.0000000]
Training progress:  64%|██████▍   | 1280/2000 [12:57<04:14,  2.83it/s, Loss=0.0668962, Gaussian number=224652, print grad=0.0022491414565593004, Depth Loss=0.0000000]
Training progress:  64%|██████▍   | 1280/2000 [13:01<04:14,  2.83it/s, Loss=0.0504135, Gaussian number=224652, print grad=0.002545675029978156, Depth Loss=0.0000000] 
Training progress:  64%|██████▍   | 1290/2000 [13:01<04:10,  2.83it/s, Loss=0.0504135, Gaussian number=224652, print grad=0.002545675029978156, Depth Loss=0.0000000]
Training progress:  64%|██████▍   | 1290/2000 [13:04<04:10,  2.83it/s, Loss=0.0774186, Gaussian number=224652, print grad=0.0028049901593476534, Depth Loss=0.0000000]
Training progress:  65%|██████▌   | 1300/2000 [13:04<04:07,  2.83it/s, Loss=0.0774186, Gaussian number=224652, print grad=0.0028049901593476534, Depth Loss=0.0000000]
Training progress:  65%|██████▌   | 1300/2000 [13:08<04:07,  2.83it/s, Loss=0.0747318, Gaussian number=232401, print grad=0.0002938239194918424, Depth Loss=0.0000000]
Training progress:  66%|██████▌   | 1310/2000 [13:08<04:04,  2.82it/s, Loss=0.0747318, Gaussian number=232401, print grad=0.0002938239194918424, Depth Loss=0.0000000]
Training progress:  66%|██████▌   | 1310/2000 [13:11<04:04,  2.82it/s, Loss=0.0760591, Gaussian number=232401, print grad=0.0005779055063612759, Depth Loss=0.0000000]
Training progress:  66%|██████▌   | 1320/2000 [13:11<04:01,  2.82it/s, Loss=0.0760591, Gaussian number=232401, print grad=0.0005779055063612759, Depth Loss=0.0000000]
Training progress:  66%|██████▌   | 1320/2000 [13:15<04:01,  2.82it/s, Loss=0.0594708, Gaussian number=232401, print grad=0.0008805760880932212, Depth Loss=0.0000000]
Training progress:  66%|██████▋   | 1330/2000 [13:15<03:57,  2.82it/s, Loss=0.0594708, Gaussian number=232401, print grad=0.0008805760880932212, Depth Loss=0.0000000]
Training progress:  66%|██████▋   | 1330/2000 [13:18<03:57,  2.82it/s, Loss=0.0618018, Gaussian number=232401, print grad=0.001174377859570086, Depth Loss=0.0000000] 
Training progress:  67%|██████▋   | 1340/2000 [13:18<03:54,  2.82it/s, Loss=0.0618018, Gaussian number=232401, print grad=0.001174377859570086, Depth Loss=0.0000000]
Training progress:  67%|██████▋   | 1340/2000 [13:22<03:54,  2.82it/s, Loss=0.0833635, Gaussian number=232401, print grad=0.0014228913933038712, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1350/2000 [13:22<03:50,  2.82it/s, Loss=0.0833635, Gaussian number=232401, print grad=0.0014228913933038712, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1350/2000 [13:25<03:50,  2.82it/s, Loss=0.0494951, Gaussian number=232401, print grad=0.001676729996688664, Depth Loss=0.0000000] 
Training progress:  68%|██████▊   | 1360/2000 [13:25<03:46,  2.82it/s, Loss=0.0494951, Gaussian number=232401, print grad=0.001676729996688664, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1360/2000 [13:29<03:46,  2.82it/s, Loss=0.0921261, Gaussian number=232401, print grad=0.0019687162712216377, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1370/2000 [13:29<03:43,  2.82it/s, Loss=0.0921261, Gaussian number=232401, print grad=0.0019687162712216377, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1370/2000 [13:33<03:43,  2.82it/s, Loss=0.0588909, Gaussian number=232401, print grad=0.0022244032006710768, Depth Loss=0.0000000]
Training progress:  69%|██████▉   | 1380/2000 [13:33<03:39,  2.82it/s, Loss=0.0588909, Gaussian number=232401, print grad=0.0022244032006710768, Depth Loss=0.0000000]
Training progress:  69%|██████▉   | 1380/2000 [13:36<03:39,  2.82it/s, Loss=0.0538448, Gaussian number=232401, print grad=0.002474975073710084, Depth Loss=0.0000000] 
Training progress:  70%|██████▉   | 1390/2000 [13:36<03:36,  2.82it/s, Loss=0.0538448, Gaussian number=232401, print grad=0.002474975073710084, Depth Loss=0.0000000]
Training progress:  70%|██████▉   | 1390/2000 [13:40<03:36,  2.82it/s, Loss=0.0585632, Gaussian number=232401, print grad=0.0027397607918828726, Depth Loss=0.0000000]
Training progress:  70%|███████   | 1400/2000 [13:40<03:32,  2.82it/s, Loss=0.0585632, Gaussian number=232401, print grad=0.0027397607918828726, Depth Loss=0.0000000]
Training progress:  70%|███████   | 1400/2000 [13:43<03:32,  2.82it/s, Loss=0.0692851, Gaussian number=240246, print grad=0.00028362407465465367, Depth Loss=0.0000000]
Training progress:  70%|███████   | 1410/2000 [13:43<03:29,  2.82it/s, Loss=0.0692851, Gaussian number=240246, print grad=0.00028362407465465367, Depth Loss=0.0000000]
Training progress:  70%|███████   | 1410/2000 [13:47<03:29,  2.82it/s, Loss=0.0601531, Gaussian number=240246, print grad=0.0005913199856877327, Depth Loss=0.0000000] 
Training progress:  71%|███████   | 1420/2000 [13:47<03:25,  2.82it/s, Loss=0.0601531, Gaussian number=240246, print grad=0.0005913199856877327, Depth Loss=0.0000000]
Training progress:  71%|███████   | 1420/2000 [13:50<03:25,  2.82it/s, Loss=0.0623058, Gaussian number=240246, print grad=0.0009072539978660643, Depth Loss=0.0000000]
Training progress:  72%|███████▏  | 1430/2000 [13:50<03:22,  2.82it/s, Loss=0.0623058, Gaussian number=240246, print grad=0.0009072539978660643, Depth Loss=0.0000000]
Training progress:  72%|███████▏  | 1430/2000 [13:54<03:22,  2.82it/s, Loss=0.0579345, Gaussian number=240246, print grad=0.0011731676058843732, Depth Loss=0.0000000]
Training progress:  72%|███████▏  | 1440/2000 [13:54<03:18,  2.82it/s, Loss=0.0579345, Gaussian number=240246, print grad=0.0011731676058843732, Depth Loss=0.0000000]
Training progress:  72%|███████▏  | 1440/2000 [13:57<03:18,  2.82it/s, Loss=0.0523274, Gaussian number=240246, print grad=0.001436941558495164, Depth Loss=0.0000000] 
Training progress:  72%|███████▎  | 1450/2000 [13:57<03:14,  2.82it/s, Loss=0.0523274, Gaussian number=240246, print grad=0.001436941558495164, Depth Loss=0.0000000]
Training progress:  72%|███████▎  | 1450/2000 [14:01<03:14,  2.82it/s, Loss=0.0460679, Gaussian number=240246, print grad=0.0017034336924552917, Depth Loss=0.0000000]
Training progress:  73%|███████▎  | 1460/2000 [14:01<03:11,  2.82it/s, Loss=0.0460679, Gaussian number=240246, print grad=0.0017034336924552917, Depth Loss=0.0000000]
Training progress:  73%|███████▎  | 1460/2000 [14:04<03:11,  2.82it/s, Loss=0.0630505, Gaussian number=240246, print grad=0.0019795596599578857, Depth Loss=0.0000000]
Training progress:  74%|███████▎  | 1470/2000 [14:04<03:07,  2.82it/s, Loss=0.0630505, Gaussian number=240246, print grad=0.0019795596599578857, Depth Loss=0.0000000]
Training progress:  74%|███████▎  | 1470/2000 [14:08<03:07,  2.82it/s, Loss=0.0620881, Gaussian number=240246, print grad=0.0022661525290459394, Depth Loss=0.0000000]
Training progress:  74%|███████▍  | 1480/2000 [14:08<03:04,  2.82it/s, Loss=0.0620881, Gaussian number=240246, print grad=0.0022661525290459394, Depth Loss=0.0000000]
Training progress:  74%|███████▍  | 1480/2000 [14:12<03:04,  2.82it/s, Loss=0.0660038, Gaussian number=240246, print grad=0.0025486729573458433, Depth Loss=0.0000000]
Training progress:  74%|███████▍  | 1490/2000 [14:12<03:00,  2.82it/s, Loss=0.0660038, Gaussian number=240246, print grad=0.0025486729573458433, Depth Loss=0.0000000]
Training progress:  74%|███████▍  | 1490/2000 [14:15<03:00,  2.82it/s, Loss=0.0643798, Gaussian number=240246, print grad=0.0028290473856031895, Depth Loss=0.0000000]
Training progress:  75%|███████▌  | 1500/2000 [14:15<02:56,  2.83it/s, Loss=0.0643798, Gaussian number=240246, print grad=0.0028290473856031895, Depth Loss=0.0000000]
Training progress:  75%|███████▌  | 1500/2000 [15:22<02:56,  2.83it/s, Loss=0.0728446, Gaussian number=247966, print grad=0.00025963294319808483, Depth Loss=0.0000000]
Training progress:  76%|███████▌  | 1510/2000 [15:22<18:29,  2.26s/it, Loss=0.0728446, Gaussian number=247966, print grad=0.00025963294319808483, Depth Loss=0.0000000]
Training progress:  76%|███████▌  | 1510/2000 [15:26<18:29,  2.26s/it, Loss=0.0655951, Gaussian number=247966, print grad=0.0005249402020126581, Depth Loss=0.0000000] 
Training progress:  76%|███████▌  | 1520/2000 [15:26<13:31,  1.69s/it, Loss=0.0655951, Gaussian number=247966, print grad=0.0005249402020126581, Depth Loss=0.0000000]
Training progress:  76%|███████▌  | 1520/2000 [15:29<13:31,  1.69s/it, Loss=0.0375842, Gaussian number=247966, print grad=0.0008314428268931806, Depth Loss=0.0000000]
Training progress:  76%|███████▋  | 1530/2000 [15:29<10:06,  1.29s/it, Loss=0.0375842, Gaussian number=247966, print grad=0.0008314428268931806, Depth Loss=0.0000000]
Training progress:  76%|███████▋  | 1530/2000 [15:33<10:06,  1.29s/it, Loss=0.0540771, Gaussian number=247966, print grad=0.0011116384994238615, Depth Loss=0.0000000]
Training progress:  77%|███████▋  | 1540/2000 [15:33<07:44,  1.01s/it, Loss=0.0540771, Gaussian number=247966, print grad=0.0011116384994238615, Depth Loss=0.0000000]
Training progress:  77%|███████▋  | 1540/2000 [15:37<07:44,  1.01s/it, Loss=0.0597702, Gaussian number=247966, print grad=0.0014041027752682567, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1550/2000 [15:37<06:06,  1.23it/s, Loss=0.0597702, Gaussian number=247966, print grad=0.0014041027752682567, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1550/2000 [15:40<06:06,  1.23it/s, Loss=0.0612305, Gaussian number=247966, print grad=0.0017038172809407115, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1560/2000 [15:40<04:57,  1.48it/s, Loss=0.0612305, Gaussian number=247966, print grad=0.0017038172809407115, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1560/2000 [15:44<04:57,  1.48it/s, Loss=0.0536866, Gaussian number=247966, print grad=0.0019840309396386147, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1570/2000 [15:44<04:09,  1.72it/s, Loss=0.0536866, Gaussian number=247966, print grad=0.0019840309396386147, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1570/2000 [15:47<04:09,  1.72it/s, Loss=0.0396706, Gaussian number=247966, print grad=0.00220477650873363, Depth Loss=0.0000000]  
Training progress:  79%|███████▉  | 1580/2000 [15:47<03:35,  1.95it/s, Loss=0.0396706, Gaussian number=247966, print grad=0.00220477650873363, Depth Loss=0.0000000]
Training progress:  79%|███████▉  | 1580/2000 [15:51<03:35,  1.95it/s, Loss=0.0547454, Gaussian number=247966, print grad=0.002461625961586833, Depth Loss=0.0000000]
Training progress:  80%|███████▉  | 1590/2000 [15:51<03:11,  2.15it/s, Loss=0.0547454, Gaussian number=247966, print grad=0.002461625961586833, Depth Loss=0.0000000]
Training progress:  80%|███████▉  | 1590/2000 [15:54<03:11,  2.15it/s, Loss=0.0515557, Gaussian number=247966, print grad=0.002743647200986743, Depth Loss=0.0000000]
Training progress:  80%|████████  | 1600/2000 [15:54<02:53,  2.31it/s, Loss=0.0515557, Gaussian number=247966, print grad=0.002743647200986743, Depth Loss=0.0000000]
Training progress:  80%|████████  | 1600/2000 [15:58<02:53,  2.31it/s, Loss=0.0615845, Gaussian number=255486, print grad=0.00027860363479703665, Depth Loss=0.0000000]
Training progress:  80%|████████  | 1610/2000 [15:58<02:40,  2.44it/s, Loss=0.0615845, Gaussian number=255486, print grad=0.00027860363479703665, Depth Loss=0.0000000]
Training progress:  80%|████████  | 1610/2000 [16:01<02:40,  2.44it/s, Loss=0.0622528, Gaussian number=255486, print grad=0.0005960614653304219, Depth Loss=0.0000000] 
Training progress:  81%|████████  | 1620/2000 [16:01<02:29,  2.54it/s, Loss=0.0622528, Gaussian number=255486, print grad=0.0005960614653304219, Depth Loss=0.0000000]
Training progress:  81%|████████  | 1620/2000 [16:05<02:29,  2.54it/s, Loss=0.0533686, Gaussian number=255486, print grad=0.0008719579200260341, Depth Loss=0.0000000]
Training progress:  82%|████████▏ | 1630/2000 [16:05<02:21,  2.61it/s, Loss=0.0533686, Gaussian number=255486, print grad=0.0008719579200260341, Depth Loss=0.0000000]
Training progress:  82%|████████▏ | 1630/2000 [16:09<02:21,  2.61it/s, Loss=0.0408157, Gaussian number=255486, print grad=0.001147213508374989, Depth Loss=0.0000000] 
Training progress:  82%|████████▏ | 1640/2000 [16:09<02:15,  2.67it/s, Loss=0.0408157, Gaussian number=255486, print grad=0.001147213508374989, Depth Loss=0.0000000]
Training progress:  82%|████████▏ | 1640/2000 [16:12<02:15,  2.67it/s, Loss=0.0539747, Gaussian number=255486, print grad=0.001407303148880601, Depth Loss=0.0000000]
Training progress:  82%|████████▎ | 1650/2000 [16:12<02:09,  2.70it/s, Loss=0.0539747, Gaussian number=255486, print grad=0.001407303148880601, Depth Loss=0.0000000]
Training progress:  82%|████████▎ | 1650/2000 [16:16<02:09,  2.70it/s, Loss=0.0524749, Gaussian number=255486, print grad=0.0016715085366740823, Depth Loss=0.0000000]
Training progress:  83%|████████▎ | 1660/2000 [16:16<02:04,  2.73it/s, Loss=0.0524749, Gaussian number=255486, print grad=0.0016715085366740823, Depth Loss=0.0000000]
Training progress:  83%|████████▎ | 1660/2000 [16:19<02:04,  2.73it/s, Loss=0.0490731, Gaussian number=255486, print grad=0.0019338417332619429, Depth Loss=0.0000000]
Training progress:  84%|████████▎ | 1670/2000 [16:19<01:59,  2.75it/s, Loss=0.0490731, Gaussian number=255486, print grad=0.0019338417332619429, Depth Loss=0.0000000]
Training progress:  84%|████████▎ | 1670/2000 [16:23<01:59,  2.75it/s, Loss=0.0453859, Gaussian number=255486, print grad=0.002196415327489376, Depth Loss=0.0000000] 
Training progress:  84%|████████▍ | 1680/2000 [16:23<01:55,  2.77it/s, Loss=0.0453859, Gaussian number=255486, print grad=0.002196415327489376, Depth Loss=0.0000000]
Training progress:  84%|████████▍ | 1680/2000 [16:26<01:55,  2.77it/s, Loss=0.0538093, Gaussian number=255486, print grad=0.0024600292090326548, Depth Loss=0.0000000]
Training progress:  84%|████████▍ | 1690/2000 [16:26<01:51,  2.78it/s, Loss=0.0538093, Gaussian number=255486, print grad=0.0024600292090326548, Depth Loss=0.0000000]
Training progress:  84%|████████▍ | 1690/2000 [16:30<01:51,  2.78it/s, Loss=0.0575168, Gaussian number=255486, print grad=0.0026965574361383915, Depth Loss=0.0000000]
Training progress:  85%|████████▌ | 1700/2000 [16:30<01:47,  2.79it/s, Loss=0.0575168, Gaussian number=255486, print grad=0.0026965574361383915, Depth Loss=0.0000000]
Training progress:  85%|████████▌ | 1700/2000 [16:34<01:47,  2.79it/s, Loss=0.0606112, Gaussian number=262764, print grad=0.000283765111817047, Depth Loss=0.0000000] 
Training progress:  86%|████████▌ | 1710/2000 [16:34<01:43,  2.80it/s, Loss=0.0606112, Gaussian number=262764, print grad=0.000283765111817047, Depth Loss=0.0000000]
Training progress:  86%|████████▌ | 1710/2000 [16:37<01:43,  2.80it/s, Loss=0.0652088, Gaussian number=262764, print grad=0.0005251807742752135, Depth Loss=0.0000000]
Training progress:  86%|████████▌ | 1720/2000 [16:37<01:39,  2.81it/s, Loss=0.0652088, Gaussian number=262764, print grad=0.0005251807742752135, Depth Loss=0.0000000]
Training progress:  86%|████████▌ | 1720/2000 [16:41<01:39,  2.81it/s, Loss=0.0564381, Gaussian number=262764, print grad=0.0007919891504570842, Depth Loss=0.0000000]
Training progress:  86%|████████▋ | 1730/2000 [16:41<01:36,  2.81it/s, Loss=0.0564381, Gaussian number=262764, print grad=0.0007919891504570842, Depth Loss=0.0000000]
Training progress:  86%|████████▋ | 1730/2000 [16:44<01:36,  2.81it/s, Loss=0.0755932, Gaussian number=262764, print grad=0.0010816568974405527, Depth Loss=0.0000000]
Training progress:  87%|████████▋ | 1740/2000 [16:44<01:32,  2.81it/s, Loss=0.0755932, Gaussian number=262764, print grad=0.0010816568974405527, Depth Loss=0.0000000]
Training progress:  87%|████████▋ | 1740/2000 [16:48<01:32,  2.81it/s, Loss=0.0697546, Gaussian number=262764, print grad=0.0013720719143748283, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1750/2000 [16:48<01:28,  2.81it/s, Loss=0.0697546, Gaussian number=262764, print grad=0.0013720719143748283, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1750/2000 [16:51<01:28,  2.81it/s, Loss=0.0557295, Gaussian number=262764, print grad=0.001625354983843863, Depth Loss=0.0000000] 
Training progress:  88%|████████▊ | 1760/2000 [16:51<01:25,  2.82it/s, Loss=0.0557295, Gaussian number=262764, print grad=0.001625354983843863, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1760/2000 [16:55<01:25,  2.82it/s, Loss=0.0461767, Gaussian number=262764, print grad=0.0018676701001822948, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1770/2000 [16:55<01:21,  2.81it/s, Loss=0.0461767, Gaussian number=262764, print grad=0.0018676701001822948, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1770/2000 [16:58<01:21,  2.81it/s, Loss=0.0546158, Gaussian number=262764, print grad=0.002110631437972188, Depth Loss=0.0000000] 
Training progress:  89%|████████▉ | 1780/2000 [16:58<01:18,  2.82it/s, Loss=0.0546158, Gaussian number=262764, print grad=0.002110631437972188, Depth Loss=0.0000000]
Training progress:  89%|████████▉ | 1780/2000 [17:02<01:18,  2.82it/s, Loss=0.0505488, Gaussian number=262764, print grad=0.0023192649241536856, Depth Loss=0.0000000]
Training progress:  90%|████████▉ | 1790/2000 [17:02<01:14,  2.82it/s, Loss=0.0505488, Gaussian number=262764, print grad=0.0023192649241536856, Depth Loss=0.0000000]
Training progress:  90%|████████▉ | 1790/2000 [17:06<01:14,  2.82it/s, Loss=0.0499344, Gaussian number=262764, print grad=0.0025864101480692625, Depth Loss=0.0000000]
Training progress:  90%|█████████ | 1800/2000 [17:06<01:11,  2.81it/s, Loss=0.0499344, Gaussian number=262764, print grad=0.0025864101480692625, Depth Loss=0.0000000]
Training progress:  90%|█████████ | 1800/2000 [17:09<01:11,  2.81it/s, Loss=0.0581370, Gaussian number=269994, print grad=0.0002721776836551726, Depth Loss=0.0000000]
Training progress:  90%|█████████ | 1810/2000 [17:09<01:07,  2.81it/s, Loss=0.0581370, Gaussian number=269994, print grad=0.0002721776836551726, Depth Loss=0.0000000]
Training progress:  90%|█████████ | 1810/2000 [17:13<01:07,  2.81it/s, Loss=0.0511009, Gaussian number=269994, print grad=0.000564133923035115, Depth Loss=0.0000000] 
Training progress:  91%|█████████ | 1820/2000 [17:13<01:04,  2.81it/s, Loss=0.0511009, Gaussian number=269994, print grad=0.000564133923035115, Depth Loss=0.0000000]
Training progress:  91%|█████████ | 1820/2000 [17:16<01:04,  2.81it/s, Loss=0.0447939, Gaussian number=269994, print grad=0.0007952834712341428, Depth Loss=0.0000000]
Training progress:  92%|█████████▏| 1830/2000 [17:16<01:00,  2.81it/s, Loss=0.0447939, Gaussian number=269994, print grad=0.0007952834712341428, Depth Loss=0.0000000]
Training progress:  92%|█████████▏| 1830/2000 [17:20<01:00,  2.81it/s, Loss=0.0465732, Gaussian number=269994, print grad=0.0010736198164522648, Depth Loss=0.0000000]
Training progress:  92%|█████████▏| 1840/2000 [17:20<00:57,  2.81it/s, Loss=0.0465732, Gaussian number=269994, print grad=0.0010736198164522648, Depth Loss=0.0000000]
Training progress:  92%|█████████▏| 1840/2000 [17:23<00:57,  2.81it/s, Loss=0.0506855, Gaussian number=269994, print grad=0.0013232945930212736, Depth Loss=0.0000000]
Training progress:  92%|█████████▎| 1850/2000 [17:23<00:53,  2.80it/s, Loss=0.0506855, Gaussian number=269994, print grad=0.0013232945930212736, Depth Loss=0.0000000]
Training progress:  92%|█████████▎| 1850/2000 [17:27<00:53,  2.80it/s, Loss=0.0524003, Gaussian number=269994, print grad=0.0015444691525772214, Depth Loss=0.0000000]
Training progress:  93%|█████████▎| 1860/2000 [17:27<00:49,  2.80it/s, Loss=0.0524003, Gaussian number=269994, print grad=0.0015444691525772214, Depth Loss=0.0000000]
Training progress:  93%|█████████▎| 1860/2000 [17:30<00:49,  2.80it/s, Loss=0.0593954, Gaussian number=269994, print grad=0.001832945621572435, Depth Loss=0.0000000] 
Training progress:  94%|█████████▎| 1870/2000 [17:30<00:46,  2.81it/s, Loss=0.0593954, Gaussian number=269994, print grad=0.001832945621572435, Depth Loss=0.0000000]
Training progress:  94%|█████████▎| 1870/2000 [17:34<00:46,  2.81it/s, Loss=0.0449107, Gaussian number=269994, print grad=0.002085306216031313, Depth Loss=0.0000000]
Training progress:  94%|█████████▍| 1880/2000 [17:34<00:42,  2.81it/s, Loss=0.0449107, Gaussian number=269994, print grad=0.002085306216031313, Depth Loss=0.0000000]
Training progress:  94%|█████████▍| 1880/2000 [17:38<00:42,  2.81it/s, Loss=0.0505902, Gaussian number=269994, print grad=0.0023300014436244965, Depth Loss=0.0000000]
Training progress:  94%|█████████▍| 1890/2000 [17:38<00:39,  2.81it/s, Loss=0.0505902, Gaussian number=269994, print grad=0.0023300014436244965, Depth Loss=0.0000000]
Training progress:  94%|█████████▍| 1890/2000 [17:41<00:39,  2.81it/s, Loss=0.0624773, Gaussian number=269994, print grad=0.0025970572605729103, Depth Loss=0.0000000]
Training progress:  95%|█████████▌| 1900/2000 [17:41<00:35,  2.81it/s, Loss=0.0624773, Gaussian number=269994, print grad=0.0025970572605729103, Depth Loss=0.0000000]
Training progress:  95%|█████████▌| 1900/2000 [17:45<00:35,  2.81it/s, Loss=0.0574392, Gaussian number=277990, print grad=0.0002311581338290125, Depth Loss=0.0000000]
Training progress:  96%|█████████▌| 1910/2000 [17:45<00:32,  2.81it/s, Loss=0.0574392, Gaussian number=277990, print grad=0.0002311581338290125, Depth Loss=0.0000000]
Training progress:  96%|█████████▌| 1910/2000 [17:48<00:32,  2.81it/s, Loss=0.0485537, Gaussian number=277990, print grad=0.0004984540864825249, Depth Loss=0.0000000]
Training progress:  96%|█████████▌| 1920/2000 [17:48<00:28,  2.81it/s, Loss=0.0485537, Gaussian number=277990, print grad=0.0004984540864825249, Depth Loss=0.0000000]
Training progress:  96%|█████████▌| 1920/2000 [17:52<00:28,  2.81it/s, Loss=0.0414315, Gaussian number=277990, print grad=0.0007667160825803876, Depth Loss=0.0000000]
Training progress:  96%|█████████▋| 1930/2000 [17:52<00:24,  2.81it/s, Loss=0.0414315, Gaussian number=277990, print grad=0.0007667160825803876, Depth Loss=0.0000000]
Training progress:  96%|█████████▋| 1930/2000 [17:55<00:24,  2.81it/s, Loss=0.0566040, Gaussian number=277990, print grad=0.001017114263959229, Depth Loss=0.0000000] 
Training progress:  97%|█████████▋| 1940/2000 [17:55<00:21,  2.81it/s, Loss=0.0566040, Gaussian number=277990, print grad=0.001017114263959229, Depth Loss=0.0000000]
Training progress:  97%|█████████▋| 1940/2000 [17:59<00:21,  2.81it/s, Loss=0.0447230, Gaussian number=277990, print grad=0.0012642954243347049, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1950/2000 [17:59<00:17,  2.81it/s, Loss=0.0447230, Gaussian number=277990, print grad=0.0012642954243347049, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1950/2000 [18:02<00:17,  2.81it/s, Loss=0.0694971, Gaussian number=277990, print grad=0.0014959218678995967, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1960/2000 [18:02<00:14,  2.81it/s, Loss=0.0694971, Gaussian number=277990, print grad=0.0014959218678995967, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1960/2000 [18:06<00:14,  2.81it/s, Loss=0.0595801, Gaussian number=277990, print grad=0.001743809087201953, Depth Loss=0.0000000] 
Training progress:  98%|█████████▊| 1970/2000 [18:06<00:10,  2.81it/s, Loss=0.0595801, Gaussian number=277990, print grad=0.001743809087201953, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1970/2000 [18:10<00:10,  2.81it/s, Loss=0.0485774, Gaussian number=277990, print grad=0.0020017533097416162, Depth Loss=0.0000000]
Training progress:  99%|█████████▉| 1980/2000 [18:10<00:07,  2.82it/s, Loss=0.0485774, Gaussian number=277990, print grad=0.0020017533097416162, Depth Loss=0.0000000]
Training progress:  99%|█████████▉| 1980/2000 [18:13<00:07,  2.82it/s, Loss=0.0479677, Gaussian number=277990, print grad=0.002281730528920889, Depth Loss=0.0000000] 
Training progress: 100%|█████████▉| 1990/2000 [18:13<00:03,  2.82it/s, Loss=0.0479677, Gaussian number=277990, print grad=0.002281730528920889, Depth Loss=0.0000000]
Training progress: 100%|█████████▉| 1990/2000 [18:17<00:03,  2.82it/s, Loss=0.0384011, Gaussian number=277990, print grad=0.002557820873335004, Depth Loss=0.0000000]
Training progress: 100%|██████████| 2000/2000 [18:17<00:00,  2.82it/s, Loss=0.0384011, Gaussian number=277990, print grad=0.002557820873335004, Depth Loss=0.0000000]
Training progress: 100%|██████████| 2000/2000 [18:17<00:00,  1.82it/s, Loss=0.0384011, Gaussian number=277990, print grad=0.002557820873335004, Depth Loss=0.0000000]
Iteration 100 [03/12 17:02:31]

[ITER 100] Evaluating test: WD 0.133670, PSNR 12.9173,lpips 0.588399,ssim 0.451395 [03/12 17:03:28]

[ITER 100] Evaluating train: WD 0.137137, PSNR 13.3684,lpips 0.590163,ssim 0.470465 [03/12 17:03:35]
Gaussian number:182686,print gradients:1.6513582522748038e-05 [03/12 17:03:35]
Iteration 200 [03/12 17:04:11]

[ITER 200] Evaluating test: WD 0.121192, PSNR 14.2929,lpips 0.534960,ssim 0.486223 [03/12 17:05:08]

[ITER 200] Evaluating train: WD 0.120838, PSNR 14.7978,lpips 0.524830,ssim 0.505464 [03/12 17:05:15]
Gaussian number:182686,print gradients:2.167320235457737e-05 [03/12 17:05:15]
Iteration 300 [03/12 17:05:51]

[ITER 300] Evaluating test: WD 0.112718, PSNR 15.0559,lpips 0.499135,ssim 0.506745 [03/12 17:06:48]

[ITER 300] Evaluating train: WD 0.112818, PSNR 15.5577,lpips 0.485711,ssim 0.523356 [03/12 17:06:55]
Gaussian number:182686,print gradients:2.5133485905826092e-05 [03/12 17:06:55]
Iteration 400 [03/12 17:07:31]
Iteration 500 [03/12 17:08:06]

[ITER 500] Evaluating test: WD 0.103070, PSNR 15.9839,lpips 0.460062,ssim 0.529353 [03/12 17:09:03]

[ITER 500] Evaluating train: WD 0.109120, PSNR 16.2336,lpips 0.459343,ssim 0.537351 [03/12 17:09:10]
Gaussian number:182686,print gradients:2.9590450139949098e-05 [03/12 17:09:10]
Iteration 600 [03/12 17:09:46]
Iteration 700 [03/12 17:10:21]
Iteration 800 [03/12 17:10:57]
Iteration 900 [03/12 17:11:33]
Iteration 1000 [03/12 17:12:08]

[ITER 1000] Evaluating test: WD 0.090830, PSNR 16.8227,lpips 0.406586,ssim 0.550454 [03/12 17:13:04]

[ITER 1000] Evaluating train: WD 0.095690, PSNR 17.2314,lpips 0.408475,ssim 0.557381 [03/12 17:13:12]
Gaussian number:202682,print gradients:4.349680239101872e-05 [03/12 17:13:12]
Iteration 1100 [03/12 17:13:47]
Iteration 1200 [03/12 17:14:22]
Iteration 1300 [03/12 17:14:58]
Iteration 1400 [03/12 17:15:33]
Iteration 1500 [03/12 17:16:09]

[ITER 1500] Evaluating test: WD 0.082089, PSNR 17.2768,lpips 0.372440,ssim 0.561735 [03/12 17:17:05]

[ITER 1500] Evaluating train: WD 0.086461, PSNR 17.9218,lpips 0.370966,ssim 0.571626 [03/12 17:17:13]
Gaussian number:240246,print gradients:nan [03/12 17:17:13]
Iteration 1600 [03/12 17:17:48]
Iteration 1700 [03/12 17:18:24]
Iteration 1800 [03/12 17:18:59]
Iteration 1900 [03/12 17:19:35]
Iteration 2000 [03/12 17:20:10]

[ITER 2000] Evaluating test: WD 0.077041, PSNR 17.5857,lpips 0.352111,ssim 0.568663 [03/12 17:21:06]

[ITER 2000] Evaluating train: WD 0.085508, PSNR 18.0226,lpips 0.359858,ssim 0.569335 [03/12 17:21:14]
Gaussian number:277990,print gradients:nan [03/12 17:21:14]

[ITER 2000] Saving Gaussians [03/12 17:21:14]

Training complete. [03/12 17:21:16]
