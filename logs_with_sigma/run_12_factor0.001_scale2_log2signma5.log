Optimizing /home/cw4287/gaussian-model/train_30k
Output folder: /home/cw4287/gaussian-model/train_30k [03/12 20:25:52]
Tensorboard not available: not logging progress [03/12 20:25:52]
------------LLFF HOLD------------- [03/12 20:25:53]

Reading camera 1/301
Reading camera 2/301
Reading camera 3/301
Reading camera 4/301
Reading camera 5/301
Reading camera 6/301
Reading camera 7/301
Reading camera 8/301
Reading camera 9/301
Reading camera 10/301
Reading camera 11/301
Reading camera 12/301
Reading camera 13/301
Reading camera 14/301
Reading camera 15/301
Reading camera 16/301
Reading camera 17/301
Reading camera 18/301
Reading camera 19/301
Reading camera 20/301
Reading camera 21/301
Reading camera 22/301
Reading camera 23/301
Reading camera 24/301
Reading camera 25/301
Reading camera 26/301
Reading camera 27/301
Reading camera 28/301
Reading camera 29/301
Reading camera 30/301
Reading camera 31/301
Reading camera 32/301
Reading camera 33/301
Reading camera 34/301
Reading camera 35/301
Reading camera 36/301
Reading camera 37/301
Reading camera 38/301
Reading camera 39/301
Reading camera 40/301
Reading camera 41/301
Reading camera 42/301
Reading camera 43/301
Reading camera 44/301
Reading camera 45/301
Reading camera 46/301
Reading camera 47/301
Reading camera 48/301
Reading camera 49/301
Reading camera 50/301
Reading camera 51/301
Reading camera 52/301
Reading camera 53/301
Reading camera 54/301
Reading camera 55/301
Reading camera 56/301
Reading camera 57/301
Reading camera 58/301
Reading camera 59/301
Reading camera 60/301
Reading camera 61/301
Reading camera 62/301
Reading camera 63/301
Reading camera 64/301
Reading camera 65/301
Reading camera 66/301
Reading camera 67/301
Reading camera 68/301
Reading camera 69/301
Reading camera 70/301
Reading camera 71/301
Reading camera 72/301
Reading camera 73/301
Reading camera 74/301
Reading camera 75/301
Reading camera 76/301
Reading camera 77/301
Reading camera 78/301
Reading camera 79/301
Reading camera 80/301
Reading camera 81/301
Reading camera 82/301
Reading camera 83/301
Reading camera 84/301
Reading camera 85/301
Reading camera 86/301
Reading camera 87/301
Reading camera 88/301
Reading camera 89/301
Reading camera 90/301
Reading camera 91/301
Reading camera 92/301
Reading camera 93/301
Reading camera 94/301
Reading camera 95/301
Reading camera 96/301
Reading camera 97/301
Reading camera 98/301
Reading camera 99/301
Reading camera 100/301
Reading camera 101/301
Reading camera 102/301
Reading camera 103/301
Reading camera 104/301
Reading camera 105/301
Reading camera 106/301
Reading camera 107/301
Reading camera 108/301
Reading camera 109/301
Reading camera 110/301
Reading camera 111/301
Reading camera 112/301
Reading camera 113/301
Reading camera 114/301
Reading camera 115/301
Reading camera 116/301
Reading camera 117/301
Reading camera 118/301
Reading camera 119/301
Reading camera 120/301
Reading camera 121/301
Reading camera 122/301
Reading camera 123/301
Reading camera 124/301
Reading camera 125/301
Reading camera 126/301
Reading camera 127/301
Reading camera 128/301
Reading camera 129/301
Reading camera 130/301
Reading camera 131/301
Reading camera 132/301
Reading camera 133/301
Reading camera 134/301
Reading camera 135/301
Reading camera 136/301
Reading camera 137/301
Reading camera 138/301
Reading camera 139/301
Reading camera 140/301
Reading camera 141/301
Reading camera 142/301
Reading camera 143/301
Reading camera 144/301
Reading camera 145/301
Reading camera 146/301
Reading camera 147/301
Reading camera 148/301
Reading camera 149/301
Reading camera 150/301
Reading camera 151/301
Reading camera 152/301
Reading camera 153/301
Reading camera 154/301
Reading camera 155/301
Reading camera 156/301
Reading camera 157/301
Reading camera 158/301
Reading camera 159/301
Reading camera 160/301
Reading camera 161/301
Reading camera 162/301
Reading camera 163/301
Reading camera 164/301
Reading camera 165/301
Reading camera 166/301
Reading camera 167/301
Reading camera 168/301
Reading camera 169/301
Reading camera 170/301
Reading camera 171/301
Reading camera 172/301
Reading camera 173/301
Reading camera 174/301
Reading camera 175/301
Reading camera 176/301
Reading camera 177/301
Reading camera 178/301
Reading camera 179/301
Reading camera 180/301
Reading camera 181/301
Reading camera 182/301
Reading camera 183/301
Reading camera 184/301
Reading camera 185/301
Reading camera 186/301
Reading camera 187/301
Reading camera 188/301
Reading camera 189/301
Reading camera 190/301
Reading camera 191/301
Reading camera 192/301
Reading camera 193/301
Reading camera 194/301
Reading camera 195/301
Reading camera 196/301
Reading camera 197/301
Reading camera 198/301
Reading camera 199/301
Reading camera 200/301
Reading camera 201/301
Reading camera 202/301
Reading camera 203/301
Reading camera 204/301
Reading camera 205/301
Reading camera 206/301
Reading camera 207/301
Reading camera 208/301
Reading camera 209/301
Reading camera 210/301
Reading camera 211/301
Reading camera 212/301
Reading camera 213/301
Reading camera 214/301
Reading camera 215/301
Reading camera 216/301
Reading camera 217/301
Reading camera 218/301
Reading camera 219/301
Reading camera 220/301
Reading camera 221/301
Reading camera 222/301
Reading camera 223/301
Reading camera 224/301
Reading camera 225/301
Reading camera 226/301
Reading camera 227/301
Reading camera 228/301
Reading camera 229/301
Reading camera 230/301
Reading camera 231/301
Reading camera 232/301
Reading camera 233/301
Reading camera 234/301
Reading camera 235/301
Reading camera 236/301
Reading camera 237/301
Reading camera 238/301
Reading camera 239/301
Reading camera 240/301
Reading camera 241/301
Reading camera 242/301
Reading camera 243/301
Reading camera 244/301
Reading camera 245/301
Reading camera 246/301
Reading camera 247/301
Reading camera 248/301
Reading camera 249/301
Reading camera 250/301
Reading camera 251/301
Reading camera 252/301
Reading camera 253/301
Reading camera 254/301
Reading camera 255/301
Reading camera 256/301
Reading camera 257/301
Reading camera 258/301
Reading camera 259/301
Reading camera 260/301
Reading camera 261/301
Reading camera 262/301
Reading camera 263/301
Reading camera 264/301
Reading camera 265/301
Reading camera 266/301
Reading camera 267/301
Reading camera 268/301
Reading camera 269/301
Reading camera 270/301
Reading camera 271/301
Reading camera 272/301
Reading camera 273/301
Reading camera 274/301
Reading camera 275/301
Reading camera 276/301
Reading camera 277/301
Reading camera 278/301
Reading camera 279/301
Reading camera 280/301
Reading camera 281/301
Reading camera 282/301
Reading camera 283/301
Reading camera 284/301
Reading camera 285/301
Reading camera 286/301
Reading camera 287/301
Reading camera 288/301
Reading camera 289/301
Reading camera 290/301
Reading camera 291/301
Reading camera 292/301
Reading camera 293/301
Reading camera 294/301
Reading camera 295/301
Reading camera 296/301
Reading camera 297/301
Reading camera 298/301
Reading camera 299/301
Reading camera 300/301
Reading camera 301/301 [03/12 20:25:53]
Loading Training Cameras [03/12 20:25:53]
Loading Test Cameras [03/12 20:26:09]
Number of points at initialisation :  182686 [03/12 20:26:12]

Training progress:   0%|          | 0/2000 [00:00<?, ?it/s]/ext3/conda/envs/3dgs/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/ext3/conda/envs/3dgs/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)

Training progress:   0%|          | 0/2000 [00:05<?, ?it/s, Loss=0.0124631, Gaussian number=182686, print grad=7.693459338042885e-06, Depth Loss=0.0000000]
Training progress:   0%|          | 10/2000 [00:05<17:19,  1.91it/s, Loss=0.0124631, Gaussian number=182686, print grad=7.693459338042885e-06, Depth Loss=0.0000000]
Training progress:   0%|          | 10/2000 [00:08<17:19,  1.91it/s, Loss=0.0116406, Gaussian number=182686, print grad=1.832607995311264e-05, Depth Loss=0.0000000]
Training progress:   1%|          | 20/2000 [00:08<14:17,  2.31it/s, Loss=0.0116406, Gaussian number=182686, print grad=1.832607995311264e-05, Depth Loss=0.0000000]
Training progress:   1%|          | 20/2000 [00:12<14:17,  2.31it/s, Loss=0.0114280, Gaussian number=182686, print grad=2.8486261726357043e-05, Depth Loss=0.0000000]
Training progress:   2%|▏         | 30/2000 [00:12<13:15,  2.48it/s, Loss=0.0114280, Gaussian number=182686, print grad=2.8486261726357043e-05, Depth Loss=0.0000000]
Training progress:   2%|▏         | 30/2000 [00:16<13:15,  2.48it/s, Loss=0.0116699, Gaussian number=182686, print grad=3.813755392911844e-05, Depth Loss=0.0000000] 
Training progress:   2%|▏         | 40/2000 [00:16<12:46,  2.56it/s, Loss=0.0116699, Gaussian number=182686, print grad=3.813755392911844e-05, Depth Loss=0.0000000]
Training progress:   2%|▏         | 40/2000 [00:20<12:46,  2.56it/s, Loss=0.0088602, Gaussian number=182686, print grad=4.5809221774106845e-05, Depth Loss=0.0000000]
Training progress:   2%|▎         | 50/2000 [00:20<12:26,  2.61it/s, Loss=0.0088602, Gaussian number=182686, print grad=4.5809221774106845e-05, Depth Loss=0.0000000]
Training progress:   2%|▎         | 50/2000 [00:23<12:26,  2.61it/s, Loss=0.0094405, Gaussian number=182686, print grad=5.733109719585627e-05, Depth Loss=0.0000000] 
Training progress:   3%|▎         | 60/2000 [00:23<12:12,  2.65it/s, Loss=0.0094405, Gaussian number=182686, print grad=5.733109719585627e-05, Depth Loss=0.0000000]
Training progress:   3%|▎         | 60/2000 [00:27<12:12,  2.65it/s, Loss=0.0081488, Gaussian number=182686, print grad=6.941330502741039e-05, Depth Loss=0.0000000]
Training progress:   4%|▎         | 70/2000 [00:27<12:02,  2.67it/s, Loss=0.0081488, Gaussian number=182686, print grad=6.941330502741039e-05, Depth Loss=0.0000000]
Training progress:   4%|▎         | 70/2000 [00:31<12:02,  2.67it/s, Loss=0.0102005, Gaussian number=182686, print grad=7.946803816594183e-05, Depth Loss=0.0000000]
Training progress:   4%|▍         | 80/2000 [00:31<11:56,  2.68it/s, Loss=0.0102005, Gaussian number=182686, print grad=7.946803816594183e-05, Depth Loss=0.0000000]
Training progress:   4%|▍         | 80/2000 [00:34<11:56,  2.68it/s, Loss=0.0087056, Gaussian number=182686, print grad=9.034918184624985e-05, Depth Loss=0.0000000]
Training progress:   4%|▍         | 90/2000 [00:34<11:50,  2.69it/s, Loss=0.0087056, Gaussian number=182686, print grad=9.034918184624985e-05, Depth Loss=0.0000000]
Training progress:   4%|▍         | 90/2000 [00:38<11:50,  2.69it/s, Loss=0.0078585, Gaussian number=182686, print grad=0.0001028428232530132, Depth Loss=0.0000000]
Training progress:   5%|▌         | 100/2000 [00:38<11:44,  2.70it/s, Loss=0.0078585, Gaussian number=182686, print grad=0.0001028428232530132, Depth Loss=0.0000000]
Training progress:   5%|▌         | 100/2000 [01:44<11:44,  2.70it/s, Loss=0.0096641, Gaussian number=182686, print grad=0.00011548262409633026, Depth Loss=0.0000000]
Training progress:   6%|▌         | 110/2000 [01:44<1:11:53,  2.28s/it, Loss=0.0096641, Gaussian number=182686, print grad=0.00011548262409633026, Depth Loss=0.0000000]
Training progress:   6%|▌         | 110/2000 [01:48<1:11:53,  2.28s/it, Loss=0.0074617, Gaussian number=182686, print grad=0.0001276107650483027, Depth Loss=0.0000000] 
Training progress:   6%|▌         | 120/2000 [01:48<53:14,  1.70s/it, Loss=0.0074617, Gaussian number=182686, print grad=0.0001276107650483027, Depth Loss=0.0000000]  
Training progress:   6%|▌         | 120/2000 [01:51<53:14,  1.70s/it, Loss=0.0083243, Gaussian number=182686, print grad=0.00014125659072306007, Depth Loss=0.0000000]
Training progress:   6%|▋         | 130/2000 [01:51<40:22,  1.30s/it, Loss=0.0083243, Gaussian number=182686, print grad=0.00014125659072306007, Depth Loss=0.0000000]
Training progress:   6%|▋         | 130/2000 [01:55<40:22,  1.30s/it, Loss=0.0074727, Gaussian number=182686, print grad=0.00015542736218776554, Depth Loss=0.0000000]
Training progress:   7%|▋         | 140/2000 [01:55<31:27,  1.01s/it, Loss=0.0074727, Gaussian number=182686, print grad=0.00015542736218776554, Depth Loss=0.0000000]
Training progress:   7%|▋         | 140/2000 [01:59<31:27,  1.01s/it, Loss=0.0063577, Gaussian number=182686, print grad=0.00016776277334429324, Depth Loss=0.0000000]
Training progress:   8%|▊         | 150/2000 [01:59<25:16,  1.22it/s, Loss=0.0063577, Gaussian number=182686, print grad=0.00016776277334429324, Depth Loss=0.0000000]
Training progress:   8%|▊         | 150/2000 [02:02<25:16,  1.22it/s, Loss=0.0070918, Gaussian number=182686, print grad=0.00018349643505644053, Depth Loss=0.0000000]
Training progress:   8%|▊         | 160/2000 [02:02<20:55,  1.47it/s, Loss=0.0070918, Gaussian number=182686, print grad=0.00018349643505644053, Depth Loss=0.0000000]
Training progress:   8%|▊         | 160/2000 [02:06<20:55,  1.47it/s, Loss=0.0070175, Gaussian number=182686, print grad=0.00019626301946118474, Depth Loss=0.0000000]
Training progress:   8%|▊         | 170/2000 [02:06<17:54,  1.70it/s, Loss=0.0070175, Gaussian number=182686, print grad=0.00019626301946118474, Depth Loss=0.0000000]
Training progress:   8%|▊         | 170/2000 [02:10<17:54,  1.70it/s, Loss=0.0056886, Gaussian number=182686, print grad=0.00021016353275626898, Depth Loss=0.0000000]
Training progress:   9%|▉         | 180/2000 [02:10<15:45,  1.92it/s, Loss=0.0056886, Gaussian number=182686, print grad=0.00021016353275626898, Depth Loss=0.0000000]
Training progress:   9%|▉         | 180/2000 [02:13<15:45,  1.92it/s, Loss=0.0071709, Gaussian number=182686, print grad=0.00022345443721860647, Depth Loss=0.0000000]
Training progress:  10%|▉         | 190/2000 [02:13<14:15,  2.11it/s, Loss=0.0071709, Gaussian number=182686, print grad=0.00022345443721860647, Depth Loss=0.0000000]
Training progress:  10%|▉         | 190/2000 [02:17<14:15,  2.11it/s, Loss=0.0063611, Gaussian number=182686, print grad=0.0002370332949794829, Depth Loss=0.0000000] 
Training progress:  10%|█         | 200/2000 [02:17<13:11,  2.27it/s, Loss=0.0063611, Gaussian number=182686, print grad=0.0002370332949794829, Depth Loss=0.0000000]
Training progress:  10%|█         | 200/2000 [03:23<13:11,  2.27it/s, Loss=0.0068091, Gaussian number=182686, print grad=0.00025144548271782696, Depth Loss=0.0000000]
Training progress:  10%|█         | 210/2000 [03:23<1:08:26,  2.29s/it, Loss=0.0068091, Gaussian number=182686, print grad=0.00025144548271782696, Depth Loss=0.0000000]
Training progress:  10%|█         | 210/2000 [03:27<1:08:26,  2.29s/it, Loss=0.0056049, Gaussian number=182686, print grad=0.0002654455602169037, Depth Loss=0.0000000] 
Training progress:  11%|█         | 220/2000 [03:27<50:52,  1.72s/it, Loss=0.0056049, Gaussian number=182686, print grad=0.0002654455602169037, Depth Loss=0.0000000]  
Training progress:  11%|█         | 220/2000 [03:30<50:52,  1.72s/it, Loss=0.0063050, Gaussian number=182686, print grad=0.000279574072919786, Depth Loss=0.0000000] 
Training progress:  12%|█▏        | 230/2000 [03:30<38:38,  1.31s/it, Loss=0.0063050, Gaussian number=182686, print grad=0.000279574072919786, Depth Loss=0.0000000]
Training progress:  12%|█▏        | 230/2000 [03:34<38:38,  1.31s/it, Loss=0.0078489, Gaussian number=182686, print grad=0.0002930481277871877, Depth Loss=0.0000000]
Training progress:  12%|█▏        | 240/2000 [03:34<30:05,  1.03s/it, Loss=0.0078489, Gaussian number=182686, print grad=0.0002930481277871877, Depth Loss=0.0000000]
Training progress:  12%|█▏        | 240/2000 [03:38<30:05,  1.03s/it, Loss=0.0059979, Gaussian number=182686, print grad=0.0003085099160671234, Depth Loss=0.0000000]
Training progress:  12%|█▎        | 250/2000 [03:38<24:07,  1.21it/s, Loss=0.0059979, Gaussian number=182686, print grad=0.0003085099160671234, Depth Loss=0.0000000]
Training progress:  12%|█▎        | 250/2000 [03:41<24:07,  1.21it/s, Loss=0.0064712, Gaussian number=182686, print grad=0.00032240006839856505, Depth Loss=0.0000000]
Training progress:  13%|█▎        | 260/2000 [03:41<19:56,  1.45it/s, Loss=0.0064712, Gaussian number=182686, print grad=0.00032240006839856505, Depth Loss=0.0000000]
Training progress:  13%|█▎        | 260/2000 [03:45<19:56,  1.45it/s, Loss=0.0045019, Gaussian number=182686, print grad=0.0003371342027094215, Depth Loss=0.0000000] 
Training progress:  14%|█▎        | 270/2000 [03:45<17:01,  1.69it/s, Loss=0.0045019, Gaussian number=182686, print grad=0.0003371342027094215, Depth Loss=0.0000000]
Training progress:  14%|█▎        | 270/2000 [03:49<17:01,  1.69it/s, Loss=0.0060155, Gaussian number=182686, print grad=0.0003522691549733281, Depth Loss=0.0000000]
Training progress:  14%|█▍        | 280/2000 [03:49<14:57,  1.92it/s, Loss=0.0060155, Gaussian number=182686, print grad=0.0003522691549733281, Depth Loss=0.0000000]
Training progress:  14%|█▍        | 280/2000 [03:52<14:57,  1.92it/s, Loss=0.0057212, Gaussian number=182686, print grad=0.0003679028886836022, Depth Loss=0.0000000]
Training progress:  14%|█▍        | 290/2000 [03:52<13:30,  2.11it/s, Loss=0.0057212, Gaussian number=182686, print grad=0.0003679028886836022, Depth Loss=0.0000000]
Training progress:  14%|█▍        | 290/2000 [03:56<13:30,  2.11it/s, Loss=0.0052447, Gaussian number=182686, print grad=0.00038329887320287526, Depth Loss=0.0000000]
Training progress:  15%|█▌        | 300/2000 [03:56<12:29,  2.27it/s, Loss=0.0052447, Gaussian number=182686, print grad=0.00038329887320287526, Depth Loss=0.0000000]
Training progress:  15%|█▌        | 300/2000 [05:02<12:29,  2.27it/s, Loss=0.0046030, Gaussian number=182686, print grad=0.00039912122883833945, Depth Loss=0.0000000]
Training progress:  16%|█▌        | 310/2000 [05:02<1:04:45,  2.30s/it, Loss=0.0046030, Gaussian number=182686, print grad=0.00039912122883833945, Depth Loss=0.0000000]
Training progress:  16%|█▌        | 310/2000 [05:06<1:04:45,  2.30s/it, Loss=0.0046324, Gaussian number=182686, print grad=0.00041186585440300405, Depth Loss=0.0000000]
Training progress:  16%|█▌        | 320/2000 [05:06<48:05,  1.72s/it, Loss=0.0046324, Gaussian number=182686, print grad=0.00041186585440300405, Depth Loss=0.0000000]  
Training progress:  16%|█▌        | 320/2000 [05:09<48:05,  1.72s/it, Loss=0.0060383, Gaussian number=182686, print grad=0.00042553991079330444, Depth Loss=0.0000000]
Training progress:  16%|█▋        | 330/2000 [05:09<36:29,  1.31s/it, Loss=0.0060383, Gaussian number=182686, print grad=0.00042553991079330444, Depth Loss=0.0000000]
Training progress:  16%|█▋        | 330/2000 [05:13<36:29,  1.31s/it, Loss=0.0046563, Gaussian number=182686, print grad=0.000440731062553823, Depth Loss=0.0000000]  
Training progress:  17%|█▋        | 340/2000 [05:13<28:24,  1.03s/it, Loss=0.0046563, Gaussian number=182686, print grad=0.000440731062553823, Depth Loss=0.0000000]
Training progress:  17%|█▋        | 340/2000 [05:17<28:24,  1.03s/it, Loss=0.0045762, Gaussian number=182686, print grad=0.0004558130167424679, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 350/2000 [05:17<22:45,  1.21it/s, Loss=0.0045762, Gaussian number=182686, print grad=0.0004558130167424679, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 350/2000 [05:20<22:45,  1.21it/s, Loss=0.0045459, Gaussian number=182686, print grad=0.0004720932338386774, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 360/2000 [05:20<18:48,  1.45it/s, Loss=0.0045459, Gaussian number=182686, print grad=0.0004720932338386774, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 360/2000 [05:24<18:48,  1.45it/s, Loss=0.0043338, Gaussian number=182686, print grad=0.0004865335940849036, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 370/2000 [05:24<16:02,  1.69it/s, Loss=0.0043338, Gaussian number=182686, print grad=0.0004865335940849036, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 370/2000 [05:28<16:02,  1.69it/s, Loss=0.0059902, Gaussian number=182686, print grad=0.00049919867888093, Depth Loss=0.0000000]  
Training progress:  19%|█▉        | 380/2000 [05:28<14:04,  1.92it/s, Loss=0.0059902, Gaussian number=182686, print grad=0.00049919867888093, Depth Loss=0.0000000]
Training progress:  19%|█▉        | 380/2000 [05:31<14:04,  1.92it/s, Loss=0.0050470, Gaussian number=182686, print grad=0.0005142153822816908, Depth Loss=0.0000000]
Training progress:  20%|█▉        | 390/2000 [05:31<12:42,  2.11it/s, Loss=0.0050470, Gaussian number=182686, print grad=0.0005142153822816908, Depth Loss=0.0000000]
Training progress:  20%|█▉        | 390/2000 [05:35<12:42,  2.11it/s, Loss=0.0064056, Gaussian number=182686, print grad=0.0005283777136355639, Depth Loss=0.0000000]
Training progress:  20%|██        | 400/2000 [05:35<11:43,  2.28it/s, Loss=0.0064056, Gaussian number=182686, print grad=0.0005283777136355639, Depth Loss=0.0000000]
Training progress:  20%|██        | 400/2000 [05:38<11:43,  2.28it/s, Loss=0.0052569, Gaussian number=182686, print grad=0.0005454083438962698, Depth Loss=0.0000000]
Training progress:  20%|██        | 410/2000 [05:38<11:01,  2.40it/s, Loss=0.0052569, Gaussian number=182686, print grad=0.0005454083438962698, Depth Loss=0.0000000]
Training progress:  20%|██        | 410/2000 [05:42<11:01,  2.40it/s, Loss=0.0045544, Gaussian number=182686, print grad=0.0005625403136946261, Depth Loss=0.0000000]
Training progress:  21%|██        | 420/2000 [05:42<10:31,  2.50it/s, Loss=0.0045544, Gaussian number=182686, print grad=0.0005625403136946261, Depth Loss=0.0000000]
Training progress:  21%|██        | 420/2000 [05:46<10:31,  2.50it/s, Loss=0.0057257, Gaussian number=182686, print grad=0.0005792287993244827, Depth Loss=0.0000000]
Training progress:  22%|██▏       | 430/2000 [05:46<10:10,  2.57it/s, Loss=0.0057257, Gaussian number=182686, print grad=0.0005792287993244827, Depth Loss=0.0000000]
Training progress:  22%|██▏       | 430/2000 [05:49<10:10,  2.57it/s, Loss=0.0045569, Gaussian number=182686, print grad=0.0005936853704042733, Depth Loss=0.0000000]
Training progress:  22%|██▏       | 440/2000 [05:49<09:54,  2.62it/s, Loss=0.0045569, Gaussian number=182686, print grad=0.0005936853704042733, Depth Loss=0.0000000]
Training progress:  22%|██▏       | 440/2000 [05:53<09:54,  2.62it/s, Loss=0.0051384, Gaussian number=182686, print grad=0.000609524198807776, Depth Loss=0.0000000] 
Training progress:  22%|██▎       | 450/2000 [05:53<09:41,  2.67it/s, Loss=0.0051384, Gaussian number=182686, print grad=0.000609524198807776, Depth Loss=0.0000000]
Training progress:  22%|██▎       | 450/2000 [05:56<09:41,  2.67it/s, Loss=0.0053048, Gaussian number=182686, print grad=0.0006249130237847567, Depth Loss=0.0000000]
Training progress:  23%|██▎       | 460/2000 [05:56<09:31,  2.69it/s, Loss=0.0053048, Gaussian number=182686, print grad=0.0006249130237847567, Depth Loss=0.0000000]
Training progress:  23%|██▎       | 460/2000 [06:00<09:31,  2.69it/s, Loss=0.0060879, Gaussian number=182686, print grad=0.0006399491103366017, Depth Loss=0.0000000]
Training progress:  24%|██▎       | 470/2000 [06:00<09:23,  2.72it/s, Loss=0.0060879, Gaussian number=182686, print grad=0.0006399491103366017, Depth Loss=0.0000000]
Training progress:  24%|██▎       | 470/2000 [06:04<09:23,  2.72it/s, Loss=0.0041478, Gaussian number=182686, print grad=0.0006563360220752656, Depth Loss=0.0000000]
Training progress:  24%|██▍       | 480/2000 [06:04<09:16,  2.73it/s, Loss=0.0041478, Gaussian number=182686, print grad=0.0006563360220752656, Depth Loss=0.0000000]
Training progress:  24%|██▍       | 480/2000 [06:07<09:16,  2.73it/s, Loss=0.0043728, Gaussian number=182686, print grad=0.0006715791532769799, Depth Loss=0.0000000]
Training progress:  24%|██▍       | 490/2000 [06:07<09:10,  2.74it/s, Loss=0.0043728, Gaussian number=182686, print grad=0.0006715791532769799, Depth Loss=0.0000000]
Training progress:  24%|██▍       | 490/2000 [06:11<09:10,  2.74it/s, Loss=0.0033446, Gaussian number=182686, print grad=0.000686784100253135, Depth Loss=0.0000000] 
Training progress:  25%|██▌       | 500/2000 [06:11<09:05,  2.75it/s, Loss=0.0033446, Gaussian number=182686, print grad=0.000686784100253135, Depth Loss=0.0000000]
Training progress:  25%|██▌       | 500/2000 [07:17<09:05,  2.75it/s, Loss=0.0039976, Gaussian number=182686, print grad=0.0007027725805528462, Depth Loss=0.0000000]
Training progress:  26%|██▌       | 510/2000 [07:17<55:36,  2.24s/it, Loss=0.0039976, Gaussian number=182686, print grad=0.0007027725805528462, Depth Loss=0.0000000]
Training progress:  26%|██▌       | 510/2000 [07:21<55:36,  2.24s/it, Loss=0.0045159, Gaussian number=182686, print grad=0.0007179596577771008, Depth Loss=0.0000000]
Training progress:  26%|██▌       | 520/2000 [07:21<41:20,  1.68s/it, Loss=0.0045159, Gaussian number=182686, print grad=0.0007179596577771008, Depth Loss=0.0000000]
Training progress:  26%|██▌       | 520/2000 [07:24<41:20,  1.68s/it, Loss=0.0031620, Gaussian number=182686, print grad=0.0007307606283575296, Depth Loss=0.0000000]
Training progress:  26%|██▋       | 530/2000 [07:24<31:22,  1.28s/it, Loss=0.0031620, Gaussian number=182686, print grad=0.0007307606283575296, Depth Loss=0.0000000]
Training progress:  26%|██▋       | 530/2000 [07:28<31:22,  1.28s/it, Loss=0.0044153, Gaussian number=182686, print grad=0.0007454224396497011, Depth Loss=0.0000000]
Training progress:  27%|██▋       | 540/2000 [07:28<24:26,  1.00s/it, Loss=0.0044153, Gaussian number=182686, print grad=0.0007454224396497011, Depth Loss=0.0000000]
Training progress:  27%|██▋       | 540/2000 [07:31<24:26,  1.00s/it, Loss=0.0039785, Gaussian number=182686, print grad=0.0007615733193233609, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 550/2000 [07:31<19:35,  1.23it/s, Loss=0.0039785, Gaussian number=182686, print grad=0.0007615733193233609, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 550/2000 [07:35<19:35,  1.23it/s, Loss=0.0032643, Gaussian number=182686, print grad=0.0007764282636344433, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 560/2000 [07:35<16:12,  1.48it/s, Loss=0.0032643, Gaussian number=182686, print grad=0.0007764282636344433, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 560/2000 [07:39<16:12,  1.48it/s, Loss=0.0042393, Gaussian number=182686, print grad=0.000792126462329179, Depth Loss=0.0000000] 
Training progress:  28%|██▊       | 570/2000 [07:39<13:50,  1.72it/s, Loss=0.0042393, Gaussian number=182686, print grad=0.000792126462329179, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 570/2000 [07:42<13:50,  1.72it/s, Loss=0.0038046, Gaussian number=182686, print grad=0.0008081303094513714, Depth Loss=0.0000000]
Training progress:  29%|██▉       | 580/2000 [07:42<12:10,  1.94it/s, Loss=0.0038046, Gaussian number=182686, print grad=0.0008081303094513714, Depth Loss=0.0000000]
Training progress:  29%|██▉       | 580/2000 [07:46<12:10,  1.94it/s, Loss=0.0040525, Gaussian number=182686, print grad=0.0008229538798332214, Depth Loss=0.0000000]
Training progress:  30%|██▉       | 590/2000 [07:46<11:00,  2.14it/s, Loss=0.0040525, Gaussian number=182686, print grad=0.0008229538798332214, Depth Loss=0.0000000]
Training progress:  30%|██▉       | 590/2000 [07:50<11:00,  2.14it/s, Loss=0.0047607, Gaussian number=182686, print grad=0.0008377296035178006, Depth Loss=0.0000000]
Training progress:  30%|███       | 600/2000 [07:50<10:12,  2.29it/s, Loss=0.0047607, Gaussian number=182686, print grad=0.0008377296035178006, Depth Loss=0.0000000]
Training progress:  30%|███       | 600/2000 [07:53<10:12,  2.29it/s, Loss=0.0037153, Gaussian number=182679, print grad=1.3714746273763012e-05, Depth Loss=0.0000000]
Training progress:  30%|███       | 610/2000 [07:53<09:35,  2.41it/s, Loss=0.0037153, Gaussian number=182679, print grad=1.3714746273763012e-05, Depth Loss=0.0000000]
Training progress:  30%|███       | 610/2000 [07:57<09:35,  2.41it/s, Loss=0.0044832, Gaussian number=182679, print grad=2.887142363761086e-05, Depth Loss=0.0000000] 
Training progress:  31%|███       | 620/2000 [07:57<09:09,  2.51it/s, Loss=0.0044832, Gaussian number=182679, print grad=2.887142363761086e-05, Depth Loss=0.0000000]
Training progress:  31%|███       | 620/2000 [08:00<09:09,  2.51it/s, Loss=0.0032919, Gaussian number=182679, print grad=4.285039904061705e-05, Depth Loss=0.0000000]
Training progress:  32%|███▏      | 630/2000 [08:00<08:50,  2.58it/s, Loss=0.0032919, Gaussian number=182679, print grad=4.285039904061705e-05, Depth Loss=0.0000000]
Training progress:  32%|███▏      | 630/2000 [08:04<08:50,  2.58it/s, Loss=0.0038087, Gaussian number=182679, print grad=5.933410284342244e-05, Depth Loss=0.0000000]
Training progress:  32%|███▏      | 640/2000 [08:04<08:35,  2.64it/s, Loss=0.0038087, Gaussian number=182679, print grad=5.933410284342244e-05, Depth Loss=0.0000000]
Training progress:  32%|███▏      | 640/2000 [08:08<08:35,  2.64it/s, Loss=0.0039894, Gaussian number=182679, print grad=7.37101145205088e-05, Depth Loss=0.0000000] 
Training progress:  32%|███▎      | 650/2000 [08:08<08:23,  2.68it/s, Loss=0.0039894, Gaussian number=182679, print grad=7.37101145205088e-05, Depth Loss=0.0000000]
Training progress:  32%|███▎      | 650/2000 [08:11<08:23,  2.68it/s, Loss=0.0038673, Gaussian number=182679, print grad=8.944844012148678e-05, Depth Loss=0.0000000]
Training progress:  33%|███▎      | 660/2000 [08:11<08:15,  2.71it/s, Loss=0.0038673, Gaussian number=182679, print grad=8.944844012148678e-05, Depth Loss=0.0000000]
Training progress:  33%|███▎      | 660/2000 [08:15<08:15,  2.71it/s, Loss=0.0038500, Gaussian number=182679, print grad=0.00010327042400604114, Depth Loss=0.0000000]
Training progress:  34%|███▎      | 670/2000 [08:15<08:07,  2.73it/s, Loss=0.0038500, Gaussian number=182679, print grad=0.00010327042400604114, Depth Loss=0.0000000]
Training progress:  34%|███▎      | 670/2000 [08:18<08:07,  2.73it/s, Loss=0.0033439, Gaussian number=182679, print grad=0.00011903808626811951, Depth Loss=0.0000000]
Training progress:  34%|███▍      | 680/2000 [08:18<08:01,  2.74it/s, Loss=0.0033439, Gaussian number=182679, print grad=0.00011903808626811951, Depth Loss=0.0000000]
Training progress:  34%|███▍      | 680/2000 [08:22<08:01,  2.74it/s, Loss=0.0046408, Gaussian number=182679, print grad=0.00013416490401141346, Depth Loss=0.0000000]
Training progress:  34%|███▍      | 690/2000 [08:22<07:56,  2.75it/s, Loss=0.0046408, Gaussian number=182679, print grad=0.00013416490401141346, Depth Loss=0.0000000]
Training progress:  34%|███▍      | 690/2000 [08:26<07:56,  2.75it/s, Loss=0.0043933, Gaussian number=182679, print grad=0.000148427949170582, Depth Loss=0.0000000]  
Training progress:  35%|███▌      | 700/2000 [08:26<07:51,  2.76it/s, Loss=0.0043933, Gaussian number=182679, print grad=0.000148427949170582, Depth Loss=0.0000000]
Training progress:  35%|███▌      | 700/2000 [08:29<07:51,  2.76it/s, Loss=0.0033840, Gaussian number=182675, print grad=1.2396620149957016e-05, Depth Loss=0.0000000]
Training progress:  36%|███▌      | 710/2000 [08:29<07:46,  2.77it/s, Loss=0.0033840, Gaussian number=182675, print grad=1.2396620149957016e-05, Depth Loss=0.0000000]
Training progress:  36%|███▌      | 710/2000 [08:33<07:46,  2.77it/s, Loss=0.0035332, Gaussian number=182675, print grad=2.801980917865876e-05, Depth Loss=0.0000000] 
Training progress:  36%|███▌      | 720/2000 [08:33<07:43,  2.76it/s, Loss=0.0035332, Gaussian number=182675, print grad=2.801980917865876e-05, Depth Loss=0.0000000]
Training progress:  36%|███▌      | 720/2000 [08:36<07:43,  2.76it/s, Loss=0.0041934, Gaussian number=182675, print grad=4.207112215226516e-05, Depth Loss=0.0000000]
Training progress:  36%|███▋      | 730/2000 [08:36<07:38,  2.77it/s, Loss=0.0041934, Gaussian number=182675, print grad=4.207112215226516e-05, Depth Loss=0.0000000]
Training progress:  36%|███▋      | 730/2000 [08:40<07:38,  2.77it/s, Loss=0.0047225, Gaussian number=182675, print grad=5.744993541156873e-05, Depth Loss=0.0000000]
Training progress:  37%|███▋      | 740/2000 [08:40<07:34,  2.77it/s, Loss=0.0047225, Gaussian number=182675, print grad=5.744993541156873e-05, Depth Loss=0.0000000]
Training progress:  37%|███▋      | 740/2000 [08:44<07:34,  2.77it/s, Loss=0.0035221, Gaussian number=182675, print grad=7.244856533361599e-05, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 750/2000 [08:44<07:31,  2.77it/s, Loss=0.0035221, Gaussian number=182675, print grad=7.244856533361599e-05, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 750/2000 [08:47<07:31,  2.77it/s, Loss=0.0035987, Gaussian number=182675, print grad=8.740001794649288e-05, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 760/2000 [08:47<07:27,  2.77it/s, Loss=0.0035987, Gaussian number=182675, print grad=8.740001794649288e-05, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 760/2000 [08:51<07:27,  2.77it/s, Loss=0.0029031, Gaussian number=182675, print grad=0.00010234796354779974, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 770/2000 [08:51<07:23,  2.77it/s, Loss=0.0029031, Gaussian number=182675, print grad=0.00010234796354779974, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 770/2000 [08:54<07:23,  2.77it/s, Loss=0.0038518, Gaussian number=182675, print grad=0.0001166379006463103, Depth Loss=0.0000000] 
Training progress:  39%|███▉      | 780/2000 [08:54<07:19,  2.78it/s, Loss=0.0038518, Gaussian number=182675, print grad=0.0001166379006463103, Depth Loss=0.0000000]
Training progress:  39%|███▉      | 780/2000 [08:58<07:19,  2.78it/s, Loss=0.0050289, Gaussian number=182675, print grad=0.00013157616194803268, Depth Loss=0.0000000]
Training progress:  40%|███▉      | 790/2000 [08:58<07:16,  2.77it/s, Loss=0.0050289, Gaussian number=182675, print grad=0.00013157616194803268, Depth Loss=0.0000000]
Training progress:  40%|███▉      | 790/2000 [09:02<07:16,  2.77it/s, Loss=0.0035667, Gaussian number=182675, print grad=0.00014675059355795383, Depth Loss=0.0000000]
Training progress:  40%|████      | 800/2000 [09:02<07:12,  2.77it/s, Loss=0.0035667, Gaussian number=182675, print grad=0.00014675059355795383, Depth Loss=0.0000000]
Training progress:  40%|████      | 800/2000 [09:05<07:12,  2.77it/s, Loss=0.0035044, Gaussian number=182663, print grad=1.3354565453482792e-05, Depth Loss=0.0000000]
Training progress:  40%|████      | 810/2000 [09:05<07:08,  2.77it/s, Loss=0.0035044, Gaussian number=182663, print grad=1.3354565453482792e-05, Depth Loss=0.0000000]
Training progress:  40%|████      | 810/2000 [09:09<07:08,  2.77it/s, Loss=0.0036481, Gaussian number=182663, print grad=2.7256864996161312e-05, Depth Loss=0.0000000]
Training progress:  41%|████      | 820/2000 [09:09<07:05,  2.78it/s, Loss=0.0036481, Gaussian number=182663, print grad=2.7256864996161312e-05, Depth Loss=0.0000000]
Training progress:  41%|████      | 820/2000 [09:12<07:05,  2.78it/s, Loss=0.0027043, Gaussian number=182663, print grad=4.192454071016982e-05, Depth Loss=0.0000000] 
Training progress:  42%|████▏     | 830/2000 [09:12<07:01,  2.77it/s, Loss=0.0027043, Gaussian number=182663, print grad=4.192454071016982e-05, Depth Loss=0.0000000]
Training progress:  42%|████▏     | 830/2000 [09:16<07:01,  2.77it/s, Loss=0.0031919, Gaussian number=182663, print grad=5.6287819461431354e-05, Depth Loss=0.0000000]
Training progress:  42%|████▏     | 840/2000 [09:16<06:57,  2.78it/s, Loss=0.0031919, Gaussian number=182663, print grad=5.6287819461431354e-05, Depth Loss=0.0000000]
Training progress:  42%|████▏     | 840/2000 [09:20<06:57,  2.78it/s, Loss=0.0034974, Gaussian number=182663, print grad=7.106855628080666e-05, Depth Loss=0.0000000] 
Training progress:  42%|████▎     | 850/2000 [09:20<06:53,  2.78it/s, Loss=0.0034974, Gaussian number=182663, print grad=7.106855628080666e-05, Depth Loss=0.0000000]
Training progress:  42%|████▎     | 850/2000 [09:23<06:53,  2.78it/s, Loss=0.0029839, Gaussian number=182663, print grad=8.499308751197532e-05, Depth Loss=0.0000000]
Training progress:  43%|████▎     | 860/2000 [09:23<06:50,  2.78it/s, Loss=0.0029839, Gaussian number=182663, print grad=8.499308751197532e-05, Depth Loss=0.0000000]
Training progress:  43%|████▎     | 860/2000 [09:27<06:50,  2.78it/s, Loss=0.0037685, Gaussian number=182663, print grad=9.841332939686254e-05, Depth Loss=0.0000000]
Training progress:  44%|████▎     | 870/2000 [09:27<06:46,  2.78it/s, Loss=0.0037685, Gaussian number=182663, print grad=9.841332939686254e-05, Depth Loss=0.0000000]
Training progress:  44%|████▎     | 870/2000 [09:30<06:46,  2.78it/s, Loss=0.0038424, Gaussian number=182663, print grad=0.00011339398042764515, Depth Loss=0.0000000]
Training progress:  44%|████▍     | 880/2000 [09:30<06:42,  2.78it/s, Loss=0.0038424, Gaussian number=182663, print grad=0.00011339398042764515, Depth Loss=0.0000000]
Training progress:  44%|████▍     | 880/2000 [09:34<06:42,  2.78it/s, Loss=0.0030591, Gaussian number=182663, print grad=0.00012823182623833418, Depth Loss=0.0000000]
Training progress:  44%|████▍     | 890/2000 [09:34<06:38,  2.78it/s, Loss=0.0030591, Gaussian number=182663, print grad=0.00012823182623833418, Depth Loss=0.0000000]
Training progress:  44%|████▍     | 890/2000 [09:38<06:38,  2.78it/s, Loss=0.0035977, Gaussian number=182663, print grad=0.00014286331133916974, Depth Loss=0.0000000]
Training progress:  45%|████▌     | 900/2000 [09:38<06:35,  2.78it/s, Loss=0.0035977, Gaussian number=182663, print grad=0.00014286331133916974, Depth Loss=0.0000000]
Training progress:  45%|████▌     | 900/2000 [09:41<06:35,  2.78it/s, Loss=0.0026249, Gaussian number=182641, print grad=1.2444564163160976e-05, Depth Loss=0.0000000]
Training progress:  46%|████▌     | 910/2000 [09:41<06:31,  2.78it/s, Loss=0.0026249, Gaussian number=182641, print grad=1.2444564163160976e-05, Depth Loss=0.0000000]
Training progress:  46%|████▌     | 910/2000 [09:45<06:31,  2.78it/s, Loss=0.0038637, Gaussian number=182641, print grad=2.4995739295263775e-05, Depth Loss=0.0000000]
Training progress:  46%|████▌     | 920/2000 [09:45<06:28,  2.78it/s, Loss=0.0038637, Gaussian number=182641, print grad=2.4995739295263775e-05, Depth Loss=0.0000000]
Training progress:  46%|████▌     | 920/2000 [09:48<06:28,  2.78it/s, Loss=0.0034915, Gaussian number=182641, print grad=3.972912236349657e-05, Depth Loss=0.0000000] 
Training progress:  46%|████▋     | 930/2000 [09:48<06:24,  2.78it/s, Loss=0.0034915, Gaussian number=182641, print grad=3.972912236349657e-05, Depth Loss=0.0000000]
Training progress:  46%|████▋     | 930/2000 [09:52<06:24,  2.78it/s, Loss=0.0032674, Gaussian number=182641, print grad=5.484083158080466e-05, Depth Loss=0.0000000]
Training progress:  47%|████▋     | 940/2000 [09:52<06:20,  2.78it/s, Loss=0.0032674, Gaussian number=182641, print grad=5.484083158080466e-05, Depth Loss=0.0000000]
Training progress:  47%|████▋     | 940/2000 [09:56<06:20,  2.78it/s, Loss=0.0030944, Gaussian number=182641, print grad=6.804371514590457e-05, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 950/2000 [09:56<06:17,  2.78it/s, Loss=0.0030944, Gaussian number=182641, print grad=6.804371514590457e-05, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 950/2000 [09:59<06:17,  2.78it/s, Loss=0.0029575, Gaussian number=182641, print grad=8.183350291801617e-05, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 960/2000 [09:59<06:14,  2.78it/s, Loss=0.0029575, Gaussian number=182641, print grad=8.183350291801617e-05, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 960/2000 [10:03<06:14,  2.78it/s, Loss=0.0038792, Gaussian number=182641, print grad=9.709411096991971e-05, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 970/2000 [10:03<06:11,  2.77it/s, Loss=0.0038792, Gaussian number=182641, print grad=9.709411096991971e-05, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 970/2000 [10:06<06:11,  2.77it/s, Loss=0.0025400, Gaussian number=182641, print grad=0.00011027986329281703, Depth Loss=0.0000000]
Training progress:  49%|████▉     | 980/2000 [10:06<06:07,  2.78it/s, Loss=0.0025400, Gaussian number=182641, print grad=0.00011027986329281703, Depth Loss=0.0000000]
Training progress:  49%|████▉     | 980/2000 [10:10<06:07,  2.78it/s, Loss=0.0027173, Gaussian number=182641, print grad=0.0001223739964189008, Depth Loss=0.0000000] 
Training progress:  50%|████▉     | 990/2000 [10:10<06:04,  2.77it/s, Loss=0.0027173, Gaussian number=182641, print grad=0.0001223739964189008, Depth Loss=0.0000000]
Training progress:  50%|████▉     | 990/2000 [10:14<06:04,  2.77it/s, Loss=0.0033071, Gaussian number=182641, print grad=0.00013416736328508705, Depth Loss=0.0000000]
Training progress:  50%|█████     | 1000/2000 [10:14<06:00,  2.77it/s, Loss=0.0033071, Gaussian number=182641, print grad=0.00013416736328508705, Depth Loss=0.0000000]
Training progress:  50%|█████     | 1000/2000 [11:20<06:00,  2.77it/s, Loss=0.0032048, Gaussian number=182617, print grad=1.237864216818707e-05, Depth Loss=0.0000000] 
Training progress:  50%|█████     | 1010/2000 [11:20<36:54,  2.24s/it, Loss=0.0032048, Gaussian number=182617, print grad=1.237864216818707e-05, Depth Loss=0.0000000]
Training progress:  50%|█████     | 1010/2000 [11:23<36:54,  2.24s/it, Loss=0.0036875, Gaussian number=182617, print grad=2.738559851422906e-05, Depth Loss=0.0000000]
Training progress:  51%|█████     | 1020/2000 [11:23<27:19,  1.67s/it, Loss=0.0036875, Gaussian number=182617, print grad=2.738559851422906e-05, Depth Loss=0.0000000]
Training progress:  51%|█████     | 1020/2000 [11:27<27:19,  1.67s/it, Loss=0.0030644, Gaussian number=182617, print grad=4.2524930904619396e-05, Depth Loss=0.0000000]
Training progress:  52%|█████▏    | 1030/2000 [11:27<20:40,  1.28s/it, Loss=0.0030644, Gaussian number=182617, print grad=4.2524930904619396e-05, Depth Loss=0.0000000]
Training progress:  52%|█████▏    | 1030/2000 [11:30<20:40,  1.28s/it, Loss=0.0032074, Gaussian number=182617, print grad=5.8184072258882225e-05, Depth Loss=0.0000000]
Training progress:  52%|█████▏    | 1040/2000 [11:30<16:03,  1.00s/it, Loss=0.0032074, Gaussian number=182617, print grad=5.8184072258882225e-05, Depth Loss=0.0000000]
Training progress:  52%|█████▏    | 1040/2000 [11:34<16:03,  1.00s/it, Loss=0.0030470, Gaussian number=182617, print grad=7.024257502052933e-05, Depth Loss=0.0000000] 
Training progress:  52%|█████▎    | 1050/2000 [11:34<12:49,  1.23it/s, Loss=0.0030470, Gaussian number=182617, print grad=7.024257502052933e-05, Depth Loss=0.0000000]
Training progress:  52%|█████▎    | 1050/2000 [11:38<12:49,  1.23it/s, Loss=0.0027134, Gaussian number=182617, print grad=8.364294626517221e-05, Depth Loss=0.0000000]
Training progress:  53%|█████▎    | 1060/2000 [11:38<10:34,  1.48it/s, Loss=0.0027134, Gaussian number=182617, print grad=8.364294626517221e-05, Depth Loss=0.0000000]
Training progress:  53%|█████▎    | 1060/2000 [11:41<10:34,  1.48it/s, Loss=0.0023302, Gaussian number=182617, print grad=9.745014540385455e-05, Depth Loss=0.0000000]
Training progress:  54%|█████▎    | 1070/2000 [11:41<08:59,  1.72it/s, Loss=0.0023302, Gaussian number=182617, print grad=9.745014540385455e-05, Depth Loss=0.0000000]
Training progress:  54%|█████▎    | 1070/2000 [11:45<08:59,  1.72it/s, Loss=0.0026672, Gaussian number=182617, print grad=0.00011061882105423138, Depth Loss=0.0000000]
Training progress:  54%|█████▍    | 1080/2000 [11:45<07:53,  1.94it/s, Loss=0.0026672, Gaussian number=182617, print grad=0.00011061882105423138, Depth Loss=0.0000000]
Training progress:  54%|█████▍    | 1080/2000 [11:48<07:53,  1.94it/s, Loss=0.0027149, Gaussian number=182617, print grad=0.00012403207074385136, Depth Loss=0.0000000]
Training progress:  55%|█████▍    | 1090/2000 [11:48<07:05,  2.14it/s, Loss=0.0027149, Gaussian number=182617, print grad=0.00012403207074385136, Depth Loss=0.0000000]
Training progress:  55%|█████▍    | 1090/2000 [11:52<07:05,  2.14it/s, Loss=0.0034686, Gaussian number=182617, print grad=0.00013783683243673295, Depth Loss=0.0000000]
Training progress:  55%|█████▌    | 1100/2000 [11:52<06:32,  2.30it/s, Loss=0.0034686, Gaussian number=182617, print grad=0.00013783683243673295, Depth Loss=0.0000000]
Training progress:  55%|█████▌    | 1100/2000 [11:56<06:32,  2.30it/s, Loss=0.0030603, Gaussian number=182578, print grad=1.2292633073229808e-05, Depth Loss=0.0000000]
Training progress:  56%|█████▌    | 1110/2000 [11:56<06:07,  2.42it/s, Loss=0.0030603, Gaussian number=182578, print grad=1.2292633073229808e-05, Depth Loss=0.0000000]
Training progress:  56%|█████▌    | 1110/2000 [11:59<06:07,  2.42it/s, Loss=0.0028762, Gaussian number=182578, print grad=2.6361298296251334e-05, Depth Loss=0.0000000]
Training progress:  56%|█████▌    | 1120/2000 [11:59<05:48,  2.52it/s, Loss=0.0028762, Gaussian number=182578, print grad=2.6361298296251334e-05, Depth Loss=0.0000000]
Training progress:  56%|█████▌    | 1120/2000 [12:03<05:48,  2.52it/s, Loss=0.0025506, Gaussian number=182578, print grad=4.058185004396364e-05, Depth Loss=0.0000000] 
Training progress:  56%|█████▋    | 1130/2000 [12:03<05:34,  2.60it/s, Loss=0.0025506, Gaussian number=182578, print grad=4.058185004396364e-05, Depth Loss=0.0000000]
Training progress:  56%|█████▋    | 1130/2000 [12:06<05:34,  2.60it/s, Loss=0.0032063, Gaussian number=182578, print grad=5.533311195904389e-05, Depth Loss=0.0000000]
Training progress:  57%|█████▋    | 1140/2000 [12:06<05:24,  2.65it/s, Loss=0.0032063, Gaussian number=182578, print grad=5.533311195904389e-05, Depth Loss=0.0000000]
Training progress:  57%|█████▋    | 1140/2000 [12:10<05:24,  2.65it/s, Loss=0.0021496, Gaussian number=182578, print grad=6.939651211723685e-05, Depth Loss=0.0000000]
Training progress:  57%|█████▊    | 1150/2000 [12:10<05:15,  2.69it/s, Loss=0.0021496, Gaussian number=182578, print grad=6.939651211723685e-05, Depth Loss=0.0000000]
Training progress:  57%|█████▊    | 1150/2000 [12:14<05:15,  2.69it/s, Loss=0.0024106, Gaussian number=182578, print grad=8.24234084575437e-05, Depth Loss=0.0000000] 
Training progress:  58%|█████▊    | 1160/2000 [12:14<05:09,  2.72it/s, Loss=0.0024106, Gaussian number=182578, print grad=8.24234084575437e-05, Depth Loss=0.0000000]
Training progress:  58%|█████▊    | 1160/2000 [12:17<05:09,  2.72it/s, Loss=0.0031217, Gaussian number=182578, print grad=9.603276703273878e-05, Depth Loss=0.0000000]
Training progress:  58%|█████▊    | 1170/2000 [12:17<05:03,  2.73it/s, Loss=0.0031217, Gaussian number=182578, print grad=9.603276703273878e-05, Depth Loss=0.0000000]
Training progress:  58%|█████▊    | 1170/2000 [12:21<05:03,  2.73it/s, Loss=0.0027939, Gaussian number=182578, print grad=0.00010900490451604128, Depth Loss=0.0000000]
Training progress:  59%|█████▉    | 1180/2000 [12:21<04:58,  2.75it/s, Loss=0.0027939, Gaussian number=182578, print grad=0.00010900490451604128, Depth Loss=0.0000000]
Training progress:  59%|█████▉    | 1180/2000 [12:24<04:58,  2.75it/s, Loss=0.0025612, Gaussian number=182578, print grad=0.00012348820746410638, Depth Loss=0.0000000]
Training progress:  60%|█████▉    | 1190/2000 [12:24<04:53,  2.76it/s, Loss=0.0025612, Gaussian number=182578, print grad=0.00012348820746410638, Depth Loss=0.0000000]
Training progress:  60%|█████▉    | 1190/2000 [12:28<04:53,  2.76it/s, Loss=0.0030607, Gaussian number=182578, print grad=0.00013546877016779035, Depth Loss=0.0000000]
Training progress:  60%|██████    | 1200/2000 [12:28<04:48,  2.77it/s, Loss=0.0030607, Gaussian number=182578, print grad=0.00013546877016779035, Depth Loss=0.0000000]
Training progress:  60%|██████    | 1200/2000 [12:32<04:48,  2.77it/s, Loss=0.0024086, Gaussian number=182547, print grad=1.2418166988936719e-05, Depth Loss=0.0000000]
Training progress:  60%|██████    | 1210/2000 [12:32<04:44,  2.77it/s, Loss=0.0024086, Gaussian number=182547, print grad=1.2418166988936719e-05, Depth Loss=0.0000000]
Training progress:  60%|██████    | 1210/2000 [12:35<04:44,  2.77it/s, Loss=0.0019739, Gaussian number=182547, print grad=2.6224468456348404e-05, Depth Loss=0.0000000]
Training progress:  61%|██████    | 1220/2000 [12:35<04:40,  2.78it/s, Loss=0.0019739, Gaussian number=182547, print grad=2.6224468456348404e-05, Depth Loss=0.0000000]
Training progress:  61%|██████    | 1220/2000 [12:39<04:40,  2.78it/s, Loss=0.0024017, Gaussian number=182547, print grad=3.917017602361739e-05, Depth Loss=0.0000000] 
Training progress:  62%|██████▏   | 1230/2000 [12:39<04:36,  2.78it/s, Loss=0.0024017, Gaussian number=182547, print grad=3.917017602361739e-05, Depth Loss=0.0000000]
Training progress:  62%|██████▏   | 1230/2000 [12:42<04:36,  2.78it/s, Loss=0.0022167, Gaussian number=182547, print grad=5.2302959375083447e-05, Depth Loss=0.0000000]
Training progress:  62%|██████▏   | 1240/2000 [12:42<04:32,  2.78it/s, Loss=0.0022167, Gaussian number=182547, print grad=5.2302959375083447e-05, Depth Loss=0.0000000]
Training progress:  62%|██████▏   | 1240/2000 [12:46<04:32,  2.78it/s, Loss=0.0022093, Gaussian number=182547, print grad=6.456675328081474e-05, Depth Loss=0.0000000] 
Training progress:  62%|██████▎   | 1250/2000 [12:46<04:29,  2.79it/s, Loss=0.0022093, Gaussian number=182547, print grad=6.456675328081474e-05, Depth Loss=0.0000000]
Training progress:  62%|██████▎   | 1250/2000 [12:50<04:29,  2.79it/s, Loss=0.0022811, Gaussian number=182547, print grad=7.709870988037437e-05, Depth Loss=0.0000000]
Training progress:  63%|██████▎   | 1260/2000 [12:50<04:25,  2.78it/s, Loss=0.0022811, Gaussian number=182547, print grad=7.709870988037437e-05, Depth Loss=0.0000000]
Training progress:  63%|██████▎   | 1260/2000 [12:53<04:25,  2.78it/s, Loss=0.0031190, Gaussian number=182547, print grad=9.092895925277844e-05, Depth Loss=0.0000000]
Training progress:  64%|██████▎   | 1270/2000 [12:53<04:22,  2.78it/s, Loss=0.0031190, Gaussian number=182547, print grad=9.092895925277844e-05, Depth Loss=0.0000000]
Training progress:  64%|██████▎   | 1270/2000 [12:57<04:22,  2.78it/s, Loss=0.0031475, Gaussian number=182547, print grad=0.0001040221395669505, Depth Loss=0.0000000]
Training progress:  64%|██████▍   | 1280/2000 [12:57<04:18,  2.78it/s, Loss=0.0031475, Gaussian number=182547, print grad=0.0001040221395669505, Depth Loss=0.0000000]
Training progress:  64%|██████▍   | 1280/2000 [13:00<04:18,  2.78it/s, Loss=0.0022255, Gaussian number=182547, print grad=0.00011846322740893811, Depth Loss=0.0000000]
Training progress:  64%|██████▍   | 1290/2000 [13:00<04:14,  2.79it/s, Loss=0.0022255, Gaussian number=182547, print grad=0.00011846322740893811, Depth Loss=0.0000000]
Training progress:  64%|██████▍   | 1290/2000 [13:04<04:14,  2.79it/s, Loss=0.0032506, Gaussian number=182547, print grad=0.00013121114170644432, Depth Loss=0.0000000]
Training progress:  65%|██████▌   | 1300/2000 [13:04<04:11,  2.78it/s, Loss=0.0032506, Gaussian number=182547, print grad=0.00013121114170644432, Depth Loss=0.0000000]
Training progress:  65%|██████▌   | 1300/2000 [13:07<04:11,  2.78it/s, Loss=0.0033275, Gaussian number=182511, print grad=1.2803201570932288e-05, Depth Loss=0.0000000]
Training progress:  66%|██████▌   | 1310/2000 [13:07<04:08,  2.78it/s, Loss=0.0033275, Gaussian number=182511, print grad=1.2803201570932288e-05, Depth Loss=0.0000000]
Training progress:  66%|██████▌   | 1310/2000 [13:11<04:08,  2.78it/s, Loss=0.0029451, Gaussian number=182511, print grad=2.5727094907779247e-05, Depth Loss=0.0000000]
Training progress:  66%|██████▌   | 1320/2000 [13:11<04:04,  2.78it/s, Loss=0.0029451, Gaussian number=182511, print grad=2.5727094907779247e-05, Depth Loss=0.0000000]
Training progress:  66%|██████▌   | 1320/2000 [13:15<04:04,  2.78it/s, Loss=0.0022516, Gaussian number=182511, print grad=3.8612215575994924e-05, Depth Loss=0.0000000]
Training progress:  66%|██████▋   | 1330/2000 [13:15<04:00,  2.78it/s, Loss=0.0022516, Gaussian number=182511, print grad=3.8612215575994924e-05, Depth Loss=0.0000000]
Training progress:  66%|██████▋   | 1330/2000 [13:18<04:00,  2.78it/s, Loss=0.0026228, Gaussian number=182511, print grad=5.16808831889648e-05, Depth Loss=0.0000000]  
Training progress:  67%|██████▋   | 1340/2000 [13:18<03:57,  2.78it/s, Loss=0.0026228, Gaussian number=182511, print grad=5.16808831889648e-05, Depth Loss=0.0000000]
Training progress:  67%|██████▋   | 1340/2000 [13:22<03:57,  2.78it/s, Loss=0.0036180, Gaussian number=182511, print grad=6.369029870256782e-05, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1350/2000 [13:22<03:53,  2.79it/s, Loss=0.0036180, Gaussian number=182511, print grad=6.369029870256782e-05, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1350/2000 [13:25<03:53,  2.79it/s, Loss=0.0022851, Gaussian number=182511, print grad=7.634986832272261e-05, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1360/2000 [13:25<03:49,  2.79it/s, Loss=0.0022851, Gaussian number=182511, print grad=7.634986832272261e-05, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1360/2000 [13:29<03:49,  2.79it/s, Loss=0.0035871, Gaussian number=182511, print grad=8.943334978539497e-05, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1370/2000 [13:29<03:46,  2.79it/s, Loss=0.0035871, Gaussian number=182511, print grad=8.943334978539497e-05, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1370/2000 [13:33<03:46,  2.79it/s, Loss=0.0023757, Gaussian number=182511, print grad=0.00010204074351349846, Depth Loss=0.0000000]
Training progress:  69%|██████▉   | 1380/2000 [13:33<03:42,  2.79it/s, Loss=0.0023757, Gaussian number=182511, print grad=0.00010204074351349846, Depth Loss=0.0000000]
Training progress:  69%|██████▉   | 1380/2000 [13:36<03:42,  2.79it/s, Loss=0.0024027, Gaussian number=182511, print grad=0.00011393801105441526, Depth Loss=0.0000000]
Training progress:  70%|██████▉   | 1390/2000 [13:36<03:39,  2.78it/s, Loss=0.0024027, Gaussian number=182511, print grad=0.00011393801105441526, Depth Loss=0.0000000]
Training progress:  70%|██████▉   | 1390/2000 [13:40<03:39,  2.78it/s, Loss=0.0025443, Gaussian number=182511, print grad=0.00012685908586718142, Depth Loss=0.0000000]
Training progress:  70%|███████   | 1400/2000 [13:40<03:35,  2.78it/s, Loss=0.0025443, Gaussian number=182511, print grad=0.00012685908586718142, Depth Loss=0.0000000]
Training progress:  70%|███████   | 1400/2000 [13:43<03:35,  2.78it/s, Loss=0.0029961, Gaussian number=182471, print grad=1.1939872820221353e-05, Depth Loss=0.0000000]
Training progress:  70%|███████   | 1410/2000 [13:43<03:32,  2.78it/s, Loss=0.0029961, Gaussian number=182471, print grad=1.1939872820221353e-05, Depth Loss=0.0000000]
Training progress:  70%|███████   | 1410/2000 [13:47<03:32,  2.78it/s, Loss=0.0024648, Gaussian number=182471, print grad=2.580912405392155e-05, Depth Loss=0.0000000] 
Training progress:  71%|███████   | 1420/2000 [13:47<03:28,  2.78it/s, Loss=0.0024648, Gaussian number=182471, print grad=2.580912405392155e-05, Depth Loss=0.0000000]
Training progress:  71%|███████   | 1420/2000 [13:51<03:28,  2.78it/s, Loss=0.0025445, Gaussian number=182471, print grad=4.0494494896847755e-05, Depth Loss=0.0000000]
Training progress:  72%|███████▏  | 1430/2000 [13:51<03:24,  2.78it/s, Loss=0.0025445, Gaussian number=182471, print grad=4.0494494896847755e-05, Depth Loss=0.0000000]
Training progress:  72%|███████▏  | 1430/2000 [13:54<03:24,  2.78it/s, Loss=0.0025548, Gaussian number=182471, print grad=5.35230828972999e-05, Depth Loss=0.0000000]  
Training progress:  72%|███████▏  | 1440/2000 [13:54<03:20,  2.79it/s, Loss=0.0025548, Gaussian number=182471, print grad=5.35230828972999e-05, Depth Loss=0.0000000]
Training progress:  72%|███████▏  | 1440/2000 [13:58<03:20,  2.79it/s, Loss=0.0022767, Gaussian number=182471, print grad=6.705305713694543e-05, Depth Loss=0.0000000]
Training progress:  72%|███████▎  | 1450/2000 [13:58<03:17,  2.79it/s, Loss=0.0022767, Gaussian number=182471, print grad=6.705305713694543e-05, Depth Loss=0.0000000]
Training progress:  72%|███████▎  | 1450/2000 [14:01<03:17,  2.79it/s, Loss=0.0019810, Gaussian number=182471, print grad=7.993039616849273e-05, Depth Loss=0.0000000]
Training progress:  73%|███████▎  | 1460/2000 [14:01<03:13,  2.79it/s, Loss=0.0019810, Gaussian number=182471, print grad=7.993039616849273e-05, Depth Loss=0.0000000]
Training progress:  73%|███████▎  | 1460/2000 [14:05<03:13,  2.79it/s, Loss=0.0025652, Gaussian number=182471, print grad=9.333010530099273e-05, Depth Loss=0.0000000]
Training progress:  74%|███████▎  | 1470/2000 [14:05<03:10,  2.79it/s, Loss=0.0025652, Gaussian number=182471, print grad=9.333010530099273e-05, Depth Loss=0.0000000]
Training progress:  74%|███████▎  | 1470/2000 [14:09<03:10,  2.79it/s, Loss=0.0025824, Gaussian number=182471, print grad=0.00010653448407538235, Depth Loss=0.0000000]
Training progress:  74%|███████▍  | 1480/2000 [14:09<03:06,  2.79it/s, Loss=0.0025824, Gaussian number=182471, print grad=0.00010653448407538235, Depth Loss=0.0000000]
Training progress:  74%|███████▍  | 1480/2000 [14:12<03:06,  2.79it/s, Loss=0.0027434, Gaussian number=182471, print grad=0.00011926833394682035, Depth Loss=0.0000000]
Training progress:  74%|███████▍  | 1490/2000 [14:12<03:02,  2.79it/s, Loss=0.0027434, Gaussian number=182471, print grad=0.00011926833394682035, Depth Loss=0.0000000]
Training progress:  74%|███████▍  | 1490/2000 [14:16<03:02,  2.79it/s, Loss=0.0030232, Gaussian number=182471, print grad=0.00013305511674843729, Depth Loss=0.0000000]
Training progress:  75%|███████▌  | 1500/2000 [14:16<02:59,  2.79it/s, Loss=0.0030232, Gaussian number=182471, print grad=0.00013305511674843729, Depth Loss=0.0000000]
Training progress:  75%|███████▌  | 1500/2000 [15:22<02:59,  2.79it/s, Loss=0.0032142, Gaussian number=182428, print grad=1.218332636199193e-05, Depth Loss=0.0000000] 
Training progress:  76%|███████▌  | 1510/2000 [15:22<18:13,  2.23s/it, Loss=0.0032142, Gaussian number=182428, print grad=1.218332636199193e-05, Depth Loss=0.0000000]
Training progress:  76%|███████▌  | 1510/2000 [15:25<18:13,  2.23s/it, Loss=0.0024601, Gaussian number=182428, print grad=2.4283648599521257e-05, Depth Loss=0.0000000]
Training progress:  76%|███████▌  | 1520/2000 [15:25<13:21,  1.67s/it, Loss=0.0024601, Gaussian number=182428, print grad=2.4283648599521257e-05, Depth Loss=0.0000000]
Training progress:  76%|███████▌  | 1520/2000 [15:29<13:21,  1.67s/it, Loss=0.0018069, Gaussian number=182428, print grad=3.7659254303434864e-05, Depth Loss=0.0000000]
Training progress:  76%|███████▋  | 1530/2000 [15:29<09:59,  1.28s/it, Loss=0.0018069, Gaussian number=182428, print grad=3.7659254303434864e-05, Depth Loss=0.0000000]
Training progress:  76%|███████▋  | 1530/2000 [15:32<09:59,  1.28s/it, Loss=0.0025749, Gaussian number=182428, print grad=5.045788566349074e-05, Depth Loss=0.0000000] 
Training progress:  77%|███████▋  | 1540/2000 [15:32<07:40,  1.00s/it, Loss=0.0025749, Gaussian number=182428, print grad=5.045788566349074e-05, Depth Loss=0.0000000]
Training progress:  77%|███████▋  | 1540/2000 [15:36<07:40,  1.00s/it, Loss=0.0024580, Gaussian number=182428, print grad=6.436612602556124e-05, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1550/2000 [15:36<06:03,  1.24it/s, Loss=0.0024580, Gaussian number=182428, print grad=6.436612602556124e-05, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1550/2000 [15:40<06:03,  1.24it/s, Loss=0.0023895, Gaussian number=182428, print grad=7.828487287042663e-05, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1560/2000 [15:40<04:55,  1.49it/s, Loss=0.0023895, Gaussian number=182428, print grad=7.828487287042663e-05, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1560/2000 [15:43<04:55,  1.49it/s, Loss=0.0022990, Gaussian number=182428, print grad=9.156302985502407e-05, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1570/2000 [15:43<04:08,  1.73it/s, Loss=0.0022990, Gaussian number=182428, print grad=9.156302985502407e-05, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1570/2000 [15:47<04:08,  1.73it/s, Loss=0.0016192, Gaussian number=182428, print grad=0.00010266170284012333, Depth Loss=0.0000000]
Training progress:  79%|███████▉  | 1580/2000 [15:47<03:35,  1.95it/s, Loss=0.0016192, Gaussian number=182428, print grad=0.00010266170284012333, Depth Loss=0.0000000]
Training progress:  79%|███████▉  | 1580/2000 [15:50<03:35,  1.95it/s, Loss=0.0023118, Gaussian number=182428, print grad=0.0001147921138908714, Depth Loss=0.0000000] 
Training progress:  80%|███████▉  | 1590/2000 [15:50<03:10,  2.15it/s, Loss=0.0023118, Gaussian number=182428, print grad=0.0001147921138908714, Depth Loss=0.0000000]
Training progress:  80%|███████▉  | 1590/2000 [15:54<03:10,  2.15it/s, Loss=0.0022641, Gaussian number=182428, print grad=0.00012784861610271037, Depth Loss=0.0000000]
Training progress:  80%|████████  | 1600/2000 [15:54<02:53,  2.31it/s, Loss=0.0022641, Gaussian number=182428, print grad=0.00012784861610271037, Depth Loss=0.0000000]
Training progress:  80%|████████  | 1600/2000 [15:57<02:53,  2.31it/s, Loss=0.0021822, Gaussian number=182381, print grad=1.1823164641100448e-05, Depth Loss=0.0000000]
Training progress:  80%|████████  | 1610/2000 [15:57<02:40,  2.43it/s, Loss=0.0021822, Gaussian number=182381, print grad=1.1823164641100448e-05, Depth Loss=0.0000000]
Training progress:  80%|████████  | 1610/2000 [16:01<02:40,  2.43it/s, Loss=0.0026562, Gaussian number=182381, print grad=2.5308134354418144e-05, Depth Loss=0.0000000]
Training progress:  81%|████████  | 1620/2000 [16:01<02:30,  2.53it/s, Loss=0.0026562, Gaussian number=182381, print grad=2.5308134354418144e-05, Depth Loss=0.0000000]
Training progress:  81%|████████  | 1620/2000 [16:05<02:30,  2.53it/s, Loss=0.0024065, Gaussian number=182381, print grad=3.818711047642864e-05, Depth Loss=0.0000000] 
Training progress:  82%|████████▏ | 1630/2000 [16:05<02:21,  2.61it/s, Loss=0.0024065, Gaussian number=182381, print grad=3.818711047642864e-05, Depth Loss=0.0000000]
Training progress:  82%|████████▏ | 1630/2000 [16:08<02:21,  2.61it/s, Loss=0.0016182, Gaussian number=182381, print grad=5.134253660799004e-05, Depth Loss=0.0000000]
Training progress:  82%|████████▏ | 1640/2000 [16:08<02:15,  2.66it/s, Loss=0.0016182, Gaussian number=182381, print grad=5.134253660799004e-05, Depth Loss=0.0000000]
Training progress:  82%|████████▏ | 1640/2000 [16:12<02:15,  2.66it/s, Loss=0.0022949, Gaussian number=182381, print grad=6.286567077040672e-05, Depth Loss=0.0000000]
Training progress:  82%|████████▎ | 1650/2000 [16:12<02:09,  2.70it/s, Loss=0.0022949, Gaussian number=182381, print grad=6.286567077040672e-05, Depth Loss=0.0000000]
Training progress:  82%|████████▎ | 1650/2000 [16:15<02:09,  2.70it/s, Loss=0.0021250, Gaussian number=182381, print grad=7.508954149670899e-05, Depth Loss=0.0000000]
Training progress:  83%|████████▎ | 1660/2000 [16:15<02:04,  2.73it/s, Loss=0.0021250, Gaussian number=182381, print grad=7.508954149670899e-05, Depth Loss=0.0000000]
Training progress:  83%|████████▎ | 1660/2000 [16:19<02:04,  2.73it/s, Loss=0.0021114, Gaussian number=182381, print grad=8.745730156078935e-05, Depth Loss=0.0000000]
Training progress:  84%|████████▎ | 1670/2000 [16:19<01:59,  2.75it/s, Loss=0.0021114, Gaussian number=182381, print grad=8.745730156078935e-05, Depth Loss=0.0000000]
Training progress:  84%|████████▎ | 1670/2000 [16:22<01:59,  2.75it/s, Loss=0.0018073, Gaussian number=182381, print grad=0.00010016732994699851, Depth Loss=0.0000000]
Training progress:  84%|████████▍ | 1680/2000 [16:22<01:55,  2.76it/s, Loss=0.0018073, Gaussian number=182381, print grad=0.00010016732994699851, Depth Loss=0.0000000]
Training progress:  84%|████████▍ | 1680/2000 [16:26<01:55,  2.76it/s, Loss=0.0023887, Gaussian number=182381, print grad=0.00011233267287025228, Depth Loss=0.0000000]
Training progress:  84%|████████▍ | 1690/2000 [16:26<01:51,  2.77it/s, Loss=0.0023887, Gaussian number=182381, print grad=0.00011233267287025228, Depth Loss=0.0000000]
Training progress:  84%|████████▍ | 1690/2000 [16:30<01:51,  2.77it/s, Loss=0.0022379, Gaussian number=182381, print grad=0.00012354990758467466, Depth Loss=0.0000000]
Training progress:  85%|████████▌ | 1700/2000 [16:30<01:47,  2.78it/s, Loss=0.0022379, Gaussian number=182381, print grad=0.00012354990758467466, Depth Loss=0.0000000]
Training progress:  85%|████████▌ | 1700/2000 [16:33<01:47,  2.78it/s, Loss=0.0026299, Gaussian number=182331, print grad=1.2999948921788018e-05, Depth Loss=0.0000000]
Training progress:  86%|████████▌ | 1710/2000 [16:33<01:44,  2.78it/s, Loss=0.0026299, Gaussian number=182331, print grad=1.2999948921788018e-05, Depth Loss=0.0000000]
Training progress:  86%|████████▌ | 1710/2000 [16:37<01:44,  2.78it/s, Loss=0.0024481, Gaussian number=182331, print grad=2.4656477762619033e-05, Depth Loss=0.0000000]
Training progress:  86%|████████▌ | 1720/2000 [16:37<01:40,  2.78it/s, Loss=0.0024481, Gaussian number=182331, print grad=2.4656477762619033e-05, Depth Loss=0.0000000]
Training progress:  86%|████████▌ | 1720/2000 [16:40<01:40,  2.78it/s, Loss=0.0021991, Gaussian number=182331, print grad=3.74733645003289e-05, Depth Loss=0.0000000]  
Training progress:  86%|████████▋ | 1730/2000 [16:40<01:37,  2.78it/s, Loss=0.0021991, Gaussian number=182331, print grad=3.74733645003289e-05, Depth Loss=0.0000000]
Training progress:  86%|████████▋ | 1730/2000 [16:44<01:37,  2.78it/s, Loss=0.0026962, Gaussian number=182331, print grad=5.047052400186658e-05, Depth Loss=0.0000000]
Training progress:  87%|████████▋ | 1740/2000 [16:44<01:33,  2.78it/s, Loss=0.0026962, Gaussian number=182331, print grad=5.047052400186658e-05, Depth Loss=0.0000000]
Training progress:  87%|████████▋ | 1740/2000 [16:48<01:33,  2.78it/s, Loss=0.0028218, Gaussian number=182331, print grad=6.44704996375367e-05, Depth Loss=0.0000000] 
Training progress:  88%|████████▊ | 1750/2000 [16:48<01:29,  2.79it/s, Loss=0.0028218, Gaussian number=182331, print grad=6.44704996375367e-05, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1750/2000 [16:51<01:29,  2.79it/s, Loss=0.0023180, Gaussian number=182331, print grad=7.759602158330381e-05, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1760/2000 [16:51<01:26,  2.79it/s, Loss=0.0023180, Gaussian number=182331, print grad=7.759602158330381e-05, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1760/2000 [16:55<01:26,  2.79it/s, Loss=0.0019510, Gaussian number=182331, print grad=8.993180381366983e-05, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1770/2000 [16:55<01:22,  2.79it/s, Loss=0.0019510, Gaussian number=182331, print grad=8.993180381366983e-05, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1770/2000 [16:58<01:22,  2.79it/s, Loss=0.0024812, Gaussian number=182331, print grad=0.00010218970419373363, Depth Loss=0.0000000]
Training progress:  89%|████████▉ | 1780/2000 [16:58<01:18,  2.79it/s, Loss=0.0024812, Gaussian number=182331, print grad=0.00010218970419373363, Depth Loss=0.0000000]
Training progress:  89%|████████▉ | 1780/2000 [17:02<01:18,  2.79it/s, Loss=0.0018833, Gaussian number=182331, print grad=0.00011390209692763165, Depth Loss=0.0000000]
Training progress:  90%|████████▉ | 1790/2000 [17:02<01:15,  2.79it/s, Loss=0.0018833, Gaussian number=182331, print grad=0.00011390209692763165, Depth Loss=0.0000000]
Training progress:  90%|████████▉ | 1790/2000 [17:06<01:15,  2.79it/s, Loss=0.0021706, Gaussian number=182331, print grad=0.00012685290130320936, Depth Loss=0.0000000]
Training progress:  90%|█████████ | 1800/2000 [17:06<01:11,  2.79it/s, Loss=0.0021706, Gaussian number=182331, print grad=0.00012685290130320936, Depth Loss=0.0000000]
Training progress:  90%|█████████ | 1800/2000 [17:09<01:11,  2.79it/s, Loss=0.0023833, Gaussian number=182260, print grad=1.2311762475292198e-05, Depth Loss=0.0000000]
Training progress:  90%|█████████ | 1810/2000 [17:09<01:08,  2.79it/s, Loss=0.0023833, Gaussian number=182260, print grad=1.2311762475292198e-05, Depth Loss=0.0000000]
Training progress:  90%|█████████ | 1810/2000 [17:13<01:08,  2.79it/s, Loss=0.0022314, Gaussian number=182260, print grad=2.5392666429979727e-05, Depth Loss=0.0000000]
Training progress:  91%|█████████ | 1820/2000 [17:13<01:04,  2.79it/s, Loss=0.0022314, Gaussian number=182260, print grad=2.5392666429979727e-05, Depth Loss=0.0000000]
Training progress:  91%|█████████ | 1820/2000 [17:16<01:04,  2.79it/s, Loss=0.0016367, Gaussian number=182260, print grad=3.7046826037112623e-05, Depth Loss=0.0000000]
Training progress:  92%|█████████▏| 1830/2000 [17:16<01:01,  2.79it/s, Loss=0.0016367, Gaussian number=182260, print grad=3.7046826037112623e-05, Depth Loss=0.0000000]
Training progress:  92%|█████████▏| 1830/2000 [17:20<01:01,  2.79it/s, Loss=0.0019838, Gaussian number=182260, print grad=5.112504368298687e-05, Depth Loss=0.0000000] 
Training progress:  92%|█████████▏| 1840/2000 [17:20<00:57,  2.79it/s, Loss=0.0019838, Gaussian number=182260, print grad=5.112504368298687e-05, Depth Loss=0.0000000]
Training progress:  92%|█████████▏| 1840/2000 [17:23<00:57,  2.79it/s, Loss=0.0019698, Gaussian number=182260, print grad=6.32653827778995e-05, Depth Loss=0.0000000] 
Training progress:  92%|█████████▎| 1850/2000 [17:23<00:53,  2.79it/s, Loss=0.0019698, Gaussian number=182260, print grad=6.32653827778995e-05, Depth Loss=0.0000000]
Training progress:  92%|█████████▎| 1850/2000 [17:27<00:53,  2.79it/s, Loss=0.0019722, Gaussian number=182260, print grad=7.431772246491164e-05, Depth Loss=0.0000000]
Training progress:  93%|█████████▎| 1860/2000 [17:27<00:50,  2.79it/s, Loss=0.0019722, Gaussian number=182260, print grad=7.431772246491164e-05, Depth Loss=0.0000000]
Training progress:  93%|█████████▎| 1860/2000 [17:31<00:50,  2.79it/s, Loss=0.0021875, Gaussian number=182260, print grad=8.771929424256086e-05, Depth Loss=0.0000000]
Training progress:  94%|█████████▎| 1870/2000 [17:31<00:46,  2.79it/s, Loss=0.0021875, Gaussian number=182260, print grad=8.771929424256086e-05, Depth Loss=0.0000000]
Training progress:  94%|█████████▎| 1870/2000 [17:34<00:46,  2.79it/s, Loss=0.0018806, Gaussian number=182260, print grad=0.00010056362225441262, Depth Loss=0.0000000]
Training progress:  94%|█████████▍| 1880/2000 [17:34<00:43,  2.79it/s, Loss=0.0018806, Gaussian number=182260, print grad=0.00010056362225441262, Depth Loss=0.0000000]
Training progress:  94%|█████████▍| 1880/2000 [17:38<00:43,  2.79it/s, Loss=0.0020688, Gaussian number=182260, print grad=0.00011271398398093879, Depth Loss=0.0000000]
Training progress:  94%|█████████▍| 1890/2000 [17:38<00:39,  2.79it/s, Loss=0.0020688, Gaussian number=182260, print grad=0.00011271398398093879, Depth Loss=0.0000000]
Training progress:  94%|█████████▍| 1890/2000 [17:41<00:39,  2.79it/s, Loss=0.0023249, Gaussian number=182260, print grad=0.00012562568008434027, Depth Loss=0.0000000]
Training progress:  95%|█████████▌| 1900/2000 [17:41<00:35,  2.79it/s, Loss=0.0023249, Gaussian number=182260, print grad=0.00012562568008434027, Depth Loss=0.0000000]
Training progress:  95%|█████████▌| 1900/2000 [17:45<00:35,  2.79it/s, Loss=0.0022925, Gaussian number=182198, print grad=1.1362491932231933e-05, Depth Loss=0.0000000]
Training progress:  96%|█████████▌| 1910/2000 [17:45<00:32,  2.79it/s, Loss=0.0022925, Gaussian number=182198, print grad=1.1362491932231933e-05, Depth Loss=0.0000000]
Training progress:  96%|█████████▌| 1910/2000 [17:49<00:32,  2.79it/s, Loss=0.0017187, Gaussian number=182198, print grad=2.4303109967149794e-05, Depth Loss=0.0000000]
Training progress:  96%|█████████▌| 1920/2000 [17:49<00:28,  2.79it/s, Loss=0.0017187, Gaussian number=182198, print grad=2.4303109967149794e-05, Depth Loss=0.0000000]
Training progress:  96%|█████████▌| 1920/2000 [17:52<00:28,  2.79it/s, Loss=0.0015347, Gaussian number=182198, print grad=3.6158973671263084e-05, Depth Loss=0.0000000]
Training progress:  96%|█████████▋| 1930/2000 [17:52<00:25,  2.78it/s, Loss=0.0015347, Gaussian number=182198, print grad=3.6158973671263084e-05, Depth Loss=0.0000000]
Training progress:  96%|█████████▋| 1930/2000 [17:56<00:25,  2.78it/s, Loss=0.0022947, Gaussian number=182198, print grad=4.8333877202821895e-05, Depth Loss=0.0000000]
Training progress:  97%|█████████▋| 1940/2000 [17:56<00:21,  2.78it/s, Loss=0.0022947, Gaussian number=182198, print grad=4.8333877202821895e-05, Depth Loss=0.0000000]
Training progress:  97%|█████████▋| 1940/2000 [17:59<00:21,  2.78it/s, Loss=0.0018498, Gaussian number=182198, print grad=6.0683523770421743e-05, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1950/2000 [17:59<00:17,  2.78it/s, Loss=0.0018498, Gaussian number=182198, print grad=6.0683523770421743e-05, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1950/2000 [18:03<00:17,  2.78it/s, Loss=0.0028437, Gaussian number=182198, print grad=7.27366641513072e-05, Depth Loss=0.0000000]  
Training progress:  98%|█████████▊| 1960/2000 [18:03<00:14,  2.78it/s, Loss=0.0028437, Gaussian number=182198, print grad=7.27366641513072e-05, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1960/2000 [18:07<00:14,  2.78it/s, Loss=0.0022195, Gaussian number=182198, print grad=8.517127571394667e-05, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1970/2000 [18:07<00:10,  2.79it/s, Loss=0.0022195, Gaussian number=182198, print grad=8.517127571394667e-05, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1970/2000 [18:10<00:10,  2.79it/s, Loss=0.0020140, Gaussian number=182198, print grad=9.765351569512859e-05, Depth Loss=0.0000000]
Training progress:  99%|█████████▉| 1980/2000 [18:10<00:07,  2.79it/s, Loss=0.0020140, Gaussian number=182198, print grad=9.765351569512859e-05, Depth Loss=0.0000000]
Training progress:  99%|█████████▉| 1980/2000 [18:14<00:07,  2.79it/s, Loss=0.0020172, Gaussian number=182198, print grad=0.00011175291001563892, Depth Loss=0.0000000]
Training progress: 100%|█████████▉| 1990/2000 [18:14<00:03,  2.79it/s, Loss=0.0020172, Gaussian number=182198, print grad=0.00011175291001563892, Depth Loss=0.0000000]
Training progress: 100%|█████████▉| 1990/2000 [18:17<00:03,  2.79it/s, Loss=0.0017315, Gaussian number=182198, print grad=0.0001257030526176095, Depth Loss=0.0000000] 
Training progress: 100%|██████████| 2000/2000 [18:17<00:00,  2.79it/s, Loss=0.0017315, Gaussian number=182198, print grad=0.0001257030526176095, Depth Loss=0.0000000]
Training progress: 100%|██████████| 2000/2000 [18:17<00:00,  1.82it/s, Loss=0.0017315, Gaussian number=182198, print grad=0.0001257030526176095, Depth Loss=0.0000000]
Iteration 100 [03/12 20:26:50]

[ITER 100] Evaluating test: WD 0.015248, PSNR 12.5808,lpips 0.615487,ssim 0.421667 [03/12 20:27:46]

[ITER 100] Evaluating train: WD 0.015510, PSNR 12.9737,lpips 0.617827,ssim 0.442066 [03/12 20:27:53]
Gaussian number:182686,print gradients:1.533298586764431e-06 [03/12 20:27:53]
Iteration 200 [03/12 20:28:29]

[ITER 200] Evaluating test: WD 0.015231, PSNR 13.7873,lpips 0.573249,ssim 0.432287 [03/12 20:29:25]

[ITER 200] Evaluating train: WD 0.015407, PSNR 14.2677,lpips 0.563284,ssim 0.448496 [03/12 20:29:32]
Gaussian number:182686,print gradients:1.730824578771717e-06 [03/12 20:29:32]
Iteration 300 [03/12 20:30:08]

[ITER 300] Evaluating test: WD 0.015077, PSNR 14.2773,lpips 0.543267,ssim 0.436007 [03/12 20:31:04]

[ITER 300] Evaluating train: WD 0.015340, PSNR 14.8332,lpips 0.533561,ssim 0.449065 [03/12 20:31:11]
Gaussian number:182686,print gradients:1.8564185211289441e-06 [03/12 20:31:11]
Iteration 400 [03/12 20:31:47]
Iteration 500 [03/12 20:32:23]

[ITER 500] Evaluating test: WD 0.014483, PSNR 14.8935,lpips 0.509687,ssim 0.443546 [03/12 20:33:19]

[ITER 500] Evaluating train: WD 0.015221, PSNR 15.2871,lpips 0.508818,ssim 0.452368 [03/12 20:33:26]
Gaussian number:182686,print gradients:1.9969922959717223e-06 [03/12 20:33:26]
Iteration 600 [03/12 20:34:02]
Iteration 700 [03/12 20:34:38]
Iteration 800 [03/12 20:35:14]
Iteration 900 [03/12 20:35:50]
Iteration 1000 [03/12 20:36:26]

[ITER 1000] Evaluating test: WD 0.012924, PSNR 15.5435,lpips 0.454808,ssim 0.457819 [03/12 20:37:22]

[ITER 1000] Evaluating train: WD 0.013679, PSNR 15.8785,lpips 0.456443,ssim 0.468729 [03/12 20:37:29]
Gaussian number:182641,print gradients:2.063956344500184e-06 [03/12 20:37:29]
Iteration 1100 [03/12 20:38:04]
Iteration 1200 [03/12 20:38:40]
Iteration 1300 [03/12 20:39:16]
Iteration 1400 [03/12 20:39:52]
Iteration 1500 [03/12 20:40:28]

[ITER 1500] Evaluating test: WD 0.011953, PSNR 15.8206,lpips 0.423832,ssim 0.468853 [03/12 20:41:24]

[ITER 1500] Evaluating train: WD 0.012601, PSNR 16.2281,lpips 0.423435,ssim 0.480662 [03/12 20:41:31]
Gaussian number:182471,print gradients:2.004140696953982e-06 [03/12 20:41:31]
Iteration 1600 [03/12 20:42:06]
Iteration 1700 [03/12 20:42:42]
Iteration 1800 [03/12 20:43:18]
Iteration 1900 [03/12 20:43:54]
Iteration 2000 [03/12 20:44:30]

[ITER 2000] Evaluating test: WD 0.011269, PSNR 16.0831,lpips 0.405660,ssim 0.478229 [03/12 20:45:26]

[ITER 2000] Evaluating train: WD 0.011882, PSNR 16.5502,lpips 0.405406,ssim 0.490666 [03/12 20:45:33]
Gaussian number:182198,print gradients:1.9191513729310827e-06 [03/12 20:45:33]

[ITER 2000] Saving Gaussians [03/12 20:45:33]

Training complete. [03/12 20:45:35]
