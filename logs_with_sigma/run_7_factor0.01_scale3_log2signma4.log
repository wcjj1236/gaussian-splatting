Optimizing /home/cw4287/gaussian-model/train_30k
Output folder: /home/cw4287/gaussian-model/train_30k [03/12 18:43:52]
Tensorboard not available: not logging progress [03/12 18:43:52]
------------LLFF HOLD------------- [03/12 18:43:54]

Reading camera 1/301
Reading camera 2/301
Reading camera 3/301
Reading camera 4/301
Reading camera 5/301
Reading camera 6/301
Reading camera 7/301
Reading camera 8/301
Reading camera 9/301
Reading camera 10/301
Reading camera 11/301
Reading camera 12/301
Reading camera 13/301
Reading camera 14/301
Reading camera 15/301
Reading camera 16/301
Reading camera 17/301
Reading camera 18/301
Reading camera 19/301
Reading camera 20/301
Reading camera 21/301
Reading camera 22/301
Reading camera 23/301
Reading camera 24/301
Reading camera 25/301
Reading camera 26/301
Reading camera 27/301
Reading camera 28/301
Reading camera 29/301
Reading camera 30/301
Reading camera 31/301
Reading camera 32/301
Reading camera 33/301
Reading camera 34/301
Reading camera 35/301
Reading camera 36/301
Reading camera 37/301
Reading camera 38/301
Reading camera 39/301
Reading camera 40/301
Reading camera 41/301
Reading camera 42/301
Reading camera 43/301
Reading camera 44/301
Reading camera 45/301
Reading camera 46/301
Reading camera 47/301
Reading camera 48/301
Reading camera 49/301
Reading camera 50/301
Reading camera 51/301
Reading camera 52/301
Reading camera 53/301
Reading camera 54/301
Reading camera 55/301
Reading camera 56/301
Reading camera 57/301
Reading camera 58/301
Reading camera 59/301
Reading camera 60/301
Reading camera 61/301
Reading camera 62/301
Reading camera 63/301
Reading camera 64/301
Reading camera 65/301
Reading camera 66/301
Reading camera 67/301
Reading camera 68/301
Reading camera 69/301
Reading camera 70/301
Reading camera 71/301
Reading camera 72/301
Reading camera 73/301
Reading camera 74/301
Reading camera 75/301
Reading camera 76/301
Reading camera 77/301
Reading camera 78/301
Reading camera 79/301
Reading camera 80/301
Reading camera 81/301
Reading camera 82/301
Reading camera 83/301
Reading camera 84/301
Reading camera 85/301
Reading camera 86/301
Reading camera 87/301
Reading camera 88/301
Reading camera 89/301
Reading camera 90/301
Reading camera 91/301
Reading camera 92/301
Reading camera 93/301
Reading camera 94/301
Reading camera 95/301
Reading camera 96/301
Reading camera 97/301
Reading camera 98/301
Reading camera 99/301
Reading camera 100/301
Reading camera 101/301
Reading camera 102/301
Reading camera 103/301
Reading camera 104/301
Reading camera 105/301
Reading camera 106/301
Reading camera 107/301
Reading camera 108/301
Reading camera 109/301
Reading camera 110/301
Reading camera 111/301
Reading camera 112/301
Reading camera 113/301
Reading camera 114/301
Reading camera 115/301
Reading camera 116/301
Reading camera 117/301
Reading camera 118/301
Reading camera 119/301
Reading camera 120/301
Reading camera 121/301
Reading camera 122/301
Reading camera 123/301
Reading camera 124/301
Reading camera 125/301
Reading camera 126/301
Reading camera 127/301
Reading camera 128/301
Reading camera 129/301
Reading camera 130/301
Reading camera 131/301
Reading camera 132/301
Reading camera 133/301
Reading camera 134/301
Reading camera 135/301
Reading camera 136/301
Reading camera 137/301
Reading camera 138/301
Reading camera 139/301
Reading camera 140/301
Reading camera 141/301
Reading camera 142/301
Reading camera 143/301
Reading camera 144/301
Reading camera 145/301
Reading camera 146/301
Reading camera 147/301
Reading camera 148/301
Reading camera 149/301
Reading camera 150/301
Reading camera 151/301
Reading camera 152/301
Reading camera 153/301
Reading camera 154/301
Reading camera 155/301
Reading camera 156/301
Reading camera 157/301
Reading camera 158/301
Reading camera 159/301
Reading camera 160/301
Reading camera 161/301
Reading camera 162/301
Reading camera 163/301
Reading camera 164/301
Reading camera 165/301
Reading camera 166/301
Reading camera 167/301
Reading camera 168/301
Reading camera 169/301
Reading camera 170/301
Reading camera 171/301
Reading camera 172/301
Reading camera 173/301
Reading camera 174/301
Reading camera 175/301
Reading camera 176/301
Reading camera 177/301
Reading camera 178/301
Reading camera 179/301
Reading camera 180/301
Reading camera 181/301
Reading camera 182/301
Reading camera 183/301
Reading camera 184/301
Reading camera 185/301
Reading camera 186/301
Reading camera 187/301
Reading camera 188/301
Reading camera 189/301
Reading camera 190/301
Reading camera 191/301
Reading camera 192/301
Reading camera 193/301
Reading camera 194/301
Reading camera 195/301
Reading camera 196/301
Reading camera 197/301
Reading camera 198/301
Reading camera 199/301
Reading camera 200/301
Reading camera 201/301
Reading camera 202/301
Reading camera 203/301
Reading camera 204/301
Reading camera 205/301
Reading camera 206/301
Reading camera 207/301
Reading camera 208/301
Reading camera 209/301
Reading camera 210/301
Reading camera 211/301
Reading camera 212/301
Reading camera 213/301
Reading camera 214/301
Reading camera 215/301
Reading camera 216/301
Reading camera 217/301
Reading camera 218/301
Reading camera 219/301
Reading camera 220/301
Reading camera 221/301
Reading camera 222/301
Reading camera 223/301
Reading camera 224/301
Reading camera 225/301
Reading camera 226/301
Reading camera 227/301
Reading camera 228/301
Reading camera 229/301
Reading camera 230/301
Reading camera 231/301
Reading camera 232/301
Reading camera 233/301
Reading camera 234/301
Reading camera 235/301
Reading camera 236/301
Reading camera 237/301
Reading camera 238/301
Reading camera 239/301
Reading camera 240/301
Reading camera 241/301
Reading camera 242/301
Reading camera 243/301
Reading camera 244/301
Reading camera 245/301
Reading camera 246/301
Reading camera 247/301
Reading camera 248/301
Reading camera 249/301
Reading camera 250/301
Reading camera 251/301
Reading camera 252/301
Reading camera 253/301
Reading camera 254/301
Reading camera 255/301
Reading camera 256/301
Reading camera 257/301
Reading camera 258/301
Reading camera 259/301
Reading camera 260/301
Reading camera 261/301
Reading camera 262/301
Reading camera 263/301
Reading camera 264/301
Reading camera 265/301
Reading camera 266/301
Reading camera 267/301
Reading camera 268/301
Reading camera 269/301
Reading camera 270/301
Reading camera 271/301
Reading camera 272/301
Reading camera 273/301
Reading camera 274/301
Reading camera 275/301
Reading camera 276/301
Reading camera 277/301
Reading camera 278/301
Reading camera 279/301
Reading camera 280/301
Reading camera 281/301
Reading camera 282/301
Reading camera 283/301
Reading camera 284/301
Reading camera 285/301
Reading camera 286/301
Reading camera 287/301
Reading camera 288/301
Reading camera 289/301
Reading camera 290/301
Reading camera 291/301
Reading camera 292/301
Reading camera 293/301
Reading camera 294/301
Reading camera 295/301
Reading camera 296/301
Reading camera 297/301
Reading camera 298/301
Reading camera 299/301
Reading camera 300/301
Reading camera 301/301 [03/12 18:43:54]
Loading Training Cameras [03/12 18:43:54]
Loading Test Cameras [03/12 18:44:08]
Number of points at initialisation :  182686 [03/12 18:44:10]

Training progress:   0%|          | 0/2000 [00:00<?, ?it/s]/ext3/conda/envs/3dgs/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/ext3/conda/envs/3dgs/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)

Training progress:   0%|          | 0/2000 [00:05<?, ?it/s, Loss=0.2181612, Gaussian number=182686, print grad=0.00011915017967112362, Depth Loss=0.0000000]
Training progress:   0%|          | 10/2000 [00:05<18:35,  1.78it/s, Loss=0.2181612, Gaussian number=182686, print grad=0.00011915017967112362, Depth Loss=0.0000000]
Training progress:   0%|          | 10/2000 [00:09<18:35,  1.78it/s, Loss=0.1993170, Gaussian number=182686, print grad=0.00029502998222596943, Depth Loss=0.0000000]
Training progress:   1%|          | 20/2000 [00:09<15:27,  2.13it/s, Loss=0.1993170, Gaussian number=182686, print grad=0.00029502998222596943, Depth Loss=0.0000000]
Training progress:   1%|          | 20/2000 [00:13<15:27,  2.13it/s, Loss=0.1974772, Gaussian number=182686, print grad=0.0004614897770807147, Depth Loss=0.0000000] 
Training progress:   2%|▏         | 30/2000 [00:13<14:23,  2.28it/s, Loss=0.1974772, Gaussian number=182686, print grad=0.0004614897770807147, Depth Loss=0.0000000]
Training progress:   2%|▏         | 30/2000 [00:17<14:23,  2.28it/s, Loss=0.2092210, Gaussian number=182686, print grad=0.0006271959864534438, Depth Loss=0.0000000]
Training progress:   2%|▏         | 40/2000 [00:17<13:52,  2.35it/s, Loss=0.2092210, Gaussian number=182686, print grad=0.0006271959864534438, Depth Loss=0.0000000]
Training progress:   2%|▏         | 40/2000 [00:21<13:52,  2.35it/s, Loss=0.1598054, Gaussian number=182686, print grad=0.0007676998502574861, Depth Loss=0.0000000]
Training progress:   2%|▎         | 50/2000 [00:21<13:32,  2.40it/s, Loss=0.1598054, Gaussian number=182686, print grad=0.0007676998502574861, Depth Loss=0.0000000]
Training progress:   2%|▎         | 50/2000 [00:25<13:32,  2.40it/s, Loss=0.1706535, Gaussian number=182686, print grad=0.0009658644557930529, Depth Loss=0.0000000]
Training progress:   3%|▎         | 60/2000 [00:25<13:17,  2.43it/s, Loss=0.1706535, Gaussian number=182686, print grad=0.0009658644557930529, Depth Loss=0.0000000]
Training progress:   3%|▎         | 60/2000 [00:29<13:17,  2.43it/s, Loss=0.1512103, Gaussian number=182686, print grad=0.0011912983609363437, Depth Loss=0.0000000]
Training progress:   4%|▎         | 70/2000 [00:29<13:07,  2.45it/s, Loss=0.1512103, Gaussian number=182686, print grad=0.0011912983609363437, Depth Loss=0.0000000]
Training progress:   4%|▎         | 70/2000 [00:33<13:07,  2.45it/s, Loss=0.1936535, Gaussian number=182686, print grad=0.001382922986522317, Depth Loss=0.0000000] 
Training progress:   4%|▍         | 80/2000 [00:33<13:00,  2.46it/s, Loss=0.1936535, Gaussian number=182686, print grad=0.001382922986522317, Depth Loss=0.0000000]
Training progress:   4%|▍         | 80/2000 [00:37<13:00,  2.46it/s, Loss=0.1627996, Gaussian number=182686, print grad=0.0015854735393077135, Depth Loss=0.0000000]
Training progress:   4%|▍         | 90/2000 [00:37<12:53,  2.47it/s, Loss=0.1627996, Gaussian number=182686, print grad=0.0015854735393077135, Depth Loss=0.0000000]
Training progress:   4%|▍         | 90/2000 [00:41<12:53,  2.47it/s, Loss=0.1499989, Gaussian number=182686, print grad=0.0018140895990654826, Depth Loss=0.0000000]
Training progress:   5%|▌         | 100/2000 [00:41<12:47,  2.48it/s, Loss=0.1499989, Gaussian number=182686, print grad=0.0018140895990654826, Depth Loss=0.0000000]
Training progress:   5%|▌         | 100/2000 [01:51<12:47,  2.48it/s, Loss=0.1773413, Gaussian number=182686, print grad=0.0020557416137307882, Depth Loss=0.0000000]
Training progress:   6%|▌         | 110/2000 [01:51<1:15:41,  2.40s/it, Loss=0.1773413, Gaussian number=182686, print grad=0.0020557416137307882, Depth Loss=0.0000000]
Training progress:   6%|▌         | 110/2000 [01:55<1:15:41,  2.40s/it, Loss=0.1438192, Gaussian number=182686, print grad=0.002285322640091181, Depth Loss=0.0000000] 
Training progress:   6%|▌         | 120/2000 [01:55<56:12,  1.79s/it, Loss=0.1438192, Gaussian number=182686, print grad=0.002285322640091181, Depth Loss=0.0000000]  
Training progress:   6%|▌         | 120/2000 [01:59<56:12,  1.79s/it, Loss=0.1612551, Gaussian number=182686, print grad=0.002554995473474264, Depth Loss=0.0000000]
Training progress:   6%|▋         | 130/2000 [01:59<42:45,  1.37s/it, Loss=0.1612551, Gaussian number=182686, print grad=0.002554995473474264, Depth Loss=0.0000000]
Training progress:   6%|▋         | 130/2000 [02:03<42:45,  1.37s/it, Loss=0.1459996, Gaussian number=182686, print grad=0.0028269467875361443, Depth Loss=0.0000000]
Training progress:   7%|▋         | 140/2000 [02:03<33:26,  1.08s/it, Loss=0.1459996, Gaussian number=182686, print grad=0.0028269467875361443, Depth Loss=0.0000000]
Training progress:   7%|▋         | 140/2000 [02:07<33:26,  1.08s/it, Loss=0.1287861, Gaussian number=182686, print grad=0.003069067606702447, Depth Loss=0.0000000] 
Training progress:   8%|▊         | 150/2000 [02:07<26:58,  1.14it/s, Loss=0.1287861, Gaussian number=182686, print grad=0.003069067606702447, Depth Loss=0.0000000]
Training progress:   8%|▊         | 150/2000 [02:11<26:58,  1.14it/s, Loss=0.1394001, Gaussian number=182686, print grad=0.003361837472766638, Depth Loss=0.0000000]
Training progress:   8%|▊         | 160/2000 [02:11<22:25,  1.37it/s, Loss=0.1394001, Gaussian number=182686, print grad=0.003361837472766638, Depth Loss=0.0000000]
Training progress:   8%|▊         | 160/2000 [02:15<22:25,  1.37it/s, Loss=0.1388865, Gaussian number=182686, print grad=0.0036169944796711206, Depth Loss=0.0000000]
Training progress:   8%|▊         | 170/2000 [02:15<19:16,  1.58it/s, Loss=0.1388865, Gaussian number=182686, print grad=0.0036169944796711206, Depth Loss=0.0000000]
Training progress:   8%|▊         | 170/2000 [02:19<19:16,  1.58it/s, Loss=0.1135690, Gaussian number=182686, print grad=0.003885512938722968, Depth Loss=0.0000000] 
Training progress:   9%|▉         | 180/2000 [02:19<17:03,  1.78it/s, Loss=0.1135690, Gaussian number=182686, print grad=0.003885512938722968, Depth Loss=0.0000000]
Training progress:   9%|▉         | 180/2000 [02:23<17:03,  1.78it/s, Loss=0.1462139, Gaussian number=182686, print grad=0.004140468314290047, Depth Loss=0.0000000]
Training progress:  10%|▉         | 190/2000 [02:23<15:28,  1.95it/s, Loss=0.1462139, Gaussian number=182686, print grad=0.004140468314290047, Depth Loss=0.0000000]
Training progress:  10%|▉         | 190/2000 [02:27<15:28,  1.95it/s, Loss=0.1240278, Gaussian number=182686, print grad=0.004424748010933399, Depth Loss=0.0000000]
Training progress:  10%|█         | 200/2000 [02:27<14:21,  2.09it/s, Loss=0.1240278, Gaussian number=182686, print grad=0.004424748010933399, Depth Loss=0.0000000]
Training progress:  10%|█         | 200/2000 [03:36<14:21,  2.09it/s, Loss=0.1402099, Gaussian number=182686, print grad=0.004712871741503477, Depth Loss=0.0000000]
Training progress:  10%|█         | 210/2000 [03:36<1:11:59,  2.41s/it, Loss=0.1402099, Gaussian number=182686, print grad=0.004712871741503477, Depth Loss=0.0000000]
Training progress:  10%|█         | 210/2000 [03:40<1:11:59,  2.41s/it, Loss=0.1118317, Gaussian number=182686, print grad=0.004985668696463108, Depth Loss=0.0000000]
Training progress:  11%|█         | 220/2000 [03:40<53:38,  1.81s/it, Loss=0.1118317, Gaussian number=182686, print grad=0.004985668696463108, Depth Loss=0.0000000]  
Training progress:  11%|█         | 220/2000 [03:44<53:38,  1.81s/it, Loss=0.1262846, Gaussian number=182686, print grad=0.005273247603327036, Depth Loss=0.0000000]
Training progress:  12%|█▏        | 230/2000 [03:44<40:51,  1.39s/it, Loss=0.1262846, Gaussian number=182686, print grad=0.005273247603327036, Depth Loss=0.0000000]
Training progress:  12%|█▏        | 230/2000 [03:48<40:51,  1.39s/it, Loss=0.1594128, Gaussian number=182686, print grad=0.005536215845495462, Depth Loss=0.0000000]
Training progress:  12%|█▏        | 240/2000 [03:48<31:57,  1.09s/it, Loss=0.1594128, Gaussian number=182686, print grad=0.005536215845495462, Depth Loss=0.0000000]
Training progress:  12%|█▏        | 240/2000 [03:52<31:57,  1.09s/it, Loss=0.1235879, Gaussian number=182686, print grad=0.005829445086419582, Depth Loss=0.0000000]
Training progress:  12%|█▎        | 250/2000 [03:52<25:42,  1.13it/s, Loss=0.1235879, Gaussian number=182686, print grad=0.005829445086419582, Depth Loss=0.0000000]
Training progress:  12%|█▎        | 250/2000 [03:56<25:42,  1.13it/s, Loss=0.1363094, Gaussian number=182686, print grad=0.006098744925111532, Depth Loss=0.0000000]
Training progress:  13%|█▎        | 260/2000 [03:56<21:20,  1.36it/s, Loss=0.1363094, Gaussian number=182686, print grad=0.006098744925111532, Depth Loss=0.0000000]
Training progress:  13%|█▎        | 260/2000 [04:00<21:20,  1.36it/s, Loss=0.0911849, Gaussian number=182686, print grad=0.006383072584867477, Depth Loss=0.0000000]
Training progress:  14%|█▎        | 270/2000 [04:00<18:18,  1.58it/s, Loss=0.0911849, Gaussian number=182686, print grad=0.006383072584867477, Depth Loss=0.0000000]
Training progress:  14%|█▎        | 270/2000 [04:04<18:18,  1.58it/s, Loss=0.1183592, Gaussian number=182686, print grad=0.006676928140223026, Depth Loss=0.0000000]
Training progress:  14%|█▍        | 280/2000 [04:04<16:09,  1.77it/s, Loss=0.1183592, Gaussian number=182686, print grad=0.006676928140223026, Depth Loss=0.0000000]
Training progress:  14%|█▍        | 280/2000 [04:08<16:09,  1.77it/s, Loss=0.1215592, Gaussian number=182686, print grad=0.006980211939662695, Depth Loss=0.0000000]
Training progress:  14%|█▍        | 290/2000 [04:08<14:38,  1.95it/s, Loss=0.1215592, Gaussian number=182686, print grad=0.006980211939662695, Depth Loss=0.0000000]
Training progress:  14%|█▍        | 290/2000 [04:12<14:38,  1.95it/s, Loss=0.1151089, Gaussian number=182686, print grad=0.007294326554983854, Depth Loss=0.0000000]
Training progress:  15%|█▌        | 300/2000 [04:12<13:33,  2.09it/s, Loss=0.1151089, Gaussian number=182686, print grad=0.007294326554983854, Depth Loss=0.0000000]
Training progress:  15%|█▌        | 300/2000 [05:21<13:33,  2.09it/s, Loss=0.0947192, Gaussian number=182686, print grad=0.0075988611206412315, Depth Loss=0.0000000]
Training progress:  16%|█▌        | 310/2000 [05:21<1:07:54,  2.41s/it, Loss=0.0947192, Gaussian number=182686, print grad=0.0075988611206412315, Depth Loss=0.0000000]
Training progress:  16%|█▌        | 310/2000 [05:25<1:07:54,  2.41s/it, Loss=0.0970375, Gaussian number=182686, print grad=0.00783916562795639, Depth Loss=0.0000000]  
Training progress:  16%|█▌        | 320/2000 [05:25<50:35,  1.81s/it, Loss=0.0970375, Gaussian number=182686, print grad=0.00783916562795639, Depth Loss=0.0000000]  
Training progress:  16%|█▌        | 320/2000 [05:29<50:35,  1.81s/it, Loss=0.1294100, Gaussian number=182686, print grad=0.008104739710688591, Depth Loss=0.0000000]
Training progress:  16%|█▋        | 330/2000 [05:29<38:31,  1.38s/it, Loss=0.1294100, Gaussian number=182686, print grad=0.008104739710688591, Depth Loss=0.0000000]
Training progress:  16%|█▋        | 330/2000 [05:33<38:31,  1.38s/it, Loss=0.0932313, Gaussian number=182686, print grad=0.008414104580879211, Depth Loss=0.0000000]
Training progress:  17%|█▋        | 340/2000 [05:33<30:05,  1.09s/it, Loss=0.0932313, Gaussian number=182686, print grad=0.008414104580879211, Depth Loss=0.0000000]
Training progress:  17%|█▋        | 340/2000 [05:37<30:05,  1.09s/it, Loss=0.0980585, Gaussian number=182686, print grad=0.008702931925654411, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 350/2000 [05:37<24:12,  1.14it/s, Loss=0.0980585, Gaussian number=182686, print grad=0.008702931925654411, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 350/2000 [05:41<24:12,  1.14it/s, Loss=0.0967908, Gaussian number=182686, print grad=0.009027093648910522, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 360/2000 [05:41<20:05,  1.36it/s, Loss=0.0967908, Gaussian number=182686, print grad=0.009027093648910522, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 360/2000 [05:45<20:05,  1.36it/s, Loss=0.0883346, Gaussian number=182686, print grad=0.009314239025115967, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 370/2000 [05:45<17:12,  1.58it/s, Loss=0.0883346, Gaussian number=182686, print grad=0.009314239025115967, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 370/2000 [05:49<17:12,  1.58it/s, Loss=0.1257295, Gaussian number=182686, print grad=0.009572685696184635, Depth Loss=0.0000000]
Training progress:  19%|█▉        | 380/2000 [05:49<15:10,  1.78it/s, Loss=0.1257295, Gaussian number=182686, print grad=0.009572685696184635, Depth Loss=0.0000000]
Training progress:  19%|█▉        | 380/2000 [05:53<15:10,  1.78it/s, Loss=0.1065350, Gaussian number=182686, print grad=0.009882617741823196, Depth Loss=0.0000000]
Training progress:  20%|█▉        | 390/2000 [05:53<13:44,  1.95it/s, Loss=0.1065350, Gaussian number=182686, print grad=0.009882617741823196, Depth Loss=0.0000000]
Training progress:  20%|█▉        | 390/2000 [05:57<13:44,  1.95it/s, Loss=0.1329996, Gaussian number=182686, print grad=0.010175030678510666, Depth Loss=0.0000000]
Training progress:  20%|██        | 400/2000 [05:57<12:42,  2.10it/s, Loss=0.1329996, Gaussian number=182686, print grad=0.010175030678510666, Depth Loss=0.0000000]
Training progress:  20%|██        | 400/2000 [06:01<12:42,  2.10it/s, Loss=0.1124048, Gaussian number=182686, print grad=0.010518726892769337, Depth Loss=0.0000000]
Training progress:  20%|██        | 410/2000 [06:01<11:59,  2.21it/s, Loss=0.1124048, Gaussian number=182686, print grad=0.010518726892769337, Depth Loss=0.0000000]
Training progress:  20%|██        | 410/2000 [06:04<11:59,  2.21it/s, Loss=0.0981730, Gaussian number=182686, print grad=0.010851013474166393, Depth Loss=0.0000000]
Training progress:  21%|██        | 420/2000 [06:04<11:28,  2.30it/s, Loss=0.0981730, Gaussian number=182686, print grad=0.010851013474166393, Depth Loss=0.0000000]
Training progress:  21%|██        | 420/2000 [06:08<11:28,  2.30it/s, Loss=0.1237220, Gaussian number=182686, print grad=0.011186826042830944, Depth Loss=0.0000000]
Training progress:  22%|██▏       | 430/2000 [06:08<11:05,  2.36it/s, Loss=0.1237220, Gaussian number=182686, print grad=0.011186826042830944, Depth Loss=0.0000000]
Training progress:  22%|██▏       | 430/2000 [06:12<11:05,  2.36it/s, Loss=0.0965616, Gaussian number=182686, print grad=0.01148912776261568, Depth Loss=0.0000000] 
Training progress:  22%|██▏       | 440/2000 [06:12<10:47,  2.41it/s, Loss=0.0965616, Gaussian number=182686, print grad=0.01148912776261568, Depth Loss=0.0000000]
Training progress:  22%|██▏       | 440/2000 [06:16<10:47,  2.41it/s, Loss=0.1143831, Gaussian number=182686, print grad=0.01180242095142603, Depth Loss=0.0000000]
Training progress:  22%|██▎       | 450/2000 [06:16<10:35,  2.44it/s, Loss=0.1143831, Gaussian number=182686, print grad=0.01180242095142603, Depth Loss=0.0000000]
Training progress:  22%|██▎       | 450/2000 [06:20<10:35,  2.44it/s, Loss=0.1205180, Gaussian number=182686, print grad=0.01211418304592371, Depth Loss=0.0000000]
Training progress:  23%|██▎       | 460/2000 [06:20<10:25,  2.46it/s, Loss=0.1205180, Gaussian number=182686, print grad=0.01211418304592371, Depth Loss=0.0000000]
Training progress:  23%|██▎       | 460/2000 [06:24<10:25,  2.46it/s, Loss=0.1379169, Gaussian number=182686, print grad=0.012415776029229164, Depth Loss=0.0000000]
Training progress:  24%|██▎       | 470/2000 [06:24<10:15,  2.49it/s, Loss=0.1379169, Gaussian number=182686, print grad=0.012415776029229164, Depth Loss=0.0000000]
Training progress:  24%|██▎       | 470/2000 [06:28<10:15,  2.49it/s, Loss=0.0884496, Gaussian number=182686, print grad=0.012756762094795704, Depth Loss=0.0000000]
Training progress:  24%|██▍       | 480/2000 [06:28<10:08,  2.50it/s, Loss=0.0884496, Gaussian number=182686, print grad=0.012756762094795704, Depth Loss=0.0000000]
Training progress:  24%|██▍       | 480/2000 [06:32<10:08,  2.50it/s, Loss=0.0991753, Gaussian number=182686, print grad=0.013063604012131691, Depth Loss=0.0000000]
Training progress:  24%|██▍       | 490/2000 [06:32<10:02,  2.51it/s, Loss=0.0991753, Gaussian number=182686, print grad=0.013063604012131691, Depth Loss=0.0000000]
Training progress:  24%|██▍       | 490/2000 [06:36<10:02,  2.51it/s, Loss=0.0733137, Gaussian number=182686, print grad=0.01337682269513607, Depth Loss=0.0000000] 
Training progress:  25%|██▌       | 500/2000 [06:36<09:57,  2.51it/s, Loss=0.0733137, Gaussian number=182686, print grad=0.01337682269513607, Depth Loss=0.0000000]
Training progress:  25%|██▌       | 500/2000 [07:45<09:57,  2.51it/s, Loss=0.0896930, Gaussian number=182686, print grad=0.0136863449588418, Depth Loss=0.0000000] 
Training progress:  26%|██▌       | 510/2000 [07:45<58:29,  2.36s/it, Loss=0.0896930, Gaussian number=182686, print grad=0.0136863449588418, Depth Loss=0.0000000]
Training progress:  26%|██▌       | 510/2000 [07:49<58:29,  2.36s/it, Loss=0.0960667, Gaussian number=182686, print grad=0.014009488746523857, Depth Loss=0.0000000]
Training progress:  26%|██▌       | 520/2000 [07:49<43:35,  1.77s/it, Loss=0.0960667, Gaussian number=182686, print grad=0.014009488746523857, Depth Loss=0.0000000]
Training progress:  26%|██▌       | 520/2000 [07:53<43:35,  1.77s/it, Loss=0.0690601, Gaussian number=182686, print grad=0.014288663864135742, Depth Loss=0.0000000]
Training progress:  26%|██▋       | 530/2000 [07:53<33:12,  1.36s/it, Loss=0.0690601, Gaussian number=182686, print grad=0.014288663864135742, Depth Loss=0.0000000]
Training progress:  26%|██▋       | 530/2000 [07:57<33:12,  1.36s/it, Loss=0.0956001, Gaussian number=182686, print grad=0.01459351647645235, Depth Loss=0.0000000] 
Training progress:  27%|██▋       | 540/2000 [07:57<25:58,  1.07s/it, Loss=0.0956001, Gaussian number=182686, print grad=0.01459351647645235, Depth Loss=0.0000000]
Training progress:  27%|██▋       | 540/2000 [08:01<25:58,  1.07s/it, Loss=0.0884743, Gaussian number=182686, print grad=0.014929785393178463, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 550/2000 [08:01<20:54,  1.16it/s, Loss=0.0884743, Gaussian number=182686, print grad=0.014929785393178463, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 550/2000 [08:05<20:54,  1.16it/s, Loss=0.0701784, Gaussian number=182686, print grad=0.015230397693812847, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 560/2000 [08:05<17:23,  1.38it/s, Loss=0.0701784, Gaussian number=182686, print grad=0.015230397693812847, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 560/2000 [08:09<17:23,  1.38it/s, Loss=0.0975073, Gaussian number=182686, print grad=0.01555811706930399, Depth Loss=0.0000000] 
Training progress:  28%|██▊       | 570/2000 [08:09<14:54,  1.60it/s, Loss=0.0975073, Gaussian number=182686, print grad=0.01555811706930399, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 570/2000 [08:13<14:54,  1.60it/s, Loss=0.0854610, Gaussian number=182686, print grad=0.0158908199518919, Depth Loss=0.0000000] 
Training progress:  29%|██▉       | 580/2000 [08:13<13:10,  1.80it/s, Loss=0.0854610, Gaussian number=182686, print grad=0.0158908199518919, Depth Loss=0.0000000]
Training progress:  29%|██▉       | 580/2000 [08:17<13:10,  1.80it/s, Loss=0.0982576, Gaussian number=182686, print grad=0.016222408041357994, Depth Loss=0.0000000]
Training progress:  30%|██▉       | 590/2000 [08:17<11:56,  1.97it/s, Loss=0.0982576, Gaussian number=182686, print grad=0.016222408041357994, Depth Loss=0.0000000]
Training progress:  30%|██▉       | 590/2000 [08:21<11:56,  1.97it/s, Loss=0.1023912, Gaussian number=182686, print grad=0.016525471583008766, Depth Loss=0.0000000]
Training progress:  30%|███       | 600/2000 [08:21<11:03,  2.11it/s, Loss=0.1023912, Gaussian number=182686, print grad=0.016525471583008766, Depth Loss=0.0000000]
Training progress:  30%|███       | 600/2000 [08:25<11:03,  2.11it/s, Loss=0.0856492, Gaussian number=185432, print grad=0.0002917943347711116, Depth Loss=0.0000000]
Training progress:  30%|███       | 610/2000 [08:25<10:26,  2.22it/s, Loss=0.0856492, Gaussian number=185432, print grad=0.0002917943347711116, Depth Loss=0.0000000]
Training progress:  30%|███       | 610/2000 [08:29<10:26,  2.22it/s, Loss=0.1171468, Gaussian number=185432, print grad=0.0006334183271974325, Depth Loss=0.0000000]
Training progress:  31%|███       | 620/2000 [08:29<09:58,  2.31it/s, Loss=0.1171468, Gaussian number=185432, print grad=0.0006334183271974325, Depth Loss=0.0000000]
Training progress:  31%|███       | 620/2000 [08:33<09:58,  2.31it/s, Loss=0.0772516, Gaussian number=185432, print grad=0.0009568298701196909, Depth Loss=0.0000000]
Training progress:  32%|███▏      | 630/2000 [08:33<09:38,  2.37it/s, Loss=0.0772516, Gaussian number=185432, print grad=0.0009568298701196909, Depth Loss=0.0000000]
Training progress:  32%|███▏      | 630/2000 [08:37<09:38,  2.37it/s, Loss=0.0855752, Gaussian number=185432, print grad=0.0013109144056215882, Depth Loss=0.0000000]
Training progress:  32%|███▏      | 640/2000 [08:37<09:23,  2.42it/s, Loss=0.0855752, Gaussian number=185432, print grad=0.0013109144056215882, Depth Loss=0.0000000]
Training progress:  32%|███▏      | 640/2000 [08:41<09:23,  2.42it/s, Loss=0.0995107, Gaussian number=185432, print grad=0.0016183896223083138, Depth Loss=0.0000000]
Training progress:  32%|███▎      | 650/2000 [08:41<09:10,  2.45it/s, Loss=0.0995107, Gaussian number=185432, print grad=0.0016183896223083138, Depth Loss=0.0000000]
Training progress:  32%|███▎      | 650/2000 [08:45<09:10,  2.45it/s, Loss=0.0941851, Gaussian number=185432, print grad=0.0019698026590049267, Depth Loss=0.0000000]
Training progress:  33%|███▎      | 660/2000 [08:45<09:01,  2.47it/s, Loss=0.0941851, Gaussian number=185432, print grad=0.0019698026590049267, Depth Loss=0.0000000]
Training progress:  33%|███▎      | 660/2000 [08:49<09:01,  2.47it/s, Loss=0.0867158, Gaussian number=185432, print grad=0.0022761865984648466, Depth Loss=0.0000000]
Training progress:  34%|███▎      | 670/2000 [08:49<08:53,  2.49it/s, Loss=0.0867158, Gaussian number=185432, print grad=0.0022761865984648466, Depth Loss=0.0000000]
Training progress:  34%|███▎      | 670/2000 [08:52<08:53,  2.49it/s, Loss=0.0772017, Gaussian number=185432, print grad=0.0026153100188821554, Depth Loss=0.0000000]
Training progress:  34%|███▍      | 680/2000 [08:52<08:47,  2.50it/s, Loss=0.0772017, Gaussian number=185432, print grad=0.0026153100188821554, Depth Loss=0.0000000]
Training progress:  34%|███▍      | 680/2000 [08:56<08:47,  2.50it/s, Loss=0.0978506, Gaussian number=185432, print grad=0.002943973755463958, Depth Loss=0.0000000] 
Training progress:  34%|███▍      | 690/2000 [08:56<08:41,  2.51it/s, Loss=0.0978506, Gaussian number=185432, print grad=0.002943973755463958, Depth Loss=0.0000000]
Training progress:  34%|███▍      | 690/2000 [09:00<08:41,  2.51it/s, Loss=0.0945984, Gaussian number=185432, print grad=0.0032675941474735737, Depth Loss=0.0000000]
Training progress:  35%|███▌      | 700/2000 [09:00<08:35,  2.52it/s, Loss=0.0945984, Gaussian number=185432, print grad=0.0032675941474735737, Depth Loss=0.0000000]
Training progress:  35%|███▌      | 700/2000 [09:04<08:35,  2.52it/s, Loss=0.0896553, Gaussian number=193064, print grad=0.000304005661746487, Depth Loss=0.0000000] 
Training progress:  36%|███▌      | 710/2000 [09:04<08:30,  2.53it/s, Loss=0.0896553, Gaussian number=193064, print grad=0.000304005661746487, Depth Loss=0.0000000]
Training progress:  36%|███▌      | 710/2000 [09:08<08:30,  2.53it/s, Loss=0.0800276, Gaussian number=193064, print grad=0.0006567452219314873, Depth Loss=0.0000000]
Training progress:  36%|███▌      | 720/2000 [09:08<08:26,  2.53it/s, Loss=0.0800276, Gaussian number=193064, print grad=0.0006567452219314873, Depth Loss=0.0000000]
Training progress:  36%|███▌      | 720/2000 [09:12<08:26,  2.53it/s, Loss=0.1080457, Gaussian number=193064, print grad=0.0009817311074584723, Depth Loss=0.0000000]
Training progress:  36%|███▋      | 730/2000 [09:12<08:21,  2.53it/s, Loss=0.1080457, Gaussian number=193064, print grad=0.0009817311074584723, Depth Loss=0.0000000]
Training progress:  36%|███▋      | 730/2000 [09:16<08:21,  2.53it/s, Loss=0.1190183, Gaussian number=193064, print grad=0.0013530532596632838, Depth Loss=0.0000000]
Training progress:  37%|███▋      | 740/2000 [09:16<08:18,  2.53it/s, Loss=0.1190183, Gaussian number=193064, print grad=0.0013530532596632838, Depth Loss=0.0000000]
Training progress:  37%|███▋      | 740/2000 [09:20<08:18,  2.53it/s, Loss=0.0816409, Gaussian number=193064, print grad=0.0016977902268990874, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 750/2000 [09:20<08:14,  2.53it/s, Loss=0.0816409, Gaussian number=193064, print grad=0.0016977902268990874, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 750/2000 [09:24<08:14,  2.53it/s, Loss=0.0820187, Gaussian number=193064, print grad=0.0020269518718123436, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 760/2000 [09:24<08:10,  2.53it/s, Loss=0.0820187, Gaussian number=193064, print grad=0.0020269518718123436, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 760/2000 [09:28<08:10,  2.53it/s, Loss=0.0706278, Gaussian number=193064, print grad=0.0023841941729187965, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 770/2000 [09:28<08:06,  2.53it/s, Loss=0.0706278, Gaussian number=193064, print grad=0.0023841941729187965, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 770/2000 [09:32<08:06,  2.53it/s, Loss=0.1002486, Gaussian number=193064, print grad=0.0027078031562268734, Depth Loss=0.0000000]
Training progress:  39%|███▉      | 780/2000 [09:32<08:01,  2.53it/s, Loss=0.1002486, Gaussian number=193064, print grad=0.0027078031562268734, Depth Loss=0.0000000]
Training progress:  39%|███▉      | 780/2000 [09:36<08:01,  2.53it/s, Loss=0.1176203, Gaussian number=193064, print grad=0.003043226897716522, Depth Loss=0.0000000] 
Training progress:  40%|███▉      | 790/2000 [09:36<07:58,  2.53it/s, Loss=0.1176203, Gaussian number=193064, print grad=0.003043226897716522, Depth Loss=0.0000000]
Training progress:  40%|███▉      | 790/2000 [09:40<07:58,  2.53it/s, Loss=0.0953521, Gaussian number=193064, print grad=0.003388863056898117, Depth Loss=0.0000000]
Training progress:  40%|████      | 800/2000 [09:40<07:53,  2.53it/s, Loss=0.0953521, Gaussian number=193064, print grad=0.003388863056898117, Depth Loss=0.0000000]
Training progress:  40%|████      | 800/2000 [09:44<07:53,  2.53it/s, Loss=0.0952393, Gaussian number=202090, print grad=0.00030885421438142657, Depth Loss=0.0000000]
Training progress:  40%|████      | 810/2000 [09:44<07:49,  2.53it/s, Loss=0.0952393, Gaussian number=202090, print grad=0.00030885421438142657, Depth Loss=0.0000000]
Training progress:  40%|████      | 810/2000 [09:48<07:49,  2.53it/s, Loss=0.0915688, Gaussian number=202090, print grad=0.0006595957675017416, Depth Loss=0.0000000] 
Training progress:  41%|████      | 820/2000 [09:48<07:46,  2.53it/s, Loss=0.0915688, Gaussian number=202090, print grad=0.0006595957675017416, Depth Loss=0.0000000]
Training progress:  41%|████      | 820/2000 [09:52<07:46,  2.53it/s, Loss=0.0741798, Gaussian number=202090, print grad=0.0010512538719922304, Depth Loss=0.0000000]
Training progress:  42%|████▏     | 830/2000 [09:52<07:44,  2.52it/s, Loss=0.0741798, Gaussian number=202090, print grad=0.0010512538719922304, Depth Loss=0.0000000]
Training progress:  42%|████▏     | 830/2000 [09:56<07:44,  2.52it/s, Loss=0.0822100, Gaussian number=202090, print grad=0.0014023850671947002, Depth Loss=0.0000000]
Training progress:  42%|████▏     | 840/2000 [09:56<07:39,  2.53it/s, Loss=0.0822100, Gaussian number=202090, print grad=0.0014023850671947002, Depth Loss=0.0000000]
Training progress:  42%|████▏     | 840/2000 [10:00<07:39,  2.53it/s, Loss=0.0787805, Gaussian number=202090, print grad=0.001747134025208652, Depth Loss=0.0000000] 
Training progress:  42%|████▎     | 850/2000 [10:00<07:34,  2.53it/s, Loss=0.0787805, Gaussian number=202090, print grad=0.001747134025208652, Depth Loss=0.0000000]
Training progress:  42%|████▎     | 850/2000 [10:04<07:34,  2.53it/s, Loss=0.0804814, Gaussian number=202090, print grad=0.00206984905526042, Depth Loss=0.0000000] 
Training progress:  43%|████▎     | 860/2000 [10:04<07:30,  2.53it/s, Loss=0.0804814, Gaussian number=202090, print grad=0.00206984905526042, Depth Loss=0.0000000]
Training progress:  43%|████▎     | 860/2000 [10:08<07:30,  2.53it/s, Loss=0.0934541, Gaussian number=202090, print grad=0.0023955546785146, Depth Loss=0.0000000] 
Training progress:  44%|████▎     | 870/2000 [10:08<07:26,  2.53it/s, Loss=0.0934541, Gaussian number=202090, print grad=0.0023955546785146, Depth Loss=0.0000000]
Training progress:  44%|████▎     | 870/2000 [10:12<07:26,  2.53it/s, Loss=0.0862697, Gaussian number=202090, print grad=0.0027347251307219267, Depth Loss=0.0000000]
Training progress:  44%|████▍     | 880/2000 [10:12<07:22,  2.53it/s, Loss=0.0862697, Gaussian number=202090, print grad=0.0027347251307219267, Depth Loss=0.0000000]
Training progress:  44%|████▍     | 880/2000 [10:15<07:22,  2.53it/s, Loss=0.0693186, Gaussian number=202090, print grad=0.003069897647947073, Depth Loss=0.0000000] 
Training progress:  44%|████▍     | 890/2000 [10:15<07:17,  2.53it/s, Loss=0.0693186, Gaussian number=202090, print grad=0.003069897647947073, Depth Loss=0.0000000]
Training progress:  44%|████▍     | 890/2000 [10:19<07:17,  2.53it/s, Loss=0.0918934, Gaussian number=202090, print grad=0.003419226501137018, Depth Loss=0.0000000]
Training progress:  45%|████▌     | 900/2000 [10:19<07:13,  2.54it/s, Loss=0.0918934, Gaussian number=202090, print grad=0.003419226501137018, Depth Loss=0.0000000]
Training progress:  45%|████▌     | 900/2000 [10:23<07:13,  2.54it/s, Loss=0.0778230, Gaussian number=212075, print grad=0.0003038909053429961, Depth Loss=0.0000000]
Training progress:  46%|████▌     | 910/2000 [10:23<07:09,  2.54it/s, Loss=0.0778230, Gaussian number=212075, print grad=0.0003038909053429961, Depth Loss=0.0000000]
Training progress:  46%|████▌     | 910/2000 [10:27<07:09,  2.54it/s, Loss=0.0872284, Gaussian number=212075, print grad=0.0006300872773863375, Depth Loss=0.0000000]
Training progress:  46%|████▌     | 920/2000 [10:27<07:05,  2.54it/s, Loss=0.0872284, Gaussian number=212075, print grad=0.0006300872773863375, Depth Loss=0.0000000]
Training progress:  46%|████▌     | 920/2000 [10:31<07:05,  2.54it/s, Loss=0.0886378, Gaussian number=212075, print grad=0.0010161285754293203, Depth Loss=0.0000000]
Training progress:  46%|████▋     | 930/2000 [10:31<07:02,  2.53it/s, Loss=0.0886378, Gaussian number=212075, print grad=0.0010161285754293203, Depth Loss=0.0000000]
Training progress:  46%|████▋     | 930/2000 [10:35<07:02,  2.53it/s, Loss=0.0804400, Gaussian number=212075, print grad=0.0013612326001748443, Depth Loss=0.0000000]
Training progress:  47%|████▋     | 940/2000 [10:35<06:58,  2.53it/s, Loss=0.0804400, Gaussian number=212075, print grad=0.0013612326001748443, Depth Loss=0.0000000]
Training progress:  47%|████▋     | 940/2000 [10:39<06:58,  2.53it/s, Loss=0.0819577, Gaussian number=212075, print grad=0.0016905631637200713, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 950/2000 [10:39<06:54,  2.53it/s, Loss=0.0819577, Gaussian number=212075, print grad=0.0016905631637200713, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 950/2000 [10:43<06:54,  2.53it/s, Loss=0.0793811, Gaussian number=212075, print grad=0.002005558228120208, Depth Loss=0.0000000] 
Training progress:  48%|████▊     | 960/2000 [10:43<06:51,  2.53it/s, Loss=0.0793811, Gaussian number=212075, print grad=0.002005558228120208, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 960/2000 [10:47<06:51,  2.53it/s, Loss=0.1093306, Gaussian number=212075, print grad=0.0023764879442751408, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 970/2000 [10:47<06:47,  2.53it/s, Loss=0.1093306, Gaussian number=212075, print grad=0.0023764879442751408, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 970/2000 [10:51<06:47,  2.53it/s, Loss=0.0621566, Gaussian number=212075, print grad=0.0027097847778350115, Depth Loss=0.0000000]
Training progress:  49%|████▉     | 980/2000 [10:51<06:43,  2.53it/s, Loss=0.0621566, Gaussian number=212075, print grad=0.0027097847778350115, Depth Loss=0.0000000]
Training progress:  49%|████▉     | 980/2000 [10:55<06:43,  2.53it/s, Loss=0.0711603, Gaussian number=212075, print grad=0.0029965508729219437, Depth Loss=0.0000000]
Training progress:  50%|████▉     | 990/2000 [10:55<06:39,  2.53it/s, Loss=0.0711603, Gaussian number=212075, print grad=0.0029965508729219437, Depth Loss=0.0000000]
Training progress:  50%|████▉     | 990/2000 [10:59<06:39,  2.53it/s, Loss=0.0857857, Gaussian number=212075, print grad=0.003272866364568472, Depth Loss=0.0000000] 
Training progress:  50%|█████     | 1000/2000 [10:59<06:35,  2.53it/s, Loss=0.0857857, Gaussian number=212075, print grad=0.003272866364568472, Depth Loss=0.0000000]
Training progress:  50%|█████     | 1000/2000 [12:08<06:35,  2.53it/s, Loss=0.0908632, Gaussian number=222463, print grad=0.00030654965667054057, Depth Loss=0.0000000]
Training progress:  50%|█████     | 1010/2000 [12:08<38:49,  2.35s/it, Loss=0.0908632, Gaussian number=222463, print grad=0.00030654965667054057, Depth Loss=0.0000000]
Training progress:  50%|█████     | 1010/2000 [12:12<38:49,  2.35s/it, Loss=0.1109888, Gaussian number=222463, print grad=0.0006966945948079228, Depth Loss=0.0000000] 
Training progress:  51%|█████     | 1020/2000 [12:12<28:50,  1.77s/it, Loss=0.1109888, Gaussian number=222463, print grad=0.0006966945948079228, Depth Loss=0.0000000]
Training progress:  51%|█████     | 1020/2000 [12:16<28:50,  1.77s/it, Loss=0.0827938, Gaussian number=222463, print grad=0.0010646164882928133, Depth Loss=0.0000000]
Training progress:  52%|█████▏    | 1030/2000 [12:16<21:53,  1.35s/it, Loss=0.0827938, Gaussian number=222463, print grad=0.0010646164882928133, Depth Loss=0.0000000]
Training progress:  52%|█████▏    | 1030/2000 [12:20<21:53,  1.35s/it, Loss=0.0897628, Gaussian number=222463, print grad=0.0014445182168856263, Depth Loss=0.0000000]
Training progress:  52%|█████▏    | 1040/2000 [12:20<17:03,  1.07s/it, Loss=0.0897628, Gaussian number=222463, print grad=0.0014445182168856263, Depth Loss=0.0000000]
Training progress:  52%|█████▏    | 1040/2000 [12:24<17:03,  1.07s/it, Loss=0.0788493, Gaussian number=222463, print grad=0.0017341090133413672, Depth Loss=0.0000000]
Training progress:  52%|█████▎    | 1050/2000 [12:24<13:41,  1.16it/s, Loss=0.0788493, Gaussian number=222463, print grad=0.0017341090133413672, Depth Loss=0.0000000]
Training progress:  52%|█████▎    | 1050/2000 [12:28<13:41,  1.16it/s, Loss=0.0696289, Gaussian number=222463, print grad=0.002059899503365159, Depth Loss=0.0000000] 
Training progress:  53%|█████▎    | 1060/2000 [12:28<11:20,  1.38it/s, Loss=0.0696289, Gaussian number=222463, print grad=0.002059899503365159, Depth Loss=0.0000000]
Training progress:  53%|█████▎    | 1060/2000 [12:32<11:20,  1.38it/s, Loss=0.0584182, Gaussian number=222463, print grad=0.002399906050413847, Depth Loss=0.0000000]
Training progress:  54%|█████▎    | 1070/2000 [12:32<09:41,  1.60it/s, Loss=0.0584182, Gaussian number=222463, print grad=0.002399906050413847, Depth Loss=0.0000000]
Training progress:  54%|█████▎    | 1070/2000 [12:36<09:41,  1.60it/s, Loss=0.0630405, Gaussian number=222463, print grad=0.0027176574803888798, Depth Loss=0.0000000]
Training progress:  54%|█████▍    | 1080/2000 [12:36<08:31,  1.80it/s, Loss=0.0630405, Gaussian number=222463, print grad=0.0027176574803888798, Depth Loss=0.0000000]
Training progress:  54%|█████▍    | 1080/2000 [12:40<08:31,  1.80it/s, Loss=0.0757281, Gaussian number=222463, print grad=0.003031069179996848, Depth Loss=0.0000000] 
Training progress:  55%|█████▍    | 1090/2000 [12:40<07:42,  1.97it/s, Loss=0.0757281, Gaussian number=222463, print grad=0.003031069179996848, Depth Loss=0.0000000]
Training progress:  55%|█████▍    | 1090/2000 [12:44<07:42,  1.97it/s, Loss=0.0847409, Gaussian number=222463, print grad=0.0033438829705119133, Depth Loss=0.0000000]
Training progress:  55%|█████▌    | 1100/2000 [12:44<07:06,  2.11it/s, Loss=0.0847409, Gaussian number=222463, print grad=0.0033438829705119133, Depth Loss=0.0000000]
Training progress:  55%|█████▌    | 1100/2000 [12:48<07:06,  2.11it/s, Loss=0.0928919, Gaussian number=233308, print grad=0.0003109680546913296, Depth Loss=0.0000000]
Training progress:  56%|█████▌    | 1110/2000 [12:48<06:40,  2.22it/s, Loss=0.0928919, Gaussian number=233308, print grad=0.0003109680546913296, Depth Loss=0.0000000]
Training progress:  56%|█████▌    | 1110/2000 [12:51<06:40,  2.22it/s, Loss=0.0835790, Gaussian number=233308, print grad=0.0006827474571764469, Depth Loss=0.0000000]
Training progress:  56%|█████▌    | 1120/2000 [12:51<06:20,  2.31it/s, Loss=0.0835790, Gaussian number=233308, print grad=0.0006827474571764469, Depth Loss=0.0000000]
Training progress:  56%|█████▌    | 1120/2000 [12:55<06:20,  2.31it/s, Loss=0.0624141, Gaussian number=233308, print grad=0.0010515389731153846, Depth Loss=0.0000000]
Training progress:  56%|█████▋    | 1130/2000 [12:55<06:06,  2.37it/s, Loss=0.0624141, Gaussian number=233308, print grad=0.0010515389731153846, Depth Loss=0.0000000]
Training progress:  56%|█████▋    | 1130/2000 [12:59<06:06,  2.37it/s, Loss=0.0824526, Gaussian number=233308, print grad=0.0014100843109190464, Depth Loss=0.0000000]
Training progress:  57%|█████▋    | 1140/2000 [12:59<05:54,  2.43it/s, Loss=0.0824526, Gaussian number=233308, print grad=0.0014100843109190464, Depth Loss=0.0000000]
Training progress:  57%|█████▋    | 1140/2000 [13:03<05:54,  2.43it/s, Loss=0.0547775, Gaussian number=233308, print grad=0.0017400633078068495, Depth Loss=0.0000000]
Training progress:  57%|█████▊    | 1150/2000 [13:03<05:45,  2.46it/s, Loss=0.0547775, Gaussian number=233308, print grad=0.0017400633078068495, Depth Loss=0.0000000]
Training progress:  57%|█████▊    | 1150/2000 [13:07<05:45,  2.46it/s, Loss=0.0625099, Gaussian number=233308, print grad=0.0020604573655873537, Depth Loss=0.0000000]
Training progress:  58%|█████▊    | 1160/2000 [13:07<05:37,  2.49it/s, Loss=0.0625099, Gaussian number=233308, print grad=0.0020604573655873537, Depth Loss=0.0000000]
Training progress:  58%|█████▊    | 1160/2000 [13:11<05:37,  2.49it/s, Loss=0.0779755, Gaussian number=233308, print grad=0.0023924419656395912, Depth Loss=0.0000000]
Training progress:  58%|█████▊    | 1170/2000 [13:11<05:31,  2.51it/s, Loss=0.0779755, Gaussian number=233308, print grad=0.0023924419656395912, Depth Loss=0.0000000]
Training progress:  58%|█████▊    | 1170/2000 [13:15<05:31,  2.51it/s, Loss=0.0806406, Gaussian number=233308, print grad=0.0027040562126785517, Depth Loss=0.0000000]
Training progress:  59%|█████▉    | 1180/2000 [13:15<05:25,  2.52it/s, Loss=0.0806406, Gaussian number=233308, print grad=0.0027040562126785517, Depth Loss=0.0000000]
Training progress:  59%|█████▉    | 1180/2000 [13:19<05:25,  2.52it/s, Loss=0.0696279, Gaussian number=233308, print grad=0.0030488953925669193, Depth Loss=0.0000000]
Training progress:  60%|█████▉    | 1190/2000 [13:19<05:20,  2.52it/s, Loss=0.0696279, Gaussian number=233308, print grad=0.0030488953925669193, Depth Loss=0.0000000]
Training progress:  60%|█████▉    | 1190/2000 [13:23<05:20,  2.52it/s, Loss=0.0840214, Gaussian number=233308, print grad=0.0033283494412899017, Depth Loss=0.0000000]
Training progress:  60%|██████    | 1200/2000 [13:23<05:15,  2.53it/s, Loss=0.0840214, Gaussian number=233308, print grad=0.0033283494412899017, Depth Loss=0.0000000]
Training progress:  60%|██████    | 1200/2000 [13:27<05:15,  2.53it/s, Loss=0.0637192, Gaussian number=245077, print grad=0.0003157291212119162, Depth Loss=0.0000000]
Training progress:  60%|██████    | 1210/2000 [13:27<05:11,  2.53it/s, Loss=0.0637192, Gaussian number=245077, print grad=0.0003157291212119162, Depth Loss=0.0000000]
Training progress:  60%|██████    | 1210/2000 [13:31<05:11,  2.53it/s, Loss=0.0543554, Gaussian number=245077, print grad=0.0006780392141081393, Depth Loss=0.0000000]
Training progress:  61%|██████    | 1220/2000 [13:31<05:08,  2.53it/s, Loss=0.0543554, Gaussian number=245077, print grad=0.0006780392141081393, Depth Loss=0.0000000]
Training progress:  61%|██████    | 1220/2000 [13:35<05:08,  2.53it/s, Loss=0.0580240, Gaussian number=245077, print grad=0.0009768916061148047, Depth Loss=0.0000000]
Training progress:  62%|██████▏   | 1230/2000 [13:35<05:04,  2.53it/s, Loss=0.0580240, Gaussian number=245077, print grad=0.0009768916061148047, Depth Loss=0.0000000]
Training progress:  62%|██████▏   | 1230/2000 [13:39<05:04,  2.53it/s, Loss=0.0568205, Gaussian number=245077, print grad=0.0013081205543130636, Depth Loss=0.0000000]
Training progress:  62%|██████▏   | 1240/2000 [13:39<05:00,  2.53it/s, Loss=0.0568205, Gaussian number=245077, print grad=0.0013081205543130636, Depth Loss=0.0000000]
Training progress:  62%|██████▏   | 1240/2000 [13:43<05:00,  2.53it/s, Loss=0.0562069, Gaussian number=245077, print grad=0.001612614723853767, Depth Loss=0.0000000] 
Training progress:  62%|██████▎   | 1250/2000 [13:43<04:56,  2.53it/s, Loss=0.0562069, Gaussian number=245077, print grad=0.001612614723853767, Depth Loss=0.0000000]
Training progress:  62%|██████▎   | 1250/2000 [13:47<04:56,  2.53it/s, Loss=0.0578397, Gaussian number=245077, print grad=0.0018992135301232338, Depth Loss=0.0000000]
Training progress:  63%|██████▎   | 1260/2000 [13:47<04:52,  2.53it/s, Loss=0.0578397, Gaussian number=245077, print grad=0.0018992135301232338, Depth Loss=0.0000000]
Training progress:  63%|██████▎   | 1260/2000 [13:51<04:52,  2.53it/s, Loss=0.0795035, Gaussian number=245077, print grad=0.0022129802964627743, Depth Loss=0.0000000]
Training progress:  64%|██████▎   | 1270/2000 [13:51<04:48,  2.53it/s, Loss=0.0795035, Gaussian number=245077, print grad=0.0022129802964627743, Depth Loss=0.0000000]
Training progress:  64%|██████▎   | 1270/2000 [13:55<04:48,  2.53it/s, Loss=0.0728320, Gaussian number=245077, print grad=0.002523637842386961, Depth Loss=0.0000000] 
Training progress:  64%|██████▍   | 1280/2000 [13:55<04:44,  2.53it/s, Loss=0.0728320, Gaussian number=245077, print grad=0.002523637842386961, Depth Loss=0.0000000]
Training progress:  64%|██████▍   | 1280/2000 [13:58<04:44,  2.53it/s, Loss=0.0555718, Gaussian number=245077, print grad=0.0028501192573457956, Depth Loss=0.0000000]
Training progress:  64%|██████▍   | 1290/2000 [13:58<04:40,  2.53it/s, Loss=0.0555718, Gaussian number=245077, print grad=0.0028501192573457956, Depth Loss=0.0000000]
Training progress:  64%|██████▍   | 1290/2000 [14:02<04:40,  2.53it/s, Loss=0.0863893, Gaussian number=245077, print grad=0.003141636960208416, Depth Loss=0.0000000] 
Training progress:  65%|██████▌   | 1300/2000 [14:02<04:36,  2.53it/s, Loss=0.0863893, Gaussian number=245077, print grad=0.003141636960208416, Depth Loss=0.0000000]
Training progress:  65%|██████▌   | 1300/2000 [14:06<04:36,  2.53it/s, Loss=0.0854482, Gaussian number=256390, print grad=0.00032640714198350906, Depth Loss=0.0000000]
Training progress:  66%|██████▌   | 1310/2000 [14:06<04:33,  2.53it/s, Loss=0.0854482, Gaussian number=256390, print grad=0.00032640714198350906, Depth Loss=0.0000000]
Training progress:  66%|██████▌   | 1310/2000 [14:10<04:33,  2.53it/s, Loss=0.0886216, Gaussian number=256390, print grad=0.0006422068690881133, Depth Loss=0.0000000] 
Training progress:  66%|██████▌   | 1320/2000 [14:10<04:29,  2.52it/s, Loss=0.0886216, Gaussian number=256390, print grad=0.0006422068690881133, Depth Loss=0.0000000]
Training progress:  66%|██████▌   | 1320/2000 [14:14<04:29,  2.52it/s, Loss=0.0684384, Gaussian number=256390, print grad=0.0009815830271691084, Depth Loss=0.0000000]
Training progress:  66%|██████▋   | 1330/2000 [14:14<04:25,  2.52it/s, Loss=0.0684384, Gaussian number=256390, print grad=0.0009815830271691084, Depth Loss=0.0000000]
Training progress:  66%|██████▋   | 1330/2000 [14:18<04:25,  2.52it/s, Loss=0.0676650, Gaussian number=256390, print grad=0.0013193852500990033, Depth Loss=0.0000000]
Training progress:  67%|██████▋   | 1340/2000 [14:18<04:21,  2.52it/s, Loss=0.0676650, Gaussian number=256390, print grad=0.0013193852500990033, Depth Loss=0.0000000]
Training progress:  67%|██████▋   | 1340/2000 [14:22<04:21,  2.52it/s, Loss=0.0950886, Gaussian number=256390, print grad=0.0016178665682673454, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1350/2000 [14:22<04:17,  2.52it/s, Loss=0.0950886, Gaussian number=256390, print grad=0.0016178665682673454, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1350/2000 [14:26<04:17,  2.52it/s, Loss=0.0578223, Gaussian number=256390, print grad=0.001910809543915093, Depth Loss=0.0000000] 
Training progress:  68%|██████▊   | 1360/2000 [14:26<04:13,  2.52it/s, Loss=0.0578223, Gaussian number=256390, print grad=0.001910809543915093, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1360/2000 [14:30<04:13,  2.52it/s, Loss=0.1077768, Gaussian number=256390, print grad=0.002221353817731142, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1370/2000 [14:30<04:10,  2.52it/s, Loss=0.1077768, Gaussian number=256390, print grad=0.002221353817731142, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1370/2000 [14:34<04:10,  2.52it/s, Loss=0.0654917, Gaussian number=256390, print grad=0.0025079352781176567, Depth Loss=0.0000000]
Training progress:  69%|██████▉   | 1380/2000 [14:34<04:06,  2.52it/s, Loss=0.0654917, Gaussian number=256390, print grad=0.0025079352781176567, Depth Loss=0.0000000]
Training progress:  69%|██████▉   | 1380/2000 [14:38<04:06,  2.52it/s, Loss=0.0574438, Gaussian number=256390, print grad=0.00278422050178051, Depth Loss=0.0000000]  
Training progress:  70%|██████▉   | 1390/2000 [14:38<04:02,  2.52it/s, Loss=0.0574438, Gaussian number=256390, print grad=0.00278422050178051, Depth Loss=0.0000000]
Training progress:  70%|██████▉   | 1390/2000 [14:42<04:02,  2.52it/s, Loss=0.0649416, Gaussian number=256390, print grad=0.0030814993660897017, Depth Loss=0.0000000]
Training progress:  70%|███████   | 1400/2000 [14:42<03:58,  2.52it/s, Loss=0.0649416, Gaussian number=256390, print grad=0.0030814993660897017, Depth Loss=0.0000000]
Training progress:  70%|███████   | 1400/2000 [14:46<03:58,  2.52it/s, Loss=0.0811887, Gaussian number=268063, print grad=0.0003058287547901273, Depth Loss=0.0000000]
Training progress:  70%|███████   | 1410/2000 [14:46<03:54,  2.52it/s, Loss=0.0811887, Gaussian number=268063, print grad=0.0003058287547901273, Depth Loss=0.0000000]
Training progress:  70%|███████   | 1410/2000 [14:50<03:54,  2.52it/s, Loss=0.0662474, Gaussian number=268063, print grad=0.0006617757608182728, Depth Loss=0.0000000]
Training progress:  71%|███████   | 1420/2000 [14:50<03:49,  2.52it/s, Loss=0.0662474, Gaussian number=268063, print grad=0.0006617757608182728, Depth Loss=0.0000000]
Training progress:  71%|███████   | 1420/2000 [14:54<03:49,  2.52it/s, Loss=0.0740495, Gaussian number=268063, print grad=0.0009997186716645956, Depth Loss=0.0000000]
Training progress:  72%|███████▏  | 1430/2000 [14:54<03:45,  2.53it/s, Loss=0.0740495, Gaussian number=268063, print grad=0.0009997186716645956, Depth Loss=0.0000000]
Training progress:  72%|███████▏  | 1430/2000 [14:58<03:45,  2.53it/s, Loss=0.0632821, Gaussian number=268063, print grad=0.0013043155195191503, Depth Loss=0.0000000]
Training progress:  72%|███████▏  | 1440/2000 [14:58<03:41,  2.53it/s, Loss=0.0632821, Gaussian number=268063, print grad=0.0013043155195191503, Depth Loss=0.0000000]
Training progress:  72%|███████▏  | 1440/2000 [15:02<03:41,  2.53it/s, Loss=0.0619218, Gaussian number=268063, print grad=0.0015950641827657819, Depth Loss=0.0000000]
Training progress:  72%|███████▎  | 1450/2000 [15:02<03:37,  2.53it/s, Loss=0.0619218, Gaussian number=268063, print grad=0.0015950641827657819, Depth Loss=0.0000000]
Training progress:  72%|███████▎  | 1450/2000 [15:06<03:37,  2.53it/s, Loss=0.0505794, Gaussian number=268063, print grad=0.0018796760123223066, Depth Loss=0.0000000]
Training progress:  73%|███████▎  | 1460/2000 [15:06<03:33,  2.53it/s, Loss=0.0505794, Gaussian number=268063, print grad=0.0018796760123223066, Depth Loss=0.0000000]
Training progress:  73%|███████▎  | 1460/2000 [15:10<03:33,  2.53it/s, Loss=0.0700877, Gaussian number=268063, print grad=0.0021785080898553133, Depth Loss=0.0000000]
Training progress:  74%|███████▎  | 1470/2000 [15:10<03:29,  2.53it/s, Loss=0.0700877, Gaussian number=268063, print grad=0.0021785080898553133, Depth Loss=0.0000000]
Training progress:  74%|███████▎  | 1470/2000 [15:14<03:29,  2.53it/s, Loss=0.0696147, Gaussian number=268063, print grad=0.002495243214070797, Depth Loss=0.0000000] 
Training progress:  74%|███████▍  | 1480/2000 [15:14<03:25,  2.53it/s, Loss=0.0696147, Gaussian number=268063, print grad=0.002495243214070797, Depth Loss=0.0000000]
Training progress:  74%|███████▍  | 1480/2000 [15:18<03:25,  2.53it/s, Loss=0.0737760, Gaussian number=268063, print grad=0.002812738763168454, Depth Loss=0.0000000]
Training progress:  74%|███████▍  | 1490/2000 [15:18<03:21,  2.53it/s, Loss=0.0737760, Gaussian number=268063, print grad=0.002812738763168454, Depth Loss=0.0000000]
Training progress:  74%|███████▍  | 1490/2000 [15:22<03:21,  2.53it/s, Loss=0.0734052, Gaussian number=268063, print grad=0.003120790235698223, Depth Loss=0.0000000]
Training progress:  75%|███████▌  | 1500/2000 [15:22<03:17,  2.53it/s, Loss=0.0734052, Gaussian number=268063, print grad=0.003120790235698223, Depth Loss=0.0000000]
Training progress:  75%|███████▌  | 1500/2000 [16:31<03:17,  2.53it/s, Loss=0.0795342, Gaussian number=278912, print grad=0.0002795690961647779, Depth Loss=0.0000000]
Training progress:  76%|███████▌  | 1510/2000 [16:31<19:17,  2.36s/it, Loss=0.0795342, Gaussian number=278912, print grad=0.0002795690961647779, Depth Loss=0.0000000]
Training progress:  76%|███████▌  | 1510/2000 [16:35<19:17,  2.36s/it, Loss=0.0755699, Gaussian number=278912, print grad=0.0005805867840535939, Depth Loss=0.0000000]
Training progress:  76%|███████▌  | 1520/2000 [16:35<14:10,  1.77s/it, Loss=0.0755699, Gaussian number=278912, print grad=0.0005805867840535939, Depth Loss=0.0000000]
Training progress:  76%|███████▌  | 1520/2000 [16:39<14:10,  1.77s/it, Loss=0.0411535, Gaussian number=278912, print grad=0.0009008458000607789, Depth Loss=0.0000000]
Training progress:  76%|███████▋  | 1530/2000 [16:39<10:38,  1.36s/it, Loss=0.0411535, Gaussian number=278912, print grad=0.0009008458000607789, Depth Loss=0.0000000]
Training progress:  76%|███████▋  | 1530/2000 [16:43<10:38,  1.36s/it, Loss=0.0612941, Gaussian number=278912, print grad=0.0011987020261585712, Depth Loss=0.0000000]
Training progress:  77%|███████▋  | 1540/2000 [16:43<08:11,  1.07s/it, Loss=0.0612941, Gaussian number=278912, print grad=0.0011987020261585712, Depth Loss=0.0000000]
Training progress:  77%|███████▋  | 1540/2000 [16:47<08:11,  1.07s/it, Loss=0.0683708, Gaussian number=278912, print grad=0.0015304450644180179, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1550/2000 [16:47<06:29,  1.15it/s, Loss=0.0683708, Gaussian number=278912, print grad=0.0015304450644180179, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1550/2000 [16:51<06:29,  1.15it/s, Loss=0.0669998, Gaussian number=278912, print grad=0.0018566196085885167, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1560/2000 [16:51<05:18,  1.38it/s, Loss=0.0669998, Gaussian number=278912, print grad=0.0018566196085885167, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1560/2000 [16:55<05:18,  1.38it/s, Loss=0.0583691, Gaussian number=278912, print grad=0.0021528322249650955, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1570/2000 [16:55<04:28,  1.60it/s, Loss=0.0583691, Gaussian number=278912, print grad=0.0021528322249650955, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1570/2000 [16:59<04:28,  1.60it/s, Loss=0.0422867, Gaussian number=278912, print grad=0.002389957197010517, Depth Loss=0.0000000] 
Training progress:  79%|███████▉  | 1580/2000 [16:59<03:53,  1.80it/s, Loss=0.0422867, Gaussian number=278912, print grad=0.002389957197010517, Depth Loss=0.0000000]
Training progress:  79%|███████▉  | 1580/2000 [17:03<03:53,  1.80it/s, Loss=0.0564063, Gaussian number=278912, print grad=0.0026699926238507032, Depth Loss=0.0000000]
Training progress:  80%|███████▉  | 1590/2000 [17:03<03:27,  1.97it/s, Loss=0.0564063, Gaussian number=278912, print grad=0.0026699926238507032, Depth Loss=0.0000000]
Training progress:  80%|███████▉  | 1590/2000 [17:07<03:27,  1.97it/s, Loss=0.0580492, Gaussian number=278912, print grad=0.0029693027026951313, Depth Loss=0.0000000]
Training progress:  80%|████████  | 1600/2000 [17:07<03:09,  2.11it/s, Loss=0.0580492, Gaussian number=278912, print grad=0.0029693027026951313, Depth Loss=0.0000000]
Training progress:  80%|████████  | 1600/2000 [17:11<03:09,  2.11it/s, Loss=0.0667107, Gaussian number=288981, print grad=0.0003052922256756574, Depth Loss=0.0000000]
Training progress:  80%|████████  | 1610/2000 [17:11<02:55,  2.22it/s, Loss=0.0667107, Gaussian number=288981, print grad=0.0003052922256756574, Depth Loss=0.0000000]
Training progress:  80%|████████  | 1610/2000 [17:15<02:55,  2.22it/s, Loss=0.0684800, Gaussian number=288981, print grad=0.0006435666000470519, Depth Loss=0.0000000]
Training progress:  81%|████████  | 1620/2000 [17:15<02:45,  2.30it/s, Loss=0.0684800, Gaussian number=288981, print grad=0.0006435666000470519, Depth Loss=0.0000000]
Training progress:  81%|████████  | 1620/2000 [17:19<02:45,  2.30it/s, Loss=0.0566824, Gaussian number=288981, print grad=0.0009352354099974036, Depth Loss=0.0000000]
Training progress:  82%|████████▏ | 1630/2000 [17:19<02:37,  2.35it/s, Loss=0.0566824, Gaussian number=288981, print grad=0.0009352354099974036, Depth Loss=0.0000000]
Training progress:  82%|████████▏ | 1630/2000 [17:23<02:37,  2.35it/s, Loss=0.0431319, Gaussian number=288981, print grad=0.0012297272915020585, Depth Loss=0.0000000]
Training progress:  82%|████████▏ | 1640/2000 [17:23<02:29,  2.40it/s, Loss=0.0431319, Gaussian number=288981, print grad=0.0012297272915020585, Depth Loss=0.0000000]
Training progress:  82%|████████▏ | 1640/2000 [17:26<02:29,  2.40it/s, Loss=0.0595390, Gaussian number=288981, print grad=0.0014974919613450766, Depth Loss=0.0000000]
Training progress:  82%|████████▎ | 1650/2000 [17:26<02:23,  2.44it/s, Loss=0.0595390, Gaussian number=288981, print grad=0.0014974919613450766, Depth Loss=0.0000000]
Training progress:  82%|████████▎ | 1650/2000 [17:30<02:23,  2.44it/s, Loss=0.0574525, Gaussian number=288981, print grad=0.0017903384286910295, Depth Loss=0.0000000]
Training progress:  83%|████████▎ | 1660/2000 [17:30<02:18,  2.46it/s, Loss=0.0574525, Gaussian number=288981, print grad=0.0017903384286910295, Depth Loss=0.0000000]
Training progress:  83%|████████▎ | 1660/2000 [17:34<02:18,  2.46it/s, Loss=0.0525891, Gaussian number=288981, print grad=0.002069445326924324, Depth Loss=0.0000000] 
Training progress:  84%|████████▎ | 1670/2000 [17:34<02:13,  2.48it/s, Loss=0.0525891, Gaussian number=288981, print grad=0.002069445326924324, Depth Loss=0.0000000]
Training progress:  84%|████████▎ | 1670/2000 [17:38<02:13,  2.48it/s, Loss=0.0498421, Gaussian number=288981, print grad=0.0023665146436542273, Depth Loss=0.0000000]
Training progress:  84%|████████▍ | 1680/2000 [17:38<02:08,  2.49it/s, Loss=0.0498421, Gaussian number=288981, print grad=0.0023665146436542273, Depth Loss=0.0000000]
Training progress:  84%|████████▍ | 1680/2000 [17:42<02:08,  2.49it/s, Loss=0.0584464, Gaussian number=288981, print grad=0.002642990555614233, Depth Loss=0.0000000] 
Training progress:  84%|████████▍ | 1690/2000 [17:42<02:04,  2.50it/s, Loss=0.0584464, Gaussian number=288981, print grad=0.002642990555614233, Depth Loss=0.0000000]
Training progress:  84%|████████▍ | 1690/2000 [17:46<02:04,  2.50it/s, Loss=0.0610818, Gaussian number=288981, print grad=0.0028937996830791235, Depth Loss=0.0000000]
Training progress:  85%|████████▌ | 1700/2000 [17:46<01:59,  2.51it/s, Loss=0.0610818, Gaussian number=288981, print grad=0.0028937996830791235, Depth Loss=0.0000000]
Training progress:  85%|████████▌ | 1700/2000 [17:50<01:59,  2.51it/s, Loss=0.0634892, Gaussian number=299090, print grad=0.00029696282581426203, Depth Loss=0.0000000]
Training progress:  86%|████████▌ | 1710/2000 [17:50<01:55,  2.51it/s, Loss=0.0634892, Gaussian number=299090, print grad=0.00029696282581426203, Depth Loss=0.0000000]
Training progress:  86%|████████▌ | 1710/2000 [17:54<01:55,  2.51it/s, Loss=0.0741313, Gaussian number=299090, print grad=0.0005595731199719012, Depth Loss=0.0000000] 
Training progress:  86%|████████▌ | 1720/2000 [17:54<01:51,  2.51it/s, Loss=0.0741313, Gaussian number=299090, print grad=0.0005595731199719012, Depth Loss=0.0000000]
Training progress:  86%|████████▌ | 1720/2000 [17:58<01:51,  2.51it/s, Loss=0.0587883, Gaussian number=299090, print grad=0.0008466494618915021, Depth Loss=0.0000000]
Training progress:  86%|████████▋ | 1730/2000 [17:58<01:47,  2.51it/s, Loss=0.0587883, Gaussian number=299090, print grad=0.0008466494618915021, Depth Loss=0.0000000]
Training progress:  86%|████████▋ | 1730/2000 [18:02<01:47,  2.51it/s, Loss=0.0854240, Gaussian number=299090, print grad=0.0011621444718912244, Depth Loss=0.0000000]
Training progress:  87%|████████▋ | 1740/2000 [18:02<01:43,  2.51it/s, Loss=0.0854240, Gaussian number=299090, print grad=0.0011621444718912244, Depth Loss=0.0000000]
Training progress:  87%|████████▋ | 1740/2000 [18:06<01:43,  2.51it/s, Loss=0.0828997, Gaussian number=299090, print grad=0.001471459399908781, Depth Loss=0.0000000] 
Training progress:  88%|████████▊ | 1750/2000 [18:06<01:39,  2.52it/s, Loss=0.0828997, Gaussian number=299090, print grad=0.001471459399908781, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1750/2000 [18:10<01:39,  2.52it/s, Loss=0.0620074, Gaussian number=299090, print grad=0.0017332067945972085, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1760/2000 [18:10<01:35,  2.52it/s, Loss=0.0620074, Gaussian number=299090, print grad=0.0017332067945972085, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1760/2000 [18:14<01:35,  2.52it/s, Loss=0.0492257, Gaussian number=299090, print grad=0.0019959372002631426, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1770/2000 [18:14<01:31,  2.52it/s, Loss=0.0492257, Gaussian number=299090, print grad=0.0019959372002631426, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1770/2000 [18:18<01:31,  2.52it/s, Loss=0.0591777, Gaussian number=299090, print grad=0.002251395722851157, Depth Loss=0.0000000] 
Training progress:  89%|████████▉ | 1780/2000 [18:18<01:27,  2.52it/s, Loss=0.0591777, Gaussian number=299090, print grad=0.002251395722851157, Depth Loss=0.0000000]
Training progress:  89%|████████▉ | 1780/2000 [18:22<01:27,  2.52it/s, Loss=0.0534949, Gaussian number=299090, print grad=0.002470561070367694, Depth Loss=0.0000000]
Training progress:  90%|████████▉ | 1790/2000 [18:22<01:23,  2.52it/s, Loss=0.0534949, Gaussian number=299090, print grad=0.002470561070367694, Depth Loss=0.0000000]
Training progress:  90%|████████▉ | 1790/2000 [18:26<01:23,  2.52it/s, Loss=0.0515552, Gaussian number=299090, print grad=0.0027535236440598965, Depth Loss=0.0000000]
Training progress:  90%|█████████ | 1800/2000 [18:26<01:19,  2.52it/s, Loss=0.0515552, Gaussian number=299090, print grad=0.0027535236440598965, Depth Loss=0.0000000]
Training progress:  90%|█████████ | 1800/2000 [18:30<01:19,  2.52it/s, Loss=0.0651418, Gaussian number=308632, print grad=0.00030384366982616484, Depth Loss=0.0000000]
Training progress:  90%|█████████ | 1810/2000 [18:30<01:15,  2.52it/s, Loss=0.0651418, Gaussian number=308632, print grad=0.00030384366982616484, Depth Loss=0.0000000]
Training progress:  90%|█████████ | 1810/2000 [18:34<01:15,  2.52it/s, Loss=0.0523546, Gaussian number=308632, print grad=0.0006085641216486692, Depth Loss=0.0000000] 
Training progress:  91%|█████████ | 1820/2000 [18:34<01:11,  2.53it/s, Loss=0.0523546, Gaussian number=308632, print grad=0.0006085641216486692, Depth Loss=0.0000000]
Training progress:  91%|█████████ | 1820/2000 [18:38<01:11,  2.53it/s, Loss=0.0529807, Gaussian number=308632, print grad=0.000865900656208396, Depth Loss=0.0000000] 
Training progress:  92%|█████████▏| 1830/2000 [18:38<01:07,  2.53it/s, Loss=0.0529807, Gaussian number=308632, print grad=0.000865900656208396, Depth Loss=0.0000000]
Training progress:  92%|█████████▏| 1830/2000 [18:42<01:07,  2.53it/s, Loss=0.0475357, Gaussian number=308632, print grad=0.0011463072150945663, Depth Loss=0.0000000]
Training progress:  92%|█████████▏| 1840/2000 [18:42<01:03,  2.53it/s, Loss=0.0475357, Gaussian number=308632, print grad=0.0011463072150945663, Depth Loss=0.0000000]
Training progress:  92%|█████████▏| 1840/2000 [18:46<01:03,  2.53it/s, Loss=0.0535771, Gaussian number=308632, print grad=0.0014135001692920923, Depth Loss=0.0000000]
Training progress:  92%|█████████▎| 1850/2000 [18:46<00:59,  2.53it/s, Loss=0.0535771, Gaussian number=308632, print grad=0.0014135001692920923, Depth Loss=0.0000000]
Training progress:  92%|█████████▎| 1850/2000 [18:50<00:59,  2.53it/s, Loss=0.0618667, Gaussian number=308632, print grad=0.0016380612505599856, Depth Loss=0.0000000]
Training progress:  93%|█████████▎| 1860/2000 [18:50<00:55,  2.53it/s, Loss=0.0618667, Gaussian number=308632, print grad=0.0016380612505599856, Depth Loss=0.0000000]
Training progress:  93%|█████████▎| 1860/2000 [18:54<00:55,  2.53it/s, Loss=0.0645047, Gaussian number=308632, print grad=0.0019351098453626037, Depth Loss=0.0000000]
Training progress:  94%|█████████▎| 1870/2000 [18:54<00:51,  2.53it/s, Loss=0.0645047, Gaussian number=308632, print grad=0.0019351098453626037, Depth Loss=0.0000000]
Training progress:  94%|█████████▎| 1870/2000 [18:58<00:51,  2.53it/s, Loss=0.0460233, Gaussian number=308632, print grad=0.0021930711809545755, Depth Loss=0.0000000]
Training progress:  94%|█████████▍| 1880/2000 [18:58<00:47,  2.53it/s, Loss=0.0460233, Gaussian number=308632, print grad=0.0021930711809545755, Depth Loss=0.0000000]
Training progress:  94%|█████████▍| 1880/2000 [19:02<00:47,  2.53it/s, Loss=0.0566101, Gaussian number=308632, print grad=0.002442405093461275, Depth Loss=0.0000000] 
Training progress:  94%|█████████▍| 1890/2000 [19:02<00:43,  2.53it/s, Loss=0.0566101, Gaussian number=308632, print grad=0.002442405093461275, Depth Loss=0.0000000]
Training progress:  94%|█████████▍| 1890/2000 [19:06<00:43,  2.53it/s, Loss=0.0732068, Gaussian number=308632, print grad=0.0027304976247251034, Depth Loss=0.0000000]
Training progress:  95%|█████████▌| 1900/2000 [19:06<00:39,  2.53it/s, Loss=0.0732068, Gaussian number=308632, print grad=0.0027304976247251034, Depth Loss=0.0000000]
Training progress:  95%|█████████▌| 1900/2000 [19:09<00:39,  2.53it/s, Loss=0.0607200, Gaussian number=319513, print grad=0.0002514420193620026, Depth Loss=0.0000000]
Training progress:  96%|█████████▌| 1910/2000 [19:09<00:35,  2.53it/s, Loss=0.0607200, Gaussian number=319513, print grad=0.0002514420193620026, Depth Loss=0.0000000]
Training progress:  96%|█████████▌| 1910/2000 [19:13<00:35,  2.53it/s, Loss=0.0498524, Gaussian number=319513, print grad=0.0005270629771985114, Depth Loss=0.0000000]
Training progress:  96%|█████████▌| 1920/2000 [19:13<00:31,  2.53it/s, Loss=0.0498524, Gaussian number=319513, print grad=0.0005270629771985114, Depth Loss=0.0000000]
Training progress:  96%|█████████▌| 1920/2000 [19:17<00:31,  2.53it/s, Loss=0.0440818, Gaussian number=319513, print grad=0.0008098158286884427, Depth Loss=0.0000000]
Training progress:  96%|█████████▋| 1930/2000 [19:17<00:27,  2.53it/s, Loss=0.0440818, Gaussian number=319513, print grad=0.0008098158286884427, Depth Loss=0.0000000]
Training progress:  96%|█████████▋| 1930/2000 [19:21<00:27,  2.53it/s, Loss=0.0643150, Gaussian number=319513, print grad=0.0010666961316019297, Depth Loss=0.0000000]
Training progress:  97%|█████████▋| 1940/2000 [19:21<00:23,  2.53it/s, Loss=0.0643150, Gaussian number=319513, print grad=0.0010666961316019297, Depth Loss=0.0000000]
Training progress:  97%|█████████▋| 1940/2000 [19:25<00:23,  2.53it/s, Loss=0.0465439, Gaussian number=319513, print grad=0.0013256408274173737, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1950/2000 [19:25<00:19,  2.53it/s, Loss=0.0465439, Gaussian number=319513, print grad=0.0013256408274173737, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1950/2000 [19:29<00:19,  2.53it/s, Loss=0.0778133, Gaussian number=319513, print grad=0.0015685802791267633, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1960/2000 [19:29<00:15,  2.53it/s, Loss=0.0778133, Gaussian number=319513, print grad=0.0015685802791267633, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1960/2000 [19:33<00:15,  2.53it/s, Loss=0.0702802, Gaussian number=319513, print grad=0.0018319961382076144, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1970/2000 [19:33<00:11,  2.53it/s, Loss=0.0702802, Gaussian number=319513, print grad=0.0018319961382076144, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1970/2000 [19:37<00:11,  2.53it/s, Loss=0.0549540, Gaussian number=319513, print grad=0.0020946781150996685, Depth Loss=0.0000000]
Training progress:  99%|█████████▉| 1980/2000 [19:37<00:07,  2.53it/s, Loss=0.0549540, Gaussian number=319513, print grad=0.0020946781150996685, Depth Loss=0.0000000]
Training progress:  99%|█████████▉| 1980/2000 [19:41<00:07,  2.53it/s, Loss=0.0512104, Gaussian number=319513, print grad=0.002399763325229287, Depth Loss=0.0000000] 
Training progress: 100%|█████████▉| 1990/2000 [19:41<00:03,  2.53it/s, Loss=0.0512104, Gaussian number=319513, print grad=0.002399763325229287, Depth Loss=0.0000000]
Training progress: 100%|█████████▉| 1990/2000 [19:45<00:03,  2.53it/s, Loss=0.0389631, Gaussian number=319513, print grad=0.002672543516382575, Depth Loss=0.0000000]
Training progress: 100%|██████████| 2000/2000 [19:45<00:00,  2.53it/s, Loss=0.0389631, Gaussian number=319513, print grad=0.002672543516382575, Depth Loss=0.0000000]
Training progress: 100%|██████████| 2000/2000 [19:45<00:00,  1.69it/s, Loss=0.0389631, Gaussian number=319513, print grad=0.002672543516382575, Depth Loss=0.0000000]
Iteration 100 [03/12 18:44:52]

[ITER 100] Evaluating test: WD 0.210327, PSNR 12.7817,lpips 0.601511,ssim 0.440966 [03/12 18:45:50]

[ITER 100] Evaluating train: WD 0.220265, PSNR 13.0765,lpips 0.603720,ssim 0.458448 [03/12 18:45:58]
Gaussian number:182686,print gradients:2.712473906285595e-05 [03/12 18:45:58]
Iteration 200 [03/12 18:46:37]

[ITER 200] Evaluating test: WD 0.190842, PSNR 14.2059,lpips 0.551557,ssim 0.473000 [03/12 18:47:35]

[ITER 200] Evaluating train: WD 0.193718, PSNR 14.3651,lpips 0.542126,ssim 0.486962 [03/12 18:47:43]
Gaussian number:182686,print gradients:3.2605174055788666e-05 [03/12 18:47:43]
Iteration 300 [03/12 18:48:22]

[ITER 300] Evaluating test: WD 0.178584, PSNR 14.8792,lpips 0.519868,ssim 0.489838 [03/12 18:49:20]

[ITER 300] Evaluating train: WD 0.181628, PSNR 15.1385,lpips 0.508171,ssim 0.503001 [03/12 18:49:28]
Gaussian number:182686,print gradients:3.577826646505855e-05 [03/12 18:49:28]
Iteration 400 [03/12 18:50:07]
Iteration 500 [03/12 18:50:47]

[ITER 500] Evaluating test: WD 0.165830, PSNR 15.6644,lpips 0.487808,ssim 0.507745 [03/12 18:51:45]

[ITER 500] Evaluating train: WD 0.178633, PSNR 15.6343,lpips 0.487432,ssim 0.512650 [03/12 18:51:52]
Gaussian number:182686,print gradients:3.949072561226785e-05 [03/12 18:51:53]
Iteration 600 [03/12 18:52:32]
Iteration 700 [03/12 18:53:11]
Iteration 800 [03/12 18:53:51]
Iteration 900 [03/12 18:54:30]
Iteration 1000 [03/12 18:55:10]

[ITER 1000] Evaluating test: WD 0.149564, PSNR 16.3820,lpips 0.437351,ssim 0.514408 [03/12 18:56:08]

[ITER 1000] Evaluating train: WD 0.161573, PSNR 16.6517,lpips 0.441219,ssim 0.519709 [03/12 18:56:15]
Gaussian number:212075,print gradients:nan [03/12 18:56:15]
Iteration 1100 [03/12 18:56:54]
Iteration 1200 [03/12 18:57:34]
Iteration 1300 [03/12 18:58:13]
Iteration 1400 [03/12 18:58:53]
Iteration 1500 [03/12 18:59:32]

[ITER 1500] Evaluating test: WD 0.137453, PSNR 16.7290,lpips 0.403377,ssim 0.515487 [03/12 19:00:31]

[ITER 1500] Evaluating train: WD 0.148402, PSNR 17.0288,lpips 0.406175,ssim 0.520152 [03/12 19:00:38]
Gaussian number:268063,print gradients:nan [03/12 19:00:38]
Iteration 1600 [03/12 19:01:17]
Iteration 1700 [03/12 19:01:57]
Iteration 1800 [03/12 19:02:37]
Iteration 1900 [03/12 19:03:16]
Iteration 2000 [03/12 19:03:56]

[ITER 2000] Evaluating test: WD 0.128273, PSNR 17.0388,lpips 0.382292,ssim 0.524360 [03/12 19:04:54]

[ITER 2000] Evaluating train: WD 0.143958, PSNR 17.5232,lpips 0.393582,ssim 0.522149 [03/12 19:05:02]
Gaussian number:319513,print gradients:nan [03/12 19:05:02]

[ITER 2000] Saving Gaussians [03/12 19:05:02]

Training complete. [03/12 19:05:05]
