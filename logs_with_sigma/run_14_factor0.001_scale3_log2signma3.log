Optimizing /home/cw4287/gaussian-model/train_30k
Output folder: /home/cw4287/gaussian-model/train_30k [03/12 21:06:49]
Tensorboard not available: not logging progress [03/12 21:06:49]
------------LLFF HOLD------------- [03/12 21:06:50]

Reading camera 1/301
Reading camera 2/301
Reading camera 3/301
Reading camera 4/301
Reading camera 5/301
Reading camera 6/301
Reading camera 7/301
Reading camera 8/301
Reading camera 9/301
Reading camera 10/301
Reading camera 11/301
Reading camera 12/301
Reading camera 13/301
Reading camera 14/301
Reading camera 15/301
Reading camera 16/301
Reading camera 17/301
Reading camera 18/301
Reading camera 19/301
Reading camera 20/301
Reading camera 21/301
Reading camera 22/301
Reading camera 23/301
Reading camera 24/301
Reading camera 25/301
Reading camera 26/301
Reading camera 27/301
Reading camera 28/301
Reading camera 29/301
Reading camera 30/301
Reading camera 31/301
Reading camera 32/301
Reading camera 33/301
Reading camera 34/301
Reading camera 35/301
Reading camera 36/301
Reading camera 37/301
Reading camera 38/301
Reading camera 39/301
Reading camera 40/301
Reading camera 41/301
Reading camera 42/301
Reading camera 43/301
Reading camera 44/301
Reading camera 45/301
Reading camera 46/301
Reading camera 47/301
Reading camera 48/301
Reading camera 49/301
Reading camera 50/301
Reading camera 51/301
Reading camera 52/301
Reading camera 53/301
Reading camera 54/301
Reading camera 55/301
Reading camera 56/301
Reading camera 57/301
Reading camera 58/301
Reading camera 59/301
Reading camera 60/301
Reading camera 61/301
Reading camera 62/301
Reading camera 63/301
Reading camera 64/301
Reading camera 65/301
Reading camera 66/301
Reading camera 67/301
Reading camera 68/301
Reading camera 69/301
Reading camera 70/301
Reading camera 71/301
Reading camera 72/301
Reading camera 73/301
Reading camera 74/301
Reading camera 75/301
Reading camera 76/301
Reading camera 77/301
Reading camera 78/301
Reading camera 79/301
Reading camera 80/301
Reading camera 81/301
Reading camera 82/301
Reading camera 83/301
Reading camera 84/301
Reading camera 85/301
Reading camera 86/301
Reading camera 87/301
Reading camera 88/301
Reading camera 89/301
Reading camera 90/301
Reading camera 91/301
Reading camera 92/301
Reading camera 93/301
Reading camera 94/301
Reading camera 95/301
Reading camera 96/301
Reading camera 97/301
Reading camera 98/301
Reading camera 99/301
Reading camera 100/301
Reading camera 101/301
Reading camera 102/301
Reading camera 103/301
Reading camera 104/301
Reading camera 105/301
Reading camera 106/301
Reading camera 107/301
Reading camera 108/301
Reading camera 109/301
Reading camera 110/301
Reading camera 111/301
Reading camera 112/301
Reading camera 113/301
Reading camera 114/301
Reading camera 115/301
Reading camera 116/301
Reading camera 117/301
Reading camera 118/301
Reading camera 119/301
Reading camera 120/301
Reading camera 121/301
Reading camera 122/301
Reading camera 123/301
Reading camera 124/301
Reading camera 125/301
Reading camera 126/301
Reading camera 127/301
Reading camera 128/301
Reading camera 129/301
Reading camera 130/301
Reading camera 131/301
Reading camera 132/301
Reading camera 133/301
Reading camera 134/301
Reading camera 135/301
Reading camera 136/301
Reading camera 137/301
Reading camera 138/301
Reading camera 139/301
Reading camera 140/301
Reading camera 141/301
Reading camera 142/301
Reading camera 143/301
Reading camera 144/301
Reading camera 145/301
Reading camera 146/301
Reading camera 147/301
Reading camera 148/301
Reading camera 149/301
Reading camera 150/301
Reading camera 151/301
Reading camera 152/301
Reading camera 153/301
Reading camera 154/301
Reading camera 155/301
Reading camera 156/301
Reading camera 157/301
Reading camera 158/301
Reading camera 159/301
Reading camera 160/301
Reading camera 161/301
Reading camera 162/301
Reading camera 163/301
Reading camera 164/301
Reading camera 165/301
Reading camera 166/301
Reading camera 167/301
Reading camera 168/301
Reading camera 169/301
Reading camera 170/301
Reading camera 171/301
Reading camera 172/301
Reading camera 173/301
Reading camera 174/301
Reading camera 175/301
Reading camera 176/301
Reading camera 177/301
Reading camera 178/301
Reading camera 179/301
Reading camera 180/301
Reading camera 181/301
Reading camera 182/301
Reading camera 183/301
Reading camera 184/301
Reading camera 185/301
Reading camera 186/301
Reading camera 187/301
Reading camera 188/301
Reading camera 189/301
Reading camera 190/301
Reading camera 191/301
Reading camera 192/301
Reading camera 193/301
Reading camera 194/301
Reading camera 195/301
Reading camera 196/301
Reading camera 197/301
Reading camera 198/301
Reading camera 199/301
Reading camera 200/301
Reading camera 201/301
Reading camera 202/301
Reading camera 203/301
Reading camera 204/301
Reading camera 205/301
Reading camera 206/301
Reading camera 207/301
Reading camera 208/301
Reading camera 209/301
Reading camera 210/301
Reading camera 211/301
Reading camera 212/301
Reading camera 213/301
Reading camera 214/301
Reading camera 215/301
Reading camera 216/301
Reading camera 217/301
Reading camera 218/301
Reading camera 219/301
Reading camera 220/301
Reading camera 221/301
Reading camera 222/301
Reading camera 223/301
Reading camera 224/301
Reading camera 225/301
Reading camera 226/301
Reading camera 227/301
Reading camera 228/301
Reading camera 229/301
Reading camera 230/301
Reading camera 231/301
Reading camera 232/301
Reading camera 233/301
Reading camera 234/301
Reading camera 235/301
Reading camera 236/301
Reading camera 237/301
Reading camera 238/301
Reading camera 239/301
Reading camera 240/301
Reading camera 241/301
Reading camera 242/301
Reading camera 243/301
Reading camera 244/301
Reading camera 245/301
Reading camera 246/301
Reading camera 247/301
Reading camera 248/301
Reading camera 249/301
Reading camera 250/301
Reading camera 251/301
Reading camera 252/301
Reading camera 253/301
Reading camera 254/301
Reading camera 255/301
Reading camera 256/301
Reading camera 257/301
Reading camera 258/301
Reading camera 259/301
Reading camera 260/301
Reading camera 261/301
Reading camera 262/301
Reading camera 263/301
Reading camera 264/301
Reading camera 265/301
Reading camera 266/301
Reading camera 267/301
Reading camera 268/301
Reading camera 269/301
Reading camera 270/301
Reading camera 271/301
Reading camera 272/301
Reading camera 273/301
Reading camera 274/301
Reading camera 275/301
Reading camera 276/301
Reading camera 277/301
Reading camera 278/301
Reading camera 279/301
Reading camera 280/301
Reading camera 281/301
Reading camera 282/301
Reading camera 283/301
Reading camera 284/301
Reading camera 285/301
Reading camera 286/301
Reading camera 287/301
Reading camera 288/301
Reading camera 289/301
Reading camera 290/301
Reading camera 291/301
Reading camera 292/301
Reading camera 293/301
Reading camera 294/301
Reading camera 295/301
Reading camera 296/301
Reading camera 297/301
Reading camera 298/301
Reading camera 299/301
Reading camera 300/301
Reading camera 301/301 [03/12 21:06:50]
Loading Training Cameras [03/12 21:06:50]
Loading Test Cameras [03/12 21:07:07]
Number of points at initialisation :  182686 [03/12 21:07:10]

Training progress:   0%|          | 0/2000 [00:00<?, ?it/s]/ext3/conda/envs/3dgs/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/ext3/conda/envs/3dgs/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)

Training progress:   0%|          | 0/2000 [00:05<?, ?it/s, Loss=0.0232754, Gaussian number=182686, print grad=1.1574271411518566e-05, Depth Loss=0.0000000]
Training progress:   0%|          | 10/2000 [00:05<18:53,  1.76it/s, Loss=0.0232754, Gaussian number=182686, print grad=1.1574271411518566e-05, Depth Loss=0.0000000]
Training progress:   0%|          | 10/2000 [00:09<18:53,  1.76it/s, Loss=0.0215832, Gaussian number=182686, print grad=2.9624321541632526e-05, Depth Loss=0.0000000]
Training progress:   1%|          | 20/2000 [00:09<15:37,  2.11it/s, Loss=0.0215832, Gaussian number=182686, print grad=2.9624321541632526e-05, Depth Loss=0.0000000]
Training progress:   1%|          | 20/2000 [00:13<15:37,  2.11it/s, Loss=0.0214415, Gaussian number=182686, print grad=4.674029696616344e-05, Depth Loss=0.0000000] 
Training progress:   2%|▏         | 30/2000 [00:13<14:30,  2.26it/s, Loss=0.0214415, Gaussian number=182686, print grad=4.674029696616344e-05, Depth Loss=0.0000000]
Training progress:   2%|▏         | 30/2000 [00:17<14:30,  2.26it/s, Loss=0.0230199, Gaussian number=182686, print grad=6.427102925954387e-05, Depth Loss=0.0000000]
Training progress:   2%|▏         | 40/2000 [00:17<13:57,  2.34it/s, Loss=0.0230199, Gaussian number=182686, print grad=6.427102925954387e-05, Depth Loss=0.0000000]
Training progress:   2%|▏         | 40/2000 [00:21<13:57,  2.34it/s, Loss=0.0176467, Gaussian number=182686, print grad=7.896192255429924e-05, Depth Loss=0.0000000]
Training progress:   2%|▎         | 50/2000 [00:21<13:36,  2.39it/s, Loss=0.0176467, Gaussian number=182686, print grad=7.896192255429924e-05, Depth Loss=0.0000000]
Training progress:   2%|▎         | 50/2000 [00:25<13:36,  2.39it/s, Loss=0.0192951, Gaussian number=182686, print grad=0.00010009784455178306, Depth Loss=0.0000000]
Training progress:   3%|▎         | 60/2000 [00:25<13:21,  2.42it/s, Loss=0.0192951, Gaussian number=182686, print grad=0.00010009784455178306, Depth Loss=0.0000000]
Training progress:   3%|▎         | 60/2000 [00:29<13:21,  2.42it/s, Loss=0.0172584, Gaussian number=182686, print grad=0.0001257241819985211, Depth Loss=0.0000000] 
Training progress:   4%|▎         | 70/2000 [00:29<13:11,  2.44it/s, Loss=0.0172584, Gaussian number=182686, print grad=0.0001257241819985211, Depth Loss=0.0000000]
Training progress:   4%|▎         | 70/2000 [00:33<13:11,  2.44it/s, Loss=0.0215170, Gaussian number=182686, print grad=0.00014651923265773803, Depth Loss=0.0000000]
Training progress:   4%|▍         | 80/2000 [00:33<13:03,  2.45it/s, Loss=0.0215170, Gaussian number=182686, print grad=0.00014651923265773803, Depth Loss=0.0000000]
Training progress:   4%|▍         | 80/2000 [00:38<13:03,  2.45it/s, Loss=0.0181214, Gaussian number=182686, print grad=0.00016837799921631813, Depth Loss=0.0000000]
Training progress:   4%|▍         | 90/2000 [00:38<12:57,  2.46it/s, Loss=0.0181214, Gaussian number=182686, print grad=0.00016837799921631813, Depth Loss=0.0000000]
Training progress:   4%|▍         | 90/2000 [00:42<12:57,  2.46it/s, Loss=0.0172435, Gaussian number=182686, print grad=0.0001936086919158697, Depth Loss=0.0000000] 
Training progress:   5%|▌         | 100/2000 [00:42<12:51,  2.46it/s, Loss=0.0172435, Gaussian number=182686, print grad=0.0001936086919158697, Depth Loss=0.0000000]
Training progress:   5%|▌         | 100/2000 [01:50<12:51,  2.46it/s, Loss=0.0201444, Gaussian number=182686, print grad=0.00022073573200032115, Depth Loss=0.0000000]
Training progress:   6%|▌         | 110/2000 [01:50<1:14:31,  2.37s/it, Loss=0.0201444, Gaussian number=182686, print grad=0.00022073573200032115, Depth Loss=0.0000000]
Training progress:   6%|▌         | 110/2000 [01:54<1:14:31,  2.37s/it, Loss=0.0165986, Gaussian number=182686, print grad=0.00024646997917443514, Depth Loss=0.0000000]
Training progress:   6%|▌         | 120/2000 [01:54<55:24,  1.77s/it, Loss=0.0165986, Gaussian number=182686, print grad=0.00024646997917443514, Depth Loss=0.0000000]  
Training progress:   6%|▌         | 120/2000 [01:58<55:24,  1.77s/it, Loss=0.0189733, Gaussian number=182686, print grad=0.0002778778725769371, Depth Loss=0.0000000] 
Training progress:   6%|▋         | 130/2000 [01:58<42:12,  1.35s/it, Loss=0.0189733, Gaussian number=182686, print grad=0.0002778778725769371, Depth Loss=0.0000000]
Training progress:   6%|▋         | 130/2000 [02:02<42:12,  1.35s/it, Loss=0.0171508, Gaussian number=182686, print grad=0.0003095904248766601, Depth Loss=0.0000000]
Training progress:   7%|▋         | 140/2000 [02:02<33:04,  1.07s/it, Loss=0.0171508, Gaussian number=182686, print grad=0.0003095904248766601, Depth Loss=0.0000000]
Training progress:   7%|▋         | 140/2000 [02:06<33:04,  1.07s/it, Loss=0.0151980, Gaussian number=182686, print grad=0.00033805743441917, Depth Loss=0.0000000]  
Training progress:   8%|▊         | 150/2000 [02:06<26:42,  1.15it/s, Loss=0.0151980, Gaussian number=182686, print grad=0.00033805743441917, Depth Loss=0.0000000]
Training progress:   8%|▊         | 150/2000 [02:10<26:42,  1.15it/s, Loss=0.0161878, Gaussian number=182686, print grad=0.00037297900416888297, Depth Loss=0.0000000]
Training progress:   8%|▊         | 160/2000 [02:10<22:15,  1.38it/s, Loss=0.0161878, Gaussian number=182686, print grad=0.00037297900416888297, Depth Loss=0.0000000]
Training progress:   8%|▊         | 160/2000 [02:14<22:15,  1.38it/s, Loss=0.0162194, Gaussian number=182686, print grad=0.0004021241911686957, Depth Loss=0.0000000] 
Training progress:   8%|▊         | 170/2000 [02:14<19:09,  1.59it/s, Loss=0.0162194, Gaussian number=182686, print grad=0.0004021241911686957, Depth Loss=0.0000000]
Training progress:   8%|▊         | 170/2000 [02:18<19:09,  1.59it/s, Loss=0.0135331, Gaussian number=182686, print grad=0.0004340251616667956, Depth Loss=0.0000000]
Training progress:   9%|▉         | 180/2000 [02:18<16:59,  1.79it/s, Loss=0.0135331, Gaussian number=182686, print grad=0.0004340251616667956, Depth Loss=0.0000000]
Training progress:   9%|▉         | 180/2000 [02:22<16:59,  1.79it/s, Loss=0.0176327, Gaussian number=182686, print grad=0.00046298428787849844, Depth Loss=0.0000000]
Training progress:  10%|▉         | 190/2000 [02:22<15:26,  1.95it/s, Loss=0.0176327, Gaussian number=182686, print grad=0.00046298428787849844, Depth Loss=0.0000000]
Training progress:  10%|▉         | 190/2000 [02:26<15:26,  1.95it/s, Loss=0.0150278, Gaussian number=182686, print grad=0.0004974979674443603, Depth Loss=0.0000000] 
Training progress:  10%|█         | 200/2000 [02:26<14:20,  2.09it/s, Loss=0.0150278, Gaussian number=182686, print grad=0.0004974979674443603, Depth Loss=0.0000000]
Training progress:  10%|█         | 200/2000 [03:34<14:20,  2.09it/s, Loss=0.0169579, Gaussian number=182686, print grad=0.0005323514342308044, Depth Loss=0.0000000]
Training progress:  10%|█         | 210/2000 [03:34<1:10:44,  2.37s/it, Loss=0.0169579, Gaussian number=182686, print grad=0.0005323514342308044, Depth Loss=0.0000000]
Training progress:  10%|█         | 210/2000 [03:38<1:10:44,  2.37s/it, Loss=0.0137196, Gaussian number=182686, print grad=0.0005643522017635405, Depth Loss=0.0000000]
Training progress:  11%|█         | 220/2000 [03:38<52:47,  1.78s/it, Loss=0.0137196, Gaussian number=182686, print grad=0.0005643522017635405, Depth Loss=0.0000000]  
Training progress:  11%|█         | 220/2000 [03:42<52:47,  1.78s/it, Loss=0.0153121, Gaussian number=182686, print grad=0.0005977434339001775, Depth Loss=0.0000000]
Training progress:  12%|█▏        | 230/2000 [03:42<40:17,  1.37s/it, Loss=0.0153121, Gaussian number=182686, print grad=0.0005977434339001775, Depth Loss=0.0000000]
Training progress:  12%|█▏        | 230/2000 [03:46<40:17,  1.37s/it, Loss=0.0193248, Gaussian number=182686, print grad=0.0006291996105574071, Depth Loss=0.0000000]
Training progress:  12%|█▏        | 240/2000 [03:46<31:33,  1.08s/it, Loss=0.0193248, Gaussian number=182686, print grad=0.0006291996105574071, Depth Loss=0.0000000]
Training progress:  12%|█▏        | 240/2000 [03:50<31:33,  1.08s/it, Loss=0.0147338, Gaussian number=182686, print grad=0.0006638881750404835, Depth Loss=0.0000000]
Training progress:  12%|█▎        | 250/2000 [03:50<25:27,  1.15it/s, Loss=0.0147338, Gaussian number=182686, print grad=0.0006638881750404835, Depth Loss=0.0000000]
Training progress:  12%|█▎        | 250/2000 [03:54<25:27,  1.15it/s, Loss=0.0166321, Gaussian number=182686, print grad=0.0006956344004720449, Depth Loss=0.0000000]
Training progress:  13%|█▎        | 260/2000 [03:54<21:11,  1.37it/s, Loss=0.0166321, Gaussian number=182686, print grad=0.0006956344004720449, Depth Loss=0.0000000]
Training progress:  13%|█▎        | 260/2000 [03:58<21:11,  1.37it/s, Loss=0.0112840, Gaussian number=182686, print grad=0.000729680061340332, Depth Loss=0.0000000] 
Training progress:  14%|█▎        | 270/2000 [03:58<18:12,  1.58it/s, Loss=0.0112840, Gaussian number=182686, print grad=0.000729680061340332, Depth Loss=0.0000000]
Training progress:  14%|█▎        | 270/2000 [04:02<18:12,  1.58it/s, Loss=0.0147187, Gaussian number=182686, print grad=0.0007665943703614175, Depth Loss=0.0000000]
Training progress:  14%|█▍        | 280/2000 [04:02<16:05,  1.78it/s, Loss=0.0147187, Gaussian number=182686, print grad=0.0007665943703614175, Depth Loss=0.0000000]
Training progress:  14%|█▍        | 280/2000 [04:06<16:05,  1.78it/s, Loss=0.0150673, Gaussian number=182686, print grad=0.0008029246237128973, Depth Loss=0.0000000]
Training progress:  14%|█▍        | 290/2000 [04:06<14:36,  1.95it/s, Loss=0.0150673, Gaussian number=182686, print grad=0.0008029246237128973, Depth Loss=0.0000000]
Training progress:  14%|█▍        | 290/2000 [04:10<14:36,  1.95it/s, Loss=0.0141949, Gaussian number=182686, print grad=0.0008405412663705647, Depth Loss=0.0000000]
Training progress:  15%|█▌        | 300/2000 [04:10<13:33,  2.09it/s, Loss=0.0141949, Gaussian number=182686, print grad=0.0008405412663705647, Depth Loss=0.0000000]
Training progress:  15%|█▌        | 300/2000 [05:17<13:33,  2.09it/s, Loss=0.0116486, Gaussian number=182686, print grad=0.0008781463257037103, Depth Loss=0.0000000]
Training progress:  16%|█▌        | 310/2000 [05:17<1:06:44,  2.37s/it, Loss=0.0116486, Gaussian number=182686, print grad=0.0008781463257037103, Depth Loss=0.0000000]
Training progress:  16%|█▌        | 310/2000 [05:21<1:06:44,  2.37s/it, Loss=0.0120054, Gaussian number=182686, print grad=0.0009067688952200115, Depth Loss=0.0000000]
Training progress:  16%|█▌        | 320/2000 [05:21<49:47,  1.78s/it, Loss=0.0120054, Gaussian number=182686, print grad=0.0009067688952200115, Depth Loss=0.0000000]  
Training progress:  16%|█▌        | 320/2000 [05:25<49:47,  1.78s/it, Loss=0.0161217, Gaussian number=182686, print grad=0.0009393452201038599, Depth Loss=0.0000000]
Training progress:  16%|█▋        | 330/2000 [05:25<37:58,  1.36s/it, Loss=0.0161217, Gaussian number=182686, print grad=0.0009393452201038599, Depth Loss=0.0000000]
Training progress:  16%|█▋        | 330/2000 [05:29<37:58,  1.36s/it, Loss=0.0114616, Gaussian number=182686, print grad=0.0009772765915840864, Depth Loss=0.0000000]
Training progress:  17%|█▋        | 340/2000 [05:29<29:43,  1.07s/it, Loss=0.0114616, Gaussian number=182686, print grad=0.0009772765915840864, Depth Loss=0.0000000]
Training progress:  17%|█▋        | 340/2000 [05:33<29:43,  1.07s/it, Loss=0.0121993, Gaussian number=182686, print grad=0.0010119271464645863, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 350/2000 [05:33<23:57,  1.15it/s, Loss=0.0121993, Gaussian number=182686, print grad=0.0010119271464645863, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 350/2000 [05:37<23:57,  1.15it/s, Loss=0.0118783, Gaussian number=182686, print grad=0.0010524587705731392, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 360/2000 [05:37<19:56,  1.37it/s, Loss=0.0118783, Gaussian number=182686, print grad=0.0010524587705731392, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 360/2000 [05:41<19:56,  1.37it/s, Loss=0.0110902, Gaussian number=182686, print grad=0.001088217948563397, Depth Loss=0.0000000] 
Training progress:  18%|█▊        | 370/2000 [05:41<17:06,  1.59it/s, Loss=0.0110902, Gaussian number=182686, print grad=0.001088217948563397, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 370/2000 [05:45<17:06,  1.59it/s, Loss=0.0155584, Gaussian number=182686, print grad=0.001119786174967885, Depth Loss=0.0000000]
Training progress:  19%|█▉        | 380/2000 [05:45<15:06,  1.79it/s, Loss=0.0155584, Gaussian number=182686, print grad=0.001119786174967885, Depth Loss=0.0000000]
Training progress:  19%|█▉        | 380/2000 [05:49<15:06,  1.79it/s, Loss=0.0135273, Gaussian number=182686, print grad=0.0011582255829125643, Depth Loss=0.0000000]
Training progress:  20%|█▉        | 390/2000 [05:49<13:42,  1.96it/s, Loss=0.0135273, Gaussian number=182686, print grad=0.0011582255829125643, Depth Loss=0.0000000]
Training progress:  20%|█▉        | 390/2000 [05:53<13:42,  1.96it/s, Loss=0.0165153, Gaussian number=182686, print grad=0.0011943475110456347, Depth Loss=0.0000000]
Training progress:  20%|██        | 400/2000 [05:53<12:42,  2.10it/s, Loss=0.0165153, Gaussian number=182686, print grad=0.0011943475110456347, Depth Loss=0.0000000]
Training progress:  20%|██        | 400/2000 [05:57<12:42,  2.10it/s, Loss=0.0140445, Gaussian number=182686, print grad=0.0012365271104499698, Depth Loss=0.0000000]
Training progress:  20%|██        | 410/2000 [05:57<12:00,  2.21it/s, Loss=0.0140445, Gaussian number=182686, print grad=0.0012365271104499698, Depth Loss=0.0000000]
Training progress:  20%|██        | 410/2000 [06:01<12:00,  2.21it/s, Loss=0.0123252, Gaussian number=182686, print grad=0.0012770865578204393, Depth Loss=0.0000000]
Training progress:  21%|██        | 420/2000 [06:01<11:29,  2.29it/s, Loss=0.0123252, Gaussian number=182686, print grad=0.0012770865578204393, Depth Loss=0.0000000]
Training progress:  21%|██        | 420/2000 [06:05<11:29,  2.29it/s, Loss=0.0155823, Gaussian number=182686, print grad=0.0013187049189582467, Depth Loss=0.0000000]
Training progress:  22%|██▏       | 430/2000 [06:05<11:07,  2.35it/s, Loss=0.0155823, Gaussian number=182686, print grad=0.0013187049189582467, Depth Loss=0.0000000]
Training progress:  22%|██▏       | 430/2000 [06:09<11:07,  2.35it/s, Loss=0.0121239, Gaussian number=182686, print grad=0.0013566669076681137, Depth Loss=0.0000000]
Training progress:  22%|██▏       | 440/2000 [06:09<10:49,  2.40it/s, Loss=0.0121239, Gaussian number=182686, print grad=0.0013566669076681137, Depth Loss=0.0000000]
Training progress:  22%|██▏       | 440/2000 [06:13<10:49,  2.40it/s, Loss=0.0140436, Gaussian number=182686, print grad=0.001395797822624445, Depth Loss=0.0000000] 
Training progress:  22%|██▎       | 450/2000 [06:13<10:35,  2.44it/s, Loss=0.0140436, Gaussian number=182686, print grad=0.001395797822624445, Depth Loss=0.0000000]
Training progress:  22%|██▎       | 450/2000 [06:17<10:35,  2.44it/s, Loss=0.0147788, Gaussian number=182686, print grad=0.0014345647068694234, Depth Loss=0.0000000]
Training progress:  23%|██▎       | 460/2000 [06:17<10:25,  2.46it/s, Loss=0.0147788, Gaussian number=182686, print grad=0.0014345647068694234, Depth Loss=0.0000000]
Training progress:  23%|██▎       | 460/2000 [06:21<10:25,  2.46it/s, Loss=0.0174185, Gaussian number=182686, print grad=0.0014715098077431321, Depth Loss=0.0000000]
Training progress:  24%|██▎       | 470/2000 [06:21<10:16,  2.48it/s, Loss=0.0174185, Gaussian number=182686, print grad=0.0014715098077431321, Depth Loss=0.0000000]
Training progress:  24%|██▎       | 470/2000 [06:25<10:16,  2.48it/s, Loss=0.0110817, Gaussian number=182686, print grad=0.0015135081484913826, Depth Loss=0.0000000]
Training progress:  24%|██▍       | 480/2000 [06:25<10:09,  2.49it/s, Loss=0.0110817, Gaussian number=182686, print grad=0.0015135081484913826, Depth Loss=0.0000000]
Training progress:  24%|██▍       | 480/2000 [06:29<10:09,  2.49it/s, Loss=0.0124969, Gaussian number=182686, print grad=0.0015514781698584557, Depth Loss=0.0000000]
Training progress:  24%|██▍       | 490/2000 [06:29<10:03,  2.50it/s, Loss=0.0124969, Gaussian number=182686, print grad=0.0015514781698584557, Depth Loss=0.0000000]
Training progress:  24%|██▍       | 490/2000 [06:33<10:03,  2.50it/s, Loss=0.0093601, Gaussian number=182686, print grad=0.0015904270112514496, Depth Loss=0.0000000]
Training progress:  25%|██▌       | 500/2000 [06:33<09:58,  2.51it/s, Loss=0.0093601, Gaussian number=182686, print grad=0.0015904270112514496, Depth Loss=0.0000000]
Training progress:  25%|██▌       | 500/2000 [07:41<09:58,  2.51it/s, Loss=0.0114428, Gaussian number=182686, print grad=0.0016290177591145039, Depth Loss=0.0000000]
Training progress:  26%|██▌       | 510/2000 [07:41<57:27,  2.31s/it, Loss=0.0114428, Gaussian number=182686, print grad=0.0016290177591145039, Depth Loss=0.0000000]
Training progress:  26%|██▌       | 510/2000 [07:45<57:27,  2.31s/it, Loss=0.0117917, Gaussian number=182686, print grad=0.0016697056125849485, Depth Loss=0.0000000]
Training progress:  26%|██▌       | 520/2000 [07:45<42:52,  1.74s/it, Loss=0.0117917, Gaussian number=182686, print grad=0.0016697056125849485, Depth Loss=0.0000000]
Training progress:  26%|██▌       | 520/2000 [07:49<42:52,  1.74s/it, Loss=0.0089548, Gaussian number=182686, print grad=0.0017049533780664206, Depth Loss=0.0000000]
Training progress:  26%|██▋       | 530/2000 [07:49<32:42,  1.34s/it, Loss=0.0089548, Gaussian number=182686, print grad=0.0017049533780664206, Depth Loss=0.0000000]
Training progress:  26%|██▋       | 530/2000 [07:53<32:42,  1.34s/it, Loss=0.0122640, Gaussian number=182686, print grad=0.001743717584758997, Depth Loss=0.0000000] 
Training progress:  27%|██▋       | 540/2000 [07:53<25:38,  1.05s/it, Loss=0.0122640, Gaussian number=182686, print grad=0.001743717584758997, Depth Loss=0.0000000]
Training progress:  27%|██▋       | 540/2000 [07:56<25:38,  1.05s/it, Loss=0.0115694, Gaussian number=182686, print grad=0.0017854314064607024, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 550/2000 [07:56<20:42,  1.17it/s, Loss=0.0115694, Gaussian number=182686, print grad=0.0017854314064607024, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 550/2000 [08:00<20:42,  1.17it/s, Loss=0.0090581, Gaussian number=182686, print grad=0.0018230621935799718, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 560/2000 [08:00<17:14,  1.39it/s, Loss=0.0090581, Gaussian number=182686, print grad=0.0018230621935799718, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 560/2000 [08:04<17:14,  1.39it/s, Loss=0.0125814, Gaussian number=182686, print grad=0.001864418387413025, Depth Loss=0.0000000] 
Training progress:  28%|██▊       | 570/2000 [08:04<14:48,  1.61it/s, Loss=0.0125814, Gaussian number=182686, print grad=0.001864418387413025, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 570/2000 [08:08<14:48,  1.61it/s, Loss=0.0109206, Gaussian number=182686, print grad=0.0019054714357480407, Depth Loss=0.0000000]
Training progress:  29%|██▉       | 580/2000 [08:08<13:06,  1.81it/s, Loss=0.0109206, Gaussian number=182686, print grad=0.0019054714357480407, Depth Loss=0.0000000]
Training progress:  29%|██▉       | 580/2000 [08:12<13:06,  1.81it/s, Loss=0.0127489, Gaussian number=182686, print grad=0.00194729829672724, Depth Loss=0.0000000]  
Training progress:  30%|██▉       | 590/2000 [08:12<11:54,  1.97it/s, Loss=0.0127489, Gaussian number=182686, print grad=0.00194729829672724, Depth Loss=0.0000000]
Training progress:  30%|██▉       | 590/2000 [08:16<11:54,  1.97it/s, Loss=0.0127093, Gaussian number=182686, print grad=0.0019855834543704987, Depth Loss=0.0000000]
Training progress:  30%|███       | 600/2000 [08:16<11:03,  2.11it/s, Loss=0.0127093, Gaussian number=182686, print grad=0.0019855834543704987, Depth Loss=0.0000000]
Training progress:  30%|███       | 600/2000 [08:20<11:03,  2.11it/s, Loss=0.0102409, Gaussian number=182693, print grad=3.52157476299908e-05, Depth Loss=0.0000000] 
Training progress:  30%|███       | 610/2000 [08:20<10:26,  2.22it/s, Loss=0.0102409, Gaussian number=182693, print grad=3.52157476299908e-05, Depth Loss=0.0000000]
Training progress:  30%|███       | 610/2000 [08:24<10:26,  2.22it/s, Loss=0.0138582, Gaussian number=182693, print grad=7.656493107788265e-05, Depth Loss=0.0000000]
Training progress:  31%|███       | 620/2000 [08:24<09:58,  2.30it/s, Loss=0.0138582, Gaussian number=182693, print grad=7.656493107788265e-05, Depth Loss=0.0000000]
Training progress:  31%|███       | 620/2000 [08:28<09:58,  2.30it/s, Loss=0.0095656, Gaussian number=182693, print grad=0.00011508062016218901, Depth Loss=0.0000000]
Training progress:  32%|███▏      | 630/2000 [08:28<09:39,  2.36it/s, Loss=0.0095656, Gaussian number=182693, print grad=0.00011508062016218901, Depth Loss=0.0000000]
Training progress:  32%|███▏      | 630/2000 [08:32<09:39,  2.36it/s, Loss=0.0105296, Gaussian number=182693, print grad=0.00015911382797639817, Depth Loss=0.0000000]
Training progress:  32%|███▏      | 640/2000 [08:32<09:23,  2.41it/s, Loss=0.0105296, Gaussian number=182693, print grad=0.00015911382797639817, Depth Loss=0.0000000]
Training progress:  32%|███▏      | 640/2000 [08:36<09:23,  2.41it/s, Loss=0.0125966, Gaussian number=182693, print grad=0.00019640421669464558, Depth Loss=0.0000000]
Training progress:  32%|███▎      | 650/2000 [08:36<09:11,  2.45it/s, Loss=0.0125966, Gaussian number=182693, print grad=0.00019640421669464558, Depth Loss=0.0000000]
Training progress:  32%|███▎      | 650/2000 [08:40<09:11,  2.45it/s, Loss=0.0123652, Gaussian number=182693, print grad=0.00024014018708840013, Depth Loss=0.0000000]
Training progress:  33%|███▎      | 660/2000 [08:40<09:02,  2.47it/s, Loss=0.0123652, Gaussian number=182693, print grad=0.00024014018708840013, Depth Loss=0.0000000]
Training progress:  33%|███▎      | 660/2000 [08:44<09:02,  2.47it/s, Loss=0.0110621, Gaussian number=182693, print grad=0.0002787256380543113, Depth Loss=0.0000000] 
Training progress:  34%|███▎      | 670/2000 [08:44<08:54,  2.49it/s, Loss=0.0110621, Gaussian number=182693, print grad=0.0002787256380543113, Depth Loss=0.0000000]
Training progress:  34%|███▎      | 670/2000 [08:48<08:54,  2.49it/s, Loss=0.0100490, Gaussian number=182693, print grad=0.0003212189767509699, Depth Loss=0.0000000]
Training progress:  34%|███▍      | 680/2000 [08:48<08:47,  2.50it/s, Loss=0.0100490, Gaussian number=182693, print grad=0.0003212189767509699, Depth Loss=0.0000000]
Training progress:  34%|███▍      | 680/2000 [08:52<08:47,  2.50it/s, Loss=0.0122336, Gaussian number=182693, print grad=0.0003618505143094808, Depth Loss=0.0000000]
Training progress:  34%|███▍      | 690/2000 [08:52<08:41,  2.51it/s, Loss=0.0122336, Gaussian number=182693, print grad=0.0003618505143094808, Depth Loss=0.0000000]
Training progress:  34%|███▍      | 690/2000 [08:56<08:41,  2.51it/s, Loss=0.0123079, Gaussian number=182693, print grad=0.0004020231426693499, Depth Loss=0.0000000]
Training progress:  35%|███▌      | 700/2000 [08:56<08:36,  2.52it/s, Loss=0.0123079, Gaussian number=182693, print grad=0.0004020231426693499, Depth Loss=0.0000000]
Training progress:  35%|███▌      | 700/2000 [09:00<08:36,  2.52it/s, Loss=0.0106267, Gaussian number=182790, print grad=3.6258643376640975e-05, Depth Loss=0.0000000]
Training progress:  36%|███▌      | 710/2000 [09:00<08:32,  2.52it/s, Loss=0.0106267, Gaussian number=182790, print grad=3.6258643376640975e-05, Depth Loss=0.0000000]
Training progress:  36%|███▌      | 710/2000 [09:04<08:32,  2.52it/s, Loss=0.0097282, Gaussian number=182790, print grad=7.581125100841746e-05, Depth Loss=0.0000000] 
Training progress:  36%|███▌      | 720/2000 [09:04<08:28,  2.52it/s, Loss=0.0097282, Gaussian number=182790, print grad=7.581125100841746e-05, Depth Loss=0.0000000]
Training progress:  36%|███▌      | 720/2000 [09:08<08:28,  2.52it/s, Loss=0.0132918, Gaussian number=182790, print grad=0.00011408212594687939, Depth Loss=0.0000000]
Training progress:  36%|███▋      | 730/2000 [09:08<08:23,  2.52it/s, Loss=0.0132918, Gaussian number=182790, print grad=0.00011408212594687939, Depth Loss=0.0000000]
Training progress:  36%|███▋      | 730/2000 [09:12<08:23,  2.52it/s, Loss=0.0151692, Gaussian number=182790, print grad=0.00015815264487173408, Depth Loss=0.0000000]
Training progress:  37%|███▋      | 740/2000 [09:12<08:18,  2.53it/s, Loss=0.0151692, Gaussian number=182790, print grad=0.00015815264487173408, Depth Loss=0.0000000]
Training progress:  37%|███▋      | 740/2000 [09:16<08:18,  2.53it/s, Loss=0.0106267, Gaussian number=182790, print grad=0.00019945659732911736, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 750/2000 [09:16<08:14,  2.53it/s, Loss=0.0106267, Gaussian number=182790, print grad=0.00019945659732911736, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 750/2000 [09:20<08:14,  2.53it/s, Loss=0.0103448, Gaussian number=182790, print grad=0.00023881295055616647, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 760/2000 [09:20<08:10,  2.53it/s, Loss=0.0103448, Gaussian number=182790, print grad=0.00023881295055616647, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 760/2000 [09:24<08:10,  2.53it/s, Loss=0.0092447, Gaussian number=182790, print grad=0.0002822319802362472, Depth Loss=0.0000000] 
Training progress:  38%|███▊      | 770/2000 [09:24<08:06,  2.53it/s, Loss=0.0092447, Gaussian number=182790, print grad=0.0002822319802362472, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 770/2000 [09:27<08:06,  2.53it/s, Loss=0.0129837, Gaussian number=182790, print grad=0.0003219180798623711, Depth Loss=0.0000000]
Training progress:  39%|███▉      | 780/2000 [09:27<08:02,  2.53it/s, Loss=0.0129837, Gaussian number=182790, print grad=0.0003219180798623711, Depth Loss=0.0000000]
Training progress:  39%|███▉      | 780/2000 [09:31<08:02,  2.53it/s, Loss=0.0150190, Gaussian number=182790, print grad=0.0003632822772487998, Depth Loss=0.0000000]
Training progress:  40%|███▉      | 790/2000 [09:31<07:59,  2.52it/s, Loss=0.0150190, Gaussian number=182790, print grad=0.0003632822772487998, Depth Loss=0.0000000]
Training progress:  40%|███▉      | 790/2000 [09:35<07:59,  2.52it/s, Loss=0.0127174, Gaussian number=182790, print grad=0.0004060013743583113, Depth Loss=0.0000000]
Training progress:  40%|████      | 800/2000 [09:35<07:55,  2.52it/s, Loss=0.0127174, Gaussian number=182790, print grad=0.0004060013743583113, Depth Loss=0.0000000]
Training progress:  40%|████      | 800/2000 [09:39<07:55,  2.52it/s, Loss=0.0116922, Gaussian number=182879, print grad=3.587776518543251e-05, Depth Loss=0.0000000]
Training progress:  40%|████      | 810/2000 [09:39<07:51,  2.52it/s, Loss=0.0116922, Gaussian number=182879, print grad=3.587776518543251e-05, Depth Loss=0.0000000]
Training progress:  40%|████      | 810/2000 [09:43<07:51,  2.52it/s, Loss=0.0116209, Gaussian number=182879, print grad=7.641979755135253e-05, Depth Loss=0.0000000]
Training progress:  41%|████      | 820/2000 [09:43<07:47,  2.52it/s, Loss=0.0116209, Gaussian number=182879, print grad=7.641979755135253e-05, Depth Loss=0.0000000]
Training progress:  41%|████      | 820/2000 [09:47<07:47,  2.52it/s, Loss=0.0089527, Gaussian number=182879, print grad=0.0001229507615789771, Depth Loss=0.0000000]
Training progress:  42%|████▏     | 830/2000 [09:47<07:46,  2.51it/s, Loss=0.0089527, Gaussian number=182879, print grad=0.0001229507615789771, Depth Loss=0.0000000]
Training progress:  42%|████▏     | 830/2000 [09:51<07:46,  2.51it/s, Loss=0.0101082, Gaussian number=182879, print grad=0.00016435625730082393, Depth Loss=0.0000000]
Training progress:  42%|████▏     | 840/2000 [09:51<07:41,  2.51it/s, Loss=0.0101082, Gaussian number=182879, print grad=0.00016435625730082393, Depth Loss=0.0000000]
Training progress:  42%|████▏     | 840/2000 [09:55<07:41,  2.51it/s, Loss=0.0102949, Gaussian number=182879, print grad=0.00020701441098935902, Depth Loss=0.0000000]
Training progress:  42%|████▎     | 850/2000 [09:55<07:36,  2.52it/s, Loss=0.0102949, Gaussian number=182879, print grad=0.00020701441098935902, Depth Loss=0.0000000]
Training progress:  42%|████▎     | 850/2000 [09:59<07:36,  2.52it/s, Loss=0.0104434, Gaussian number=182879, print grad=0.00024676183238625526, Depth Loss=0.0000000]
Training progress:  43%|████▎     | 860/2000 [09:59<07:32,  2.52it/s, Loss=0.0104434, Gaussian number=182879, print grad=0.00024676183238625526, Depth Loss=0.0000000]
Training progress:  43%|████▎     | 860/2000 [10:03<07:32,  2.52it/s, Loss=0.0121984, Gaussian number=182879, print grad=0.0002875001810025424, Depth Loss=0.0000000] 
Training progress:  44%|████▎     | 870/2000 [10:03<07:28,  2.52it/s, Loss=0.0121984, Gaussian number=182879, print grad=0.0002875001810025424, Depth Loss=0.0000000]
Training progress:  44%|████▎     | 870/2000 [10:07<07:28,  2.52it/s, Loss=0.0113467, Gaussian number=182879, print grad=0.0003296967188362032, Depth Loss=0.0000000]
Training progress:  44%|████▍     | 880/2000 [10:07<07:23,  2.52it/s, Loss=0.0113467, Gaussian number=182879, print grad=0.0003296967188362032, Depth Loss=0.0000000]
Training progress:  44%|████▍     | 880/2000 [10:11<07:23,  2.52it/s, Loss=0.0091190, Gaussian number=182879, print grad=0.00037076164153404534, Depth Loss=0.0000000]
Training progress:  44%|████▍     | 890/2000 [10:11<07:19,  2.52it/s, Loss=0.0091190, Gaussian number=182879, print grad=0.00037076164153404534, Depth Loss=0.0000000]
Training progress:  44%|████▍     | 890/2000 [10:15<07:19,  2.52it/s, Loss=0.0121469, Gaussian number=182879, print grad=0.00041369415703229606, Depth Loss=0.0000000]
Training progress:  45%|████▌     | 900/2000 [10:15<07:15,  2.53it/s, Loss=0.0121469, Gaussian number=182879, print grad=0.00041369415703229606, Depth Loss=0.0000000]
Training progress:  45%|████▌     | 900/2000 [10:19<07:15,  2.53it/s, Loss=0.0089548, Gaussian number=182950, print grad=3.610683052102104e-05, Depth Loss=0.0000000] 
Training progress:  46%|████▌     | 910/2000 [10:19<07:11,  2.53it/s, Loss=0.0089548, Gaussian number=182950, print grad=3.610683052102104e-05, Depth Loss=0.0000000]
Training progress:  46%|████▌     | 910/2000 [10:23<07:11,  2.53it/s, Loss=0.0109182, Gaussian number=182950, print grad=7.271800859598443e-05, Depth Loss=0.0000000]
Training progress:  46%|████▌     | 920/2000 [10:23<07:06,  2.53it/s, Loss=0.0109182, Gaussian number=182950, print grad=7.271800859598443e-05, Depth Loss=0.0000000]
Training progress:  46%|████▌     | 920/2000 [10:27<07:06,  2.53it/s, Loss=0.0113329, Gaussian number=182950, print grad=0.00011641070159384981, Depth Loss=0.0000000]
Training progress:  46%|████▋     | 930/2000 [10:27<07:02,  2.53it/s, Loss=0.0113329, Gaussian number=182950, print grad=0.00011641070159384981, Depth Loss=0.0000000]
Training progress:  46%|████▋     | 930/2000 [10:31<07:02,  2.53it/s, Loss=0.0105176, Gaussian number=182950, print grad=0.00015699316281825304, Depth Loss=0.0000000]
Training progress:  47%|████▋     | 940/2000 [10:31<06:59,  2.53it/s, Loss=0.0105176, Gaussian number=182950, print grad=0.00015699316281825304, Depth Loss=0.0000000]
Training progress:  47%|████▋     | 940/2000 [10:35<06:59,  2.53it/s, Loss=0.0102820, Gaussian number=182950, print grad=0.0001979485823540017, Depth Loss=0.0000000] 
Training progress:  48%|████▊     | 950/2000 [10:35<06:55,  2.53it/s, Loss=0.0102820, Gaussian number=182950, print grad=0.0001979485823540017, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 950/2000 [10:39<06:55,  2.53it/s, Loss=0.0105127, Gaussian number=182950, print grad=0.0002372515737079084, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 960/2000 [10:39<06:51,  2.53it/s, Loss=0.0105127, Gaussian number=182950, print grad=0.0002372515737079084, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 960/2000 [10:43<06:51,  2.53it/s, Loss=0.0138455, Gaussian number=182950, print grad=0.0002816957712639123, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 970/2000 [10:43<06:47,  2.53it/s, Loss=0.0138455, Gaussian number=182950, print grad=0.0002816957712639123, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 970/2000 [10:47<06:47,  2.53it/s, Loss=0.0086014, Gaussian number=182950, print grad=0.00032365781953558326, Depth Loss=0.0000000]
Training progress:  49%|████▉     | 980/2000 [10:47<06:43,  2.53it/s, Loss=0.0086014, Gaussian number=182950, print grad=0.00032365781953558326, Depth Loss=0.0000000]
Training progress:  49%|████▉     | 980/2000 [10:51<06:43,  2.53it/s, Loss=0.0090673, Gaussian number=182950, print grad=0.00036041735438629985, Depth Loss=0.0000000]
Training progress:  50%|████▉     | 990/2000 [10:51<06:39,  2.53it/s, Loss=0.0090673, Gaussian number=182950, print grad=0.00036041735438629985, Depth Loss=0.0000000]
Training progress:  50%|████▉     | 990/2000 [10:55<06:39,  2.53it/s, Loss=0.0117721, Gaussian number=182950, print grad=0.0003959310124628246, Depth Loss=0.0000000] 
Training progress:  50%|█████     | 1000/2000 [10:55<06:35,  2.53it/s, Loss=0.0117721, Gaussian number=182950, print grad=0.0003959310124628246, Depth Loss=0.0000000]
Training progress:  50%|█████     | 1000/2000 [12:03<06:35,  2.53it/s, Loss=0.0105814, Gaussian number=183038, print grad=3.5528817534213886e-05, Depth Loss=0.0000000]
Training progress:  50%|█████     | 1010/2000 [12:03<38:10,  2.31s/it, Loss=0.0105814, Gaussian number=183038, print grad=3.5528817534213886e-05, Depth Loss=0.0000000]
Training progress:  50%|█████     | 1010/2000 [12:06<38:10,  2.31s/it, Loss=0.0131893, Gaussian number=183038, print grad=8.25974639155902e-05, Depth Loss=0.0000000]  
Training progress:  51%|█████     | 1020/2000 [12:06<28:23,  1.74s/it, Loss=0.0131893, Gaussian number=183038, print grad=8.25974639155902e-05, Depth Loss=0.0000000]
Training progress:  51%|█████     | 1020/2000 [12:10<28:23,  1.74s/it, Loss=0.0104773, Gaussian number=183038, print grad=0.0001267090265173465, Depth Loss=0.0000000]
Training progress:  52%|█████▏    | 1030/2000 [12:10<21:34,  1.33s/it, Loss=0.0104773, Gaussian number=183038, print grad=0.0001267090265173465, Depth Loss=0.0000000]
Training progress:  52%|█████▏    | 1030/2000 [12:14<21:34,  1.33s/it, Loss=0.0111918, Gaussian number=183038, print grad=0.0001730176736600697, Depth Loss=0.0000000]
Training progress:  52%|█████▏    | 1040/2000 [12:14<16:50,  1.05s/it, Loss=0.0111918, Gaussian number=183038, print grad=0.0001730176736600697, Depth Loss=0.0000000]
Training progress:  52%|█████▏    | 1040/2000 [12:18<16:50,  1.05s/it, Loss=0.0103189, Gaussian number=183038, print grad=0.00020987054449506104, Depth Loss=0.0000000]
Training progress:  52%|█████▎    | 1050/2000 [12:18<13:32,  1.17it/s, Loss=0.0103189, Gaussian number=183038, print grad=0.00020987054449506104, Depth Loss=0.0000000]
Training progress:  52%|█████▎    | 1050/2000 [12:22<13:32,  1.17it/s, Loss=0.0093132, Gaussian number=183038, print grad=0.00025015760911628604, Depth Loss=0.0000000]
Training progress:  53%|█████▎    | 1060/2000 [12:22<11:13,  1.40it/s, Loss=0.0093132, Gaussian number=183038, print grad=0.00025015760911628604, Depth Loss=0.0000000]
Training progress:  53%|█████▎    | 1060/2000 [12:26<11:13,  1.40it/s, Loss=0.0078859, Gaussian number=183038, print grad=0.00029395378078334033, Depth Loss=0.0000000]
Training progress:  54%|█████▎    | 1070/2000 [12:26<09:36,  1.61it/s, Loss=0.0078859, Gaussian number=183038, print grad=0.00029395378078334033, Depth Loss=0.0000000]
Training progress:  54%|█████▎    | 1070/2000 [12:30<09:36,  1.61it/s, Loss=0.0088046, Gaussian number=183038, print grad=0.0003346419252920896, Depth Loss=0.0000000] 
Training progress:  54%|█████▍    | 1080/2000 [12:30<08:27,  1.81it/s, Loss=0.0088046, Gaussian number=183038, print grad=0.0003346419252920896, Depth Loss=0.0000000]
Training progress:  54%|█████▍    | 1080/2000 [12:34<08:27,  1.81it/s, Loss=0.0109420, Gaussian number=183038, print grad=0.00037616852205246687, Depth Loss=0.0000000]
Training progress:  55%|█████▍    | 1090/2000 [12:34<07:39,  1.98it/s, Loss=0.0109420, Gaussian number=183038, print grad=0.00037616852205246687, Depth Loss=0.0000000]
Training progress:  55%|█████▍    | 1090/2000 [12:38<07:39,  1.98it/s, Loss=0.0110205, Gaussian number=183038, print grad=0.0004170644679106772, Depth Loss=0.0000000] 
Training progress:  55%|█████▌    | 1100/2000 [12:38<07:04,  2.12it/s, Loss=0.0110205, Gaussian number=183038, print grad=0.0004170644679106772, Depth Loss=0.0000000]
Training progress:  55%|█████▌    | 1100/2000 [12:42<07:04,  2.12it/s, Loss=0.0117164, Gaussian number=183142, print grad=3.7878809962421656e-05, Depth Loss=0.0000000]
Training progress:  56%|█████▌    | 1110/2000 [12:42<06:39,  2.23it/s, Loss=0.0117164, Gaussian number=183142, print grad=3.7878809962421656e-05, Depth Loss=0.0000000]
Training progress:  56%|█████▌    | 1110/2000 [12:46<06:39,  2.23it/s, Loss=0.0104057, Gaussian number=183142, print grad=8.331362187163904e-05, Depth Loss=0.0000000] 
Training progress:  56%|█████▌    | 1120/2000 [12:46<06:20,  2.31it/s, Loss=0.0104057, Gaussian number=183142, print grad=8.331362187163904e-05, Depth Loss=0.0000000]
Training progress:  56%|█████▌    | 1120/2000 [12:50<06:20,  2.31it/s, Loss=0.0083844, Gaussian number=183142, print grad=0.00012857132242061198, Depth Loss=0.0000000]
Training progress:  56%|█████▋    | 1130/2000 [12:50<06:06,  2.38it/s, Loss=0.0083844, Gaussian number=183142, print grad=0.00012857132242061198, Depth Loss=0.0000000]
Training progress:  56%|█████▋    | 1130/2000 [12:54<06:06,  2.38it/s, Loss=0.0107258, Gaussian number=183142, print grad=0.0001737681741360575, Depth Loss=0.0000000] 
Training progress:  57%|█████▋    | 1140/2000 [12:54<05:54,  2.42it/s, Loss=0.0107258, Gaussian number=183142, print grad=0.0001737681741360575, Depth Loss=0.0000000]
Training progress:  57%|█████▋    | 1140/2000 [12:58<05:54,  2.42it/s, Loss=0.0074485, Gaussian number=183142, print grad=0.00021583236230071634, Depth Loss=0.0000000]
Training progress:  57%|█████▊    | 1150/2000 [12:58<05:46,  2.46it/s, Loss=0.0074485, Gaussian number=183142, print grad=0.00021583236230071634, Depth Loss=0.0000000]
Training progress:  57%|█████▊    | 1150/2000 [13:02<05:46,  2.46it/s, Loss=0.0083424, Gaussian number=183142, print grad=0.0002551967045292258, Depth Loss=0.0000000] 
Training progress:  58%|█████▊    | 1160/2000 [13:02<05:38,  2.48it/s, Loss=0.0083424, Gaussian number=183142, print grad=0.0002551967045292258, Depth Loss=0.0000000]
Training progress:  58%|█████▊    | 1160/2000 [13:06<05:38,  2.48it/s, Loss=0.0104079, Gaussian number=183142, print grad=0.00029751172405667603, Depth Loss=0.0000000]
Training progress:  58%|█████▊    | 1170/2000 [13:06<05:32,  2.50it/s, Loss=0.0104079, Gaussian number=183142, print grad=0.00029751172405667603, Depth Loss=0.0000000]
Training progress:  58%|█████▊    | 1170/2000 [13:10<05:32,  2.50it/s, Loss=0.0109996, Gaussian number=183142, print grad=0.0003388512704987079, Depth Loss=0.0000000] 
Training progress:  59%|█████▉    | 1180/2000 [13:10<05:26,  2.51it/s, Loss=0.0109996, Gaussian number=183142, print grad=0.0003388512704987079, Depth Loss=0.0000000]
Training progress:  59%|█████▉    | 1180/2000 [13:13<05:26,  2.51it/s, Loss=0.0099077, Gaussian number=183142, print grad=0.00038381078047677875, Depth Loss=0.0000000]
Training progress:  60%|█████▉    | 1190/2000 [13:13<05:22,  2.51it/s, Loss=0.0099077, Gaussian number=183142, print grad=0.00038381078047677875, Depth Loss=0.0000000]
Training progress:  60%|█████▉    | 1190/2000 [13:17<05:22,  2.51it/s, Loss=0.0115988, Gaussian number=183142, print grad=0.00042055867379531264, Depth Loss=0.0000000]
Training progress:  60%|██████    | 1200/2000 [13:17<05:17,  2.52it/s, Loss=0.0115988, Gaussian number=183142, print grad=0.00042055867379531264, Depth Loss=0.0000000]
Training progress:  60%|██████    | 1200/2000 [13:21<05:17,  2.52it/s, Loss=0.0086217, Gaussian number=183236, print grad=4.018758045276627e-05, Depth Loss=0.0000000] 
Training progress:  60%|██████    | 1210/2000 [13:21<05:12,  2.53it/s, Loss=0.0086217, Gaussian number=183236, print grad=4.018758045276627e-05, Depth Loss=0.0000000]
Training progress:  60%|██████    | 1210/2000 [13:25<05:12,  2.53it/s, Loss=0.0070785, Gaussian number=183236, print grad=8.548515324946493e-05, Depth Loss=0.0000000]
Training progress:  61%|██████    | 1220/2000 [13:25<05:08,  2.53it/s, Loss=0.0070785, Gaussian number=183236, print grad=8.548515324946493e-05, Depth Loss=0.0000000]
Training progress:  61%|██████    | 1220/2000 [13:29<05:08,  2.53it/s, Loss=0.0078527, Gaussian number=183236, print grad=0.00012404678273014724, Depth Loss=0.0000000]
Training progress:  62%|██████▏   | 1230/2000 [13:29<05:04,  2.53it/s, Loss=0.0078527, Gaussian number=183236, print grad=0.00012404678273014724, Depth Loss=0.0000000]
Training progress:  62%|██████▏   | 1230/2000 [13:33<05:04,  2.53it/s, Loss=0.0076760, Gaussian number=183236, print grad=0.00016758128185756505, Depth Loss=0.0000000]
Training progress:  62%|██████▏   | 1240/2000 [13:33<04:59,  2.53it/s, Loss=0.0076760, Gaussian number=183236, print grad=0.00016758128185756505, Depth Loss=0.0000000]
Training progress:  62%|██████▏   | 1240/2000 [13:37<04:59,  2.53it/s, Loss=0.0077136, Gaussian number=183236, print grad=0.00020573267829604447, Depth Loss=0.0000000]
Training progress:  62%|██████▎   | 1250/2000 [13:37<04:55,  2.54it/s, Loss=0.0077136, Gaussian number=183236, print grad=0.00020573267829604447, Depth Loss=0.0000000]
Training progress:  62%|██████▎   | 1250/2000 [13:41<04:55,  2.54it/s, Loss=0.0081686, Gaussian number=183236, print grad=0.00024317385395988822, Depth Loss=0.0000000]
Training progress:  63%|██████▎   | 1260/2000 [13:41<04:51,  2.54it/s, Loss=0.0081686, Gaussian number=183236, print grad=0.00024317385395988822, Depth Loss=0.0000000]
Training progress:  63%|██████▎   | 1260/2000 [13:45<04:51,  2.54it/s, Loss=0.0103439, Gaussian number=183236, print grad=0.00028599757933989167, Depth Loss=0.0000000]
Training progress:  64%|██████▎   | 1270/2000 [13:45<04:47,  2.54it/s, Loss=0.0103439, Gaussian number=183236, print grad=0.00028599757933989167, Depth Loss=0.0000000]
Training progress:  64%|██████▎   | 1270/2000 [13:49<04:47,  2.54it/s, Loss=0.0102586, Gaussian number=183236, print grad=0.0003262117097619921, Depth Loss=0.0000000] 
Training progress:  64%|██████▍   | 1280/2000 [13:49<04:43,  2.54it/s, Loss=0.0102586, Gaussian number=183236, print grad=0.0003262117097619921, Depth Loss=0.0000000]
Training progress:  64%|██████▍   | 1280/2000 [13:53<04:43,  2.54it/s, Loss=0.0080134, Gaussian number=183236, print grad=0.0003709738957695663, Depth Loss=0.0000000]
Training progress:  64%|██████▍   | 1290/2000 [13:53<04:40,  2.54it/s, Loss=0.0080134, Gaussian number=183236, print grad=0.0003709738957695663, Depth Loss=0.0000000]
Training progress:  64%|██████▍   | 1290/2000 [13:57<04:40,  2.54it/s, Loss=0.0120776, Gaussian number=183236, print grad=0.00041028778650797904, Depth Loss=0.0000000]
Training progress:  65%|██████▌   | 1300/2000 [13:57<04:36,  2.53it/s, Loss=0.0120776, Gaussian number=183236, print grad=0.00041028778650797904, Depth Loss=0.0000000]
Training progress:  65%|██████▌   | 1300/2000 [14:01<04:36,  2.53it/s, Loss=0.0114193, Gaussian number=183332, print grad=4.152839392190799e-05, Depth Loss=0.0000000] 
Training progress:  66%|██████▌   | 1310/2000 [14:01<04:32,  2.53it/s, Loss=0.0114193, Gaussian number=183332, print grad=4.152839392190799e-05, Depth Loss=0.0000000]
Training progress:  66%|██████▌   | 1310/2000 [14:05<04:32,  2.53it/s, Loss=0.0109680, Gaussian number=183332, print grad=8.155669638654217e-05, Depth Loss=0.0000000]
Training progress:  66%|██████▌   | 1320/2000 [14:05<04:28,  2.53it/s, Loss=0.0109680, Gaussian number=183332, print grad=8.155669638654217e-05, Depth Loss=0.0000000]
Training progress:  66%|██████▌   | 1320/2000 [14:09<04:28,  2.53it/s, Loss=0.0085007, Gaussian number=183332, print grad=0.00012300813978072256, Depth Loss=0.0000000]
Training progress:  66%|██████▋   | 1330/2000 [14:09<04:24,  2.53it/s, Loss=0.0085007, Gaussian number=183332, print grad=0.00012300813978072256, Depth Loss=0.0000000]
Training progress:  66%|██████▋   | 1330/2000 [14:13<04:24,  2.53it/s, Loss=0.0092568, Gaussian number=183332, print grad=0.00016748113557696342, Depth Loss=0.0000000]
Training progress:  67%|██████▋   | 1340/2000 [14:13<04:20,  2.53it/s, Loss=0.0092568, Gaussian number=183332, print grad=0.00016748113557696342, Depth Loss=0.0000000]
Training progress:  67%|██████▋   | 1340/2000 [14:17<04:20,  2.53it/s, Loss=0.0126765, Gaussian number=183332, print grad=0.00020564648730214685, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1350/2000 [14:17<04:16,  2.54it/s, Loss=0.0126765, Gaussian number=183332, print grad=0.00020564648730214685, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1350/2000 [14:21<04:16,  2.54it/s, Loss=0.0076980, Gaussian number=183332, print grad=0.0002453594352118671, Depth Loss=0.0000000] 
Training progress:  68%|██████▊   | 1360/2000 [14:21<04:12,  2.54it/s, Loss=0.0076980, Gaussian number=183332, print grad=0.0002453594352118671, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1360/2000 [14:24<04:12,  2.54it/s, Loss=0.0143805, Gaussian number=183332, print grad=0.00028778295381926, Depth Loss=0.0000000]  
Training progress:  68%|██████▊   | 1370/2000 [14:24<04:08,  2.54it/s, Loss=0.0143805, Gaussian number=183332, print grad=0.00028778295381926, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1370/2000 [14:28<04:08,  2.54it/s, Loss=0.0090551, Gaussian number=183332, print grad=0.00032776009174995124, Depth Loss=0.0000000]
Training progress:  69%|██████▉   | 1380/2000 [14:28<04:04,  2.54it/s, Loss=0.0090551, Gaussian number=183332, print grad=0.00032776009174995124, Depth Loss=0.0000000]
Training progress:  69%|██████▉   | 1380/2000 [14:32<04:04,  2.54it/s, Loss=0.0082048, Gaussian number=183332, print grad=0.00036622511106543243, Depth Loss=0.0000000]
Training progress:  70%|██████▉   | 1390/2000 [14:32<04:00,  2.53it/s, Loss=0.0082048, Gaussian number=183332, print grad=0.00036622511106543243, Depth Loss=0.0000000]
Training progress:  70%|██████▉   | 1390/2000 [14:36<04:00,  2.53it/s, Loss=0.0092898, Gaussian number=183332, print grad=0.0004087122797500342, Depth Loss=0.0000000] 
Training progress:  70%|███████   | 1400/2000 [14:36<03:56,  2.53it/s, Loss=0.0092898, Gaussian number=183332, print grad=0.0004087122797500342, Depth Loss=0.0000000]
Training progress:  70%|███████   | 1400/2000 [14:40<03:56,  2.53it/s, Loss=0.0102671, Gaussian number=183437, print grad=4.2144194594584405e-05, Depth Loss=0.0000000]
Training progress:  70%|███████   | 1410/2000 [14:40<03:53,  2.53it/s, Loss=0.0102671, Gaussian number=183437, print grad=4.2144194594584405e-05, Depth Loss=0.0000000]
Training progress:  70%|███████   | 1410/2000 [14:44<03:53,  2.53it/s, Loss=0.0091644, Gaussian number=183437, print grad=8.793614688329399e-05, Depth Loss=0.0000000] 
Training progress:  71%|███████   | 1420/2000 [14:44<03:49,  2.53it/s, Loss=0.0091644, Gaussian number=183437, print grad=8.793614688329399e-05, Depth Loss=0.0000000]
Training progress:  71%|███████   | 1420/2000 [14:48<03:49,  2.53it/s, Loss=0.0093670, Gaussian number=183437, print grad=0.0001343813637504354, Depth Loss=0.0000000]
Training progress:  72%|███████▏  | 1430/2000 [14:48<03:45,  2.53it/s, Loss=0.0093670, Gaussian number=183437, print grad=0.0001343813637504354, Depth Loss=0.0000000]
Training progress:  72%|███████▏  | 1430/2000 [14:52<03:45,  2.53it/s, Loss=0.0089111, Gaussian number=183437, print grad=0.00017425722035113722, Depth Loss=0.0000000]
Training progress:  72%|███████▏  | 1440/2000 [14:52<03:41,  2.53it/s, Loss=0.0089111, Gaussian number=183437, print grad=0.00017425722035113722, Depth Loss=0.0000000]
Training progress:  72%|███████▏  | 1440/2000 [14:56<03:41,  2.53it/s, Loss=0.0080257, Gaussian number=183437, print grad=0.00021378404926508665, Depth Loss=0.0000000]
Training progress:  72%|███████▎  | 1450/2000 [14:56<03:37,  2.53it/s, Loss=0.0080257, Gaussian number=183437, print grad=0.00021378404926508665, Depth Loss=0.0000000]
Training progress:  72%|███████▎  | 1450/2000 [15:00<03:37,  2.53it/s, Loss=0.0072604, Gaussian number=183437, print grad=0.0002552292717155069, Depth Loss=0.0000000] 
Training progress:  73%|███████▎  | 1460/2000 [15:00<03:33,  2.53it/s, Loss=0.0072604, Gaussian number=183437, print grad=0.0002552292717155069, Depth Loss=0.0000000]
Training progress:  73%|███████▎  | 1460/2000 [15:04<03:33,  2.53it/s, Loss=0.0094940, Gaussian number=183437, print grad=0.0002963446022477001, Depth Loss=0.0000000]
Training progress:  74%|███████▎  | 1470/2000 [15:04<03:29,  2.53it/s, Loss=0.0094940, Gaussian number=183437, print grad=0.0002963446022477001, Depth Loss=0.0000000]
Training progress:  74%|███████▎  | 1470/2000 [15:08<03:29,  2.53it/s, Loss=0.0098699, Gaussian number=183437, print grad=0.00034032241092063487, Depth Loss=0.0000000]
Training progress:  74%|███████▍  | 1480/2000 [15:08<03:25,  2.53it/s, Loss=0.0098699, Gaussian number=183437, print grad=0.00034032241092063487, Depth Loss=0.0000000]
Training progress:  74%|███████▍  | 1480/2000 [15:12<03:25,  2.53it/s, Loss=0.0101609, Gaussian number=183437, print grad=0.0003849700733553618, Depth Loss=0.0000000] 
Training progress:  74%|███████▍  | 1490/2000 [15:12<03:21,  2.53it/s, Loss=0.0101609, Gaussian number=183437, print grad=0.0003849700733553618, Depth Loss=0.0000000]
Training progress:  74%|███████▍  | 1490/2000 [15:16<03:21,  2.53it/s, Loss=0.0097966, Gaussian number=183437, print grad=0.0004283574817236513, Depth Loss=0.0000000]
Training progress:  75%|███████▌  | 1500/2000 [15:16<03:17,  2.53it/s, Loss=0.0097966, Gaussian number=183437, print grad=0.0004283574817236513, Depth Loss=0.0000000]
Training progress:  75%|███████▌  | 1500/2000 [16:24<03:17,  2.53it/s, Loss=0.0105561, Gaussian number=183545, print grad=3.6826753785135224e-05, Depth Loss=0.0000000]
Training progress:  76%|███████▌  | 1510/2000 [16:24<18:51,  2.31s/it, Loss=0.0105561, Gaussian number=183545, print grad=3.6826753785135224e-05, Depth Loss=0.0000000]
Training progress:  76%|███████▌  | 1510/2000 [16:28<18:51,  2.31s/it, Loss=0.0092691, Gaussian number=183545, print grad=7.691307837376371e-05, Depth Loss=0.0000000] 
Training progress:  76%|███████▌  | 1520/2000 [16:28<13:52,  1.73s/it, Loss=0.0092691, Gaussian number=183545, print grad=7.691307837376371e-05, Depth Loss=0.0000000]
Training progress:  76%|███████▌  | 1520/2000 [16:31<13:52,  1.73s/it, Loss=0.0058072, Gaussian number=183545, print grad=0.00012095403508283198, Depth Loss=0.0000000]
Training progress:  76%|███████▋  | 1530/2000 [16:31<10:26,  1.33s/it, Loss=0.0058072, Gaussian number=183545, print grad=0.00012095403508283198, Depth Loss=0.0000000]
Training progress:  76%|███████▋  | 1530/2000 [16:35<10:26,  1.33s/it, Loss=0.0081868, Gaussian number=183545, print grad=0.00016202278493437916, Depth Loss=0.0000000]
Training progress:  77%|███████▋  | 1540/2000 [16:35<08:03,  1.05s/it, Loss=0.0081868, Gaussian number=183545, print grad=0.00016202278493437916, Depth Loss=0.0000000]
Training progress:  77%|███████▋  | 1540/2000 [16:39<08:03,  1.05s/it, Loss=0.0088372, Gaussian number=183545, print grad=0.00020727560331579298, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1550/2000 [16:39<06:23,  1.17it/s, Loss=0.0088372, Gaussian number=183545, print grad=0.00020727560331579298, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1550/2000 [16:43<06:23,  1.17it/s, Loss=0.0091678, Gaussian number=183545, print grad=0.00025269054458476603, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1560/2000 [16:43<05:14,  1.40it/s, Loss=0.0091678, Gaussian number=183545, print grad=0.00025269054458476603, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1560/2000 [16:47<05:14,  1.40it/s, Loss=0.0081936, Gaussian number=183545, print grad=0.0002960854908451438, Depth Loss=0.0000000] 
Training progress:  78%|███████▊  | 1570/2000 [16:47<04:25,  1.62it/s, Loss=0.0081936, Gaussian number=183545, print grad=0.0002960854908451438, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1570/2000 [16:51<04:25,  1.62it/s, Loss=0.0062405, Gaussian number=183545, print grad=0.0003317519149277359, Depth Loss=0.0000000]
Training progress:  79%|███████▉  | 1580/2000 [16:51<03:51,  1.81it/s, Loss=0.0062405, Gaussian number=183545, print grad=0.0003317519149277359, Depth Loss=0.0000000]
Training progress:  79%|███████▉  | 1580/2000 [16:55<03:51,  1.81it/s, Loss=0.0085054, Gaussian number=183545, print grad=0.0003707809664774686, Depth Loss=0.0000000]
Training progress:  80%|███████▉  | 1590/2000 [16:55<03:26,  1.99it/s, Loss=0.0085054, Gaussian number=183545, print grad=0.0003707809664774686, Depth Loss=0.0000000]
Training progress:  80%|███████▉  | 1590/2000 [16:59<03:26,  1.99it/s, Loss=0.0083248, Gaussian number=183545, print grad=0.0004148205916862935, Depth Loss=0.0000000]
Training progress:  80%|████████  | 1600/2000 [16:59<03:08,  2.13it/s, Loss=0.0083248, Gaussian number=183545, print grad=0.0004148205916862935, Depth Loss=0.0000000]
Training progress:  80%|████████  | 1600/2000 [17:03<03:08,  2.13it/s, Loss=0.0087230, Gaussian number=183620, print grad=4.247089600539766e-05, Depth Loss=0.0000000]
Training progress:  80%|████████  | 1610/2000 [17:03<02:54,  2.23it/s, Loss=0.0087230, Gaussian number=183620, print grad=4.247089600539766e-05, Depth Loss=0.0000000]
Training progress:  80%|████████  | 1610/2000 [17:07<02:54,  2.23it/s, Loss=0.0092087, Gaussian number=183620, print grad=8.853555482346565e-05, Depth Loss=0.0000000]
Training progress:  81%|████████  | 1620/2000 [17:07<02:43,  2.32it/s, Loss=0.0092087, Gaussian number=183620, print grad=8.853555482346565e-05, Depth Loss=0.0000000]
Training progress:  81%|████████  | 1620/2000 [17:11<02:43,  2.32it/s, Loss=0.0079766, Gaussian number=183620, print grad=0.0001291298831347376, Depth Loss=0.0000000]
Training progress:  82%|████████▏ | 1630/2000 [17:11<02:36,  2.37it/s, Loss=0.0079766, Gaussian number=183620, print grad=0.0001291298831347376, Depth Loss=0.0000000]
Training progress:  82%|████████▏ | 1630/2000 [17:15<02:36,  2.37it/s, Loss=0.0059995, Gaussian number=183620, print grad=0.00017081167607102543, Depth Loss=0.0000000]
Training progress:  82%|████████▏ | 1640/2000 [17:15<02:28,  2.42it/s, Loss=0.0059995, Gaussian number=183620, print grad=0.00017081167607102543, Depth Loss=0.0000000]
Training progress:  82%|████████▏ | 1640/2000 [17:19<02:28,  2.42it/s, Loss=0.0082962, Gaussian number=183620, print grad=0.0002094941883115098, Depth Loss=0.0000000] 
Training progress:  82%|████████▎ | 1650/2000 [17:19<02:22,  2.46it/s, Loss=0.0082962, Gaussian number=183620, print grad=0.0002094941883115098, Depth Loss=0.0000000]
Training progress:  82%|████████▎ | 1650/2000 [17:23<02:22,  2.46it/s, Loss=0.0081414, Gaussian number=183620, print grad=0.0002504976000636816, Depth Loss=0.0000000]
Training progress:  83%|████████▎ | 1660/2000 [17:23<02:16,  2.48it/s, Loss=0.0081414, Gaussian number=183620, print grad=0.0002504976000636816, Depth Loss=0.0000000]
Training progress:  83%|████████▎ | 1660/2000 [17:27<02:16,  2.48it/s, Loss=0.0076269, Gaussian number=183620, print grad=0.0002907726156990975, Depth Loss=0.0000000]
Training progress:  84%|████████▎ | 1670/2000 [17:27<02:12,  2.50it/s, Loss=0.0076269, Gaussian number=183620, print grad=0.0002907726156990975, Depth Loss=0.0000000]
Training progress:  84%|████████▎ | 1670/2000 [17:31<02:12,  2.50it/s, Loss=0.0069792, Gaussian number=183620, print grad=0.0003346287994645536, Depth Loss=0.0000000]
Training progress:  84%|████████▍ | 1680/2000 [17:31<02:07,  2.51it/s, Loss=0.0069792, Gaussian number=183620, print grad=0.0003346287994645536, Depth Loss=0.0000000]
Training progress:  84%|████████▍ | 1680/2000 [17:34<02:07,  2.51it/s, Loss=0.0083164, Gaussian number=183620, print grad=0.00037699253880418837, Depth Loss=0.0000000]
Training progress:  84%|████████▍ | 1690/2000 [17:34<02:03,  2.52it/s, Loss=0.0083164, Gaussian number=183620, print grad=0.00037699253880418837, Depth Loss=0.0000000]
Training progress:  84%|████████▍ | 1690/2000 [17:38<02:03,  2.52it/s, Loss=0.0089572, Gaussian number=183620, print grad=0.00041581541881896555, Depth Loss=0.0000000]
Training progress:  85%|████████▌ | 1700/2000 [17:38<01:58,  2.52it/s, Loss=0.0089572, Gaussian number=183620, print grad=0.00041581541881896555, Depth Loss=0.0000000]
Training progress:  85%|████████▌ | 1700/2000 [17:42<01:58,  2.52it/s, Loss=0.0088591, Gaussian number=183743, print grad=4.2435141949681565e-05, Depth Loss=0.0000000]
Training progress:  86%|████████▌ | 1710/2000 [17:42<01:54,  2.53it/s, Loss=0.0088591, Gaussian number=183743, print grad=4.2435141949681565e-05, Depth Loss=0.0000000]
Training progress:  86%|████████▌ | 1710/2000 [17:46<01:54,  2.53it/s, Loss=0.0092700, Gaussian number=183743, print grad=8.026277646422386e-05, Depth Loss=0.0000000] 
Training progress:  86%|████████▌ | 1720/2000 [17:46<01:50,  2.53it/s, Loss=0.0092700, Gaussian number=183743, print grad=8.026277646422386e-05, Depth Loss=0.0000000]
Training progress:  86%|████████▌ | 1720/2000 [17:50<01:50,  2.53it/s, Loss=0.0082375, Gaussian number=183743, print grad=0.00012287691060919315, Depth Loss=0.0000000]
Training progress:  86%|████████▋ | 1730/2000 [17:50<01:46,  2.53it/s, Loss=0.0082375, Gaussian number=183743, print grad=0.00012287691060919315, Depth Loss=0.0000000]
Training progress:  86%|████████▋ | 1730/2000 [17:54<01:46,  2.53it/s, Loss=0.0110181, Gaussian number=183743, print grad=0.0001689675700617954, Depth Loss=0.0000000] 
Training progress:  87%|████████▋ | 1740/2000 [17:54<01:42,  2.53it/s, Loss=0.0110181, Gaussian number=183743, print grad=0.0001689675700617954, Depth Loss=0.0000000]
Training progress:  87%|████████▋ | 1740/2000 [17:58<01:42,  2.53it/s, Loss=0.0104982, Gaussian number=183743, print grad=0.00021455666865222156, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1750/2000 [17:58<01:38,  2.54it/s, Loss=0.0104982, Gaussian number=183743, print grad=0.00021455666865222156, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1750/2000 [18:02<01:38,  2.54it/s, Loss=0.0086674, Gaussian number=183743, print grad=0.0002568286145105958, Depth Loss=0.0000000] 
Training progress:  88%|████████▊ | 1760/2000 [18:02<01:34,  2.53it/s, Loss=0.0086674, Gaussian number=183743, print grad=0.0002568286145105958, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1760/2000 [18:06<01:34,  2.53it/s, Loss=0.0070982, Gaussian number=183743, print grad=0.00029665124020539224, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1770/2000 [18:06<01:30,  2.53it/s, Loss=0.0070982, Gaussian number=183743, print grad=0.00029665124020539224, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1770/2000 [18:10<01:30,  2.53it/s, Loss=0.0086612, Gaussian number=183743, print grad=0.000336566154146567, Depth Loss=0.0000000]  
Training progress:  89%|████████▉ | 1780/2000 [18:10<01:26,  2.53it/s, Loss=0.0086612, Gaussian number=183743, print grad=0.000336566154146567, Depth Loss=0.0000000]
Training progress:  89%|████████▉ | 1780/2000 [18:14<01:26,  2.53it/s, Loss=0.0078548, Gaussian number=183743, print grad=0.00037222125683911145, Depth Loss=0.0000000]
Training progress:  90%|████████▉ | 1790/2000 [18:14<01:22,  2.53it/s, Loss=0.0078548, Gaussian number=183743, print grad=0.00037222125683911145, Depth Loss=0.0000000]
Training progress:  90%|████████▉ | 1790/2000 [18:18<01:22,  2.53it/s, Loss=0.0077957, Gaussian number=183743, print grad=0.0004173248598817736, Depth Loss=0.0000000] 
Training progress:  90%|█████████ | 1800/2000 [18:18<01:18,  2.53it/s, Loss=0.0077957, Gaussian number=183743, print grad=0.0004173248598817736, Depth Loss=0.0000000]
Training progress:  90%|█████████ | 1800/2000 [18:22<01:18,  2.53it/s, Loss=0.0085653, Gaussian number=183807, print grad=4.309884752728976e-05, Depth Loss=0.0000000]
Training progress:  90%|█████████ | 1810/2000 [18:22<01:14,  2.53it/s, Loss=0.0085653, Gaussian number=183807, print grad=4.309884752728976e-05, Depth Loss=0.0000000]
Training progress:  90%|█████████ | 1810/2000 [18:26<01:14,  2.53it/s, Loss=0.0075223, Gaussian number=183807, print grad=8.847010758472607e-05, Depth Loss=0.0000000]
Training progress:  91%|█████████ | 1820/2000 [18:26<01:10,  2.54it/s, Loss=0.0075223, Gaussian number=183807, print grad=8.847010758472607e-05, Depth Loss=0.0000000]
Training progress:  91%|█████████ | 1820/2000 [18:30<01:10,  2.54it/s, Loss=0.0063622, Gaussian number=183807, print grad=0.00012584911019075662, Depth Loss=0.0000000]
Training progress:  92%|█████████▏| 1830/2000 [18:30<01:07,  2.53it/s, Loss=0.0063622, Gaussian number=183807, print grad=0.00012584911019075662, Depth Loss=0.0000000]
Training progress:  92%|█████████▏| 1830/2000 [18:34<01:07,  2.53it/s, Loss=0.0071794, Gaussian number=183807, print grad=0.0001702224399195984, Depth Loss=0.0000000] 
Training progress:  92%|█████████▏| 1840/2000 [18:34<01:03,  2.54it/s, Loss=0.0071794, Gaussian number=183807, print grad=0.0001702224399195984, Depth Loss=0.0000000]
Training progress:  92%|█████████▏| 1840/2000 [18:38<01:03,  2.54it/s, Loss=0.0076002, Gaussian number=183807, print grad=0.00021203044161666185, Depth Loss=0.0000000]
Training progress:  92%|█████████▎| 1850/2000 [18:38<00:59,  2.54it/s, Loss=0.0076002, Gaussian number=183807, print grad=0.00021203044161666185, Depth Loss=0.0000000]
Training progress:  92%|█████████▎| 1850/2000 [18:41<00:59,  2.54it/s, Loss=0.0081388, Gaussian number=183807, print grad=0.00024818957899697125, Depth Loss=0.0000000]
Training progress:  93%|█████████▎| 1860/2000 [18:41<00:55,  2.54it/s, Loss=0.0081388, Gaussian number=183807, print grad=0.00024818957899697125, Depth Loss=0.0000000]
Training progress:  93%|█████████▎| 1860/2000 [18:45<00:55,  2.54it/s, Loss=0.0088659, Gaussian number=183807, print grad=0.00029576299129985273, Depth Loss=0.0000000]
Training progress:  94%|█████████▎| 1870/2000 [18:45<00:51,  2.54it/s, Loss=0.0088659, Gaussian number=183807, print grad=0.00029576299129985273, Depth Loss=0.0000000]
Training progress:  94%|█████████▎| 1870/2000 [18:49<00:51,  2.54it/s, Loss=0.0067972, Gaussian number=183807, print grad=0.00033735577017068863, Depth Loss=0.0000000]
Training progress:  94%|█████████▍| 1880/2000 [18:49<00:47,  2.54it/s, Loss=0.0067972, Gaussian number=183807, print grad=0.00033735577017068863, Depth Loss=0.0000000]
Training progress:  94%|█████████▍| 1880/2000 [18:53<00:47,  2.54it/s, Loss=0.0078452, Gaussian number=183807, print grad=0.0003778659738600254, Depth Loss=0.0000000] 
Training progress:  94%|█████████▍| 1890/2000 [18:53<00:43,  2.54it/s, Loss=0.0078452, Gaussian number=183807, print grad=0.0003778659738600254, Depth Loss=0.0000000]
Training progress:  94%|█████████▍| 1890/2000 [18:57<00:43,  2.54it/s, Loss=0.0094369, Gaussian number=183807, print grad=0.0004217229434289038, Depth Loss=0.0000000]
Training progress:  95%|█████████▌| 1900/2000 [18:57<00:39,  2.54it/s, Loss=0.0094369, Gaussian number=183807, print grad=0.0004217229434289038, Depth Loss=0.0000000]
Training progress:  95%|█████████▌| 1900/2000 [19:01<00:39,  2.54it/s, Loss=0.0087536, Gaussian number=183934, print grad=3.746143920579925e-05, Depth Loss=0.0000000]
Training progress:  96%|█████████▌| 1910/2000 [19:01<00:35,  2.54it/s, Loss=0.0087536, Gaussian number=183934, print grad=3.746143920579925e-05, Depth Loss=0.0000000]
Training progress:  96%|█████████▌| 1910/2000 [19:05<00:35,  2.54it/s, Loss=0.0066281, Gaussian number=183934, print grad=7.879480108385906e-05, Depth Loss=0.0000000]
Training progress:  96%|█████████▌| 1920/2000 [19:05<00:31,  2.54it/s, Loss=0.0066281, Gaussian number=183934, print grad=7.879480108385906e-05, Depth Loss=0.0000000]
Training progress:  96%|█████████▌| 1920/2000 [19:09<00:31,  2.54it/s, Loss=0.0060669, Gaussian number=183934, print grad=0.00012160618643974885, Depth Loss=0.0000000]
Training progress:  96%|█████████▋| 1930/2000 [19:09<00:27,  2.54it/s, Loss=0.0060669, Gaussian number=183934, print grad=0.00012160618643974885, Depth Loss=0.0000000]
Training progress:  96%|█████████▋| 1930/2000 [19:13<00:27,  2.54it/s, Loss=0.0086544, Gaussian number=183934, print grad=0.00016226577281486243, Depth Loss=0.0000000]
Training progress:  97%|█████████▋| 1940/2000 [19:13<00:23,  2.54it/s, Loss=0.0086544, Gaussian number=183934, print grad=0.00016226577281486243, Depth Loss=0.0000000]
Training progress:  97%|█████████▋| 1940/2000 [19:17<00:23,  2.54it/s, Loss=0.0065349, Gaussian number=183934, print grad=0.00020350074919406325, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1950/2000 [19:17<00:19,  2.54it/s, Loss=0.0065349, Gaussian number=183934, print grad=0.00020350074919406325, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1950/2000 [19:21<00:19,  2.54it/s, Loss=0.0106304, Gaussian number=183934, print grad=0.00024308815773110837, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1960/2000 [19:21<00:15,  2.54it/s, Loss=0.0106304, Gaussian number=183934, print grad=0.00024308815773110837, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1960/2000 [19:25<00:15,  2.54it/s, Loss=0.0089204, Gaussian number=183934, print grad=0.00028465056675486267, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1970/2000 [19:25<00:11,  2.54it/s, Loss=0.0089204, Gaussian number=183934, print grad=0.00028465056675486267, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1970/2000 [19:29<00:11,  2.54it/s, Loss=0.0076444, Gaussian number=183934, print grad=0.0003262616810388863, Depth Loss=0.0000000] 
Training progress:  99%|█████████▉| 1980/2000 [19:29<00:07,  2.54it/s, Loss=0.0076444, Gaussian number=183934, print grad=0.0003262616810388863, Depth Loss=0.0000000]
Training progress:  99%|█████████▉| 1980/2000 [19:33<00:07,  2.54it/s, Loss=0.0073678, Gaussian number=183934, print grad=0.00037315860390663147, Depth Loss=0.0000000]
Training progress: 100%|█████████▉| 1990/2000 [19:33<00:03,  2.54it/s, Loss=0.0073678, Gaussian number=183934, print grad=0.00037315860390663147, Depth Loss=0.0000000]
Training progress: 100%|█████████▉| 1990/2000 [19:37<00:03,  2.54it/s, Loss=0.0061752, Gaussian number=183934, print grad=0.0004176724178250879, Depth Loss=0.0000000] 
Training progress: 100%|██████████| 2000/2000 [19:37<00:00,  2.54it/s, Loss=0.0061752, Gaussian number=183934, print grad=0.0004176724178250879, Depth Loss=0.0000000]
Training progress: 100%|██████████| 2000/2000 [19:37<00:00,  1.70it/s, Loss=0.0061752, Gaussian number=183934, print grad=0.0004176724178250879, Depth Loss=0.0000000]
Iteration 100 [03/12 21:07:52]

[ITER 100] Evaluating test: WD 0.019978, PSNR 12.9263,lpips 0.590464,ssim 0.452813 [03/12 21:08:49]

[ITER 100] Evaluating train: WD 0.020882, PSNR 13.2865,lpips 0.592576,ssim 0.470562 [03/12 21:08:56]
Gaussian number:182686,print gradients:2.8552960884553613e-06 [03/12 21:08:56]
Iteration 200 [03/12 21:09:36]

[ITER 200] Evaluating test: WD 0.017729, PSNR 14.2862,lpips 0.540486,ssim 0.488514 [03/12 21:10:33]

[ITER 200] Evaluating train: WD 0.017977, PSNR 14.4419,lpips 0.532059,ssim 0.502524 [03/12 21:10:40]
Gaussian number:182686,print gradients:3.618058826759807e-06 [03/12 21:10:40]
Iteration 300 [03/12 21:11:20]

[ITER 300] Evaluating test: WD 0.016265, PSNR 14.9998,lpips 0.507921,ssim 0.509006 [03/12 21:12:16]

[ITER 300] Evaluating train: WD 0.016454, PSNR 15.2398,lpips 0.497010,ssim 0.522343 [03/12 21:12:24]
Gaussian number:182686,print gradients:4.0763707147561945e-06 [03/12 21:12:24]
Iteration 400 [03/12 21:13:03]
Iteration 500 [03/12 21:13:43]

[ITER 500] Evaluating test: WD 0.014841, PSNR 15.8609,lpips 0.474085,ssim 0.531510 [03/12 21:14:40]

[ITER 500] Evaluating train: WD 0.016103, PSNR 15.8128,lpips 0.473660,ssim 0.535807 [03/12 21:14:47]
Gaussian number:182686,print gradients:4.650195478461683e-06 [03/12 21:14:47]
Iteration 600 [03/12 21:15:26]
Iteration 700 [03/12 21:16:06]
Iteration 800 [03/12 21:16:46]
Iteration 900 [03/12 21:17:25]
Iteration 1000 [03/12 21:18:05]

[ITER 1000] Evaluating test: WD 0.012929, PSNR 16.6301,lpips 0.423587,ssim 0.558877 [03/12 21:19:02]

[ITER 1000] Evaluating train: WD 0.013930, PSNR 16.6128,lpips 0.426600,ssim 0.563937 [03/12 21:19:09]
Gaussian number:182950,print gradients:6.1184700825833715e-06 [03/12 21:19:09]
Iteration 1100 [03/12 21:19:48]
Iteration 1200 [03/12 21:20:28]
Iteration 1300 [03/12 21:21:07]
Iteration 1400 [03/12 21:21:46]
Iteration 1500 [03/12 21:22:26]

[ITER 1500] Evaluating test: WD 0.011616, PSNR 17.1155,lpips 0.389981,ssim 0.575724 [03/12 21:23:23]

[ITER 1500] Evaluating train: WD 0.012344, PSNR 17.3119,lpips 0.386230,ssim 0.584645 [03/12 21:23:30]
Gaussian number:183437,print gradients:6.537326953548472e-06 [03/12 21:23:30]
Iteration 1600 [03/12 21:24:09]
Iteration 1700 [03/12 21:24:49]
Iteration 1800 [03/12 21:25:28]
Iteration 1900 [03/12 21:26:07]
Iteration 2000 [03/12 21:26:47]

[ITER 2000] Evaluating test: WD 0.010795, PSNR 17.5121,lpips 0.370380,ssim 0.588896 [03/12 21:27:43]

[ITER 2000] Evaluating train: WD 0.011937, PSNR 17.8416,lpips 0.371587,ssim 0.593670 [03/12 21:27:51]
Gaussian number:183934,print gradients:6.440156084863702e-06 [03/12 21:27:51]

[ITER 2000] Saving Gaussians [03/12 21:27:51]

Training complete. [03/12 21:27:52]
