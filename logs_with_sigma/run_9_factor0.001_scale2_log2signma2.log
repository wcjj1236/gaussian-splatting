Optimizing /home/cw4287/gaussian-model/train_30k
Output folder: /home/cw4287/gaussian-model/train_30k [03/12 19:26:22]
Tensorboard not available: not logging progress [03/12 19:26:22]
------------LLFF HOLD------------- [03/12 19:26:24]

Reading camera 1/301
Reading camera 2/301
Reading camera 3/301
Reading camera 4/301
Reading camera 5/301
Reading camera 6/301
Reading camera 7/301
Reading camera 8/301
Reading camera 9/301
Reading camera 10/301
Reading camera 11/301
Reading camera 12/301
Reading camera 13/301
Reading camera 14/301
Reading camera 15/301
Reading camera 16/301
Reading camera 17/301
Reading camera 18/301
Reading camera 19/301
Reading camera 20/301
Reading camera 21/301
Reading camera 22/301
Reading camera 23/301
Reading camera 24/301
Reading camera 25/301
Reading camera 26/301
Reading camera 27/301
Reading camera 28/301
Reading camera 29/301
Reading camera 30/301
Reading camera 31/301
Reading camera 32/301
Reading camera 33/301
Reading camera 34/301
Reading camera 35/301
Reading camera 36/301
Reading camera 37/301
Reading camera 38/301
Reading camera 39/301
Reading camera 40/301
Reading camera 41/301
Reading camera 42/301
Reading camera 43/301
Reading camera 44/301
Reading camera 45/301
Reading camera 46/301
Reading camera 47/301
Reading camera 48/301
Reading camera 49/301
Reading camera 50/301
Reading camera 51/301
Reading camera 52/301
Reading camera 53/301
Reading camera 54/301
Reading camera 55/301
Reading camera 56/301
Reading camera 57/301
Reading camera 58/301
Reading camera 59/301
Reading camera 60/301
Reading camera 61/301
Reading camera 62/301
Reading camera 63/301
Reading camera 64/301
Reading camera 65/301
Reading camera 66/301
Reading camera 67/301
Reading camera 68/301
Reading camera 69/301
Reading camera 70/301
Reading camera 71/301
Reading camera 72/301
Reading camera 73/301
Reading camera 74/301
Reading camera 75/301
Reading camera 76/301
Reading camera 77/301
Reading camera 78/301
Reading camera 79/301
Reading camera 80/301
Reading camera 81/301
Reading camera 82/301
Reading camera 83/301
Reading camera 84/301
Reading camera 85/301
Reading camera 86/301
Reading camera 87/301
Reading camera 88/301
Reading camera 89/301
Reading camera 90/301
Reading camera 91/301
Reading camera 92/301
Reading camera 93/301
Reading camera 94/301
Reading camera 95/301
Reading camera 96/301
Reading camera 97/301
Reading camera 98/301
Reading camera 99/301
Reading camera 100/301
Reading camera 101/301
Reading camera 102/301
Reading camera 103/301
Reading camera 104/301
Reading camera 105/301
Reading camera 106/301
Reading camera 107/301
Reading camera 108/301
Reading camera 109/301
Reading camera 110/301
Reading camera 111/301
Reading camera 112/301
Reading camera 113/301
Reading camera 114/301
Reading camera 115/301
Reading camera 116/301
Reading camera 117/301
Reading camera 118/301
Reading camera 119/301
Reading camera 120/301
Reading camera 121/301
Reading camera 122/301
Reading camera 123/301
Reading camera 124/301
Reading camera 125/301
Reading camera 126/301
Reading camera 127/301
Reading camera 128/301
Reading camera 129/301
Reading camera 130/301
Reading camera 131/301
Reading camera 132/301
Reading camera 133/301
Reading camera 134/301
Reading camera 135/301
Reading camera 136/301
Reading camera 137/301
Reading camera 138/301
Reading camera 139/301
Reading camera 140/301
Reading camera 141/301
Reading camera 142/301
Reading camera 143/301
Reading camera 144/301
Reading camera 145/301
Reading camera 146/301
Reading camera 147/301
Reading camera 148/301
Reading camera 149/301
Reading camera 150/301
Reading camera 151/301
Reading camera 152/301
Reading camera 153/301
Reading camera 154/301
Reading camera 155/301
Reading camera 156/301
Reading camera 157/301
Reading camera 158/301
Reading camera 159/301
Reading camera 160/301
Reading camera 161/301
Reading camera 162/301
Reading camera 163/301
Reading camera 164/301
Reading camera 165/301
Reading camera 166/301
Reading camera 167/301
Reading camera 168/301
Reading camera 169/301
Reading camera 170/301
Reading camera 171/301
Reading camera 172/301
Reading camera 173/301
Reading camera 174/301
Reading camera 175/301
Reading camera 176/301
Reading camera 177/301
Reading camera 178/301
Reading camera 179/301
Reading camera 180/301
Reading camera 181/301
Reading camera 182/301
Reading camera 183/301
Reading camera 184/301
Reading camera 185/301
Reading camera 186/301
Reading camera 187/301
Reading camera 188/301
Reading camera 189/301
Reading camera 190/301
Reading camera 191/301
Reading camera 192/301
Reading camera 193/301
Reading camera 194/301
Reading camera 195/301
Reading camera 196/301
Reading camera 197/301
Reading camera 198/301
Reading camera 199/301
Reading camera 200/301
Reading camera 201/301
Reading camera 202/301
Reading camera 203/301
Reading camera 204/301
Reading camera 205/301
Reading camera 206/301
Reading camera 207/301
Reading camera 208/301
Reading camera 209/301
Reading camera 210/301
Reading camera 211/301
Reading camera 212/301
Reading camera 213/301
Reading camera 214/301
Reading camera 215/301
Reading camera 216/301
Reading camera 217/301
Reading camera 218/301
Reading camera 219/301
Reading camera 220/301
Reading camera 221/301
Reading camera 222/301
Reading camera 223/301
Reading camera 224/301
Reading camera 225/301
Reading camera 226/301
Reading camera 227/301
Reading camera 228/301
Reading camera 229/301
Reading camera 230/301
Reading camera 231/301
Reading camera 232/301
Reading camera 233/301
Reading camera 234/301
Reading camera 235/301
Reading camera 236/301
Reading camera 237/301
Reading camera 238/301
Reading camera 239/301
Reading camera 240/301
Reading camera 241/301
Reading camera 242/301
Reading camera 243/301
Reading camera 244/301
Reading camera 245/301
Reading camera 246/301
Reading camera 247/301
Reading camera 248/301
Reading camera 249/301
Reading camera 250/301
Reading camera 251/301
Reading camera 252/301
Reading camera 253/301
Reading camera 254/301
Reading camera 255/301
Reading camera 256/301
Reading camera 257/301
Reading camera 258/301
Reading camera 259/301
Reading camera 260/301
Reading camera 261/301
Reading camera 262/301
Reading camera 263/301
Reading camera 264/301
Reading camera 265/301
Reading camera 266/301
Reading camera 267/301
Reading camera 268/301
Reading camera 269/301
Reading camera 270/301
Reading camera 271/301
Reading camera 272/301
Reading camera 273/301
Reading camera 274/301
Reading camera 275/301
Reading camera 276/301
Reading camera 277/301
Reading camera 278/301
Reading camera 279/301
Reading camera 280/301
Reading camera 281/301
Reading camera 282/301
Reading camera 283/301
Reading camera 284/301
Reading camera 285/301
Reading camera 286/301
Reading camera 287/301
Reading camera 288/301
Reading camera 289/301
Reading camera 290/301
Reading camera 291/301
Reading camera 292/301
Reading camera 293/301
Reading camera 294/301
Reading camera 295/301
Reading camera 296/301
Reading camera 297/301
Reading camera 298/301
Reading camera 299/301
Reading camera 300/301
Reading camera 301/301 [03/12 19:26:24]
Loading Training Cameras [03/12 19:26:24]
Loading Test Cameras [03/12 19:26:37]
Number of points at initialisation :  182686 [03/12 19:26:40]

Training progress:   0%|          | 0/2000 [00:00<?, ?it/s]/ext3/conda/envs/3dgs/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/ext3/conda/envs/3dgs/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)

Training progress:   0%|          | 0/2000 [00:05<?, ?it/s, Loss=0.0151829, Gaussian number=182686, print grad=6.168717391119571e-06, Depth Loss=0.0000000]
Training progress:   0%|          | 10/2000 [00:05<18:09,  1.83it/s, Loss=0.0151829, Gaussian number=182686, print grad=6.168717391119571e-06, Depth Loss=0.0000000]
Training progress:   0%|          | 10/2000 [00:09<18:09,  1.83it/s, Loss=0.0147060, Gaussian number=182686, print grad=1.637411151023116e-05, Depth Loss=0.0000000]
Training progress:   1%|          | 20/2000 [00:09<14:36,  2.26it/s, Loss=0.0147060, Gaussian number=182686, print grad=1.637411151023116e-05, Depth Loss=0.0000000]
Training progress:   1%|          | 20/2000 [00:12<14:36,  2.26it/s, Loss=0.0145985, Gaussian number=182686, print grad=2.597555794636719e-05, Depth Loss=0.0000000]
Training progress:   2%|▏         | 30/2000 [00:12<13:25,  2.45it/s, Loss=0.0145985, Gaussian number=182686, print grad=2.597555794636719e-05, Depth Loss=0.0000000]
Training progress:   2%|▏         | 30/2000 [00:16<13:25,  2.45it/s, Loss=0.0157336, Gaussian number=182686, print grad=3.6264373193262145e-05, Depth Loss=0.0000000]
Training progress:   2%|▏         | 40/2000 [00:16<12:49,  2.55it/s, Loss=0.0157336, Gaussian number=182686, print grad=3.6264373193262145e-05, Depth Loss=0.0000000]
Training progress:   2%|▏         | 40/2000 [00:20<12:49,  2.55it/s, Loss=0.0119901, Gaussian number=182686, print grad=4.4187392632011324e-05, Depth Loss=0.0000000]
Training progress:   2%|▎         | 50/2000 [00:20<12:28,  2.60it/s, Loss=0.0119901, Gaussian number=182686, print grad=4.4187392632011324e-05, Depth Loss=0.0000000]
Training progress:   2%|▎         | 50/2000 [00:23<12:28,  2.60it/s, Loss=0.0137703, Gaussian number=182686, print grad=5.655426502926275e-05, Depth Loss=0.0000000] 
Training progress:   3%|▎         | 60/2000 [00:23<12:13,  2.65it/s, Loss=0.0137703, Gaussian number=182686, print grad=5.655426502926275e-05, Depth Loss=0.0000000]
Training progress:   3%|▎         | 60/2000 [00:27<12:13,  2.65it/s, Loss=0.0124058, Gaussian number=182686, print grad=7.251843635458499e-05, Depth Loss=0.0000000]
Training progress:   4%|▎         | 70/2000 [00:27<12:03,  2.67it/s, Loss=0.0124058, Gaussian number=182686, print grad=7.251843635458499e-05, Depth Loss=0.0000000]
Training progress:   4%|▎         | 70/2000 [00:31<12:03,  2.67it/s, Loss=0.0143673, Gaussian number=182686, print grad=8.41274595586583e-05, Depth Loss=0.0000000] 
Training progress:   4%|▍         | 80/2000 [00:31<11:55,  2.68it/s, Loss=0.0143673, Gaussian number=182686, print grad=8.41274595586583e-05, Depth Loss=0.0000000]
Training progress:   4%|▍         | 80/2000 [00:34<11:55,  2.68it/s, Loss=0.0123534, Gaussian number=182686, print grad=9.617202158551663e-05, Depth Loss=0.0000000]
Training progress:   4%|▍         | 90/2000 [00:34<11:50,  2.69it/s, Loss=0.0123534, Gaussian number=182686, print grad=9.617202158551663e-05, Depth Loss=0.0000000]
Training progress:   4%|▍         | 90/2000 [00:38<11:50,  2.69it/s, Loss=0.0123467, Gaussian number=182686, print grad=0.00011076110968133435, Depth Loss=0.0000000]
Training progress:   5%|▌         | 100/2000 [00:38<11:44,  2.70it/s, Loss=0.0123467, Gaussian number=182686, print grad=0.00011076110968133435, Depth Loss=0.0000000]
Training progress:   5%|▌         | 100/2000 [01:46<11:44,  2.70it/s, Loss=0.0144303, Gaussian number=182686, print grad=0.00012688552669715136, Depth Loss=0.0000000]
Training progress:   6%|▌         | 110/2000 [01:46<1:13:59,  2.35s/it, Loss=0.0144303, Gaussian number=182686, print grad=0.00012688552669715136, Depth Loss=0.0000000]
Training progress:   6%|▌         | 110/2000 [01:50<1:13:59,  2.35s/it, Loss=0.0119697, Gaussian number=182686, print grad=0.00014251754328142852, Depth Loss=0.0000000]
Training progress:   6%|▌         | 120/2000 [01:50<54:41,  1.75s/it, Loss=0.0119697, Gaussian number=182686, print grad=0.00014251754328142852, Depth Loss=0.0000000]  
Training progress:   6%|▌         | 120/2000 [01:54<54:41,  1.75s/it, Loss=0.0139706, Gaussian number=182686, print grad=0.00016258413961622864, Depth Loss=0.0000000]
Training progress:   6%|▋         | 130/2000 [01:54<41:23,  1.33s/it, Loss=0.0139706, Gaussian number=182686, print grad=0.00016258413961622864, Depth Loss=0.0000000]
Training progress:   6%|▋         | 130/2000 [01:57<41:23,  1.33s/it, Loss=0.0126855, Gaussian number=182686, print grad=0.00018299654766451567, Depth Loss=0.0000000]
Training progress:   7%|▋         | 140/2000 [01:57<32:10,  1.04s/it, Loss=0.0126855, Gaussian number=182686, print grad=0.00018299654766451567, Depth Loss=0.0000000]
Training progress:   7%|▋         | 140/2000 [02:01<32:10,  1.04s/it, Loss=0.0109988, Gaussian number=182686, print grad=0.00020087602024432272, Depth Loss=0.0000000]
Training progress:   8%|▊         | 150/2000 [02:01<25:45,  1.20it/s, Loss=0.0109988, Gaussian number=182686, print grad=0.00020087602024432272, Depth Loss=0.0000000]
Training progress:   8%|▊         | 150/2000 [02:05<25:45,  1.20it/s, Loss=0.0117401, Gaussian number=182686, print grad=0.00022478590835817158, Depth Loss=0.0000000]
Training progress:   8%|▊         | 160/2000 [02:05<21:15,  1.44it/s, Loss=0.0117401, Gaussian number=182686, print grad=0.00022478590835817158, Depth Loss=0.0000000]
Training progress:   8%|▊         | 160/2000 [02:08<21:15,  1.44it/s, Loss=0.0116064, Gaussian number=182686, print grad=0.00024209263210650533, Depth Loss=0.0000000]
Training progress:   8%|▊         | 170/2000 [02:08<18:07,  1.68it/s, Loss=0.0116064, Gaussian number=182686, print grad=0.00024209263210650533, Depth Loss=0.0000000]
Training progress:   8%|▊         | 170/2000 [02:12<18:07,  1.68it/s, Loss=0.0102144, Gaussian number=182686, print grad=0.00026354973670095205, Depth Loss=0.0000000]
Training progress:   9%|▉         | 180/2000 [02:12<15:57,  1.90it/s, Loss=0.0102144, Gaussian number=182686, print grad=0.00026354973670095205, Depth Loss=0.0000000]
Training progress:   9%|▉         | 180/2000 [02:16<15:57,  1.90it/s, Loss=0.0128635, Gaussian number=182686, print grad=0.0002812834572978318, Depth Loss=0.0000000] 
Training progress:  10%|▉         | 190/2000 [02:16<14:24,  2.09it/s, Loss=0.0128635, Gaussian number=182686, print grad=0.0002812834572978318, Depth Loss=0.0000000]
Training progress:  10%|▉         | 190/2000 [02:19<14:24,  2.09it/s, Loss=0.0115627, Gaussian number=182686, print grad=0.0003035859845113009, Depth Loss=0.0000000]
Training progress:  10%|█         | 200/2000 [02:19<13:19,  2.25it/s, Loss=0.0115627, Gaussian number=182686, print grad=0.0003035859845113009, Depth Loss=0.0000000]
Training progress:  10%|█         | 200/2000 [03:28<13:19,  2.25it/s, Loss=0.0128376, Gaussian number=182686, print grad=0.0003273615147918463, Depth Loss=0.0000000]
Training progress:  10%|█         | 210/2000 [03:28<1:10:24,  2.36s/it, Loss=0.0128376, Gaussian number=182686, print grad=0.0003273615147918463, Depth Loss=0.0000000]
Training progress:  10%|█         | 210/2000 [03:31<1:10:24,  2.36s/it, Loss=0.0107153, Gaussian number=182686, print grad=0.00034817756386473775, Depth Loss=0.0000000]
Training progress:  11%|█         | 220/2000 [03:31<52:14,  1.76s/it, Loss=0.0107153, Gaussian number=182686, print grad=0.00034817756386473775, Depth Loss=0.0000000]  
Training progress:  11%|█         | 220/2000 [03:35<52:14,  1.76s/it, Loss=0.0118471, Gaussian number=182686, print grad=0.0003694028710015118, Depth Loss=0.0000000] 
Training progress:  12%|█▏        | 230/2000 [03:35<39:35,  1.34s/it, Loss=0.0118471, Gaussian number=182686, print grad=0.0003694028710015118, Depth Loss=0.0000000]
Training progress:  12%|█▏        | 230/2000 [03:39<39:35,  1.34s/it, Loss=0.0142473, Gaussian number=182686, print grad=0.00039014092180877924, Depth Loss=0.0000000]
Training progress:  12%|█▏        | 240/2000 [03:39<30:45,  1.05s/it, Loss=0.0142473, Gaussian number=182686, print grad=0.00039014092180877924, Depth Loss=0.0000000]
Training progress:  12%|█▏        | 240/2000 [03:42<30:45,  1.05s/it, Loss=0.0109495, Gaussian number=182686, print grad=0.00041399456677027047, Depth Loss=0.0000000]
Training progress:  12%|█▎        | 250/2000 [03:42<24:35,  1.19it/s, Loss=0.0109495, Gaussian number=182686, print grad=0.00041399456677027047, Depth Loss=0.0000000]
Training progress:  12%|█▎        | 250/2000 [03:46<24:35,  1.19it/s, Loss=0.0123504, Gaussian number=182686, print grad=0.00043595710303634405, Depth Loss=0.0000000]
Training progress:  13%|█▎        | 260/2000 [03:46<20:16,  1.43it/s, Loss=0.0123504, Gaussian number=182686, print grad=0.00043595710303634405, Depth Loss=0.0000000]
Training progress:  13%|█▎        | 260/2000 [03:49<20:16,  1.43it/s, Loss=0.0090941, Gaussian number=182686, print grad=0.0004589863237924874, Depth Loss=0.0000000] 
Training progress:  14%|█▎        | 270/2000 [03:49<17:14,  1.67it/s, Loss=0.0090941, Gaussian number=182686, print grad=0.0004589863237924874, Depth Loss=0.0000000]
Training progress:  14%|█▎        | 270/2000 [03:53<17:14,  1.67it/s, Loss=0.0117438, Gaussian number=182686, print grad=0.00048743755905888975, Depth Loss=0.0000000]
Training progress:  14%|█▍        | 280/2000 [03:53<15:07,  1.90it/s, Loss=0.0117438, Gaussian number=182686, print grad=0.00048743755905888975, Depth Loss=0.0000000]
Training progress:  14%|█▍        | 280/2000 [03:57<15:07,  1.90it/s, Loss=0.0114244, Gaussian number=182686, print grad=0.0005125844036228955, Depth Loss=0.0000000] 
Training progress:  14%|█▍        | 290/2000 [03:57<13:36,  2.09it/s, Loss=0.0114244, Gaussian number=182686, print grad=0.0005125844036228955, Depth Loss=0.0000000]
Training progress:  14%|█▍        | 290/2000 [04:00<13:36,  2.09it/s, Loss=0.0106624, Gaussian number=182686, print grad=0.0005377075867727399, Depth Loss=0.0000000]
Training progress:  15%|█▌        | 300/2000 [04:00<12:34,  2.25it/s, Loss=0.0106624, Gaussian number=182686, print grad=0.0005377075867727399, Depth Loss=0.0000000]
Training progress:  15%|█▌        | 300/2000 [05:09<12:34,  2.25it/s, Loss=0.0090812, Gaussian number=182686, print grad=0.00056606181897223, Depth Loss=0.0000000]  
Training progress:  16%|█▌        | 310/2000 [05:09<1:06:29,  2.36s/it, Loss=0.0090812, Gaussian number=182686, print grad=0.00056606181897223, Depth Loss=0.0000000]
Training progress:  16%|█▌        | 310/2000 [05:12<1:06:29,  2.36s/it, Loss=0.0094296, Gaussian number=182686, print grad=0.0005847734282724559, Depth Loss=0.0000000]
Training progress:  16%|█▌        | 320/2000 [05:12<49:18,  1.76s/it, Loss=0.0094296, Gaussian number=182686, print grad=0.0005847734282724559, Depth Loss=0.0000000]  
Training progress:  16%|█▌        | 320/2000 [05:16<49:18,  1.76s/it, Loss=0.0122296, Gaussian number=182686, print grad=0.0006089935777708888, Depth Loss=0.0000000]
Training progress:  16%|█▋        | 330/2000 [05:16<37:20,  1.34s/it, Loss=0.0122296, Gaussian number=182686, print grad=0.0006089935777708888, Depth Loss=0.0000000]
Training progress:  16%|█▋        | 330/2000 [05:20<37:20,  1.34s/it, Loss=0.0092075, Gaussian number=182686, print grad=0.0006355961668305099, Depth Loss=0.0000000]
Training progress:  17%|█▋        | 340/2000 [05:20<28:58,  1.05s/it, Loss=0.0092075, Gaussian number=182686, print grad=0.0006355961668305099, Depth Loss=0.0000000]
Training progress:  17%|█▋        | 340/2000 [05:23<28:58,  1.05s/it, Loss=0.0095047, Gaussian number=182686, print grad=0.000661570462398231, Depth Loss=0.0000000] 
Training progress:  18%|█▊        | 350/2000 [05:23<23:08,  1.19it/s, Loss=0.0095047, Gaussian number=182686, print grad=0.000661570462398231, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 350/2000 [05:27<23:08,  1.19it/s, Loss=0.0090499, Gaussian number=182686, print grad=0.0006928861257620156, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 360/2000 [05:27<19:03,  1.43it/s, Loss=0.0090499, Gaussian number=182686, print grad=0.0006928861257620156, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 360/2000 [05:30<19:03,  1.43it/s, Loss=0.0092339, Gaussian number=182686, print grad=0.0007206151494756341, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 370/2000 [05:30<16:12,  1.68it/s, Loss=0.0092339, Gaussian number=182686, print grad=0.0007206151494756341, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 370/2000 [05:34<16:12,  1.68it/s, Loss=0.0118050, Gaussian number=182686, print grad=0.0007426542579196393, Depth Loss=0.0000000]
Training progress:  19%|█▉        | 380/2000 [05:34<14:12,  1.90it/s, Loss=0.0118050, Gaussian number=182686, print grad=0.0007426542579196393, Depth Loss=0.0000000]
Training progress:  19%|█▉        | 380/2000 [05:38<14:12,  1.90it/s, Loss=0.0108396, Gaussian number=182686, print grad=0.0007698208792135119, Depth Loss=0.0000000]
Training progress:  20%|█▉        | 390/2000 [05:38<12:47,  2.10it/s, Loss=0.0108396, Gaussian number=182686, print grad=0.0007698208792135119, Depth Loss=0.0000000]
Training progress:  20%|█▉        | 390/2000 [05:41<12:47,  2.10it/s, Loss=0.0126812, Gaussian number=182686, print grad=0.0007948402781039476, Depth Loss=0.0000000]
Training progress:  20%|██        | 400/2000 [05:41<11:46,  2.26it/s, Loss=0.0126812, Gaussian number=182686, print grad=0.0007948402781039476, Depth Loss=0.0000000]
Training progress:  20%|██        | 400/2000 [05:45<11:46,  2.26it/s, Loss=0.0108590, Gaussian number=182686, print grad=0.0008261164766736329, Depth Loss=0.0000000]
Training progress:  20%|██        | 410/2000 [05:45<11:04,  2.39it/s, Loss=0.0108590, Gaussian number=182686, print grad=0.0008261164766736329, Depth Loss=0.0000000]
Training progress:  20%|██        | 410/2000 [05:48<11:04,  2.39it/s, Loss=0.0097515, Gaussian number=182686, print grad=0.000855469552334398, Depth Loss=0.0000000] 
Training progress:  21%|██        | 420/2000 [05:48<10:33,  2.49it/s, Loss=0.0097515, Gaussian number=182686, print grad=0.000855469552334398, Depth Loss=0.0000000]
Training progress:  21%|██        | 420/2000 [05:52<10:33,  2.49it/s, Loss=0.0120316, Gaussian number=182686, print grad=0.0008858941146172583, Depth Loss=0.0000000]
Training progress:  22%|██▏       | 430/2000 [05:52<10:11,  2.57it/s, Loss=0.0120316, Gaussian number=182686, print grad=0.0008858941146172583, Depth Loss=0.0000000]
Training progress:  22%|██▏       | 430/2000 [05:56<10:11,  2.57it/s, Loss=0.0095860, Gaussian number=182686, print grad=0.0009143444476649165, Depth Loss=0.0000000]
Training progress:  22%|██▏       | 440/2000 [05:56<09:53,  2.63it/s, Loss=0.0095860, Gaussian number=182686, print grad=0.0009143444476649165, Depth Loss=0.0000000]
Training progress:  22%|██▏       | 440/2000 [05:59<09:53,  2.63it/s, Loss=0.0106606, Gaussian number=182686, print grad=0.0009446595213375986, Depth Loss=0.0000000]
Training progress:  22%|██▎       | 450/2000 [05:59<09:40,  2.67it/s, Loss=0.0106606, Gaussian number=182686, print grad=0.0009446595213375986, Depth Loss=0.0000000]
Training progress:  22%|██▎       | 450/2000 [06:03<09:40,  2.67it/s, Loss=0.0108205, Gaussian number=182686, print grad=0.0009735607309266925, Depth Loss=0.0000000]
Training progress:  23%|██▎       | 460/2000 [06:03<09:31,  2.70it/s, Loss=0.0108205, Gaussian number=182686, print grad=0.0009735607309266925, Depth Loss=0.0000000]
Training progress:  23%|██▎       | 460/2000 [06:07<09:31,  2.70it/s, Loss=0.0129496, Gaussian number=182686, print grad=0.0010005430085584521, Depth Loss=0.0000000]
Training progress:  24%|██▎       | 470/2000 [06:07<09:22,  2.72it/s, Loss=0.0129496, Gaussian number=182686, print grad=0.0010005430085584521, Depth Loss=0.0000000]
Training progress:  24%|██▎       | 470/2000 [06:10<09:22,  2.72it/s, Loss=0.0088500, Gaussian number=182686, print grad=0.0010309895733371377, Depth Loss=0.0000000]
Training progress:  24%|██▍       | 480/2000 [06:10<09:15,  2.73it/s, Loss=0.0088500, Gaussian number=182686, print grad=0.0010309895733371377, Depth Loss=0.0000000]
Training progress:  24%|██▍       | 480/2000 [06:14<09:15,  2.73it/s, Loss=0.0093927, Gaussian number=182686, print grad=0.001059116912074387, Depth Loss=0.0000000] 
Training progress:  24%|██▍       | 490/2000 [06:14<09:09,  2.75it/s, Loss=0.0093927, Gaussian number=182686, print grad=0.001059116912074387, Depth Loss=0.0000000]
Training progress:  24%|██▍       | 490/2000 [06:17<09:09,  2.75it/s, Loss=0.0076697, Gaussian number=182686, print grad=0.0010878433240577579, Depth Loss=0.0000000]
Training progress:  25%|██▌       | 500/2000 [06:17<09:04,  2.75it/s, Loss=0.0076697, Gaussian number=182686, print grad=0.0010878433240577579, Depth Loss=0.0000000]
Training progress:  25%|██▌       | 500/2000 [07:26<09:04,  2.75it/s, Loss=0.0088293, Gaussian number=182686, print grad=0.0011173684615641832, Depth Loss=0.0000000]
Training progress:  26%|██▌       | 510/2000 [07:26<57:07,  2.30s/it, Loss=0.0088293, Gaussian number=182686, print grad=0.0011173684615641832, Depth Loss=0.0000000]
Training progress:  26%|██▌       | 510/2000 [07:29<57:07,  2.30s/it, Loss=0.0091161, Gaussian number=182686, print grad=0.0011486340081319213, Depth Loss=0.0000000]
Training progress:  26%|██▌       | 520/2000 [07:29<42:23,  1.72s/it, Loss=0.0091161, Gaussian number=182686, print grad=0.0011486340081319213, Depth Loss=0.0000000]
Training progress:  26%|██▌       | 520/2000 [07:33<42:23,  1.72s/it, Loss=0.0074238, Gaussian number=182686, print grad=0.001174694043584168, Depth Loss=0.0000000] 
Training progress:  26%|██▋       | 530/2000 [07:33<32:06,  1.31s/it, Loss=0.0074238, Gaussian number=182686, print grad=0.001174694043584168, Depth Loss=0.0000000]
Training progress:  26%|██▋       | 530/2000 [07:36<32:06,  1.31s/it, Loss=0.0099560, Gaussian number=182686, print grad=0.0012040219735354185, Depth Loss=0.0000000]
Training progress:  27%|██▋       | 540/2000 [07:36<24:57,  1.03s/it, Loss=0.0099560, Gaussian number=182686, print grad=0.0012040219735354185, Depth Loss=0.0000000]
Training progress:  27%|██▋       | 540/2000 [07:40<24:57,  1.03s/it, Loss=0.0094919, Gaussian number=182686, print grad=0.0012359967222437263, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 550/2000 [07:40<19:56,  1.21it/s, Loss=0.0094919, Gaussian number=182686, print grad=0.0012359967222437263, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 550/2000 [07:44<19:56,  1.21it/s, Loss=0.0077485, Gaussian number=182686, print grad=0.0012662666849792004, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 560/2000 [07:44<16:27,  1.46it/s, Loss=0.0077485, Gaussian number=182686, print grad=0.0012662666849792004, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 560/2000 [07:47<16:27,  1.46it/s, Loss=0.0098887, Gaussian number=182686, print grad=0.001300556119531393, Depth Loss=0.0000000] 
Training progress:  28%|██▊       | 570/2000 [07:47<14:01,  1.70it/s, Loss=0.0098887, Gaussian number=182686, print grad=0.001300556119531393, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 570/2000 [07:51<14:01,  1.70it/s, Loss=0.0085304, Gaussian number=182686, print grad=0.0013303925516083837, Depth Loss=0.0000000]
Training progress:  29%|██▉       | 580/2000 [07:51<12:18,  1.92it/s, Loss=0.0085304, Gaussian number=182686, print grad=0.0013303925516083837, Depth Loss=0.0000000]
Training progress:  29%|██▉       | 580/2000 [07:54<12:18,  1.92it/s, Loss=0.0097371, Gaussian number=182686, print grad=0.0013618981465697289, Depth Loss=0.0000000]
Training progress:  30%|██▉       | 590/2000 [07:54<11:07,  2.11it/s, Loss=0.0097371, Gaussian number=182686, print grad=0.0013618981465697289, Depth Loss=0.0000000]
Training progress:  30%|██▉       | 590/2000 [07:58<11:07,  2.11it/s, Loss=0.0099143, Gaussian number=182686, print grad=0.0013909913832321763, Depth Loss=0.0000000]
Training progress:  30%|███       | 600/2000 [07:58<10:14,  2.28it/s, Loss=0.0099143, Gaussian number=182686, print grad=0.0013909913832321763, Depth Loss=0.0000000]
Training progress:  30%|███       | 600/2000 [08:02<10:14,  2.28it/s, Loss=0.0084319, Gaussian number=182645, print grad=2.8810129151679575e-05, Depth Loss=0.0000000]
Training progress:  30%|███       | 610/2000 [08:02<09:37,  2.41it/s, Loss=0.0084319, Gaussian number=182645, print grad=2.8810129151679575e-05, Depth Loss=0.0000000]
Training progress:  30%|███       | 610/2000 [08:05<09:37,  2.41it/s, Loss=0.0108545, Gaussian number=182645, print grad=6.184328231029212e-05, Depth Loss=0.0000000] 
Training progress:  31%|███       | 620/2000 [08:05<09:09,  2.51it/s, Loss=0.0108545, Gaussian number=182645, print grad=6.184328231029212e-05, Depth Loss=0.0000000]
Training progress:  31%|███       | 620/2000 [08:09<09:09,  2.51it/s, Loss=0.0079516, Gaussian number=182645, print grad=8.898989472072572e-05, Depth Loss=0.0000000]
Training progress:  32%|███▏      | 630/2000 [08:09<08:49,  2.59it/s, Loss=0.0079516, Gaussian number=182645, print grad=8.898989472072572e-05, Depth Loss=0.0000000]
Training progress:  32%|███▏      | 630/2000 [08:12<08:49,  2.59it/s, Loss=0.0086005, Gaussian number=182645, print grad=0.00012575268920045346, Depth Loss=0.0000000]
Training progress:  32%|███▏      | 640/2000 [08:12<08:34,  2.64it/s, Loss=0.0086005, Gaussian number=182645, print grad=0.00012575268920045346, Depth Loss=0.0000000]
Training progress:  32%|███▏      | 640/2000 [08:16<08:34,  2.64it/s, Loss=0.0097384, Gaussian number=182645, print grad=0.00015325628919526935, Depth Loss=0.0000000]
Training progress:  32%|███▎      | 650/2000 [08:16<08:22,  2.68it/s, Loss=0.0097384, Gaussian number=182645, print grad=0.00015325628919526935, Depth Loss=0.0000000]
Training progress:  32%|███▎      | 650/2000 [08:20<08:22,  2.68it/s, Loss=0.0102360, Gaussian number=182645, print grad=0.00018712524615693837, Depth Loss=0.0000000]
Training progress:  33%|███▎      | 660/2000 [08:20<08:13,  2.71it/s, Loss=0.0102360, Gaussian number=182645, print grad=0.00018712524615693837, Depth Loss=0.0000000]
Training progress:  33%|███▎      | 660/2000 [08:23<08:13,  2.71it/s, Loss=0.0087923, Gaussian number=182645, print grad=0.00021800764079671353, Depth Loss=0.0000000]
Training progress:  34%|███▎      | 670/2000 [08:23<08:05,  2.74it/s, Loss=0.0087923, Gaussian number=182645, print grad=0.00021800764079671353, Depth Loss=0.0000000]
Training progress:  34%|███▎      | 670/2000 [08:27<08:05,  2.74it/s, Loss=0.0084242, Gaussian number=182645, print grad=0.0002535465464461595, Depth Loss=0.0000000] 
Training progress:  34%|███▍      | 680/2000 [08:27<07:59,  2.75it/s, Loss=0.0084242, Gaussian number=182645, print grad=0.0002535465464461595, Depth Loss=0.0000000]
Training progress:  34%|███▍      | 680/2000 [08:30<07:59,  2.75it/s, Loss=0.0098635, Gaussian number=182645, print grad=0.00028428196674212813, Depth Loss=0.0000000]
Training progress:  34%|███▍      | 690/2000 [08:30<07:53,  2.76it/s, Loss=0.0098635, Gaussian number=182645, print grad=0.00028428196674212813, Depth Loss=0.0000000]
Training progress:  34%|███▍      | 690/2000 [08:34<07:53,  2.76it/s, Loss=0.0099059, Gaussian number=182645, print grad=0.00031388428760692477, Depth Loss=0.0000000]
Training progress:  35%|███▌      | 700/2000 [08:34<07:49,  2.77it/s, Loss=0.0099059, Gaussian number=182645, print grad=0.00031388428760692477, Depth Loss=0.0000000]
Training progress:  35%|███▌      | 700/2000 [08:37<07:49,  2.77it/s, Loss=0.0084421, Gaussian number=182703, print grad=2.6995230655302294e-05, Depth Loss=0.0000000]
Training progress:  36%|███▌      | 710/2000 [08:37<07:45,  2.77it/s, Loss=0.0084421, Gaussian number=182703, print grad=2.6995230655302294e-05, Depth Loss=0.0000000]
Training progress:  36%|███▌      | 710/2000 [08:41<07:45,  2.77it/s, Loss=0.0078679, Gaussian number=182703, print grad=5.8600020565791056e-05, Depth Loss=0.0000000]
Training progress:  36%|███▌      | 720/2000 [08:41<07:41,  2.77it/s, Loss=0.0078679, Gaussian number=182703, print grad=5.8600020565791056e-05, Depth Loss=0.0000000]
Training progress:  36%|███▌      | 720/2000 [08:45<07:41,  2.77it/s, Loss=0.0099559, Gaussian number=182703, print grad=8.762069046497345e-05, Depth Loss=0.0000000] 
Training progress:  36%|███▋      | 730/2000 [08:45<07:36,  2.78it/s, Loss=0.0099559, Gaussian number=182703, print grad=8.762069046497345e-05, Depth Loss=0.0000000]
Training progress:  36%|███▋      | 730/2000 [08:48<07:36,  2.78it/s, Loss=0.0122513, Gaussian number=182703, print grad=0.00012331588368397206, Depth Loss=0.0000000]
Training progress:  37%|███▋      | 740/2000 [08:48<07:32,  2.79it/s, Loss=0.0122513, Gaussian number=182703, print grad=0.00012331588368397206, Depth Loss=0.0000000]
Training progress:  37%|███▋      | 740/2000 [08:52<07:32,  2.79it/s, Loss=0.0088768, Gaussian number=182703, print grad=0.00015727234131190926, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 750/2000 [08:52<07:28,  2.79it/s, Loss=0.0088768, Gaussian number=182703, print grad=0.00015727234131190926, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 750/2000 [08:55<07:28,  2.79it/s, Loss=0.0082313, Gaussian number=182703, print grad=0.00018940979498438537, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 760/2000 [08:55<07:24,  2.79it/s, Loss=0.0082313, Gaussian number=182703, print grad=0.00018940979498438537, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 760/2000 [08:59<07:24,  2.79it/s, Loss=0.0077862, Gaussian number=182703, print grad=0.00022279871336650103, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 770/2000 [08:59<07:21,  2.79it/s, Loss=0.0077862, Gaussian number=182703, print grad=0.00022279871336650103, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 770/2000 [09:03<07:21,  2.79it/s, Loss=0.0098234, Gaussian number=182703, print grad=0.00025348764029331505, Depth Loss=0.0000000]
Training progress:  39%|███▉      | 780/2000 [09:03<07:17,  2.79it/s, Loss=0.0098234, Gaussian number=182703, print grad=0.00025348764029331505, Depth Loss=0.0000000]
Training progress:  39%|███▉      | 780/2000 [09:06<07:17,  2.79it/s, Loss=0.0114355, Gaussian number=182703, print grad=0.00028545549139380455, Depth Loss=0.0000000]
Training progress:  40%|███▉      | 790/2000 [09:06<07:13,  2.79it/s, Loss=0.0114355, Gaussian number=182703, print grad=0.00028545549139380455, Depth Loss=0.0000000]
Training progress:  40%|███▉      | 790/2000 [09:10<07:13,  2.79it/s, Loss=0.0096946, Gaussian number=182703, print grad=0.00032076778006739914, Depth Loss=0.0000000]
Training progress:  40%|████      | 800/2000 [09:10<07:10,  2.79it/s, Loss=0.0096946, Gaussian number=182703, print grad=0.00032076778006739914, Depth Loss=0.0000000]
Training progress:  40%|████      | 800/2000 [09:13<07:10,  2.79it/s, Loss=0.0095813, Gaussian number=182751, print grad=3.0093257009866647e-05, Depth Loss=0.0000000]
Training progress:  40%|████      | 810/2000 [09:13<07:06,  2.79it/s, Loss=0.0095813, Gaussian number=182751, print grad=3.0093257009866647e-05, Depth Loss=0.0000000]
Training progress:  40%|████      | 810/2000 [09:17<07:06,  2.79it/s, Loss=0.0093156, Gaussian number=182751, print grad=6.0827689594589174e-05, Depth Loss=0.0000000]
Training progress:  41%|████      | 820/2000 [09:17<07:03,  2.79it/s, Loss=0.0093156, Gaussian number=182751, print grad=6.0827689594589174e-05, Depth Loss=0.0000000]
Training progress:  41%|████      | 820/2000 [09:20<07:03,  2.79it/s, Loss=0.0075885, Gaussian number=182751, print grad=9.978679736377671e-05, Depth Loss=0.0000000] 
Training progress:  42%|████▏     | 830/2000 [09:20<06:59,  2.79it/s, Loss=0.0075885, Gaussian number=182751, print grad=9.978679736377671e-05, Depth Loss=0.0000000]
Training progress:  42%|████▏     | 830/2000 [09:24<06:59,  2.79it/s, Loss=0.0079624, Gaussian number=182751, print grad=0.00013349714572541416, Depth Loss=0.0000000]
Training progress:  42%|████▏     | 840/2000 [09:24<06:55,  2.79it/s, Loss=0.0079624, Gaussian number=182751, print grad=0.00013349714572541416, Depth Loss=0.0000000]
Training progress:  42%|████▏     | 840/2000 [09:28<06:55,  2.79it/s, Loss=0.0089479, Gaussian number=182751, print grad=0.00016955341561697423, Depth Loss=0.0000000]
Training progress:  42%|████▎     | 850/2000 [09:28<06:51,  2.79it/s, Loss=0.0089479, Gaussian number=182751, print grad=0.00016955341561697423, Depth Loss=0.0000000]
Training progress:  42%|████▎     | 850/2000 [09:31<06:51,  2.79it/s, Loss=0.0083541, Gaussian number=182751, print grad=0.00020242428581696004, Depth Loss=0.0000000]
Training progress:  43%|████▎     | 860/2000 [09:31<06:48,  2.79it/s, Loss=0.0083541, Gaussian number=182751, print grad=0.00020242428581696004, Depth Loss=0.0000000]
Training progress:  43%|████▎     | 860/2000 [09:35<06:48,  2.79it/s, Loss=0.0100461, Gaussian number=182751, print grad=0.00023560735280625522, Depth Loss=0.0000000]
Training progress:  44%|████▎     | 870/2000 [09:35<06:44,  2.79it/s, Loss=0.0100461, Gaussian number=182751, print grad=0.00023560735280625522, Depth Loss=0.0000000]
Training progress:  44%|████▎     | 870/2000 [09:38<06:44,  2.79it/s, Loss=0.0095688, Gaussian number=182751, print grad=0.00026770716067403555, Depth Loss=0.0000000]
Training progress:  44%|████▍     | 880/2000 [09:38<06:40,  2.79it/s, Loss=0.0095688, Gaussian number=182751, print grad=0.00026770716067403555, Depth Loss=0.0000000]
Training progress:  44%|████▍     | 880/2000 [09:42<06:40,  2.79it/s, Loss=0.0075180, Gaussian number=182751, print grad=0.0003025952319148928, Depth Loss=0.0000000] 
Training progress:  44%|████▍     | 890/2000 [09:42<06:37,  2.79it/s, Loss=0.0075180, Gaussian number=182751, print grad=0.0003025952319148928, Depth Loss=0.0000000]
Training progress:  44%|████▍     | 890/2000 [09:46<06:37,  2.79it/s, Loss=0.0094340, Gaussian number=182751, print grad=0.0003347890742588788, Depth Loss=0.0000000]
Training progress:  45%|████▌     | 900/2000 [09:46<06:33,  2.80it/s, Loss=0.0094340, Gaussian number=182751, print grad=0.0003347890742588788, Depth Loss=0.0000000]
Training progress:  45%|████▌     | 900/2000 [09:49<06:33,  2.80it/s, Loss=0.0073056, Gaussian number=182813, print grad=2.9738488592556678e-05, Depth Loss=0.0000000]
Training progress:  46%|████▌     | 910/2000 [09:49<06:29,  2.80it/s, Loss=0.0073056, Gaussian number=182813, print grad=2.9738488592556678e-05, Depth Loss=0.0000000]
Training progress:  46%|████▌     | 910/2000 [09:53<06:29,  2.80it/s, Loss=0.0090115, Gaussian number=182813, print grad=5.683786730514839e-05, Depth Loss=0.0000000] 
Training progress:  46%|████▌     | 920/2000 [09:53<06:25,  2.80it/s, Loss=0.0090115, Gaussian number=182813, print grad=5.683786730514839e-05, Depth Loss=0.0000000]
Training progress:  46%|████▌     | 920/2000 [09:56<06:25,  2.80it/s, Loss=0.0094125, Gaussian number=182813, print grad=9.392815263709053e-05, Depth Loss=0.0000000]
Training progress:  46%|████▋     | 930/2000 [09:56<06:21,  2.80it/s, Loss=0.0094125, Gaussian number=182813, print grad=9.392815263709053e-05, Depth Loss=0.0000000]
Training progress:  46%|████▋     | 930/2000 [10:00<06:21,  2.80it/s, Loss=0.0086742, Gaussian number=182813, print grad=0.00012550107203423977, Depth Loss=0.0000000]
Training progress:  47%|████▋     | 940/2000 [10:00<06:18,  2.80it/s, Loss=0.0086742, Gaussian number=182813, print grad=0.00012550107203423977, Depth Loss=0.0000000]
Training progress:  47%|████▋     | 940/2000 [10:03<06:18,  2.80it/s, Loss=0.0079494, Gaussian number=182813, print grad=0.00016049426631070673, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 950/2000 [10:03<06:14,  2.80it/s, Loss=0.0079494, Gaussian number=182813, print grad=0.00016049426631070673, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 950/2000 [10:07<06:14,  2.80it/s, Loss=0.0084082, Gaussian number=182813, print grad=0.0001931970618898049, Depth Loss=0.0000000] 
Training progress:  48%|████▊     | 960/2000 [10:07<06:11,  2.80it/s, Loss=0.0084082, Gaussian number=182813, print grad=0.0001931970618898049, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 960/2000 [10:10<06:11,  2.80it/s, Loss=0.0103789, Gaussian number=182813, print grad=0.00022828034707345068, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 970/2000 [10:10<06:07,  2.80it/s, Loss=0.0103789, Gaussian number=182813, print grad=0.00022828034707345068, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 970/2000 [10:14<06:07,  2.80it/s, Loss=0.0072482, Gaussian number=182813, print grad=0.0002622352330945432, Depth Loss=0.0000000] 
Training progress:  49%|████▉     | 980/2000 [10:14<06:03,  2.80it/s, Loss=0.0072482, Gaussian number=182813, print grad=0.0002622352330945432, Depth Loss=0.0000000]
Training progress:  49%|████▉     | 980/2000 [10:18<06:03,  2.80it/s, Loss=0.0072401, Gaussian number=182813, print grad=0.0002917356905527413, Depth Loss=0.0000000]
Training progress:  50%|████▉     | 990/2000 [10:18<06:00,  2.80it/s, Loss=0.0072401, Gaussian number=182813, print grad=0.0002917356905527413, Depth Loss=0.0000000]
Training progress:  50%|████▉     | 990/2000 [10:21<06:00,  2.80it/s, Loss=0.0095128, Gaussian number=182813, print grad=0.00032011762959882617, Depth Loss=0.0000000]
Training progress:  50%|█████     | 1000/2000 [10:21<05:56,  2.80it/s, Loss=0.0095128, Gaussian number=182813, print grad=0.00032011762959882617, Depth Loss=0.0000000]
Training progress:  50%|█████     | 1000/2000 [11:29<05:56,  2.80it/s, Loss=0.0084697, Gaussian number=182875, print grad=2.7609732569544576e-05, Depth Loss=0.0000000]
Training progress:  50%|█████     | 1010/2000 [11:29<37:50,  2.29s/it, Loss=0.0084697, Gaussian number=182875, print grad=2.7609732569544576e-05, Depth Loss=0.0000000]
Training progress:  50%|█████     | 1010/2000 [11:33<37:50,  2.29s/it, Loss=0.0105543, Gaussian number=182875, print grad=6.562801718246192e-05, Depth Loss=0.0000000] 
Training progress:  51%|█████     | 1020/2000 [11:33<27:58,  1.71s/it, Loss=0.0105543, Gaussian number=182875, print grad=6.562801718246192e-05, Depth Loss=0.0000000]
Training progress:  51%|█████     | 1020/2000 [11:36<27:58,  1.71s/it, Loss=0.0088588, Gaussian number=182875, print grad=0.00010034233855549246, Depth Loss=0.0000000]
Training progress:  52%|█████▏    | 1030/2000 [11:36<21:07,  1.31s/it, Loss=0.0088588, Gaussian number=182875, print grad=0.00010034233855549246, Depth Loss=0.0000000]
Training progress:  52%|█████▏    | 1030/2000 [11:40<21:07,  1.31s/it, Loss=0.0092795, Gaussian number=182875, print grad=0.00013773635146208107, Depth Loss=0.0000000]
Training progress:  52%|█████▏    | 1040/2000 [11:40<16:20,  1.02s/it, Loss=0.0092795, Gaussian number=182875, print grad=0.00013773635146208107, Depth Loss=0.0000000]
Training progress:  52%|█████▏    | 1040/2000 [11:44<16:20,  1.02s/it, Loss=0.0084021, Gaussian number=182875, print grad=0.00016695045633241534, Depth Loss=0.0000000]
Training progress:  52%|█████▎    | 1050/2000 [11:44<13:01,  1.22it/s, Loss=0.0084021, Gaussian number=182875, print grad=0.00016695045633241534, Depth Loss=0.0000000]
Training progress:  52%|█████▎    | 1050/2000 [11:47<13:01,  1.22it/s, Loss=0.0082954, Gaussian number=182875, print grad=0.00020000309450551867, Depth Loss=0.0000000]
Training progress:  53%|█████▎    | 1060/2000 [11:47<10:41,  1.46it/s, Loss=0.0082954, Gaussian number=182875, print grad=0.00020000309450551867, Depth Loss=0.0000000]
Training progress:  53%|█████▎    | 1060/2000 [11:51<10:41,  1.46it/s, Loss=0.0068471, Gaussian number=182875, print grad=0.00023784354561939836, Depth Loss=0.0000000]
Training progress:  54%|█████▎    | 1070/2000 [11:51<09:04,  1.71it/s, Loss=0.0068471, Gaussian number=182875, print grad=0.00023784354561939836, Depth Loss=0.0000000]
Training progress:  54%|█████▎    | 1070/2000 [11:54<09:04,  1.71it/s, Loss=0.0073328, Gaussian number=182875, print grad=0.0002698626194614917, Depth Loss=0.0000000] 
Training progress:  54%|█████▍    | 1080/2000 [11:54<07:55,  1.94it/s, Loss=0.0073328, Gaussian number=182875, print grad=0.0002698626194614917, Depth Loss=0.0000000]
Training progress:  54%|█████▍    | 1080/2000 [11:58<07:55,  1.94it/s, Loss=0.0088495, Gaussian number=182875, print grad=0.00030554429395124316, Depth Loss=0.0000000]
Training progress:  55%|█████▍    | 1090/2000 [11:58<07:06,  2.14it/s, Loss=0.0088495, Gaussian number=182875, print grad=0.00030554429395124316, Depth Loss=0.0000000]
Training progress:  55%|█████▍    | 1090/2000 [12:01<07:06,  2.14it/s, Loss=0.0089452, Gaussian number=182875, print grad=0.0003402159782126546, Depth Loss=0.0000000] 
Training progress:  55%|█████▌    | 1100/2000 [12:01<06:31,  2.30it/s, Loss=0.0089452, Gaussian number=182875, print grad=0.0003402159782126546, Depth Loss=0.0000000]
Training progress:  55%|█████▌    | 1100/2000 [12:05<06:31,  2.30it/s, Loss=0.0093758, Gaussian number=182921, print grad=2.8909829779877327e-05, Depth Loss=0.0000000]
Training progress:  56%|█████▌    | 1110/2000 [12:05<06:05,  2.43it/s, Loss=0.0093758, Gaussian number=182921, print grad=2.8909829779877327e-05, Depth Loss=0.0000000]
Training progress:  56%|█████▌    | 1110/2000 [12:09<06:05,  2.43it/s, Loss=0.0087946, Gaussian number=182921, print grad=6.432511145249009e-05, Depth Loss=0.0000000] 
Training progress:  56%|█████▌    | 1120/2000 [12:09<05:47,  2.53it/s, Loss=0.0087946, Gaussian number=182921, print grad=6.432511145249009e-05, Depth Loss=0.0000000]
Training progress:  56%|█████▌    | 1120/2000 [12:12<05:47,  2.53it/s, Loss=0.0071905, Gaussian number=182921, print grad=0.0001019828996504657, Depth Loss=0.0000000]
Training progress:  56%|█████▋    | 1130/2000 [12:12<05:33,  2.61it/s, Loss=0.0071905, Gaussian number=182921, print grad=0.0001019828996504657, Depth Loss=0.0000000]
Training progress:  56%|█████▋    | 1130/2000 [12:16<05:33,  2.61it/s, Loss=0.0087384, Gaussian number=182921, print grad=0.00013813862460665405, Depth Loss=0.0000000]
Training progress:  57%|█████▋    | 1140/2000 [12:16<05:22,  2.67it/s, Loss=0.0087384, Gaussian number=182921, print grad=0.00013813862460665405, Depth Loss=0.0000000]
Training progress:  57%|█████▋    | 1140/2000 [12:19<05:22,  2.67it/s, Loss=0.0065311, Gaussian number=182921, print grad=0.00017473641491960734, Depth Loss=0.0000000]
Training progress:  57%|█████▊    | 1150/2000 [12:19<05:13,  2.71it/s, Loss=0.0065311, Gaussian number=182921, print grad=0.00017473641491960734, Depth Loss=0.0000000]
Training progress:  57%|█████▊    | 1150/2000 [12:23<05:13,  2.71it/s, Loss=0.0070141, Gaussian number=182921, print grad=0.00020481395768001676, Depth Loss=0.0000000]
Training progress:  58%|█████▊    | 1160/2000 [12:23<05:06,  2.74it/s, Loss=0.0070141, Gaussian number=182921, print grad=0.00020481395768001676, Depth Loss=0.0000000]
Training progress:  58%|█████▊    | 1160/2000 [12:26<05:06,  2.74it/s, Loss=0.0084868, Gaussian number=182921, print grad=0.0002395892806816846, Depth Loss=0.0000000] 
Training progress:  58%|█████▊    | 1170/2000 [12:26<05:00,  2.76it/s, Loss=0.0084868, Gaussian number=182921, print grad=0.0002395892806816846, Depth Loss=0.0000000]
Training progress:  58%|█████▊    | 1170/2000 [12:30<05:00,  2.76it/s, Loss=0.0085856, Gaussian number=182921, print grad=0.00027578609297052026, Depth Loss=0.0000000]
Training progress:  59%|█████▉    | 1180/2000 [12:30<04:55,  2.78it/s, Loss=0.0085856, Gaussian number=182921, print grad=0.00027578609297052026, Depth Loss=0.0000000]
Training progress:  59%|█████▉    | 1180/2000 [12:33<04:55,  2.78it/s, Loss=0.0085619, Gaussian number=182921, print grad=0.00031221669632941484, Depth Loss=0.0000000]
Training progress:  60%|█████▉    | 1190/2000 [12:33<04:50,  2.79it/s, Loss=0.0085619, Gaussian number=182921, print grad=0.00031221669632941484, Depth Loss=0.0000000]
Training progress:  60%|█████▉    | 1190/2000 [12:37<04:50,  2.79it/s, Loss=0.0092727, Gaussian number=182921, print grad=0.0003419862187001854, Depth Loss=0.0000000] 
Training progress:  60%|██████    | 1200/2000 [12:37<04:46,  2.80it/s, Loss=0.0092727, Gaussian number=182921, print grad=0.0003419862187001854, Depth Loss=0.0000000]
Training progress:  60%|██████    | 1200/2000 [12:41<04:46,  2.80it/s, Loss=0.0074732, Gaussian number=182985, print grad=3.2931111491052434e-05, Depth Loss=0.0000000]
Training progress:  60%|██████    | 1210/2000 [12:41<04:42,  2.80it/s, Loss=0.0074732, Gaussian number=182985, print grad=3.2931111491052434e-05, Depth Loss=0.0000000]
Training progress:  60%|██████    | 1210/2000 [12:44<04:42,  2.80it/s, Loss=0.0064331, Gaussian number=182985, print grad=7.129783625714481e-05, Depth Loss=0.0000000] 
Training progress:  61%|██████    | 1220/2000 [12:44<04:38,  2.80it/s, Loss=0.0064331, Gaussian number=182985, print grad=7.129783625714481e-05, Depth Loss=0.0000000]
Training progress:  61%|██████    | 1220/2000 [12:48<04:38,  2.80it/s, Loss=0.0069108, Gaussian number=182985, print grad=0.00010497874609427527, Depth Loss=0.0000000]
Training progress:  62%|██████▏   | 1230/2000 [12:48<04:33,  2.81it/s, Loss=0.0069108, Gaussian number=182985, print grad=0.00010497874609427527, Depth Loss=0.0000000]
Training progress:  62%|██████▏   | 1230/2000 [12:51<04:33,  2.81it/s, Loss=0.0067186, Gaussian number=182985, print grad=0.0001427888055332005, Depth Loss=0.0000000] 
Training progress:  62%|██████▏   | 1240/2000 [12:51<04:30,  2.81it/s, Loss=0.0067186, Gaussian number=182985, print grad=0.0001427888055332005, Depth Loss=0.0000000]
Training progress:  62%|██████▏   | 1240/2000 [12:55<04:30,  2.81it/s, Loss=0.0068415, Gaussian number=182985, print grad=0.00017364737868774682, Depth Loss=0.0000000]
Training progress:  62%|██████▎   | 1250/2000 [12:55<04:26,  2.81it/s, Loss=0.0068415, Gaussian number=182985, print grad=0.00017364737868774682, Depth Loss=0.0000000]
Training progress:  62%|██████▎   | 1250/2000 [12:58<04:26,  2.81it/s, Loss=0.0071495, Gaussian number=182985, print grad=0.00020398458582349122, Depth Loss=0.0000000]
Training progress:  63%|██████▎   | 1260/2000 [12:58<04:22,  2.81it/s, Loss=0.0071495, Gaussian number=182985, print grad=0.00020398458582349122, Depth Loss=0.0000000]
Training progress:  63%|██████▎   | 1260/2000 [13:02<04:22,  2.81it/s, Loss=0.0084281, Gaussian number=182985, print grad=0.00024010043125599623, Depth Loss=0.0000000]
Training progress:  64%|██████▎   | 1270/2000 [13:02<04:19,  2.81it/s, Loss=0.0084281, Gaussian number=182985, print grad=0.00024010043125599623, Depth Loss=0.0000000]
Training progress:  64%|██████▎   | 1270/2000 [13:05<04:19,  2.81it/s, Loss=0.0087017, Gaussian number=182985, print grad=0.00027171632973477244, Depth Loss=0.0000000]
Training progress:  64%|██████▍   | 1280/2000 [13:05<04:16,  2.81it/s, Loss=0.0087017, Gaussian number=182985, print grad=0.00027171632973477244, Depth Loss=0.0000000]
Training progress:  64%|██████▍   | 1280/2000 [13:09<04:16,  2.81it/s, Loss=0.0067475, Gaussian number=182985, print grad=0.00030898541444912553, Depth Loss=0.0000000]
Training progress:  64%|██████▍   | 1290/2000 [13:09<04:12,  2.81it/s, Loss=0.0067475, Gaussian number=182985, print grad=0.00030898541444912553, Depth Loss=0.0000000]
Training progress:  64%|██████▍   | 1290/2000 [13:13<04:12,  2.81it/s, Loss=0.0101137, Gaussian number=182985, print grad=0.00034168563433922827, Depth Loss=0.0000000]
Training progress:  65%|██████▌   | 1300/2000 [13:13<04:09,  2.81it/s, Loss=0.0101137, Gaussian number=182985, print grad=0.00034168563433922827, Depth Loss=0.0000000]
Training progress:  65%|██████▌   | 1300/2000 [13:16<04:09,  2.81it/s, Loss=0.0093260, Gaussian number=183024, print grad=3.5074092011200264e-05, Depth Loss=0.0000000]
Training progress:  66%|██████▌   | 1310/2000 [13:16<04:05,  2.82it/s, Loss=0.0093260, Gaussian number=183024, print grad=3.5074092011200264e-05, Depth Loss=0.0000000]
Training progress:  66%|██████▌   | 1310/2000 [13:20<04:05,  2.82it/s, Loss=0.0092057, Gaussian number=183024, print grad=6.83653270243667e-05, Depth Loss=0.0000000]  
Training progress:  66%|██████▌   | 1320/2000 [13:20<04:01,  2.82it/s, Loss=0.0092057, Gaussian number=183024, print grad=6.83653270243667e-05, Depth Loss=0.0000000]
Training progress:  66%|██████▌   | 1320/2000 [13:23<04:01,  2.82it/s, Loss=0.0071406, Gaussian number=183024, print grad=0.00010425465006846935, Depth Loss=0.0000000]
Training progress:  66%|██████▋   | 1330/2000 [13:23<03:57,  2.82it/s, Loss=0.0071406, Gaussian number=183024, print grad=0.00010425465006846935, Depth Loss=0.0000000]
Training progress:  66%|██████▋   | 1330/2000 [13:27<03:57,  2.82it/s, Loss=0.0080169, Gaussian number=183024, print grad=0.0001405627408530563, Depth Loss=0.0000000] 
Training progress:  67%|██████▋   | 1340/2000 [13:27<03:53,  2.83it/s, Loss=0.0080169, Gaussian number=183024, print grad=0.0001405627408530563, Depth Loss=0.0000000]
Training progress:  67%|██████▋   | 1340/2000 [13:30<03:53,  2.83it/s, Loss=0.0105864, Gaussian number=183024, print grad=0.00017022210522554815, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1350/2000 [13:30<03:49,  2.83it/s, Loss=0.0105864, Gaussian number=183024, print grad=0.00017022210522554815, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1350/2000 [13:34<03:49,  2.83it/s, Loss=0.0064955, Gaussian number=183024, print grad=0.00020253524417057633, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1360/2000 [13:34<03:46,  2.83it/s, Loss=0.0064955, Gaussian number=183024, print grad=0.00020253524417057633, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1360/2000 [13:37<03:46,  2.83it/s, Loss=0.0114302, Gaussian number=183024, print grad=0.00024125061463564634, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1370/2000 [13:37<03:42,  2.83it/s, Loss=0.0114302, Gaussian number=183024, print grad=0.00024125061463564634, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1370/2000 [13:41<03:42,  2.83it/s, Loss=0.0078053, Gaussian number=183024, print grad=0.0002738850307650864, Depth Loss=0.0000000] 
Training progress:  69%|██████▉   | 1380/2000 [13:41<03:38,  2.83it/s, Loss=0.0078053, Gaussian number=183024, print grad=0.0002738850307650864, Depth Loss=0.0000000]
Training progress:  69%|██████▉   | 1380/2000 [13:44<03:38,  2.83it/s, Loss=0.0072959, Gaussian number=183024, print grad=0.00030668405815958977, Depth Loss=0.0000000]
Training progress:  70%|██████▉   | 1390/2000 [13:44<03:35,  2.83it/s, Loss=0.0072959, Gaussian number=183024, print grad=0.00030668405815958977, Depth Loss=0.0000000]
Training progress:  70%|██████▉   | 1390/2000 [13:48<03:35,  2.83it/s, Loss=0.0080716, Gaussian number=183024, print grad=0.00034119628253392875, Depth Loss=0.0000000]
Training progress:  70%|███████   | 1400/2000 [13:48<03:31,  2.83it/s, Loss=0.0080716, Gaussian number=183024, print grad=0.00034119628253392875, Depth Loss=0.0000000]
Training progress:  70%|███████   | 1400/2000 [13:51<03:31,  2.83it/s, Loss=0.0087053, Gaussian number=183087, print grad=3.644388561951928e-05, Depth Loss=0.0000000] 
Training progress:  70%|███████   | 1410/2000 [13:51<03:29,  2.82it/s, Loss=0.0087053, Gaussian number=183087, print grad=3.644388561951928e-05, Depth Loss=0.0000000]
Training progress:  70%|███████   | 1410/2000 [13:55<03:29,  2.82it/s, Loss=0.0078113, Gaussian number=183087, print grad=7.210899639176205e-05, Depth Loss=0.0000000]
Training progress:  71%|███████   | 1420/2000 [13:55<03:26,  2.81it/s, Loss=0.0078113, Gaussian number=183087, print grad=7.210899639176205e-05, Depth Loss=0.0000000]
Training progress:  71%|███████   | 1420/2000 [13:59<03:26,  2.81it/s, Loss=0.0076339, Gaussian number=183087, print grad=0.0001117708015954122, Depth Loss=0.0000000]
Training progress:  72%|███████▏  | 1430/2000 [13:59<03:22,  2.81it/s, Loss=0.0076339, Gaussian number=183087, print grad=0.0001117708015954122, Depth Loss=0.0000000]
Training progress:  72%|███████▏  | 1430/2000 [14:02<03:22,  2.81it/s, Loss=0.0076143, Gaussian number=183087, print grad=0.00014338114124257118, Depth Loss=0.0000000]
Training progress:  72%|███████▏  | 1440/2000 [14:02<03:19,  2.81it/s, Loss=0.0076143, Gaussian number=183087, print grad=0.00014338114124257118, Depth Loss=0.0000000]
Training progress:  72%|███████▏  | 1440/2000 [14:06<03:19,  2.81it/s, Loss=0.0065819, Gaussian number=183087, print grad=0.0001766414352459833, Depth Loss=0.0000000] 
Training progress:  72%|███████▎  | 1450/2000 [14:06<03:15,  2.81it/s, Loss=0.0065819, Gaussian number=183087, print grad=0.0001766414352459833, Depth Loss=0.0000000]
Training progress:  72%|███████▎  | 1450/2000 [14:09<03:15,  2.81it/s, Loss=0.0061776, Gaussian number=183087, print grad=0.00021155033027753234, Depth Loss=0.0000000]
Training progress:  73%|███████▎  | 1460/2000 [14:09<03:12,  2.81it/s, Loss=0.0061776, Gaussian number=183087, print grad=0.00021155033027753234, Depth Loss=0.0000000]
Training progress:  73%|███████▎  | 1460/2000 [14:13<03:12,  2.81it/s, Loss=0.0082566, Gaussian number=183087, print grad=0.00024712353479117155, Depth Loss=0.0000000]
Training progress:  74%|███████▎  | 1470/2000 [14:13<03:08,  2.81it/s, Loss=0.0082566, Gaussian number=183087, print grad=0.00024712353479117155, Depth Loss=0.0000000]
Training progress:  74%|███████▎  | 1470/2000 [14:16<03:08,  2.81it/s, Loss=0.0083509, Gaussian number=183087, print grad=0.0002842718386091292, Depth Loss=0.0000000] 
Training progress:  74%|███████▍  | 1480/2000 [14:16<03:05,  2.81it/s, Loss=0.0083509, Gaussian number=183087, print grad=0.0002842718386091292, Depth Loss=0.0000000]
Training progress:  74%|███████▍  | 1480/2000 [14:20<03:05,  2.81it/s, Loss=0.0087704, Gaussian number=183087, print grad=0.0003209562855772674, Depth Loss=0.0000000]
Training progress:  74%|███████▍  | 1490/2000 [14:20<03:01,  2.81it/s, Loss=0.0087704, Gaussian number=183087, print grad=0.0003209562855772674, Depth Loss=0.0000000]
Training progress:  74%|███████▍  | 1490/2000 [14:24<03:01,  2.81it/s, Loss=0.0082739, Gaussian number=183087, print grad=0.0003571235865820199, Depth Loss=0.0000000]
Training progress:  75%|███████▌  | 1500/2000 [14:24<02:58,  2.81it/s, Loss=0.0082739, Gaussian number=183087, print grad=0.0003571235865820199, Depth Loss=0.0000000]
Training progress:  75%|███████▌  | 1500/2000 [15:32<02:58,  2.81it/s, Loss=0.0093200, Gaussian number=183141, print grad=3.2282703614328057e-05, Depth Loss=0.0000000]
Training progress:  76%|███████▌  | 1510/2000 [15:32<18:43,  2.29s/it, Loss=0.0093200, Gaussian number=183141, print grad=3.2282703614328057e-05, Depth Loss=0.0000000]
Training progress:  76%|███████▌  | 1510/2000 [15:35<18:43,  2.29s/it, Loss=0.0080524, Gaussian number=183141, print grad=6.456454138970003e-05, Depth Loss=0.0000000] 
Training progress:  76%|███████▌  | 1520/2000 [15:35<13:41,  1.71s/it, Loss=0.0080524, Gaussian number=183141, print grad=6.456454138970003e-05, Depth Loss=0.0000000]
Training progress:  76%|███████▌  | 1520/2000 [15:39<13:41,  1.71s/it, Loss=0.0052063, Gaussian number=183141, print grad=0.00010436451702844352, Depth Loss=0.0000000]
Training progress:  76%|███████▋  | 1530/2000 [15:39<10:13,  1.30s/it, Loss=0.0052063, Gaussian number=183141, print grad=0.00010436451702844352, Depth Loss=0.0000000]
Training progress:  76%|███████▋  | 1530/2000 [15:42<10:13,  1.30s/it, Loss=0.0068907, Gaussian number=183141, print grad=0.00014086814189795405, Depth Loss=0.0000000]
Training progress:  77%|███████▋  | 1540/2000 [15:42<07:49,  1.02s/it, Loss=0.0068907, Gaussian number=183141, print grad=0.00014086814189795405, Depth Loss=0.0000000]
Training progress:  77%|███████▋  | 1540/2000 [15:46<07:49,  1.02s/it, Loss=0.0077561, Gaussian number=183141, print grad=0.0001776392018655315, Depth Loss=0.0000000] 
Training progress:  78%|███████▊  | 1550/2000 [15:46<06:09,  1.22it/s, Loss=0.0077561, Gaussian number=183141, print grad=0.0001776392018655315, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1550/2000 [15:49<06:09,  1.22it/s, Loss=0.0081991, Gaussian number=183141, print grad=0.00021754909539595246, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1560/2000 [15:49<04:59,  1.47it/s, Loss=0.0081991, Gaussian number=183141, print grad=0.00021754909539595246, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1560/2000 [15:53<04:59,  1.47it/s, Loss=0.0071426, Gaussian number=183141, print grad=0.00025637983344495296, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1570/2000 [15:53<04:10,  1.71it/s, Loss=0.0071426, Gaussian number=183141, print grad=0.00025637983344495296, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1570/2000 [15:57<04:10,  1.71it/s, Loss=0.0054703, Gaussian number=183141, print grad=0.0002868176670745015, Depth Loss=0.0000000] 
Training progress:  79%|███████▉  | 1580/2000 [15:57<03:36,  1.94it/s, Loss=0.0054703, Gaussian number=183141, print grad=0.0002868176670745015, Depth Loss=0.0000000]
Training progress:  79%|███████▉  | 1580/2000 [16:00<03:36,  1.94it/s, Loss=0.0077466, Gaussian number=183141, print grad=0.00032047927379608154, Depth Loss=0.0000000]
Training progress:  80%|███████▉  | 1590/2000 [16:00<03:11,  2.14it/s, Loss=0.0077466, Gaussian number=183141, print grad=0.00032047927379608154, Depth Loss=0.0000000]
Training progress:  80%|███████▉  | 1590/2000 [16:04<03:11,  2.14it/s, Loss=0.0071601, Gaussian number=183141, print grad=0.000358494435204193, Depth Loss=0.0000000]  
Training progress:  80%|████████  | 1600/2000 [16:04<02:53,  2.31it/s, Loss=0.0071601, Gaussian number=183141, print grad=0.000358494435204193, Depth Loss=0.0000000]
Training progress:  80%|████████  | 1600/2000 [16:07<02:53,  2.31it/s, Loss=0.0078717, Gaussian number=183203, print grad=3.5962166293757036e-05, Depth Loss=0.0000000]
Training progress:  80%|████████  | 1610/2000 [16:07<02:39,  2.44it/s, Loss=0.0078717, Gaussian number=183203, print grad=3.5962166293757036e-05, Depth Loss=0.0000000]
Training progress:  80%|████████  | 1610/2000 [16:11<02:39,  2.44it/s, Loss=0.0079798, Gaussian number=183203, print grad=7.762783206999302e-05, Depth Loss=0.0000000] 
Training progress:  81%|████████  | 1620/2000 [16:11<02:29,  2.54it/s, Loss=0.0079798, Gaussian number=183203, print grad=7.762783206999302e-05, Depth Loss=0.0000000]
Training progress:  81%|████████  | 1620/2000 [16:14<02:29,  2.54it/s, Loss=0.0071646, Gaussian number=183203, print grad=0.00011367983825039119, Depth Loss=0.0000000]
Training progress:  82%|████████▏ | 1630/2000 [16:14<02:21,  2.62it/s, Loss=0.0071646, Gaussian number=183203, print grad=0.00011367983825039119, Depth Loss=0.0000000]
Training progress:  82%|████████▏ | 1630/2000 [16:18<02:21,  2.62it/s, Loss=0.0055047, Gaussian number=183203, print grad=0.00015005067689344287, Depth Loss=0.0000000]
Training progress:  82%|████████▏ | 1640/2000 [16:18<02:14,  2.68it/s, Loss=0.0055047, Gaussian number=183203, print grad=0.00015005067689344287, Depth Loss=0.0000000]
Training progress:  82%|████████▏ | 1640/2000 [16:21<02:14,  2.68it/s, Loss=0.0070904, Gaussian number=183203, print grad=0.00018585480574984103, Depth Loss=0.0000000]
Training progress:  82%|████████▎ | 1650/2000 [16:21<02:08,  2.72it/s, Loss=0.0070904, Gaussian number=183203, print grad=0.00018585480574984103, Depth Loss=0.0000000]
Training progress:  82%|████████▎ | 1650/2000 [16:25<02:08,  2.72it/s, Loss=0.0069602, Gaussian number=183203, print grad=0.00021987558284308761, Depth Loss=0.0000000]
Training progress:  83%|████████▎ | 1660/2000 [16:25<02:03,  2.75it/s, Loss=0.0069602, Gaussian number=183203, print grad=0.00021987558284308761, Depth Loss=0.0000000]
Training progress:  83%|████████▎ | 1660/2000 [16:28<02:03,  2.75it/s, Loss=0.0066892, Gaussian number=183203, print grad=0.0002548804914113134, Depth Loss=0.0000000] 
Training progress:  84%|████████▎ | 1670/2000 [16:28<01:59,  2.77it/s, Loss=0.0066892, Gaussian number=183203, print grad=0.0002548804914113134, Depth Loss=0.0000000]
Training progress:  84%|████████▎ | 1670/2000 [16:32<01:59,  2.77it/s, Loss=0.0062301, Gaussian number=183203, print grad=0.00029056795756332576, Depth Loss=0.0000000]
Training progress:  84%|████████▍ | 1680/2000 [16:32<01:55,  2.78it/s, Loss=0.0062301, Gaussian number=183203, print grad=0.00029056795756332576, Depth Loss=0.0000000]
Training progress:  84%|████████▍ | 1680/2000 [16:36<01:55,  2.78it/s, Loss=0.0072530, Gaussian number=183203, print grad=0.00032884275424294174, Depth Loss=0.0000000]
Training progress:  84%|████████▍ | 1690/2000 [16:36<01:50,  2.79it/s, Loss=0.0072530, Gaussian number=183203, print grad=0.00032884275424294174, Depth Loss=0.0000000]
Training progress:  84%|████████▍ | 1690/2000 [16:39<01:50,  2.79it/s, Loss=0.0078156, Gaussian number=183203, print grad=0.00036283599911257625, Depth Loss=0.0000000]
Training progress:  85%|████████▌ | 1700/2000 [16:39<01:47,  2.80it/s, Loss=0.0078156, Gaussian number=183203, print grad=0.00036283599911257625, Depth Loss=0.0000000]
Training progress:  85%|████████▌ | 1700/2000 [16:43<01:47,  2.80it/s, Loss=0.0079530, Gaussian number=183306, print grad=3.8795256841694936e-05, Depth Loss=0.0000000]
Training progress:  86%|████████▌ | 1710/2000 [16:43<01:43,  2.80it/s, Loss=0.0079530, Gaussian number=183306, print grad=3.8795256841694936e-05, Depth Loss=0.0000000]
Training progress:  86%|████████▌ | 1710/2000 [16:46<01:43,  2.80it/s, Loss=0.0079342, Gaussian number=183306, print grad=7.074574386933818e-05, Depth Loss=0.0000000] 
Training progress:  86%|████████▌ | 1720/2000 [16:46<01:39,  2.81it/s, Loss=0.0079342, Gaussian number=183306, print grad=7.074574386933818e-05, Depth Loss=0.0000000]
Training progress:  86%|████████▌ | 1720/2000 [16:50<01:39,  2.81it/s, Loss=0.0077553, Gaussian number=183306, print grad=0.00010650247713783756, Depth Loss=0.0000000]
Training progress:  86%|████████▋ | 1730/2000 [16:50<01:36,  2.81it/s, Loss=0.0077553, Gaussian number=183306, print grad=0.00010650247713783756, Depth Loss=0.0000000]
Training progress:  86%|████████▋ | 1730/2000 [16:53<01:36,  2.81it/s, Loss=0.0092927, Gaussian number=183306, print grad=0.00014537377865053713, Depth Loss=0.0000000]
Training progress:  87%|████████▋ | 1740/2000 [16:53<01:32,  2.81it/s, Loss=0.0092927, Gaussian number=183306, print grad=0.00014537377865053713, Depth Loss=0.0000000]
Training progress:  87%|████████▋ | 1740/2000 [16:57<01:32,  2.81it/s, Loss=0.0090470, Gaussian number=183306, print grad=0.00018388719763606787, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1750/2000 [16:57<01:28,  2.81it/s, Loss=0.0090470, Gaussian number=183306, print grad=0.00018388719763606787, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1750/2000 [17:00<01:28,  2.81it/s, Loss=0.0077930, Gaussian number=183306, print grad=0.0002206644567195326, Depth Loss=0.0000000] 
Training progress:  88%|████████▊ | 1760/2000 [17:00<01:25,  2.81it/s, Loss=0.0077930, Gaussian number=183306, print grad=0.0002206644567195326, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1760/2000 [17:04<01:25,  2.81it/s, Loss=0.0063000, Gaussian number=183306, print grad=0.0002544817980378866, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1770/2000 [17:04<01:21,  2.81it/s, Loss=0.0063000, Gaussian number=183306, print grad=0.0002544817980378866, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1770/2000 [17:08<01:21,  2.81it/s, Loss=0.0074108, Gaussian number=183306, print grad=0.0002888977760449052, Depth Loss=0.0000000]
Training progress:  89%|████████▉ | 1780/2000 [17:08<01:18,  2.81it/s, Loss=0.0074108, Gaussian number=183306, print grad=0.0002888977760449052, Depth Loss=0.0000000]
Training progress:  89%|████████▉ | 1780/2000 [17:11<01:18,  2.81it/s, Loss=0.0068953, Gaussian number=183306, print grad=0.00031878575100563467, Depth Loss=0.0000000]
Training progress:  90%|████████▉ | 1790/2000 [17:11<01:14,  2.81it/s, Loss=0.0068953, Gaussian number=183306, print grad=0.00031878575100563467, Depth Loss=0.0000000]
Training progress:  90%|████████▉ | 1790/2000 [17:15<01:14,  2.81it/s, Loss=0.0071328, Gaussian number=183306, print grad=0.0003575901791919023, Depth Loss=0.0000000] 
Training progress:  90%|█████████ | 1800/2000 [17:15<01:11,  2.81it/s, Loss=0.0071328, Gaussian number=183306, print grad=0.0003575901791919023, Depth Loss=0.0000000]
Training progress:  90%|█████████ | 1800/2000 [17:18<01:11,  2.81it/s, Loss=0.0073546, Gaussian number=183375, print grad=3.467279384494759e-05, Depth Loss=0.0000000]
Training progress:  90%|█████████ | 1810/2000 [17:18<01:07,  2.81it/s, Loss=0.0073546, Gaussian number=183375, print grad=3.467279384494759e-05, Depth Loss=0.0000000]
Training progress:  90%|█████████ | 1810/2000 [17:22<01:07,  2.81it/s, Loss=0.0067780, Gaussian number=183375, print grad=7.539007492596284e-05, Depth Loss=0.0000000]
Training progress:  91%|█████████ | 1820/2000 [17:22<01:04,  2.81it/s, Loss=0.0067780, Gaussian number=183375, print grad=7.539007492596284e-05, Depth Loss=0.0000000]
Training progress:  91%|█████████ | 1820/2000 [17:25<01:04,  2.81it/s, Loss=0.0056176, Gaussian number=183375, print grad=0.00010484233644092456, Depth Loss=0.0000000]
Training progress:  92%|█████████▏| 1830/2000 [17:25<01:00,  2.80it/s, Loss=0.0056176, Gaussian number=183375, print grad=0.00010484233644092456, Depth Loss=0.0000000]
Training progress:  92%|█████████▏| 1830/2000 [17:29<01:00,  2.80it/s, Loss=0.0063874, Gaussian number=183375, print grad=0.0001444980298401788, Depth Loss=0.0000000] 
Training progress:  92%|█████████▏| 1840/2000 [17:29<00:57,  2.80it/s, Loss=0.0063874, Gaussian number=183375, print grad=0.0001444980298401788, Depth Loss=0.0000000]
Training progress:  92%|█████████▏| 1840/2000 [17:32<00:57,  2.80it/s, Loss=0.0068936, Gaussian number=183375, print grad=0.00018036342225968838, Depth Loss=0.0000000]
Training progress:  92%|█████████▎| 1850/2000 [17:32<00:53,  2.80it/s, Loss=0.0068936, Gaussian number=183375, print grad=0.00018036342225968838, Depth Loss=0.0000000]
Training progress:  92%|█████████▎| 1850/2000 [17:36<00:53,  2.80it/s, Loss=0.0071067, Gaussian number=183375, print grad=0.00021269588614813983, Depth Loss=0.0000000]
Training progress:  93%|█████████▎| 1860/2000 [17:36<00:49,  2.80it/s, Loss=0.0071067, Gaussian number=183375, print grad=0.00021269588614813983, Depth Loss=0.0000000]
Training progress:  93%|█████████▎| 1860/2000 [17:40<00:49,  2.80it/s, Loss=0.0080323, Gaussian number=183375, print grad=0.0002544057497289032, Depth Loss=0.0000000] 
Training progress:  94%|█████████▎| 1870/2000 [17:40<00:46,  2.80it/s, Loss=0.0080323, Gaussian number=183375, print grad=0.0002544057497289032, Depth Loss=0.0000000]
Training progress:  94%|█████████▎| 1870/2000 [17:43<00:46,  2.80it/s, Loss=0.0063938, Gaussian number=183375, print grad=0.0002917251840699464, Depth Loss=0.0000000]
Training progress:  94%|█████████▍| 1880/2000 [17:43<00:42,  2.81it/s, Loss=0.0063938, Gaussian number=183375, print grad=0.0002917251840699464, Depth Loss=0.0000000]
Training progress:  94%|█████████▍| 1880/2000 [17:47<00:42,  2.81it/s, Loss=0.0070274, Gaussian number=183375, print grad=0.0003287800354883075, Depth Loss=0.0000000]
Training progress:  94%|█████████▍| 1890/2000 [17:47<00:39,  2.81it/s, Loss=0.0070274, Gaussian number=183375, print grad=0.0003287800354883075, Depth Loss=0.0000000]
Training progress:  94%|█████████▍| 1890/2000 [17:50<00:39,  2.81it/s, Loss=0.0082679, Gaussian number=183375, print grad=0.00036585936322808266, Depth Loss=0.0000000]
Training progress:  95%|█████████▌| 1900/2000 [17:50<00:35,  2.81it/s, Loss=0.0082679, Gaussian number=183375, print grad=0.00036585936322808266, Depth Loss=0.0000000]
Training progress:  95%|█████████▌| 1900/2000 [17:54<00:35,  2.81it/s, Loss=0.0077665, Gaussian number=183468, print grad=3.0448132747551426e-05, Depth Loss=0.0000000]
Training progress:  96%|█████████▌| 1910/2000 [17:54<00:32,  2.81it/s, Loss=0.0077665, Gaussian number=183468, print grad=3.0448132747551426e-05, Depth Loss=0.0000000]
Training progress:  96%|█████████▌| 1910/2000 [17:57<00:32,  2.81it/s, Loss=0.0059908, Gaussian number=183468, print grad=6.632397708017379e-05, Depth Loss=0.0000000] 
Training progress:  96%|█████████▌| 1920/2000 [17:57<00:28,  2.81it/s, Loss=0.0059908, Gaussian number=183468, print grad=6.632397708017379e-05, Depth Loss=0.0000000]
Training progress:  96%|█████████▌| 1920/2000 [18:01<00:28,  2.81it/s, Loss=0.0054711, Gaussian number=183468, print grad=0.00010337827552575618, Depth Loss=0.0000000]
Training progress:  96%|█████████▋| 1930/2000 [18:01<00:24,  2.81it/s, Loss=0.0054711, Gaussian number=183468, print grad=0.00010337827552575618, Depth Loss=0.0000000]
Training progress:  96%|█████████▋| 1930/2000 [18:05<00:24,  2.81it/s, Loss=0.0075740, Gaussian number=183468, print grad=0.00013934500748291612, Depth Loss=0.0000000]
Training progress:  97%|█████████▋| 1940/2000 [18:05<00:21,  2.81it/s, Loss=0.0075740, Gaussian number=183468, print grad=0.00013934500748291612, Depth Loss=0.0000000]
Training progress:  97%|█████████▋| 1940/2000 [18:08<00:21,  2.81it/s, Loss=0.0061244, Gaussian number=183468, print grad=0.00017449109873268753, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1950/2000 [18:08<00:17,  2.81it/s, Loss=0.0061244, Gaussian number=183468, print grad=0.00017449109873268753, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1950/2000 [18:12<00:17,  2.81it/s, Loss=0.0093039, Gaussian number=183468, print grad=0.0002088853798341006, Depth Loss=0.0000000] 
Training progress:  98%|█████████▊| 1960/2000 [18:12<00:14,  2.81it/s, Loss=0.0093039, Gaussian number=183468, print grad=0.0002088853798341006, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1960/2000 [18:15<00:14,  2.81it/s, Loss=0.0076647, Gaussian number=183468, print grad=0.00024405996373388916, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1970/2000 [18:15<00:10,  2.81it/s, Loss=0.0076647, Gaussian number=183468, print grad=0.00024405996373388916, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1970/2000 [18:19<00:10,  2.81it/s, Loss=0.0066322, Gaussian number=183468, print grad=0.0002816437336150557, Depth Loss=0.0000000] 
Training progress:  99%|█████████▉| 1980/2000 [18:19<00:07,  2.81it/s, Loss=0.0066322, Gaussian number=183468, print grad=0.0002816437336150557, Depth Loss=0.0000000]
Training progress:  99%|█████████▉| 1980/2000 [18:22<00:07,  2.81it/s, Loss=0.0066681, Gaussian number=183468, print grad=0.00031986343674361706, Depth Loss=0.0000000]
Training progress: 100%|█████████▉| 1990/2000 [18:22<00:03,  2.81it/s, Loss=0.0066681, Gaussian number=183468, print grad=0.00031986343674361706, Depth Loss=0.0000000]
Training progress: 100%|█████████▉| 1990/2000 [18:26<00:03,  2.81it/s, Loss=0.0056630, Gaussian number=183468, print grad=0.0003613858134485781, Depth Loss=0.0000000] 
Training progress: 100%|██████████| 2000/2000 [18:26<00:00,  2.81it/s, Loss=0.0056630, Gaussian number=183468, print grad=0.0003613858134485781, Depth Loss=0.0000000]
Training progress: 100%|██████████| 2000/2000 [18:26<00:00,  1.81it/s, Loss=0.0056630, Gaussian number=183468, print grad=0.0003613858134485781, Depth Loss=0.0000000]
Iteration 100 [03/12 19:27:18]

[ITER 100] Evaluating test: WD 0.013191, PSNR 12.8690,lpips 0.586610,ssim 0.453469 [03/12 19:28:16]

[ITER 100] Evaluating train: WD 0.013459, PSNR 13.2663,lpips 0.589796,ssim 0.472929 [03/12 19:28:23]
Gaussian number:182686,print gradients:1.5946656048981822e-06 [03/12 19:28:23]
Iteration 200 [03/12 19:29:00]

[ITER 200] Evaluating test: WD 0.011883, PSNR 14.1769,lpips 0.535875,ssim 0.488037 [03/12 19:29:57]

[ITER 200] Evaluating train: WD 0.011911, PSNR 14.6048,lpips 0.531450,ssim 0.506135 [03/12 19:30:04]
Gaussian number:182686,print gradients:2.1423441012302646e-06 [03/12 19:30:05]
Iteration 300 [03/12 19:30:41]

[ITER 300] Evaluating test: WD 0.010970, PSNR 14.9746,lpips 0.501046,ssim 0.510888 [03/12 19:31:38]

[ITER 300] Evaluating train: WD 0.010970, PSNR 15.5132,lpips 0.490405,ssim 0.529072 [03/12 19:31:46]
Gaussian number:182686,print gradients:2.5274446215917123e-06 [03/12 19:31:46]
Iteration 400 [03/12 19:32:21]
Iteration 500 [03/12 19:32:58]

[ITER 500] Evaluating test: WD 0.009932, PSNR 15.9437,lpips 0.462057,ssim 0.537545 [03/12 19:33:55]

[ITER 500] Evaluating train: WD 0.010433, PSNR 16.1976,lpips 0.460982,ssim 0.547929 [03/12 19:34:02]
Gaussian number:182686,print gradients:3.0881956263328902e-06 [03/12 19:34:02]
Iteration 600 [03/12 19:34:38]
Iteration 700 [03/12 19:35:14]
Iteration 800 [03/12 19:35:50]
Iteration 900 [03/12 19:36:26]
Iteration 1000 [03/12 19:37:01]

[ITER 1000] Evaluating test: WD 0.008704, PSNR 16.8550,lpips 0.410656,ssim 0.571107 [03/12 19:37:59]

[ITER 1000] Evaluating train: WD 0.009320, PSNR 17.0483,lpips 0.414990,ssim 0.576093 [03/12 19:38:06]
Gaussian number:182813,print gradients:4.842300768359564e-06 [03/12 19:38:06]
Iteration 1100 [03/12 19:38:42]
Iteration 1200 [03/12 19:39:17]
Iteration 1300 [03/12 19:39:53]
Iteration 1400 [03/12 19:40:28]
Iteration 1500 [03/12 19:41:04]

[ITER 1500] Evaluating test: WD 0.007854, PSNR 17.3802,lpips 0.377914,ssim 0.592844 [03/12 19:42:01]

[ITER 1500] Evaluating train: WD 0.008188, PSNR 17.6500,lpips 0.374828,ssim 0.599971 [03/12 19:42:09]
Gaussian number:183087,print gradients:5.34252058059792e-06 [03/12 19:42:09]
Iteration 1600 [03/12 19:42:44]
Iteration 1700 [03/12 19:43:19]
Iteration 1800 [03/12 19:43:55]
Iteration 1900 [03/12 19:44:30]
Iteration 2000 [03/12 19:45:06]

[ITER 2000] Evaluating test: WD 0.007289, PSNR 17.7490,lpips 0.358590,ssim 0.607821 [03/12 19:46:03]

[ITER 2000] Evaluating train: WD 0.007940, PSNR 17.9733,lpips 0.361895,ssim 0.606588 [03/12 19:46:11]
Gaussian number:183468,print gradients:5.481228527060011e-06 [03/12 19:46:11]

[ITER 2000] Saving Gaussians [03/12 19:46:11]

Training complete. [03/12 19:46:12]
