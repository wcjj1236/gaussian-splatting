Optimizing /home/cw4287/gaussian-model/train_30k
Output folder: /home/cw4287/gaussian-model/train_30k [03/12 17:41:02]
Tensorboard not available: not logging progress [03/12 17:41:02]
------------LLFF HOLD------------- [03/12 17:41:03]

Reading camera 1/301
Reading camera 2/301
Reading camera 3/301
Reading camera 4/301
Reading camera 5/301
Reading camera 6/301
Reading camera 7/301
Reading camera 8/301
Reading camera 9/301
Reading camera 10/301
Reading camera 11/301
Reading camera 12/301
Reading camera 13/301
Reading camera 14/301
Reading camera 15/301
Reading camera 16/301
Reading camera 17/301
Reading camera 18/301
Reading camera 19/301
Reading camera 20/301
Reading camera 21/301
Reading camera 22/301
Reading camera 23/301
Reading camera 24/301
Reading camera 25/301
Reading camera 26/301
Reading camera 27/301
Reading camera 28/301
Reading camera 29/301
Reading camera 30/301
Reading camera 31/301
Reading camera 32/301
Reading camera 33/301
Reading camera 34/301
Reading camera 35/301
Reading camera 36/301
Reading camera 37/301
Reading camera 38/301
Reading camera 39/301
Reading camera 40/301
Reading camera 41/301
Reading camera 42/301
Reading camera 43/301
Reading camera 44/301
Reading camera 45/301
Reading camera 46/301
Reading camera 47/301
Reading camera 48/301
Reading camera 49/301
Reading camera 50/301
Reading camera 51/301
Reading camera 52/301
Reading camera 53/301
Reading camera 54/301
Reading camera 55/301
Reading camera 56/301
Reading camera 57/301
Reading camera 58/301
Reading camera 59/301
Reading camera 60/301
Reading camera 61/301
Reading camera 62/301
Reading camera 63/301
Reading camera 64/301
Reading camera 65/301
Reading camera 66/301
Reading camera 67/301
Reading camera 68/301
Reading camera 69/301
Reading camera 70/301
Reading camera 71/301
Reading camera 72/301
Reading camera 73/301
Reading camera 74/301
Reading camera 75/301
Reading camera 76/301
Reading camera 77/301
Reading camera 78/301
Reading camera 79/301
Reading camera 80/301
Reading camera 81/301
Reading camera 82/301
Reading camera 83/301
Reading camera 84/301
Reading camera 85/301
Reading camera 86/301
Reading camera 87/301
Reading camera 88/301
Reading camera 89/301
Reading camera 90/301
Reading camera 91/301
Reading camera 92/301
Reading camera 93/301
Reading camera 94/301
Reading camera 95/301
Reading camera 96/301
Reading camera 97/301
Reading camera 98/301
Reading camera 99/301
Reading camera 100/301
Reading camera 101/301
Reading camera 102/301
Reading camera 103/301
Reading camera 104/301
Reading camera 105/301
Reading camera 106/301
Reading camera 107/301
Reading camera 108/301
Reading camera 109/301
Reading camera 110/301
Reading camera 111/301
Reading camera 112/301
Reading camera 113/301
Reading camera 114/301
Reading camera 115/301
Reading camera 116/301
Reading camera 117/301
Reading camera 118/301
Reading camera 119/301
Reading camera 120/301
Reading camera 121/301
Reading camera 122/301
Reading camera 123/301
Reading camera 124/301
Reading camera 125/301
Reading camera 126/301
Reading camera 127/301
Reading camera 128/301
Reading camera 129/301
Reading camera 130/301
Reading camera 131/301
Reading camera 132/301
Reading camera 133/301
Reading camera 134/301
Reading camera 135/301
Reading camera 136/301
Reading camera 137/301
Reading camera 138/301
Reading camera 139/301
Reading camera 140/301
Reading camera 141/301
Reading camera 142/301
Reading camera 143/301
Reading camera 144/301
Reading camera 145/301
Reading camera 146/301
Reading camera 147/301
Reading camera 148/301
Reading camera 149/301
Reading camera 150/301
Reading camera 151/301
Reading camera 152/301
Reading camera 153/301
Reading camera 154/301
Reading camera 155/301
Reading camera 156/301
Reading camera 157/301
Reading camera 158/301
Reading camera 159/301
Reading camera 160/301
Reading camera 161/301
Reading camera 162/301
Reading camera 163/301
Reading camera 164/301
Reading camera 165/301
Reading camera 166/301
Reading camera 167/301
Reading camera 168/301
Reading camera 169/301
Reading camera 170/301
Reading camera 171/301
Reading camera 172/301
Reading camera 173/301
Reading camera 174/301
Reading camera 175/301
Reading camera 176/301
Reading camera 177/301
Reading camera 178/301
Reading camera 179/301
Reading camera 180/301
Reading camera 181/301
Reading camera 182/301
Reading camera 183/301
Reading camera 184/301
Reading camera 185/301
Reading camera 186/301
Reading camera 187/301
Reading camera 188/301
Reading camera 189/301
Reading camera 190/301
Reading camera 191/301
Reading camera 192/301
Reading camera 193/301
Reading camera 194/301
Reading camera 195/301
Reading camera 196/301
Reading camera 197/301
Reading camera 198/301
Reading camera 199/301
Reading camera 200/301
Reading camera 201/301
Reading camera 202/301
Reading camera 203/301
Reading camera 204/301
Reading camera 205/301
Reading camera 206/301
Reading camera 207/301
Reading camera 208/301
Reading camera 209/301
Reading camera 210/301
Reading camera 211/301
Reading camera 212/301
Reading camera 213/301
Reading camera 214/301
Reading camera 215/301
Reading camera 216/301
Reading camera 217/301
Reading camera 218/301
Reading camera 219/301
Reading camera 220/301
Reading camera 221/301
Reading camera 222/301
Reading camera 223/301
Reading camera 224/301
Reading camera 225/301
Reading camera 226/301
Reading camera 227/301
Reading camera 228/301
Reading camera 229/301
Reading camera 230/301
Reading camera 231/301
Reading camera 232/301
Reading camera 233/301
Reading camera 234/301
Reading camera 235/301
Reading camera 236/301
Reading camera 237/301
Reading camera 238/301
Reading camera 239/301
Reading camera 240/301
Reading camera 241/301
Reading camera 242/301
Reading camera 243/301
Reading camera 244/301
Reading camera 245/301
Reading camera 246/301
Reading camera 247/301
Reading camera 248/301
Reading camera 249/301
Reading camera 250/301
Reading camera 251/301
Reading camera 252/301
Reading camera 253/301
Reading camera 254/301
Reading camera 255/301
Reading camera 256/301
Reading camera 257/301
Reading camera 258/301
Reading camera 259/301
Reading camera 260/301
Reading camera 261/301
Reading camera 262/301
Reading camera 263/301
Reading camera 264/301
Reading camera 265/301
Reading camera 266/301
Reading camera 267/301
Reading camera 268/301
Reading camera 269/301
Reading camera 270/301
Reading camera 271/301
Reading camera 272/301
Reading camera 273/301
Reading camera 274/301
Reading camera 275/301
Reading camera 276/301
Reading camera 277/301
Reading camera 278/301
Reading camera 279/301
Reading camera 280/301
Reading camera 281/301
Reading camera 282/301
Reading camera 283/301
Reading camera 284/301
Reading camera 285/301
Reading camera 286/301
Reading camera 287/301
Reading camera 288/301
Reading camera 289/301
Reading camera 290/301
Reading camera 291/301
Reading camera 292/301
Reading camera 293/301
Reading camera 294/301
Reading camera 295/301
Reading camera 296/301
Reading camera 297/301
Reading camera 298/301
Reading camera 299/301
Reading camera 300/301
Reading camera 301/301 [03/12 17:41:03]
Loading Training Cameras [03/12 17:41:03]
Loading Test Cameras [03/12 17:41:16]
Number of points at initialisation :  182686 [03/12 17:41:18]

Training progress:   0%|          | 0/2000 [00:00<?, ?it/s]/ext3/conda/envs/3dgs/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/ext3/conda/envs/3dgs/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)

Training progress:   0%|          | 0/2000 [00:05<?, ?it/s, Loss=0.1246309, Gaussian number=182686, print grad=7.693353109061718e-05, Depth Loss=0.0000000]
Training progress:   0%|          | 10/2000 [00:05<17:23,  1.91it/s, Loss=0.1246309, Gaussian number=182686, print grad=7.693353109061718e-05, Depth Loss=0.0000000]
Training progress:   0%|          | 10/2000 [00:08<17:23,  1.91it/s, Loss=0.1164051, Gaussian number=182686, print grad=0.00018325287965126336, Depth Loss=0.0000000]
Training progress:   1%|          | 20/2000 [00:08<14:15,  2.31it/s, Loss=0.1164051, Gaussian number=182686, print grad=0.00018325287965126336, Depth Loss=0.0000000]
Training progress:   1%|          | 20/2000 [00:12<14:15,  2.31it/s, Loss=0.1142806, Gaussian number=182686, print grad=0.00028487207600846887, Depth Loss=0.0000000]
Training progress:   2%|▏         | 30/2000 [00:12<13:11,  2.49it/s, Loss=0.1142806, Gaussian number=182686, print grad=0.00028487207600846887, Depth Loss=0.0000000]
Training progress:   2%|▏         | 30/2000 [00:16<13:11,  2.49it/s, Loss=0.1166991, Gaussian number=182686, print grad=0.0003812938230112195, Depth Loss=0.0000000] 
Training progress:   2%|▏         | 40/2000 [00:16<12:41,  2.57it/s, Loss=0.1166991, Gaussian number=182686, print grad=0.0003812938230112195, Depth Loss=0.0000000]
Training progress:   2%|▏         | 40/2000 [00:19<12:41,  2.57it/s, Loss=0.0885962, Gaussian number=182686, print grad=0.0004580469976644963, Depth Loss=0.0000000]
Training progress:   2%|▎         | 50/2000 [00:19<12:21,  2.63it/s, Loss=0.0885962, Gaussian number=182686, print grad=0.0004580469976644963, Depth Loss=0.0000000]
Training progress:   2%|▎         | 50/2000 [00:23<12:21,  2.63it/s, Loss=0.0944136, Gaussian number=182686, print grad=0.0005733009311370552, Depth Loss=0.0000000]
Training progress:   3%|▎         | 60/2000 [00:23<12:08,  2.66it/s, Loss=0.0944136, Gaussian number=182686, print grad=0.0005733009311370552, Depth Loss=0.0000000]
Training progress:   3%|▎         | 60/2000 [00:27<12:08,  2.66it/s, Loss=0.0814980, Gaussian number=182686, print grad=0.0006941197789274156, Depth Loss=0.0000000]
Training progress:   4%|▎         | 70/2000 [00:27<11:57,  2.69it/s, Loss=0.0814980, Gaussian number=182686, print grad=0.0006941197789274156, Depth Loss=0.0000000]
Training progress:   4%|▎         | 70/2000 [00:30<11:57,  2.69it/s, Loss=0.1019837, Gaussian number=182686, print grad=0.0007944639655761421, Depth Loss=0.0000000]
Training progress:   4%|▍         | 80/2000 [00:30<11:49,  2.71it/s, Loss=0.1019837, Gaussian number=182686, print grad=0.0007944639655761421, Depth Loss=0.0000000]
Training progress:   4%|▍         | 80/2000 [00:34<11:49,  2.71it/s, Loss=0.0870474, Gaussian number=182686, print grad=0.0009032457019202411, Depth Loss=0.0000000]
Training progress:   4%|▍         | 90/2000 [00:34<11:43,  2.72it/s, Loss=0.0870474, Gaussian number=182686, print grad=0.0009032457019202411, Depth Loss=0.0000000]
Training progress:   4%|▍         | 90/2000 [00:38<11:43,  2.72it/s, Loss=0.0785739, Gaussian number=182686, print grad=0.0010277871042490005, Depth Loss=0.0000000]
Training progress:   5%|▌         | 100/2000 [00:38<11:37,  2.72it/s, Loss=0.0785739, Gaussian number=182686, print grad=0.0010277871042490005, Depth Loss=0.0000000]
Training progress:   5%|▌         | 100/2000 [01:46<11:37,  2.72it/s, Loss=0.0966213, Gaussian number=182686, print grad=0.0011539589613676071, Depth Loss=0.0000000]
Training progress:   6%|▌         | 110/2000 [01:46<1:13:47,  2.34s/it, Loss=0.0966213, Gaussian number=182686, print grad=0.0011539589613676071, Depth Loss=0.0000000]
Training progress:   6%|▌         | 110/2000 [01:50<1:13:47,  2.34s/it, Loss=0.0746034, Gaussian number=182686, print grad=0.0012750120367854834, Depth Loss=0.0000000]
Training progress:   6%|▌         | 120/2000 [01:50<54:31,  1.74s/it, Loss=0.0746034, Gaussian number=182686, print grad=0.0012750120367854834, Depth Loss=0.0000000]  
Training progress:   6%|▌         | 120/2000 [01:53<54:31,  1.74s/it, Loss=0.0832301, Gaussian number=182686, print grad=0.0014113187789916992, Depth Loss=0.0000000]
Training progress:   6%|▋         | 130/2000 [01:53<41:13,  1.32s/it, Loss=0.0832301, Gaussian number=182686, print grad=0.0014113187789916992, Depth Loss=0.0000000]
Training progress:   6%|▋         | 130/2000 [01:57<41:13,  1.32s/it, Loss=0.0747272, Gaussian number=182686, print grad=0.0015530320815742016, Depth Loss=0.0000000]
Training progress:   7%|▋         | 140/2000 [01:57<32:01,  1.03s/it, Loss=0.0747272, Gaussian number=182686, print grad=0.0015530320815742016, Depth Loss=0.0000000]
Training progress:   7%|▋         | 140/2000 [02:00<32:01,  1.03s/it, Loss=0.0635476, Gaussian number=182686, print grad=0.001676843035966158, Depth Loss=0.0000000] 
Training progress:   8%|▊         | 150/2000 [02:00<25:37,  1.20it/s, Loss=0.0635476, Gaussian number=182686, print grad=0.001676843035966158, Depth Loss=0.0000000]
Training progress:   8%|▊         | 150/2000 [02:04<25:37,  1.20it/s, Loss=0.0709531, Gaussian number=182686, print grad=0.0018348167650401592, Depth Loss=0.0000000]
Training progress:   8%|▊         | 160/2000 [02:04<21:08,  1.45it/s, Loss=0.0709531, Gaussian number=182686, print grad=0.0018348167650401592, Depth Loss=0.0000000]
Training progress:   8%|▊         | 160/2000 [02:08<21:08,  1.45it/s, Loss=0.0701934, Gaussian number=182686, print grad=0.0019622789695858955, Depth Loss=0.0000000]
Training progress:   8%|▊         | 170/2000 [02:08<18:01,  1.69it/s, Loss=0.0701934, Gaussian number=182686, print grad=0.0019622789695858955, Depth Loss=0.0000000]
Training progress:   8%|▊         | 170/2000 [02:11<18:01,  1.69it/s, Loss=0.0568448, Gaussian number=182686, print grad=0.0021012627985328436, Depth Loss=0.0000000]
Training progress:   9%|▉         | 180/2000 [02:11<15:50,  1.92it/s, Loss=0.0568448, Gaussian number=182686, print grad=0.0021012627985328436, Depth Loss=0.0000000]
Training progress:   9%|▉         | 180/2000 [02:15<15:50,  1.92it/s, Loss=0.0715600, Gaussian number=182686, print grad=0.0022348593920469284, Depth Loss=0.0000000]
Training progress:  10%|▉         | 190/2000 [02:15<14:17,  2.11it/s, Loss=0.0715600, Gaussian number=182686, print grad=0.0022348593920469284, Depth Loss=0.0000000]
Training progress:  10%|▉         | 190/2000 [02:18<14:17,  2.11it/s, Loss=0.0635138, Gaussian number=182686, print grad=0.002370946342125535, Depth Loss=0.0000000] 
Training progress:  10%|█         | 200/2000 [02:18<13:11,  2.27it/s, Loss=0.0635138, Gaussian number=182686, print grad=0.002370946342125535, Depth Loss=0.0000000]
Training progress:  10%|█         | 200/2000 [03:27<13:11,  2.27it/s, Loss=0.0683060, Gaussian number=182686, print grad=0.0025148966815322638, Depth Loss=0.0000000]
Training progress:  10%|█         | 210/2000 [03:27<1:10:12,  2.35s/it, Loss=0.0683060, Gaussian number=182686, print grad=0.0025148966815322638, Depth Loss=0.0000000]
Training progress:  10%|█         | 210/2000 [03:30<1:10:12,  2.35s/it, Loss=0.0561285, Gaussian number=182686, print grad=0.0026546563021838665, Depth Loss=0.0000000]
Training progress:  11%|█         | 220/2000 [03:30<52:04,  1.76s/it, Loss=0.0561285, Gaussian number=182686, print grad=0.0026546563021838665, Depth Loss=0.0000000]  
Training progress:  11%|█         | 220/2000 [03:34<52:04,  1.76s/it, Loss=0.0630659, Gaussian number=182686, print grad=0.0027953770477324724, Depth Loss=0.0000000]
Training progress:  12%|█▏        | 230/2000 [03:34<39:26,  1.34s/it, Loss=0.0630659, Gaussian number=182686, print grad=0.0027953770477324724, Depth Loss=0.0000000]
Training progress:  12%|█▏        | 230/2000 [03:37<39:26,  1.34s/it, Loss=0.0784767, Gaussian number=182686, print grad=0.002930228365585208, Depth Loss=0.0000000] 
Training progress:  12%|█▏        | 240/2000 [03:37<30:36,  1.04s/it, Loss=0.0784767, Gaussian number=182686, print grad=0.002930228365585208, Depth Loss=0.0000000]
Training progress:  12%|█▏        | 240/2000 [03:41<30:36,  1.04s/it, Loss=0.0601371, Gaussian number=182686, print grad=0.0030857808887958527, Depth Loss=0.0000000]
Training progress:  12%|█▎        | 250/2000 [03:41<24:27,  1.19it/s, Loss=0.0601371, Gaussian number=182686, print grad=0.0030857808887958527, Depth Loss=0.0000000]
Training progress:  12%|█▎        | 250/2000 [03:45<24:27,  1.19it/s, Loss=0.0646081, Gaussian number=182686, print grad=0.003224244574084878, Depth Loss=0.0000000] 
Training progress:  13%|█▎        | 260/2000 [03:45<20:08,  1.44it/s, Loss=0.0646081, Gaussian number=182686, print grad=0.003224244574084878, Depth Loss=0.0000000]
Training progress:  13%|█▎        | 260/2000 [03:48<20:08,  1.44it/s, Loss=0.0448444, Gaussian number=182686, print grad=0.003370796563103795, Depth Loss=0.0000000]
Training progress:  14%|█▎        | 270/2000 [03:48<17:08,  1.68it/s, Loss=0.0448444, Gaussian number=182686, print grad=0.003370796563103795, Depth Loss=0.0000000]
Training progress:  14%|█▎        | 270/2000 [03:52<17:08,  1.68it/s, Loss=0.0600277, Gaussian number=182686, print grad=0.0035218882840126753, Depth Loss=0.0000000]
Training progress:  14%|█▍        | 280/2000 [03:52<15:00,  1.91it/s, Loss=0.0600277, Gaussian number=182686, print grad=0.0035218882840126753, Depth Loss=0.0000000]
Training progress:  14%|█▍        | 280/2000 [03:55<15:00,  1.91it/s, Loss=0.0571866, Gaussian number=182686, print grad=0.003677385626360774, Depth Loss=0.0000000] 
Training progress:  14%|█▍        | 290/2000 [03:55<13:31,  2.11it/s, Loss=0.0571866, Gaussian number=182686, print grad=0.003677385626360774, Depth Loss=0.0000000]
Training progress:  14%|█▍        | 290/2000 [03:59<13:31,  2.11it/s, Loss=0.0528227, Gaussian number=182686, print grad=0.0038324655033648014, Depth Loss=0.0000000]
Training progress:  15%|█▌        | 300/2000 [03:59<12:28,  2.27it/s, Loss=0.0528227, Gaussian number=182686, print grad=0.0038324655033648014, Depth Loss=0.0000000]
Training progress:  15%|█▌        | 300/2000 [05:07<12:28,  2.27it/s, Loss=0.0460701, Gaussian number=182686, print grad=0.003992019221186638, Depth Loss=0.0000000] 
Training progress:  16%|█▌        | 310/2000 [05:07<1:06:17,  2.35s/it, Loss=0.0460701, Gaussian number=182686, print grad=0.003992019221186638, Depth Loss=0.0000000]
Training progress:  16%|█▌        | 310/2000 [05:11<1:06:17,  2.35s/it, Loss=0.0461246, Gaussian number=182686, print grad=0.004120045807212591, Depth Loss=0.0000000]
Training progress:  16%|█▌        | 320/2000 [05:11<49:08,  1.76s/it, Loss=0.0461246, Gaussian number=182686, print grad=0.004120045807212591, Depth Loss=0.0000000]  
Training progress:  16%|█▌        | 320/2000 [05:14<49:08,  1.76s/it, Loss=0.0603125, Gaussian number=182686, print grad=0.004256713204085827, Depth Loss=0.0000000]
Training progress:  16%|█▋        | 330/2000 [05:14<37:11,  1.34s/it, Loss=0.0603125, Gaussian number=182686, print grad=0.004256713204085827, Depth Loss=0.0000000]
Training progress:  16%|█▋        | 330/2000 [05:18<37:11,  1.34s/it, Loss=0.0465979, Gaussian number=182686, print grad=0.004409295041114092, Depth Loss=0.0000000]
Training progress:  17%|█▋        | 340/2000 [05:18<28:51,  1.04s/it, Loss=0.0465979, Gaussian number=182686, print grad=0.004409295041114092, Depth Loss=0.0000000]
Training progress:  17%|█▋        | 340/2000 [05:22<28:51,  1.04s/it, Loss=0.0456470, Gaussian number=182686, print grad=0.004560301546007395, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 350/2000 [05:22<23:02,  1.19it/s, Loss=0.0456470, Gaussian number=182686, print grad=0.004560301546007395, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 350/2000 [05:25<23:02,  1.19it/s, Loss=0.0455064, Gaussian number=182686, print grad=0.004723076242953539, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 360/2000 [05:25<18:58,  1.44it/s, Loss=0.0455064, Gaussian number=182686, print grad=0.004723076242953539, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 360/2000 [05:29<18:58,  1.44it/s, Loss=0.0434489, Gaussian number=182686, print grad=0.004868462216109037, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 370/2000 [05:29<16:07,  1.68it/s, Loss=0.0434489, Gaussian number=182686, print grad=0.004868462216109037, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 370/2000 [05:32<16:07,  1.68it/s, Loss=0.0598311, Gaussian number=182686, print grad=0.0049951099790632725, Depth Loss=0.0000000]
Training progress:  19%|█▉        | 380/2000 [05:32<14:07,  1.91it/s, Loss=0.0598311, Gaussian number=182686, print grad=0.0049951099790632725, Depth Loss=0.0000000]
Training progress:  19%|█▉        | 380/2000 [05:36<14:07,  1.91it/s, Loss=0.0503037, Gaussian number=182686, print grad=0.005146119277924299, Depth Loss=0.0000000] 
Training progress:  20%|█▉        | 390/2000 [05:36<12:42,  2.11it/s, Loss=0.0503037, Gaussian number=182686, print grad=0.005146119277924299, Depth Loss=0.0000000]
Training progress:  20%|█▉        | 390/2000 [05:39<12:42,  2.11it/s, Loss=0.0640001, Gaussian number=182686, print grad=0.005287292413413525, Depth Loss=0.0000000]
Training progress:  20%|██        | 400/2000 [05:39<11:42,  2.28it/s, Loss=0.0640001, Gaussian number=182686, print grad=0.005287292413413525, Depth Loss=0.0000000]
Training progress:  20%|██        | 400/2000 [05:43<11:42,  2.28it/s, Loss=0.0525905, Gaussian number=182686, print grad=0.005457291845232248, Depth Loss=0.0000000]
Training progress:  20%|██        | 410/2000 [05:43<10:59,  2.41it/s, Loss=0.0525905, Gaussian number=182686, print grad=0.005457291845232248, Depth Loss=0.0000000]
Training progress:  20%|██        | 410/2000 [05:47<10:59,  2.41it/s, Loss=0.0456813, Gaussian number=182686, print grad=0.005628952756524086, Depth Loss=0.0000000]
Training progress:  21%|██        | 420/2000 [05:47<10:29,  2.51it/s, Loss=0.0456813, Gaussian number=182686, print grad=0.005628952756524086, Depth Loss=0.0000000]
Training progress:  21%|██        | 420/2000 [05:50<10:29,  2.51it/s, Loss=0.0573285, Gaussian number=182686, print grad=0.005796393379569054, Depth Loss=0.0000000]
Training progress:  22%|██▏       | 430/2000 [05:50<10:06,  2.59it/s, Loss=0.0573285, Gaussian number=182686, print grad=0.005796393379569054, Depth Loss=0.0000000]
Training progress:  22%|██▏       | 430/2000 [05:54<10:06,  2.59it/s, Loss=0.0454563, Gaussian number=182686, print grad=0.005941096693277359, Depth Loss=0.0000000]
Training progress:  22%|██▏       | 440/2000 [05:54<09:50,  2.64it/s, Loss=0.0454563, Gaussian number=182686, print grad=0.005941096693277359, Depth Loss=0.0000000]
Training progress:  22%|██▏       | 440/2000 [05:57<09:50,  2.64it/s, Loss=0.0516394, Gaussian number=182686, print grad=0.006098177749663591, Depth Loss=0.0000000]
Training progress:  22%|██▎       | 450/2000 [05:57<09:36,  2.69it/s, Loss=0.0516394, Gaussian number=182686, print grad=0.006098177749663591, Depth Loss=0.0000000]
Training progress:  22%|██▎       | 450/2000 [06:01<09:36,  2.69it/s, Loss=0.0535474, Gaussian number=182686, print grad=0.006251005455851555, Depth Loss=0.0000000]
Training progress:  23%|██▎       | 460/2000 [06:01<09:27,  2.71it/s, Loss=0.0535474, Gaussian number=182686, print grad=0.006251005455851555, Depth Loss=0.0000000]
Training progress:  23%|██▎       | 460/2000 [06:05<09:27,  2.71it/s, Loss=0.0615469, Gaussian number=182686, print grad=0.0064022778533399105, Depth Loss=0.0000000]
Training progress:  24%|██▎       | 470/2000 [06:05<09:18,  2.74it/s, Loss=0.0615469, Gaussian number=182686, print grad=0.0064022778533399105, Depth Loss=0.0000000]
Training progress:  24%|██▎       | 470/2000 [06:08<09:18,  2.74it/s, Loss=0.0415162, Gaussian number=182686, print grad=0.006566351745277643, Depth Loss=0.0000000] 
Training progress:  24%|██▍       | 480/2000 [06:08<09:12,  2.75it/s, Loss=0.0415162, Gaussian number=182686, print grad=0.006566351745277643, Depth Loss=0.0000000]
Training progress:  24%|██▍       | 480/2000 [06:12<09:12,  2.75it/s, Loss=0.0435393, Gaussian number=182686, print grad=0.0067196376621723175, Depth Loss=0.0000000]
Training progress:  24%|██▍       | 490/2000 [06:12<09:06,  2.77it/s, Loss=0.0435393, Gaussian number=182686, print grad=0.0067196376621723175, Depth Loss=0.0000000]
Training progress:  24%|██▍       | 490/2000 [06:15<09:06,  2.77it/s, Loss=0.0334373, Gaussian number=182686, print grad=0.006870898883789778, Depth Loss=0.0000000] 
Training progress:  25%|██▌       | 500/2000 [06:15<09:00,  2.77it/s, Loss=0.0334373, Gaussian number=182686, print grad=0.006870898883789778, Depth Loss=0.0000000]
Training progress:  25%|██▌       | 500/2000 [07:23<09:00,  2.77it/s, Loss=0.0399160, Gaussian number=182686, print grad=0.0070317089557647705, Depth Loss=0.0000000]
Training progress:  26%|██▌       | 510/2000 [07:23<57:02,  2.30s/it, Loss=0.0399160, Gaussian number=182686, print grad=0.0070317089557647705, Depth Loss=0.0000000]
Training progress:  26%|██▌       | 510/2000 [07:27<57:02,  2.30s/it, Loss=0.0450519, Gaussian number=182686, print grad=0.007184167858213186, Depth Loss=0.0000000] 
Training progress:  26%|██▌       | 520/2000 [07:27<42:18,  1.72s/it, Loss=0.0450519, Gaussian number=182686, print grad=0.007184167858213186, Depth Loss=0.0000000]
Training progress:  26%|██▌       | 520/2000 [07:31<42:18,  1.72s/it, Loss=0.0316605, Gaussian number=182686, print grad=0.007312491070479155, Depth Loss=0.0000000]
Training progress:  26%|██▋       | 530/2000 [07:31<32:02,  1.31s/it, Loss=0.0316605, Gaussian number=182686, print grad=0.007312491070479155, Depth Loss=0.0000000]
Training progress:  26%|██▋       | 530/2000 [07:34<32:02,  1.31s/it, Loss=0.0441930, Gaussian number=182686, print grad=0.00745870778337121, Depth Loss=0.0000000] 
Training progress:  27%|██▋       | 540/2000 [07:34<24:52,  1.02s/it, Loss=0.0441930, Gaussian number=182686, print grad=0.00745870778337121, Depth Loss=0.0000000]
Training progress:  27%|██▋       | 540/2000 [07:38<24:52,  1.02s/it, Loss=0.0397443, Gaussian number=182686, print grad=0.007620145566761494, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 550/2000 [07:38<19:53,  1.22it/s, Loss=0.0397443, Gaussian number=182686, print grad=0.007620145566761494, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 550/2000 [07:41<19:53,  1.22it/s, Loss=0.0326027, Gaussian number=182686, print grad=0.007768149953335524, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 560/2000 [07:41<16:23,  1.46it/s, Loss=0.0326027, Gaussian number=182686, print grad=0.007768149953335524, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 560/2000 [07:45<16:23,  1.46it/s, Loss=0.0426510, Gaussian number=182686, print grad=0.007924413308501244, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 570/2000 [07:45<13:56,  1.71it/s, Loss=0.0426510, Gaussian number=182686, print grad=0.007924413308501244, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 570/2000 [07:48<13:56,  1.71it/s, Loss=0.0376778, Gaussian number=182686, print grad=0.00808416772633791, Depth Loss=0.0000000] 
Training progress:  29%|██▉       | 580/2000 [07:48<12:13,  1.93it/s, Loss=0.0376778, Gaussian number=182686, print grad=0.00808416772633791, Depth Loss=0.0000000]
Training progress:  29%|██▉       | 580/2000 [07:52<12:13,  1.93it/s, Loss=0.0405555, Gaussian number=182686, print grad=0.008233314380049706, Depth Loss=0.0000000]
Training progress:  30%|██▉       | 590/2000 [07:52<11:01,  2.13it/s, Loss=0.0405555, Gaussian number=182686, print grad=0.008233314380049706, Depth Loss=0.0000000]
Training progress:  30%|██▉       | 590/2000 [07:56<11:01,  2.13it/s, Loss=0.0476699, Gaussian number=182686, print grad=0.008382530882954597, Depth Loss=0.0000000]
Training progress:  30%|███       | 600/2000 [07:56<10:10,  2.29it/s, Loss=0.0476699, Gaussian number=182686, print grad=0.008382530882954597, Depth Loss=0.0000000]
Training progress:  30%|███       | 600/2000 [07:59<10:10,  2.29it/s, Loss=0.0387185, Gaussian number=183030, print grad=0.00014010572340339422, Depth Loss=0.0000000]
Training progress:  30%|███       | 610/2000 [07:59<09:33,  2.43it/s, Loss=0.0387185, Gaussian number=183030, print grad=0.00014010572340339422, Depth Loss=0.0000000]
Training progress:  30%|███       | 610/2000 [08:03<09:33,  2.43it/s, Loss=0.0450647, Gaussian number=183030, print grad=0.00029550204635597765, Depth Loss=0.0000000]
Training progress:  31%|███       | 620/2000 [08:03<09:06,  2.53it/s, Loss=0.0450647, Gaussian number=183030, print grad=0.00029550204635597765, Depth Loss=0.0000000]
Training progress:  31%|███       | 620/2000 [08:06<09:06,  2.53it/s, Loss=0.0333398, Gaussian number=183030, print grad=0.0004390750837046653, Depth Loss=0.0000000] 
Training progress:  32%|███▏      | 630/2000 [08:06<08:46,  2.60it/s, Loss=0.0333398, Gaussian number=183030, print grad=0.0004390750837046653, Depth Loss=0.0000000]
Training progress:  32%|███▏      | 630/2000 [08:10<08:46,  2.60it/s, Loss=0.0386127, Gaussian number=183030, print grad=0.0006053175893612206, Depth Loss=0.0000000]
Training progress:  32%|███▏      | 640/2000 [08:10<08:30,  2.66it/s, Loss=0.0386127, Gaussian number=183030, print grad=0.0006053175893612206, Depth Loss=0.0000000]
Training progress:  32%|███▏      | 640/2000 [08:13<08:30,  2.66it/s, Loss=0.0411066, Gaussian number=183030, print grad=0.0007495470927096903, Depth Loss=0.0000000]
Training progress:  32%|███▎      | 650/2000 [08:13<08:19,  2.70it/s, Loss=0.0411066, Gaussian number=183030, print grad=0.0007495470927096903, Depth Loss=0.0000000]
Training progress:  32%|███▎      | 650/2000 [08:17<08:19,  2.70it/s, Loss=0.0388460, Gaussian number=183030, print grad=0.0009087611688300967, Depth Loss=0.0000000]
Training progress:  33%|███▎      | 660/2000 [08:17<08:10,  2.73it/s, Loss=0.0388460, Gaussian number=183030, print grad=0.0009087611688300967, Depth Loss=0.0000000]
Training progress:  33%|███▎      | 660/2000 [08:21<08:10,  2.73it/s, Loss=0.0384638, Gaussian number=183030, print grad=0.0010455114534124732, Depth Loss=0.0000000]
Training progress:  34%|███▎      | 670/2000 [08:21<08:03,  2.75it/s, Loss=0.0384638, Gaussian number=183030, print grad=0.0010455114534124732, Depth Loss=0.0000000]
Training progress:  34%|███▎      | 670/2000 [08:24<08:03,  2.75it/s, Loss=0.0339836, Gaussian number=183030, print grad=0.001205207547172904, Depth Loss=0.0000000] 
Training progress:  34%|███▍      | 680/2000 [08:24<07:57,  2.76it/s, Loss=0.0339836, Gaussian number=183030, print grad=0.001205207547172904, Depth Loss=0.0000000]
Training progress:  34%|███▍      | 680/2000 [08:28<07:57,  2.76it/s, Loss=0.0461750, Gaussian number=183030, print grad=0.001354995765723288, Depth Loss=0.0000000]
Training progress:  34%|███▍      | 690/2000 [08:28<07:51,  2.78it/s, Loss=0.0461750, Gaussian number=183030, print grad=0.001354995765723288, Depth Loss=0.0000000]
Training progress:  34%|███▍      | 690/2000 [08:31<07:51,  2.78it/s, Loss=0.0445980, Gaussian number=183030, print grad=0.0015000371495261788, Depth Loss=0.0000000]
Training progress:  35%|███▌      | 700/2000 [08:31<07:47,  2.78it/s, Loss=0.0445980, Gaussian number=183030, print grad=0.0015000371495261788, Depth Loss=0.0000000]
Training progress:  35%|███▌      | 700/2000 [08:35<07:47,  2.78it/s, Loss=0.0347863, Gaussian number=184486, print grad=0.00013255530211608857, Depth Loss=0.0000000]
Training progress:  36%|███▌      | 710/2000 [08:35<07:42,  2.79it/s, Loss=0.0347863, Gaussian number=184486, print grad=0.00013255530211608857, Depth Loss=0.0000000]
Training progress:  36%|███▌      | 710/2000 [08:38<07:42,  2.79it/s, Loss=0.0351999, Gaussian number=184486, print grad=0.00029639911372214556, Depth Loss=0.0000000]
Training progress:  36%|███▌      | 720/2000 [08:38<07:38,  2.79it/s, Loss=0.0351999, Gaussian number=184486, print grad=0.00029639911372214556, Depth Loss=0.0000000]
Training progress:  36%|███▌      | 720/2000 [08:42<07:38,  2.79it/s, Loss=0.0428032, Gaussian number=184486, print grad=0.000443458731751889, Depth Loss=0.0000000]  
Training progress:  36%|███▋      | 730/2000 [08:42<07:34,  2.80it/s, Loss=0.0428032, Gaussian number=184486, print grad=0.000443458731751889, Depth Loss=0.0000000]
Training progress:  36%|███▋      | 730/2000 [08:46<07:34,  2.80it/s, Loss=0.0485423, Gaussian number=184486, print grad=0.0006038121064193547, Depth Loss=0.0000000]
Training progress:  37%|███▋      | 740/2000 [08:46<07:30,  2.79it/s, Loss=0.0485423, Gaussian number=184486, print grad=0.0006038121064193547, Depth Loss=0.0000000]
Training progress:  37%|███▋      | 740/2000 [08:49<07:30,  2.79it/s, Loss=0.0358687, Gaussian number=184486, print grad=0.000757016649004072, Depth Loss=0.0000000] 
Training progress:  38%|███▊      | 750/2000 [08:49<07:27,  2.80it/s, Loss=0.0358687, Gaussian number=184486, print grad=0.000757016649004072, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 750/2000 [08:53<07:27,  2.80it/s, Loss=0.0363710, Gaussian number=184486, print grad=0.0009111445979215205, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 760/2000 [08:53<07:23,  2.79it/s, Loss=0.0363710, Gaussian number=184486, print grad=0.0009111445979215205, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 760/2000 [08:56<07:23,  2.79it/s, Loss=0.0295810, Gaussian number=184486, print grad=0.001066664233803749, Depth Loss=0.0000000] 
Training progress:  38%|███▊      | 770/2000 [08:56<07:20,  2.79it/s, Loss=0.0295810, Gaussian number=184486, print grad=0.001066664233803749, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 770/2000 [09:00<07:20,  2.79it/s, Loss=0.0407746, Gaussian number=184486, print grad=0.0012128540547564626, Depth Loss=0.0000000]
Training progress:  39%|███▉      | 780/2000 [09:00<07:16,  2.80it/s, Loss=0.0407746, Gaussian number=184486, print grad=0.0012128540547564626, Depth Loss=0.0000000]
Training progress:  39%|███▉      | 780/2000 [09:04<07:16,  2.80it/s, Loss=0.0504289, Gaussian number=184486, print grad=0.001366478856652975, Depth Loss=0.0000000] 
Training progress:  40%|███▉      | 790/2000 [09:04<07:12,  2.79it/s, Loss=0.0504289, Gaussian number=184486, print grad=0.001366478856652975, Depth Loss=0.0000000]
Training progress:  40%|███▉      | 790/2000 [09:07<07:12,  2.79it/s, Loss=0.0367246, Gaussian number=184486, print grad=0.001520430902019143, Depth Loss=0.0000000]
Training progress:  40%|████      | 800/2000 [09:07<07:09,  2.79it/s, Loss=0.0367246, Gaussian number=184486, print grad=0.001520430902019143, Depth Loss=0.0000000]
Training progress:  40%|████      | 800/2000 [09:11<07:09,  2.79it/s, Loss=0.0377138, Gaussian number=186289, print grad=0.00014205905608832836, Depth Loss=0.0000000]
Training progress:  40%|████      | 810/2000 [09:11<07:05,  2.80it/s, Loss=0.0377138, Gaussian number=186289, print grad=0.00014205905608832836, Depth Loss=0.0000000]
Training progress:  40%|████      | 810/2000 [09:14<07:05,  2.80it/s, Loss=0.0377466, Gaussian number=186289, print grad=0.0002958224213216454, Depth Loss=0.0000000] 
Training progress:  41%|████      | 820/2000 [09:14<07:01,  2.80it/s, Loss=0.0377466, Gaussian number=186289, print grad=0.0002958224213216454, Depth Loss=0.0000000]
Training progress:  41%|████      | 820/2000 [09:18<07:01,  2.80it/s, Loss=0.0283073, Gaussian number=186289, print grad=0.00045380773372016847, Depth Loss=0.0000000]
Training progress:  42%|████▏     | 830/2000 [09:18<06:58,  2.80it/s, Loss=0.0283073, Gaussian number=186289, print grad=0.00045380773372016847, Depth Loss=0.0000000]
Training progress:  42%|████▏     | 830/2000 [09:21<06:58,  2.80it/s, Loss=0.0334528, Gaussian number=186289, print grad=0.0006064446060918272, Depth Loss=0.0000000] 
Training progress:  42%|████▏     | 840/2000 [09:21<06:54,  2.80it/s, Loss=0.0334528, Gaussian number=186289, print grad=0.0006064446060918272, Depth Loss=0.0000000]
Training progress:  42%|████▏     | 840/2000 [09:25<06:54,  2.80it/s, Loss=0.0357658, Gaussian number=186289, print grad=0.0007641224656254053, Depth Loss=0.0000000]
Training progress:  42%|████▎     | 850/2000 [09:25<06:50,  2.80it/s, Loss=0.0357658, Gaussian number=186289, print grad=0.0007641224656254053, Depth Loss=0.0000000]
Training progress:  42%|████▎     | 850/2000 [09:29<06:50,  2.80it/s, Loss=0.0313917, Gaussian number=186289, print grad=0.0009102748590521514, Depth Loss=0.0000000]
Training progress:  43%|████▎     | 860/2000 [09:29<06:47,  2.80it/s, Loss=0.0313917, Gaussian number=186289, print grad=0.0009102748590521514, Depth Loss=0.0000000]
Training progress:  43%|████▎     | 860/2000 [09:32<06:47,  2.80it/s, Loss=0.0384591, Gaussian number=186289, print grad=0.0010514684254303575, Depth Loss=0.0000000]
Training progress:  44%|████▎     | 870/2000 [09:32<06:43,  2.80it/s, Loss=0.0384591, Gaussian number=186289, print grad=0.0010514684254303575, Depth Loss=0.0000000]
Training progress:  44%|████▎     | 870/2000 [09:36<06:43,  2.80it/s, Loss=0.0389323, Gaussian number=186289, print grad=0.0012080215383321047, Depth Loss=0.0000000]
Training progress:  44%|████▍     | 880/2000 [09:36<06:39,  2.80it/s, Loss=0.0389323, Gaussian number=186289, print grad=0.0012080215383321047, Depth Loss=0.0000000]
Training progress:  44%|████▍     | 880/2000 [09:39<06:39,  2.80it/s, Loss=0.0303143, Gaussian number=186289, print grad=0.0013645945582538843, Depth Loss=0.0000000]
Training progress:  44%|████▍     | 890/2000 [09:39<06:36,  2.80it/s, Loss=0.0303143, Gaussian number=186289, print grad=0.0013645945582538843, Depth Loss=0.0000000]
Training progress:  44%|████▍     | 890/2000 [09:43<06:36,  2.80it/s, Loss=0.0363017, Gaussian number=186289, print grad=0.0015178350731730461, Depth Loss=0.0000000]
Training progress:  45%|████▌     | 900/2000 [09:43<06:32,  2.80it/s, Loss=0.0363017, Gaussian number=186289, print grad=0.0015178350731730461, Depth Loss=0.0000000]
Training progress:  45%|████▌     | 900/2000 [09:46<06:32,  2.80it/s, Loss=0.0285526, Gaussian number=188217, print grad=0.00013572012539952993, Depth Loss=0.0000000]
Training progress:  46%|████▌     | 910/2000 [09:46<06:29,  2.80it/s, Loss=0.0285526, Gaussian number=188217, print grad=0.00013572012539952993, Depth Loss=0.0000000]
Training progress:  46%|████▌     | 910/2000 [09:50<06:29,  2.80it/s, Loss=0.0381798, Gaussian number=188217, print grad=0.0002766819088719785, Depth Loss=0.0000000] 
Training progress:  46%|████▌     | 920/2000 [09:50<06:25,  2.80it/s, Loss=0.0381798, Gaussian number=188217, print grad=0.0002766819088719785, Depth Loss=0.0000000]
Training progress:  46%|████▌     | 920/2000 [09:54<06:25,  2.80it/s, Loss=0.0359358, Gaussian number=188217, print grad=0.0004457859613467008, Depth Loss=0.0000000]
Training progress:  46%|████▋     | 930/2000 [09:54<06:22,  2.80it/s, Loss=0.0359358, Gaussian number=188217, print grad=0.0004457859613467008, Depth Loss=0.0000000]
Training progress:  46%|████▋     | 930/2000 [09:57<06:22,  2.80it/s, Loss=0.0335176, Gaussian number=188217, print grad=0.0006087712245061994, Depth Loss=0.0000000]
Training progress:  47%|████▋     | 940/2000 [09:57<06:19,  2.80it/s, Loss=0.0335176, Gaussian number=188217, print grad=0.0006087712245061994, Depth Loss=0.0000000]
Training progress:  47%|████▋     | 940/2000 [10:01<06:19,  2.80it/s, Loss=0.0322593, Gaussian number=188217, print grad=0.0007517234771512449, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 950/2000 [10:01<06:15,  2.80it/s, Loss=0.0322593, Gaussian number=188217, print grad=0.0007517234771512449, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 950/2000 [10:04<06:15,  2.80it/s, Loss=0.0314927, Gaussian number=188217, print grad=0.0008984630694612861, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 960/2000 [10:04<06:11,  2.80it/s, Loss=0.0314927, Gaussian number=188217, print grad=0.0008984630694612861, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 960/2000 [10:08<06:11,  2.80it/s, Loss=0.0411507, Gaussian number=188217, print grad=0.0010635487269610167, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 970/2000 [10:08<06:08,  2.79it/s, Loss=0.0411507, Gaussian number=188217, print grad=0.0010635487269610167, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 970/2000 [10:11<06:08,  2.79it/s, Loss=0.0255411, Gaussian number=188217, print grad=0.0012055132538080215, Depth Loss=0.0000000]
Training progress:  49%|████▉     | 980/2000 [10:11<06:05,  2.79it/s, Loss=0.0255411, Gaussian number=188217, print grad=0.0012055132538080215, Depth Loss=0.0000000]
Training progress:  49%|████▉     | 980/2000 [10:15<06:05,  2.79it/s, Loss=0.0275979, Gaussian number=188217, print grad=0.0013312684604898095, Depth Loss=0.0000000]
Training progress:  50%|████▉     | 990/2000 [10:15<06:01,  2.79it/s, Loss=0.0275979, Gaussian number=188217, print grad=0.0013312684604898095, Depth Loss=0.0000000]
Training progress:  50%|████▉     | 990/2000 [10:19<06:01,  2.79it/s, Loss=0.0333272, Gaussian number=188217, print grad=0.0014536201488226652, Depth Loss=0.0000000]
Training progress:  50%|█████     | 1000/2000 [10:19<05:57,  2.79it/s, Loss=0.0333272, Gaussian number=188217, print grad=0.0014536201488226652, Depth Loss=0.0000000]
Training progress:  50%|█████     | 1000/2000 [11:27<05:57,  2.79it/s, Loss=0.0343393, Gaussian number=190235, print grad=0.000138853196403943, Depth Loss=0.0000000] 
Training progress:  50%|█████     | 1010/2000 [11:27<37:52,  2.30s/it, Loss=0.0343393, Gaussian number=190235, print grad=0.000138853196403943, Depth Loss=0.0000000]
Training progress:  50%|█████     | 1010/2000 [11:30<37:52,  2.30s/it, Loss=0.0401856, Gaussian number=190235, print grad=0.0003115189028903842, Depth Loss=0.0000000]
Training progress:  51%|█████     | 1020/2000 [11:30<27:59,  1.71s/it, Loss=0.0401856, Gaussian number=190235, print grad=0.0003115189028903842, Depth Loss=0.0000000]
Training progress:  51%|█████     | 1020/2000 [11:34<27:59,  1.71s/it, Loss=0.0321546, Gaussian number=190235, print grad=0.0004802707117050886, Depth Loss=0.0000000]
Training progress:  52%|█████▏    | 1030/2000 [11:34<21:07,  1.31s/it, Loss=0.0321546, Gaussian number=190235, print grad=0.0004802707117050886, Depth Loss=0.0000000]
Training progress:  52%|█████▏    | 1030/2000 [11:37<21:07,  1.31s/it, Loss=0.0337550, Gaussian number=190235, print grad=0.0006533717969432473, Depth Loss=0.0000000]
Training progress:  52%|█████▏    | 1040/2000 [11:37<16:20,  1.02s/it, Loss=0.0337550, Gaussian number=190235, print grad=0.0006533717969432473, Depth Loss=0.0000000]
Training progress:  52%|█████▏    | 1040/2000 [11:41<16:20,  1.02s/it, Loss=0.0309403, Gaussian number=190235, print grad=0.0007823324995115399, Depth Loss=0.0000000]
Training progress:  52%|█████▎    | 1050/2000 [11:41<13:00,  1.22it/s, Loss=0.0309403, Gaussian number=190235, print grad=0.0007823324995115399, Depth Loss=0.0000000]
Training progress:  52%|█████▎    | 1050/2000 [11:45<13:00,  1.22it/s, Loss=0.0278553, Gaussian number=190235, print grad=0.0009294659248553216, Depth Loss=0.0000000]
Training progress:  53%|█████▎    | 1060/2000 [11:45<10:41,  1.47it/s, Loss=0.0278553, Gaussian number=190235, print grad=0.0009294659248553216, Depth Loss=0.0000000]
Training progress:  53%|█████▎    | 1060/2000 [11:48<10:41,  1.47it/s, Loss=0.0236398, Gaussian number=190235, print grad=0.0010790802771225572, Depth Loss=0.0000000]
Training progress:  54%|█████▎    | 1070/2000 [11:48<09:03,  1.71it/s, Loss=0.0236398, Gaussian number=190235, print grad=0.0010790802771225572, Depth Loss=0.0000000]
Training progress:  54%|█████▎    | 1070/2000 [11:52<09:03,  1.71it/s, Loss=0.0262887, Gaussian number=190235, print grad=0.001223788014613092, Depth Loss=0.0000000] 
Training progress:  54%|█████▍    | 1080/2000 [11:52<07:54,  1.94it/s, Loss=0.0262887, Gaussian number=190235, print grad=0.001223788014613092, Depth Loss=0.0000000]
Training progress:  54%|█████▍    | 1080/2000 [11:55<07:54,  1.94it/s, Loss=0.0277218, Gaussian number=190235, print grad=0.0013661825796589255, Depth Loss=0.0000000]
Training progress:  55%|█████▍    | 1090/2000 [11:55<07:05,  2.14it/s, Loss=0.0277218, Gaussian number=190235, print grad=0.0013661825796589255, Depth Loss=0.0000000]
Training progress:  55%|█████▍    | 1090/2000 [11:59<07:05,  2.14it/s, Loss=0.0351063, Gaussian number=190235, print grad=0.0015134684508666396, Depth Loss=0.0000000]
Training progress:  55%|█████▌    | 1100/2000 [11:59<06:31,  2.30it/s, Loss=0.0351063, Gaussian number=190235, print grad=0.0015134684508666396, Depth Loss=0.0000000]
Training progress:  55%|█████▌    | 1100/2000 [12:02<06:31,  2.30it/s, Loss=0.0323825, Gaussian number=192422, print grad=0.00013934132584836334, Depth Loss=0.0000000]
Training progress:  56%|█████▌    | 1110/2000 [12:02<06:05,  2.43it/s, Loss=0.0323825, Gaussian number=192422, print grad=0.00013934132584836334, Depth Loss=0.0000000]
Training progress:  56%|█████▌    | 1110/2000 [12:06<06:05,  2.43it/s, Loss=0.0302538, Gaussian number=192422, print grad=0.0003041413438040763, Depth Loss=0.0000000] 
Training progress:  56%|█████▌    | 1120/2000 [12:06<05:47,  2.53it/s, Loss=0.0302538, Gaussian number=192422, print grad=0.0003041413438040763, Depth Loss=0.0000000]
Training progress:  56%|█████▌    | 1120/2000 [12:10<05:47,  2.53it/s, Loss=0.0252481, Gaussian number=192422, print grad=0.00046786796883679926, Depth Loss=0.0000000]
Training progress:  56%|█████▋    | 1130/2000 [12:10<05:33,  2.61it/s, Loss=0.0252481, Gaussian number=192422, print grad=0.00046786796883679926, Depth Loss=0.0000000]
Training progress:  56%|█████▋    | 1130/2000 [12:13<05:33,  2.61it/s, Loss=0.0327799, Gaussian number=192422, print grad=0.0006299473461695015, Depth Loss=0.0000000] 
Training progress:  57%|█████▋    | 1140/2000 [12:13<05:22,  2.66it/s, Loss=0.0327799, Gaussian number=192422, print grad=0.0006299473461695015, Depth Loss=0.0000000]
Training progress:  57%|█████▋    | 1140/2000 [12:17<05:22,  2.66it/s, Loss=0.0219071, Gaussian number=192422, print grad=0.0007832679548300803, Depth Loss=0.0000000]
Training progress:  57%|█████▊    | 1150/2000 [12:17<05:14,  2.70it/s, Loss=0.0219071, Gaussian number=192422, print grad=0.0007832679548300803, Depth Loss=0.0000000]
Training progress:  57%|█████▊    | 1150/2000 [12:20<05:14,  2.70it/s, Loss=0.0248868, Gaussian number=192422, print grad=0.0009293165639974177, Depth Loss=0.0000000]
Training progress:  58%|█████▊    | 1160/2000 [12:20<05:07,  2.73it/s, Loss=0.0248868, Gaussian number=192422, print grad=0.0009293165639974177, Depth Loss=0.0000000]
Training progress:  58%|█████▊    | 1160/2000 [12:24<05:07,  2.73it/s, Loss=0.0319725, Gaussian number=192422, print grad=0.0010818224400281906, Depth Loss=0.0000000]
Training progress:  58%|█████▊    | 1170/2000 [12:24<05:01,  2.75it/s, Loss=0.0319725, Gaussian number=192422, print grad=0.0010818224400281906, Depth Loss=0.0000000]
Training progress:  58%|█████▊    | 1170/2000 [12:27<05:01,  2.75it/s, Loss=0.0300514, Gaussian number=192422, print grad=0.00122172967530787, Depth Loss=0.0000000]  
Training progress:  59%|█████▉    | 1180/2000 [12:27<04:56,  2.77it/s, Loss=0.0300514, Gaussian number=192422, print grad=0.00122172967530787, Depth Loss=0.0000000]
Training progress:  59%|█████▉    | 1180/2000 [12:31<04:56,  2.77it/s, Loss=0.0263477, Gaussian number=192422, print grad=0.0013792570680379868, Depth Loss=0.0000000]
Training progress:  60%|█████▉    | 1190/2000 [12:31<04:51,  2.78it/s, Loss=0.0263477, Gaussian number=192422, print grad=0.0013792570680379868, Depth Loss=0.0000000]
Training progress:  60%|█████▉    | 1190/2000 [12:35<04:51,  2.78it/s, Loss=0.0318783, Gaussian number=192422, print grad=0.0015079430304467678, Depth Loss=0.0000000]
Training progress:  60%|██████    | 1200/2000 [12:35<04:47,  2.78it/s, Loss=0.0318783, Gaussian number=192422, print grad=0.0015079430304467678, Depth Loss=0.0000000]
Training progress:  60%|██████    | 1200/2000 [12:38<04:47,  2.78it/s, Loss=0.0245165, Gaussian number=194820, print grad=0.00014167657354846597, Depth Loss=0.0000000]
Training progress:  60%|██████    | 1210/2000 [12:38<04:43,  2.78it/s, Loss=0.0245165, Gaussian number=194820, print grad=0.00014167657354846597, Depth Loss=0.0000000]
Training progress:  60%|██████    | 1210/2000 [12:42<04:43,  2.78it/s, Loss=0.0204258, Gaussian number=194820, print grad=0.00030245783273130655, Depth Loss=0.0000000]
Training progress:  61%|██████    | 1220/2000 [12:42<04:39,  2.79it/s, Loss=0.0204258, Gaussian number=194820, print grad=0.00030245783273130655, Depth Loss=0.0000000]
Training progress:  61%|██████    | 1220/2000 [12:45<04:39,  2.79it/s, Loss=0.0241769, Gaussian number=194820, print grad=0.00044284778414294124, Depth Loss=0.0000000]
Training progress:  62%|██████▏   | 1230/2000 [12:45<04:35,  2.80it/s, Loss=0.0241769, Gaussian number=194820, print grad=0.00044284778414294124, Depth Loss=0.0000000]
Training progress:  62%|██████▏   | 1230/2000 [12:49<04:35,  2.80it/s, Loss=0.0220378, Gaussian number=194820, print grad=0.0005915110814385116, Depth Loss=0.0000000] 
Training progress:  62%|██████▏   | 1240/2000 [12:49<04:31,  2.80it/s, Loss=0.0220378, Gaussian number=194820, print grad=0.0005915110814385116, Depth Loss=0.0000000]
Training progress:  62%|██████▏   | 1240/2000 [12:52<04:31,  2.80it/s, Loss=0.0231572, Gaussian number=194820, print grad=0.000729657185729593, Depth Loss=0.0000000] 
Training progress:  62%|██████▎   | 1250/2000 [12:52<04:27,  2.80it/s, Loss=0.0231572, Gaussian number=194820, print grad=0.000729657185729593, Depth Loss=0.0000000]
Training progress:  62%|██████▎   | 1250/2000 [12:56<04:27,  2.80it/s, Loss=0.0236221, Gaussian number=194820, print grad=0.0008689864189364016, Depth Loss=0.0000000]
Training progress:  63%|██████▎   | 1260/2000 [12:56<04:23,  2.80it/s, Loss=0.0236221, Gaussian number=194820, print grad=0.0008689864189364016, Depth Loss=0.0000000]
Training progress:  63%|██████▎   | 1260/2000 [12:59<04:23,  2.80it/s, Loss=0.0326620, Gaussian number=194820, print grad=0.0010204140562564135, Depth Loss=0.0000000]
Training progress:  64%|██████▎   | 1270/2000 [12:59<04:20,  2.80it/s, Loss=0.0326620, Gaussian number=194820, print grad=0.0010204140562564135, Depth Loss=0.0000000]
Training progress:  64%|██████▎   | 1270/2000 [13:03<04:20,  2.80it/s, Loss=0.0308758, Gaussian number=194820, print grad=0.0011637677671387792, Depth Loss=0.0000000]
Training progress:  64%|██████▍   | 1280/2000 [13:03<04:16,  2.80it/s, Loss=0.0308758, Gaussian number=194820, print grad=0.0011637677671387792, Depth Loss=0.0000000]
Training progress:  64%|██████▍   | 1280/2000 [13:07<04:16,  2.80it/s, Loss=0.0219922, Gaussian number=194820, print grad=0.001321168732829392, Depth Loss=0.0000000] 
Training progress:  64%|██████▍   | 1290/2000 [13:07<04:12,  2.81it/s, Loss=0.0219922, Gaussian number=194820, print grad=0.001321168732829392, Depth Loss=0.0000000]
Training progress:  64%|██████▍   | 1290/2000 [13:10<04:12,  2.81it/s, Loss=0.0331015, Gaussian number=194820, print grad=0.0014588928315788507, Depth Loss=0.0000000]
Training progress:  65%|██████▌   | 1300/2000 [13:10<04:09,  2.81it/s, Loss=0.0331015, Gaussian number=194820, print grad=0.0014588928315788507, Depth Loss=0.0000000]
Training progress:  65%|██████▌   | 1300/2000 [13:14<04:09,  2.81it/s, Loss=0.0332628, Gaussian number=196896, print grad=0.00014982849825173616, Depth Loss=0.0000000]
Training progress:  66%|██████▌   | 1310/2000 [13:14<04:06,  2.80it/s, Loss=0.0332628, Gaussian number=196896, print grad=0.00014982849825173616, Depth Loss=0.0000000]
Training progress:  66%|██████▌   | 1310/2000 [13:17<04:06,  2.80it/s, Loss=0.0323032, Gaussian number=196896, print grad=0.00030068043270148337, Depth Loss=0.0000000]
Training progress:  66%|██████▌   | 1320/2000 [13:17<04:02,  2.80it/s, Loss=0.0323032, Gaussian number=196896, print grad=0.00030068043270148337, Depth Loss=0.0000000]
Training progress:  66%|██████▌   | 1320/2000 [13:21<04:02,  2.80it/s, Loss=0.0232921, Gaussian number=196896, print grad=0.00045474967919290066, Depth Loss=0.0000000]
Training progress:  66%|██████▋   | 1330/2000 [13:21<03:59,  2.80it/s, Loss=0.0232921, Gaussian number=196896, print grad=0.00045474967919290066, Depth Loss=0.0000000]
Training progress:  66%|██████▋   | 1330/2000 [13:24<03:59,  2.80it/s, Loss=0.0259532, Gaussian number=196896, print grad=0.0006065634661354125, Depth Loss=0.0000000] 
Training progress:  67%|██████▋   | 1340/2000 [13:24<03:55,  2.80it/s, Loss=0.0259532, Gaussian number=196896, print grad=0.0006065634661354125, Depth Loss=0.0000000]
Training progress:  67%|██████▋   | 1340/2000 [13:28<03:55,  2.80it/s, Loss=0.0376460, Gaussian number=196896, print grad=0.0007449326803907752, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1350/2000 [13:28<03:52,  2.80it/s, Loss=0.0376460, Gaussian number=196896, print grad=0.0007449326803907752, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1350/2000 [13:32<03:52,  2.80it/s, Loss=0.0224989, Gaussian number=196896, print grad=0.0008841619128361344, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1360/2000 [13:32<03:48,  2.80it/s, Loss=0.0224989, Gaussian number=196896, print grad=0.0008841619128361344, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1360/2000 [13:35<03:48,  2.80it/s, Loss=0.0391804, Gaussian number=196896, print grad=0.001031966763548553, Depth Loss=0.0000000] 
Training progress:  68%|██████▊   | 1370/2000 [13:35<03:44,  2.80it/s, Loss=0.0391804, Gaussian number=196896, print grad=0.001031966763548553, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1370/2000 [13:39<03:44,  2.80it/s, Loss=0.0248816, Gaussian number=196896, print grad=0.0011722518829628825, Depth Loss=0.0000000]
Training progress:  69%|██████▉   | 1380/2000 [13:39<03:41,  2.80it/s, Loss=0.0248816, Gaussian number=196896, print grad=0.0011722518829628825, Depth Loss=0.0000000]
Training progress:  69%|██████▉   | 1380/2000 [13:42<03:41,  2.80it/s, Loss=0.0233316, Gaussian number=196896, print grad=0.0013029295951128006, Depth Loss=0.0000000]
Training progress:  70%|██████▉   | 1390/2000 [13:42<03:37,  2.80it/s, Loss=0.0233316, Gaussian number=196896, print grad=0.0013029295951128006, Depth Loss=0.0000000]
Training progress:  70%|██████▉   | 1390/2000 [13:46<03:37,  2.80it/s, Loss=0.0255766, Gaussian number=196896, print grad=0.0014433679170906544, Depth Loss=0.0000000]
Training progress:  70%|███████   | 1400/2000 [13:46<03:34,  2.80it/s, Loss=0.0255766, Gaussian number=196896, print grad=0.0014433679170906544, Depth Loss=0.0000000]
Training progress:  70%|███████   | 1400/2000 [13:49<03:34,  2.80it/s, Loss=0.0309605, Gaussian number=199157, print grad=0.00014004924742039293, Depth Loss=0.0000000]
Training progress:  70%|███████   | 1410/2000 [13:49<03:30,  2.80it/s, Loss=0.0309605, Gaussian number=199157, print grad=0.00014004924742039293, Depth Loss=0.0000000]
Training progress:  70%|███████   | 1410/2000 [13:53<03:30,  2.80it/s, Loss=0.0246088, Gaussian number=199157, print grad=0.000305715249851346, Depth Loss=0.0000000]  
Training progress:  71%|███████   | 1420/2000 [13:53<03:27,  2.80it/s, Loss=0.0246088, Gaussian number=199157, print grad=0.000305715249851346, Depth Loss=0.0000000]
Training progress:  71%|███████   | 1420/2000 [13:57<03:27,  2.80it/s, Loss=0.0266782, Gaussian number=199157, print grad=0.00047102614189498127, Depth Loss=0.0000000]
Training progress:  72%|███████▏  | 1430/2000 [13:57<03:23,  2.80it/s, Loss=0.0266782, Gaussian number=199157, print grad=0.00047102614189498127, Depth Loss=0.0000000]
Training progress:  72%|███████▏  | 1430/2000 [14:00<03:23,  2.80it/s, Loss=0.0249175, Gaussian number=199157, print grad=0.0006208053091540933, Depth Loss=0.0000000] 
Training progress:  72%|███████▏  | 1440/2000 [14:00<03:19,  2.80it/s, Loss=0.0249175, Gaussian number=199157, print grad=0.0006208053091540933, Depth Loss=0.0000000]
Training progress:  72%|███████▏  | 1440/2000 [14:04<03:19,  2.80it/s, Loss=0.0229597, Gaussian number=199157, print grad=0.0007682298310101032, Depth Loss=0.0000000]
Training progress:  72%|███████▎  | 1450/2000 [14:04<03:16,  2.81it/s, Loss=0.0229597, Gaussian number=199157, print grad=0.0007682298310101032, Depth Loss=0.0000000]
Training progress:  72%|███████▎  | 1450/2000 [14:07<03:16,  2.81it/s, Loss=0.0200342, Gaussian number=199157, print grad=0.000908773741684854, Depth Loss=0.0000000] 
Training progress:  73%|███████▎  | 1460/2000 [14:07<03:12,  2.81it/s, Loss=0.0200342, Gaussian number=199157, print grad=0.000908773741684854, Depth Loss=0.0000000]
Training progress:  73%|███████▎  | 1460/2000 [14:11<03:12,  2.81it/s, Loss=0.0272847, Gaussian number=199157, print grad=0.0010574889602139592, Depth Loss=0.0000000]
Training progress:  74%|███████▎  | 1470/2000 [14:11<03:08,  2.81it/s, Loss=0.0272847, Gaussian number=199157, print grad=0.0010574889602139592, Depth Loss=0.0000000]
Training progress:  74%|███████▎  | 1470/2000 [14:14<03:08,  2.81it/s, Loss=0.0265846, Gaussian number=199157, print grad=0.0012035887921229005, Depth Loss=0.0000000]
Training progress:  74%|███████▍  | 1480/2000 [14:14<03:05,  2.81it/s, Loss=0.0265846, Gaussian number=199157, print grad=0.0012035887921229005, Depth Loss=0.0000000]
Training progress:  74%|███████▍  | 1480/2000 [14:18<03:05,  2.81it/s, Loss=0.0283576, Gaussian number=199157, print grad=0.001345924916677177, Depth Loss=0.0000000] 
Training progress:  74%|███████▍  | 1490/2000 [14:18<03:01,  2.81it/s, Loss=0.0283576, Gaussian number=199157, print grad=0.001345924916677177, Depth Loss=0.0000000]
Training progress:  74%|███████▍  | 1490/2000 [14:22<03:01,  2.81it/s, Loss=0.0303312, Gaussian number=199157, print grad=0.0014959343243390322, Depth Loss=0.0000000]
Training progress:  75%|███████▌  | 1500/2000 [14:22<02:58,  2.81it/s, Loss=0.0303312, Gaussian number=199157, print grad=0.0014959343243390322, Depth Loss=0.0000000]
Training progress:  75%|███████▌  | 1500/2000 [15:30<02:58,  2.81it/s, Loss=0.0319600, Gaussian number=201166, print grad=0.00013538895291276276, Depth Loss=0.0000000]
Training progress:  76%|███████▌  | 1510/2000 [15:30<18:43,  2.29s/it, Loss=0.0319600, Gaussian number=201166, print grad=0.00013538895291276276, Depth Loss=0.0000000]
Training progress:  76%|███████▌  | 1510/2000 [15:33<18:43,  2.29s/it, Loss=0.0272500, Gaussian number=201166, print grad=0.00027434309595264494, Depth Loss=0.0000000]
Training progress:  76%|███████▌  | 1520/2000 [15:33<13:41,  1.71s/it, Loss=0.0272500, Gaussian number=201166, print grad=0.00027434309595264494, Depth Loss=0.0000000]
Training progress:  76%|███████▌  | 1520/2000 [15:37<13:41,  1.71s/it, Loss=0.0168752, Gaussian number=201166, print grad=0.00043272317270748317, Depth Loss=0.0000000]
Training progress:  76%|███████▋  | 1530/2000 [15:37<10:13,  1.30s/it, Loss=0.0168752, Gaussian number=201166, print grad=0.00043272317270748317, Depth Loss=0.0000000]
Training progress:  76%|███████▋  | 1530/2000 [15:40<10:13,  1.30s/it, Loss=0.0258065, Gaussian number=201166, print grad=0.0005772438016720116, Depth Loss=0.0000000] 
Training progress:  77%|███████▋  | 1540/2000 [15:40<07:48,  1.02s/it, Loss=0.0258065, Gaussian number=201166, print grad=0.0005772438016720116, Depth Loss=0.0000000]
Training progress:  77%|███████▋  | 1540/2000 [15:44<07:48,  1.02s/it, Loss=0.0253898, Gaussian number=201166, print grad=0.0007334059337154031, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1550/2000 [15:44<06:08,  1.22it/s, Loss=0.0253898, Gaussian number=201166, print grad=0.0007334059337154031, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1550/2000 [15:47<06:08,  1.22it/s, Loss=0.0245726, Gaussian number=201166, print grad=0.0008908609161153436, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1560/2000 [15:47<04:59,  1.47it/s, Loss=0.0245726, Gaussian number=201166, print grad=0.0008908609161153436, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1560/2000 [15:51<04:59,  1.47it/s, Loss=0.0224309, Gaussian number=201166, print grad=0.0010337436106055975, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1570/2000 [15:51<04:10,  1.72it/s, Loss=0.0224309, Gaussian number=201166, print grad=0.0010337436106055975, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1570/2000 [15:54<04:10,  1.72it/s, Loss=0.0161777, Gaussian number=201166, print grad=0.0011511915363371372, Depth Loss=0.0000000]
Training progress:  79%|███████▉  | 1580/2000 [15:54<03:36,  1.94it/s, Loss=0.0161777, Gaussian number=201166, print grad=0.0011511915363371372, Depth Loss=0.0000000]
Training progress:  79%|███████▉  | 1580/2000 [15:58<03:36,  1.94it/s, Loss=0.0226220, Gaussian number=201166, print grad=0.00128878781106323, Depth Loss=0.0000000]  
Training progress:  80%|███████▉  | 1590/2000 [15:58<03:11,  2.14it/s, Loss=0.0226220, Gaussian number=201166, print grad=0.00128878781106323, Depth Loss=0.0000000]
Training progress:  80%|███████▉  | 1590/2000 [16:02<03:11,  2.14it/s, Loss=0.0233186, Gaussian number=201166, print grad=0.0014312660787254572, Depth Loss=0.0000000]
Training progress:  80%|████████  | 1600/2000 [16:02<02:53,  2.31it/s, Loss=0.0233186, Gaussian number=201166, print grad=0.0014312660787254572, Depth Loss=0.0000000]
Training progress:  80%|████████  | 1600/2000 [16:05<02:53,  2.31it/s, Loss=0.0232665, Gaussian number=202858, print grad=0.00014194012328516692, Depth Loss=0.0000000]
Training progress:  80%|████████  | 1610/2000 [16:05<02:39,  2.44it/s, Loss=0.0232665, Gaussian number=202858, print grad=0.00014194012328516692, Depth Loss=0.0000000]
Training progress:  80%|████████  | 1610/2000 [16:09<02:39,  2.44it/s, Loss=0.0266511, Gaussian number=202858, print grad=0.0002988777996506542, Depth Loss=0.0000000] 
Training progress:  81%|████████  | 1620/2000 [16:09<02:29,  2.55it/s, Loss=0.0266511, Gaussian number=202858, print grad=0.0002988777996506542, Depth Loss=0.0000000]
Training progress:  81%|████████  | 1620/2000 [16:12<02:29,  2.55it/s, Loss=0.0238744, Gaussian number=202858, print grad=0.0004445008235052228, Depth Loss=0.0000000]
Training progress:  82%|████████▏ | 1630/2000 [16:12<02:20,  2.62it/s, Loss=0.0238744, Gaussian number=202858, print grad=0.0004445008235052228, Depth Loss=0.0000000]
Training progress:  82%|████████▏ | 1630/2000 [16:16<02:20,  2.62it/s, Loss=0.0165031, Gaussian number=202858, print grad=0.0005920537514612079, Depth Loss=0.0000000]
Training progress:  82%|████████▏ | 1640/2000 [16:16<02:14,  2.68it/s, Loss=0.0165031, Gaussian number=202858, print grad=0.0005920537514612079, Depth Loss=0.0000000]
Training progress:  82%|████████▏ | 1640/2000 [16:19<02:14,  2.68it/s, Loss=0.0235818, Gaussian number=202858, print grad=0.0007223467691801488, Depth Loss=0.0000000]
Training progress:  82%|████████▎ | 1650/2000 [16:19<02:08,  2.72it/s, Loss=0.0235818, Gaussian number=202858, print grad=0.0007223467691801488, Depth Loss=0.0000000]
Training progress:  82%|████████▎ | 1650/2000 [16:23<02:08,  2.72it/s, Loss=0.0221173, Gaussian number=202858, print grad=0.0008633847464807332, Depth Loss=0.0000000]
Training progress:  83%|████████▎ | 1660/2000 [16:23<02:03,  2.75it/s, Loss=0.0221173, Gaussian number=202858, print grad=0.0008633847464807332, Depth Loss=0.0000000]
Training progress:  83%|████████▎ | 1660/2000 [16:26<02:03,  2.75it/s, Loss=0.0206642, Gaussian number=202858, print grad=0.0010000452166423202, Depth Loss=0.0000000]
Training progress:  84%|████████▎ | 1670/2000 [16:26<01:58,  2.77it/s, Loss=0.0206642, Gaussian number=202858, print grad=0.0010000452166423202, Depth Loss=0.0000000]
Training progress:  84%|████████▎ | 1670/2000 [16:30<01:58,  2.77it/s, Loss=0.0189773, Gaussian number=202858, print grad=0.0011454347986727953, Depth Loss=0.0000000]
Training progress:  84%|████████▍ | 1680/2000 [16:30<01:54,  2.79it/s, Loss=0.0189773, Gaussian number=202858, print grad=0.0011454347986727953, Depth Loss=0.0000000]
Training progress:  84%|████████▍ | 1680/2000 [16:33<01:54,  2.79it/s, Loss=0.0237393, Gaussian number=202858, print grad=0.0012817720416933298, Depth Loss=0.0000000]
Training progress:  84%|████████▍ | 1690/2000 [16:33<01:50,  2.80it/s, Loss=0.0237393, Gaussian number=202858, print grad=0.0012817720416933298, Depth Loss=0.0000000]
Training progress:  84%|████████▍ | 1690/2000 [16:37<01:50,  2.80it/s, Loss=0.0221476, Gaussian number=202858, print grad=0.0014019922818988562, Depth Loss=0.0000000]
Training progress:  85%|████████▌ | 1700/2000 [16:37<01:46,  2.81it/s, Loss=0.0221476, Gaussian number=202858, print grad=0.0014019922818988562, Depth Loss=0.0000000]
Training progress:  85%|████████▌ | 1700/2000 [16:40<01:46,  2.81it/s, Loss=0.0259132, Gaussian number=204688, print grad=0.00015023650485090911, Depth Loss=0.0000000]
Training progress:  86%|████████▌ | 1710/2000 [16:40<01:42,  2.82it/s, Loss=0.0259132, Gaussian number=204688, print grad=0.00015023650485090911, Depth Loss=0.0000000]
Training progress:  86%|████████▌ | 1710/2000 [16:44<01:42,  2.82it/s, Loss=0.0253206, Gaussian number=204688, print grad=0.00027830395265482366, Depth Loss=0.0000000]
Training progress:  86%|████████▌ | 1720/2000 [16:44<01:38,  2.83it/s, Loss=0.0253206, Gaussian number=204688, print grad=0.00027830395265482366, Depth Loss=0.0000000]
Training progress:  86%|████████▌ | 1720/2000 [16:47<01:38,  2.83it/s, Loss=0.0219509, Gaussian number=204688, print grad=0.0004253152583260089, Depth Loss=0.0000000] 
Training progress:  86%|████████▋ | 1730/2000 [16:47<01:35,  2.84it/s, Loss=0.0219509, Gaussian number=204688, print grad=0.0004253152583260089, Depth Loss=0.0000000]
Training progress:  86%|████████▋ | 1730/2000 [16:51<01:35,  2.84it/s, Loss=0.0308386, Gaussian number=204688, print grad=0.0005781317595392466, Depth Loss=0.0000000]
Training progress:  87%|████████▋ | 1740/2000 [16:51<01:31,  2.84it/s, Loss=0.0308386, Gaussian number=204688, print grad=0.0005781317595392466, Depth Loss=0.0000000]
Training progress:  87%|████████▋ | 1740/2000 [16:54<01:31,  2.84it/s, Loss=0.0297242, Gaussian number=204688, print grad=0.0007353984983637929, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1750/2000 [16:54<01:27,  2.85it/s, Loss=0.0297242, Gaussian number=204688, print grad=0.0007353984983637929, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1750/2000 [16:58<01:27,  2.85it/s, Loss=0.0231642, Gaussian number=204688, print grad=0.0008736200397834182, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1760/2000 [16:58<01:24,  2.85it/s, Loss=0.0231642, Gaussian number=204688, print grad=0.0008736200397834182, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1760/2000 [17:01<01:24,  2.85it/s, Loss=0.0192035, Gaussian number=204688, print grad=0.0010074832243844867, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1770/2000 [17:01<01:20,  2.85it/s, Loss=0.0192035, Gaussian number=204688, print grad=0.0010074832243844867, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1770/2000 [17:05<01:20,  2.85it/s, Loss=0.0235808, Gaussian number=204688, print grad=0.0011382447555661201, Depth Loss=0.0000000]
Training progress:  89%|████████▉ | 1780/2000 [17:05<01:17,  2.85it/s, Loss=0.0235808, Gaussian number=204688, print grad=0.0011382447555661201, Depth Loss=0.0000000]
Training progress:  89%|████████▉ | 1780/2000 [17:08<01:17,  2.85it/s, Loss=0.0198700, Gaussian number=204688, print grad=0.0012579802423715591, Depth Loss=0.0000000]
Training progress:  90%|████████▉ | 1790/2000 [17:08<01:13,  2.85it/s, Loss=0.0198700, Gaussian number=204688, print grad=0.0012579802423715591, Depth Loss=0.0000000]
Training progress:  90%|████████▉ | 1790/2000 [17:12<01:13,  2.85it/s, Loss=0.0214409, Gaussian number=204688, print grad=0.0013974594185128808, Depth Loss=0.0000000]
Training progress:  90%|█████████ | 1800/2000 [17:12<01:10,  2.85it/s, Loss=0.0214409, Gaussian number=204688, print grad=0.0013974594185128808, Depth Loss=0.0000000]
Training progress:  90%|█████████ | 1800/2000 [17:16<01:10,  2.85it/s, Loss=0.0245879, Gaussian number=206243, print grad=0.0001456418976886198, Depth Loss=0.0000000]
Training progress:  90%|█████████ | 1810/2000 [17:16<01:06,  2.85it/s, Loss=0.0245879, Gaussian number=206243, print grad=0.0001456418976886198, Depth Loss=0.0000000]
Training progress:  90%|█████████ | 1810/2000 [17:19<01:06,  2.85it/s, Loss=0.0210641, Gaussian number=206243, print grad=0.0002961402351502329, Depth Loss=0.0000000]
Training progress:  91%|█████████ | 1820/2000 [17:19<01:03,  2.85it/s, Loss=0.0210641, Gaussian number=206243, print grad=0.0002961402351502329, Depth Loss=0.0000000]
Training progress:  91%|█████████ | 1820/2000 [17:23<01:03,  2.85it/s, Loss=0.0182881, Gaussian number=206243, print grad=0.00042949020280502737, Depth Loss=0.0000000]
Training progress:  92%|█████████▏| 1830/2000 [17:23<00:59,  2.85it/s, Loss=0.0182881, Gaussian number=206243, print grad=0.00042949020280502737, Depth Loss=0.0000000]
Training progress:  92%|█████████▏| 1830/2000 [17:26<00:59,  2.85it/s, Loss=0.0187994, Gaussian number=206243, print grad=0.0005840082885697484, Depth Loss=0.0000000] 
Training progress:  92%|█████████▏| 1840/2000 [17:26<00:56,  2.85it/s, Loss=0.0187994, Gaussian number=206243, print grad=0.0005840082885697484, Depth Loss=0.0000000]
Training progress:  92%|█████████▏| 1840/2000 [17:30<00:56,  2.85it/s, Loss=0.0204965, Gaussian number=206243, print grad=0.0007170816534198821, Depth Loss=0.0000000]
Training progress:  92%|█████████▎| 1850/2000 [17:30<00:52,  2.85it/s, Loss=0.0204965, Gaussian number=206243, print grad=0.0007170816534198821, Depth Loss=0.0000000]
Training progress:  92%|█████████▎| 1850/2000 [17:33<00:52,  2.85it/s, Loss=0.0215702, Gaussian number=206243, print grad=0.0008346091490238905, Depth Loss=0.0000000]
Training progress:  93%|█████████▎| 1860/2000 [17:33<00:49,  2.84it/s, Loss=0.0215702, Gaussian number=206243, print grad=0.0008346091490238905, Depth Loss=0.0000000]
Training progress:  93%|█████████▎| 1860/2000 [17:37<00:49,  2.84it/s, Loss=0.0226950, Gaussian number=206243, print grad=0.0009840723359957337, Depth Loss=0.0000000]
Training progress:  94%|█████████▎| 1870/2000 [17:37<00:45,  2.84it/s, Loss=0.0226950, Gaussian number=206243, print grad=0.0009840723359957337, Depth Loss=0.0000000]
Training progress:  94%|█████████▎| 1870/2000 [17:40<00:45,  2.84it/s, Loss=0.0183258, Gaussian number=206243, print grad=0.0011192859383299947, Depth Loss=0.0000000]
Training progress:  94%|█████████▍| 1880/2000 [17:40<00:42,  2.84it/s, Loss=0.0183258, Gaussian number=206243, print grad=0.0011192859383299947, Depth Loss=0.0000000]
Training progress:  94%|█████████▍| 1880/2000 [17:44<00:42,  2.84it/s, Loss=0.0209493, Gaussian number=206243, print grad=0.0012438513804227114, Depth Loss=0.0000000]
Training progress:  94%|█████████▍| 1890/2000 [17:44<00:38,  2.84it/s, Loss=0.0209493, Gaussian number=206243, print grad=0.0012438513804227114, Depth Loss=0.0000000]
Training progress:  94%|█████████▍| 1890/2000 [17:47<00:38,  2.84it/s, Loss=0.0257804, Gaussian number=206243, print grad=0.0013888059183955193, Depth Loss=0.0000000]
Training progress:  95%|█████████▌| 1900/2000 [17:47<00:35,  2.84it/s, Loss=0.0257804, Gaussian number=206243, print grad=0.0013888059183955193, Depth Loss=0.0000000]
Training progress:  95%|█████████▌| 1900/2000 [17:51<00:35,  2.84it/s, Loss=0.0230059, Gaussian number=208306, print grad=0.00012907685595564544, Depth Loss=0.0000000]
Training progress:  96%|█████████▌| 1910/2000 [17:51<00:31,  2.84it/s, Loss=0.0230059, Gaussian number=208306, print grad=0.00012907685595564544, Depth Loss=0.0000000]
Training progress:  96%|█████████▌| 1910/2000 [17:54<00:31,  2.84it/s, Loss=0.0179283, Gaussian number=208306, print grad=0.00027494842652231455, Depth Loss=0.0000000]
Training progress:  96%|█████████▌| 1920/2000 [17:54<00:28,  2.84it/s, Loss=0.0179283, Gaussian number=208306, print grad=0.00027494842652231455, Depth Loss=0.0000000]
Training progress:  96%|█████████▌| 1920/2000 [17:58<00:28,  2.84it/s, Loss=0.0158329, Gaussian number=208306, print grad=0.00041349080856889486, Depth Loss=0.0000000]
Training progress:  96%|█████████▋| 1930/2000 [17:58<00:24,  2.84it/s, Loss=0.0158329, Gaussian number=208306, print grad=0.00041349080856889486, Depth Loss=0.0000000]
Training progress:  96%|█████████▋| 1930/2000 [18:01<00:24,  2.84it/s, Loss=0.0240179, Gaussian number=208306, print grad=0.0005468472372740507, Depth Loss=0.0000000] 
Training progress:  97%|█████████▋| 1940/2000 [18:01<00:21,  2.84it/s, Loss=0.0240179, Gaussian number=208306, print grad=0.0005468472372740507, Depth Loss=0.0000000]
Training progress:  97%|█████████▋| 1940/2000 [18:05<00:21,  2.84it/s, Loss=0.0184163, Gaussian number=208306, print grad=0.0006787935271859169, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1950/2000 [18:05<00:17,  2.84it/s, Loss=0.0184163, Gaussian number=208306, print grad=0.0006787935271859169, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1950/2000 [18:08<00:17,  2.84it/s, Loss=0.0288851, Gaussian number=208306, print grad=0.0008084836299531162, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1960/2000 [18:08<00:14,  2.84it/s, Loss=0.0288851, Gaussian number=208306, print grad=0.0008084836299531162, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1960/2000 [18:12<00:14,  2.84it/s, Loss=0.0261548, Gaussian number=208306, print grad=0.0009438820998184383, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1970/2000 [18:12<00:10,  2.84it/s, Loss=0.0261548, Gaussian number=208306, print grad=0.0009438820998184383, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1970/2000 [18:15<00:10,  2.84it/s, Loss=0.0200398, Gaussian number=208306, print grad=0.0010808095103129745, Depth Loss=0.0000000]
Training progress:  99%|█████████▉| 1980/2000 [18:15<00:07,  2.85it/s, Loss=0.0200398, Gaussian number=208306, print grad=0.0010808095103129745, Depth Loss=0.0000000]
Training progress:  99%|█████████▉| 1980/2000 [18:19<00:07,  2.85it/s, Loss=0.0195446, Gaussian number=208306, print grad=0.001240107580088079, Depth Loss=0.0000000] 
Training progress: 100%|█████████▉| 1990/2000 [18:19<00:03,  2.83it/s, Loss=0.0195446, Gaussian number=208306, print grad=0.001240107580088079, Depth Loss=0.0000000]
Training progress: 100%|█████████▉| 1990/2000 [18:22<00:03,  2.83it/s, Loss=0.0162440, Gaussian number=208306, print grad=0.001387408236041665, Depth Loss=0.0000000]
Training progress: 100%|██████████| 2000/2000 [18:22<00:00,  2.84it/s, Loss=0.0162440, Gaussian number=208306, print grad=0.001387408236041665, Depth Loss=0.0000000]
Training progress: 100%|██████████| 2000/2000 [18:22<00:00,  1.81it/s, Loss=0.0162440, Gaussian number=208306, print grad=0.001387408236041665, Depth Loss=0.0000000]
Iteration 100 [03/12 17:41:56]

[ITER 100] Evaluating test: WD 0.152473, PSNR 12.5809,lpips 0.615503,ssim 0.421731 [03/12 17:42:54]

[ITER 100] Evaluating train: WD 0.155115, PSNR 12.9725,lpips 0.617657,ssim 0.442008 [03/12 17:43:01]
Gaussian number:182686,print gradients:1.5322264516726136e-05 [03/12 17:43:01]
Iteration 200 [03/12 17:43:37]

[ITER 200] Evaluating test: WD 0.152096, PSNR 13.7938,lpips 0.573267,ssim 0.432674 [03/12 17:44:34]

[ITER 200] Evaluating train: WD 0.153744, PSNR 14.2661,lpips 0.563632,ssim 0.448574 [03/12 17:44:42]
Gaussian number:182686,print gradients:1.7309312170254998e-05 [03/12 17:44:42]
Iteration 300 [03/12 17:45:17]

[ITER 300] Evaluating test: WD 0.150782, PSNR 14.2819,lpips 0.543596,ssim 0.436466 [03/12 17:46:15]

[ITER 300] Evaluating train: WD 0.153734, PSNR 14.8260,lpips 0.533928,ssim 0.449216 [03/12 17:46:22]
Gaussian number:182686,print gradients:1.8564804122433998e-05 [03/12 17:46:22]
Iteration 400 [03/12 17:46:58]
Iteration 500 [03/12 17:47:34]

[ITER 500] Evaluating test: WD 0.144713, PSNR 14.8926,lpips 0.509756,ssim 0.444169 [03/12 17:48:31]

[ITER 500] Evaluating train: WD 0.151491, PSNR 15.2776,lpips 0.509121,ssim 0.453783 [03/12 17:48:39]
Gaussian number:182686,print gradients:1.9983732272521593e-05 [03/12 17:48:39]
Iteration 600 [03/12 17:49:14]
Iteration 700 [03/12 17:49:50]
Iteration 800 [03/12 17:50:26]
Iteration 900 [03/12 17:51:01]
Iteration 1000 [03/12 17:51:37]

[ITER 1000] Evaluating test: WD 0.133279, PSNR 15.4017,lpips 0.461334,ssim 0.447131 [03/12 17:52:34]

[ITER 1000] Evaluating train: WD 0.140337, PSNR 16.1543,lpips 0.460759,ssim 0.459360 [03/12 17:52:42]
Gaussian number:188217,print gradients:2.2621734387939796e-05 [03/12 17:52:42]
Iteration 1100 [03/12 17:53:17]
Iteration 1200 [03/12 17:53:53]
Iteration 1300 [03/12 17:54:29]
Iteration 1400 [03/12 17:55:04]
Iteration 1500 [03/12 17:55:40]

[ITER 1500] Evaluating test: WD 0.123617, PSNR 15.7393,lpips 0.429876,ssim 0.453075 [03/12 17:56:37]

[ITER 1500] Evaluating train: WD 0.130563, PSNR 16.5415,lpips 0.427930,ssim 0.462129 [03/12 17:56:45]
Gaussian number:199157,print gradients:2.3311760742217302e-05 [03/12 17:56:45]
Iteration 1600 [03/12 17:57:20]
Iteration 1700 [03/12 17:57:55]
Iteration 1800 [03/12 17:58:30]
Iteration 1900 [03/12 17:59:06]
Iteration 2000 [03/12 17:59:41]

[ITER 2000] Evaluating test: WD 0.116783, PSNR 15.9701,lpips 0.411068,ssim 0.461328 [03/12 18:00:39]

[ITER 2000] Evaluating train: WD 0.126249, PSNR 16.6598,lpips 0.412685,ssim 0.467502 [03/12 18:00:46]
Gaussian number:208306,print gradients:2.1999558157403953e-05 [03/12 18:00:46]

[ITER 2000] Saving Gaussians [03/12 18:00:46]

Training complete. [03/12 18:00:48]
