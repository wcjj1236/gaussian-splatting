Optimizing /home/cw4287/gaussian-model/train_30k
Output folder: /home/cw4287/gaussian-model/train_30k [03/12 21:48:59]
Tensorboard not available: not logging progress [03/12 21:48:59]
------------LLFF HOLD------------- [03/12 21:49:01]

Reading camera 1/301
Reading camera 2/301
Reading camera 3/301
Reading camera 4/301
Reading camera 5/301
Reading camera 6/301
Reading camera 7/301
Reading camera 8/301
Reading camera 9/301
Reading camera 10/301
Reading camera 11/301
Reading camera 12/301
Reading camera 13/301
Reading camera 14/301
Reading camera 15/301
Reading camera 16/301
Reading camera 17/301
Reading camera 18/301
Reading camera 19/301
Reading camera 20/301
Reading camera 21/301
Reading camera 22/301
Reading camera 23/301
Reading camera 24/301
Reading camera 25/301
Reading camera 26/301
Reading camera 27/301
Reading camera 28/301
Reading camera 29/301
Reading camera 30/301
Reading camera 31/301
Reading camera 32/301
Reading camera 33/301
Reading camera 34/301
Reading camera 35/301
Reading camera 36/301
Reading camera 37/301
Reading camera 38/301
Reading camera 39/301
Reading camera 40/301
Reading camera 41/301
Reading camera 42/301
Reading camera 43/301
Reading camera 44/301
Reading camera 45/301
Reading camera 46/301
Reading camera 47/301
Reading camera 48/301
Reading camera 49/301
Reading camera 50/301
Reading camera 51/301
Reading camera 52/301
Reading camera 53/301
Reading camera 54/301
Reading camera 55/301
Reading camera 56/301
Reading camera 57/301
Reading camera 58/301
Reading camera 59/301
Reading camera 60/301
Reading camera 61/301
Reading camera 62/301
Reading camera 63/301
Reading camera 64/301
Reading camera 65/301
Reading camera 66/301
Reading camera 67/301
Reading camera 68/301
Reading camera 69/301
Reading camera 70/301
Reading camera 71/301
Reading camera 72/301
Reading camera 73/301
Reading camera 74/301
Reading camera 75/301
Reading camera 76/301
Reading camera 77/301
Reading camera 78/301
Reading camera 79/301
Reading camera 80/301
Reading camera 81/301
Reading camera 82/301
Reading camera 83/301
Reading camera 84/301
Reading camera 85/301
Reading camera 86/301
Reading camera 87/301
Reading camera 88/301
Reading camera 89/301
Reading camera 90/301
Reading camera 91/301
Reading camera 92/301
Reading camera 93/301
Reading camera 94/301
Reading camera 95/301
Reading camera 96/301
Reading camera 97/301
Reading camera 98/301
Reading camera 99/301
Reading camera 100/301
Reading camera 101/301
Reading camera 102/301
Reading camera 103/301
Reading camera 104/301
Reading camera 105/301
Reading camera 106/301
Reading camera 107/301
Reading camera 108/301
Reading camera 109/301
Reading camera 110/301
Reading camera 111/301
Reading camera 112/301
Reading camera 113/301
Reading camera 114/301
Reading camera 115/301
Reading camera 116/301
Reading camera 117/301
Reading camera 118/301
Reading camera 119/301
Reading camera 120/301
Reading camera 121/301
Reading camera 122/301
Reading camera 123/301
Reading camera 124/301
Reading camera 125/301
Reading camera 126/301
Reading camera 127/301
Reading camera 128/301
Reading camera 129/301
Reading camera 130/301
Reading camera 131/301
Reading camera 132/301
Reading camera 133/301
Reading camera 134/301
Reading camera 135/301
Reading camera 136/301
Reading camera 137/301
Reading camera 138/301
Reading camera 139/301
Reading camera 140/301
Reading camera 141/301
Reading camera 142/301
Reading camera 143/301
Reading camera 144/301
Reading camera 145/301
Reading camera 146/301
Reading camera 147/301
Reading camera 148/301
Reading camera 149/301
Reading camera 150/301
Reading camera 151/301
Reading camera 152/301
Reading camera 153/301
Reading camera 154/301
Reading camera 155/301
Reading camera 156/301
Reading camera 157/301
Reading camera 158/301
Reading camera 159/301
Reading camera 160/301
Reading camera 161/301
Reading camera 162/301
Reading camera 163/301
Reading camera 164/301
Reading camera 165/301
Reading camera 166/301
Reading camera 167/301
Reading camera 168/301
Reading camera 169/301
Reading camera 170/301
Reading camera 171/301
Reading camera 172/301
Reading camera 173/301
Reading camera 174/301
Reading camera 175/301
Reading camera 176/301
Reading camera 177/301
Reading camera 178/301
Reading camera 179/301
Reading camera 180/301
Reading camera 181/301
Reading camera 182/301
Reading camera 183/301
Reading camera 184/301
Reading camera 185/301
Reading camera 186/301
Reading camera 187/301
Reading camera 188/301
Reading camera 189/301
Reading camera 190/301
Reading camera 191/301
Reading camera 192/301
Reading camera 193/301
Reading camera 194/301
Reading camera 195/301
Reading camera 196/301
Reading camera 197/301
Reading camera 198/301
Reading camera 199/301
Reading camera 200/301
Reading camera 201/301
Reading camera 202/301
Reading camera 203/301
Reading camera 204/301
Reading camera 205/301
Reading camera 206/301
Reading camera 207/301
Reading camera 208/301
Reading camera 209/301
Reading camera 210/301
Reading camera 211/301
Reading camera 212/301
Reading camera 213/301
Reading camera 214/301
Reading camera 215/301
Reading camera 216/301
Reading camera 217/301
Reading camera 218/301
Reading camera 219/301
Reading camera 220/301
Reading camera 221/301
Reading camera 222/301
Reading camera 223/301
Reading camera 224/301
Reading camera 225/301
Reading camera 226/301
Reading camera 227/301
Reading camera 228/301
Reading camera 229/301
Reading camera 230/301
Reading camera 231/301
Reading camera 232/301
Reading camera 233/301
Reading camera 234/301
Reading camera 235/301
Reading camera 236/301
Reading camera 237/301
Reading camera 238/301
Reading camera 239/301
Reading camera 240/301
Reading camera 241/301
Reading camera 242/301
Reading camera 243/301
Reading camera 244/301
Reading camera 245/301
Reading camera 246/301
Reading camera 247/301
Reading camera 248/301
Reading camera 249/301
Reading camera 250/301
Reading camera 251/301
Reading camera 252/301
Reading camera 253/301
Reading camera 254/301
Reading camera 255/301
Reading camera 256/301
Reading camera 257/301
Reading camera 258/301
Reading camera 259/301
Reading camera 260/301
Reading camera 261/301
Reading camera 262/301
Reading camera 263/301
Reading camera 264/301
Reading camera 265/301
Reading camera 266/301
Reading camera 267/301
Reading camera 268/301
Reading camera 269/301
Reading camera 270/301
Reading camera 271/301
Reading camera 272/301
Reading camera 273/301
Reading camera 274/301
Reading camera 275/301
Reading camera 276/301
Reading camera 277/301
Reading camera 278/301
Reading camera 279/301
Reading camera 280/301
Reading camera 281/301
Reading camera 282/301
Reading camera 283/301
Reading camera 284/301
Reading camera 285/301
Reading camera 286/301
Reading camera 287/301
Reading camera 288/301
Reading camera 289/301
Reading camera 290/301
Reading camera 291/301
Reading camera 292/301
Reading camera 293/301
Reading camera 294/301
Reading camera 295/301
Reading camera 296/301
Reading camera 297/301
Reading camera 298/301
Reading camera 299/301
Reading camera 300/301
Reading camera 301/301 [03/12 21:49:01]
Loading Training Cameras [03/12 21:49:01]
Loading Test Cameras [03/12 21:49:12]
Number of points at initialisation :  182686 [03/12 21:49:14]

Training progress:   0%|          | 0/2000 [00:00<?, ?it/s]/ext3/conda/envs/3dgs/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/ext3/conda/envs/3dgs/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)

Training progress:   0%|          | 0/2000 [00:05<?, ?it/s, Loss=0.0196409, Gaussian number=182686, print grad=1.2396860256558284e-05, Depth Loss=0.0000000]
Training progress:   0%|          | 10/2000 [00:05<18:32,  1.79it/s, Loss=0.0196409, Gaussian number=182686, print grad=1.2396860256558284e-05, Depth Loss=0.0000000]
Training progress:   0%|          | 10/2000 [00:09<18:32,  1.79it/s, Loss=0.0178195, Gaussian number=182686, print grad=2.9511678803828545e-05, Depth Loss=0.0000000]
Training progress:   1%|          | 20/2000 [00:09<15:28,  2.13it/s, Loss=0.0178195, Gaussian number=182686, print grad=2.9511678803828545e-05, Depth Loss=0.0000000]
Training progress:   1%|          | 20/2000 [00:13<15:28,  2.13it/s, Loss=0.0174748, Gaussian number=182686, print grad=4.5796536142006516e-05, Depth Loss=0.0000000]
Training progress:   2%|▏         | 30/2000 [00:13<14:24,  2.28it/s, Loss=0.0174748, Gaussian number=182686, print grad=4.5796536142006516e-05, Depth Loss=0.0000000]
Training progress:   2%|▏         | 30/2000 [00:17<14:24,  2.28it/s, Loss=0.0181565, Gaussian number=182686, print grad=6.120930629549548e-05, Depth Loss=0.0000000] 
Training progress:   2%|▏         | 40/2000 [00:17<13:53,  2.35it/s, Loss=0.0181565, Gaussian number=182686, print grad=6.120930629549548e-05, Depth Loss=0.0000000]
Training progress:   2%|▏         | 40/2000 [00:21<13:53,  2.35it/s, Loss=0.0137406, Gaussian number=182686, print grad=7.405152427963912e-05, Depth Loss=0.0000000]
Training progress:   2%|▎         | 50/2000 [00:21<13:34,  2.39it/s, Loss=0.0137406, Gaussian number=182686, print grad=7.405152427963912e-05, Depth Loss=0.0000000]
Training progress:   2%|▎         | 50/2000 [00:25<13:34,  2.39it/s, Loss=0.0143132, Gaussian number=182686, print grad=9.201998909702525e-05, Depth Loss=0.0000000]
Training progress:   3%|▎         | 60/2000 [00:25<13:19,  2.43it/s, Loss=0.0143132, Gaussian number=182686, print grad=9.201998909702525e-05, Depth Loss=0.0000000]
Training progress:   3%|▎         | 60/2000 [00:29<13:19,  2.43it/s, Loss=0.0124604, Gaussian number=182686, print grad=0.00011117714166175574, Depth Loss=0.0000000]
Training progress:   4%|▎         | 70/2000 [00:29<13:09,  2.44it/s, Loss=0.0124604, Gaussian number=182686, print grad=0.00011117714166175574, Depth Loss=0.0000000]
Training progress:   4%|▎         | 70/2000 [00:33<13:09,  2.44it/s, Loss=0.0161800, Gaussian number=182686, print grad=0.0001276979746762663, Depth Loss=0.0000000] 
Training progress:   4%|▍         | 80/2000 [00:33<13:01,  2.46it/s, Loss=0.0161800, Gaussian number=182686, print grad=0.0001276979746762663, Depth Loss=0.0000000]
Training progress:   4%|▍         | 80/2000 [00:37<13:01,  2.46it/s, Loss=0.0135603, Gaussian number=182686, print grad=0.0001454874873161316, Depth Loss=0.0000000]
Training progress:   4%|▍         | 90/2000 [00:37<12:56,  2.46it/s, Loss=0.0135603, Gaussian number=182686, print grad=0.0001454874873161316, Depth Loss=0.0000000]
Training progress:   4%|▍         | 90/2000 [00:41<12:56,  2.46it/s, Loss=0.0121268, Gaussian number=182686, print grad=0.00016549225256312639, Depth Loss=0.0000000]
Training progress:   5%|▌         | 100/2000 [00:41<12:49,  2.47it/s, Loss=0.0121268, Gaussian number=182686, print grad=0.00016549225256312639, Depth Loss=0.0000000]
Training progress:   5%|▌         | 100/2000 [01:50<12:49,  2.47it/s, Loss=0.0146509, Gaussian number=182686, print grad=0.00018573833222035319, Depth Loss=0.0000000]
Training progress:   6%|▌         | 110/2000 [01:50<1:14:30,  2.37s/it, Loss=0.0146509, Gaussian number=182686, print grad=0.00018573833222035319, Depth Loss=0.0000000]
Training progress:   6%|▌         | 110/2000 [01:54<1:14:30,  2.37s/it, Loss=0.0116764, Gaussian number=182686, print grad=0.00020507807494141161, Depth Loss=0.0000000]
Training progress:   6%|▌         | 120/2000 [01:54<55:23,  1.77s/it, Loss=0.0116764, Gaussian number=182686, print grad=0.00020507807494141161, Depth Loss=0.0000000]  
Training progress:   6%|▌         | 120/2000 [01:58<55:23,  1.77s/it, Loss=0.0126999, Gaussian number=182686, print grad=0.00022674541105516255, Depth Loss=0.0000000]
Training progress:   6%|▋         | 130/2000 [01:58<42:10,  1.35s/it, Loss=0.0126999, Gaussian number=182686, print grad=0.00022674541105516255, Depth Loss=0.0000000]
Training progress:   6%|▋         | 130/2000 [02:02<42:10,  1.35s/it, Loss=0.0117548, Gaussian number=182686, print grad=0.0002483581192791462, Depth Loss=0.0000000] 
Training progress:   7%|▋         | 140/2000 [02:02<33:02,  1.07s/it, Loss=0.0117548, Gaussian number=182686, print grad=0.0002483581192791462, Depth Loss=0.0000000]
Training progress:   7%|▋         | 140/2000 [02:06<33:02,  1.07s/it, Loss=0.0101449, Gaussian number=182686, print grad=0.00026747846277430654, Depth Loss=0.0000000]
Training progress:   8%|▊         | 150/2000 [02:06<26:41,  1.16it/s, Loss=0.0101449, Gaussian number=182686, print grad=0.00026747846277430654, Depth Loss=0.0000000]
Training progress:   8%|▊         | 150/2000 [02:10<26:41,  1.16it/s, Loss=0.0111249, Gaussian number=182686, print grad=0.00029063448891974986, Depth Loss=0.0000000]
Training progress:   8%|▊         | 160/2000 [02:10<22:14,  1.38it/s, Loss=0.0111249, Gaussian number=182686, print grad=0.00029063448891974986, Depth Loss=0.0000000]
Training progress:   8%|▊         | 160/2000 [02:14<22:14,  1.38it/s, Loss=0.0110583, Gaussian number=182686, print grad=0.0003107123193331063, Depth Loss=0.0000000] 
Training progress:   8%|▊         | 170/2000 [02:14<19:07,  1.59it/s, Loss=0.0110583, Gaussian number=182686, print grad=0.0003107123193331063, Depth Loss=0.0000000]
Training progress:   8%|▊         | 170/2000 [02:18<19:07,  1.59it/s, Loss=0.0088765, Gaussian number=182686, print grad=0.0003313894849270582, Depth Loss=0.0000000]
Training progress:   9%|▉         | 180/2000 [02:18<16:57,  1.79it/s, Loss=0.0088765, Gaussian number=182686, print grad=0.0003313894849270582, Depth Loss=0.0000000]
Training progress:   9%|▉         | 180/2000 [02:22<16:57,  1.79it/s, Loss=0.0112365, Gaussian number=182686, print grad=0.00035174170625396073, Depth Loss=0.0000000]
Training progress:  10%|▉         | 190/2000 [02:22<15:26,  1.95it/s, Loss=0.0112365, Gaussian number=182686, print grad=0.00035174170625396073, Depth Loss=0.0000000]
Training progress:  10%|▉         | 190/2000 [02:26<15:26,  1.95it/s, Loss=0.0096268, Gaussian number=182686, print grad=0.00037276389775797725, Depth Loss=0.0000000]
Training progress:  10%|█         | 200/2000 [02:26<14:21,  2.09it/s, Loss=0.0096268, Gaussian number=182686, print grad=0.00037276389775797725, Depth Loss=0.0000000]
Training progress:  10%|█         | 200/2000 [03:34<14:21,  2.09it/s, Loss=0.0107161, Gaussian number=182686, print grad=0.0003946747165173292, Depth Loss=0.0000000] 
Training progress:  10%|█         | 210/2000 [03:34<1:10:56,  2.38s/it, Loss=0.0107161, Gaussian number=182686, print grad=0.0003946747165173292, Depth Loss=0.0000000]
Training progress:  10%|█         | 210/2000 [03:38<1:10:56,  2.38s/it, Loss=0.0085229, Gaussian number=182686, print grad=0.0004153550835326314, Depth Loss=0.0000000]
Training progress:  11%|█         | 220/2000 [03:38<52:55,  1.78s/it, Loss=0.0085229, Gaussian number=182686, print grad=0.0004153550835326314, Depth Loss=0.0000000]  
Training progress:  11%|█         | 220/2000 [03:42<52:55,  1.78s/it, Loss=0.0097651, Gaussian number=182686, print grad=0.0004372508265078068, Depth Loss=0.0000000]
Training progress:  12%|█▏        | 230/2000 [03:42<40:21,  1.37s/it, Loss=0.0097651, Gaussian number=182686, print grad=0.0004372508265078068, Depth Loss=0.0000000]
Training progress:  12%|█▏        | 230/2000 [03:46<40:21,  1.37s/it, Loss=0.0123375, Gaussian number=182686, print grad=0.00045738223707303405, Depth Loss=0.0000000]
Training progress:  12%|█▏        | 240/2000 [03:46<31:36,  1.08s/it, Loss=0.0123375, Gaussian number=182686, print grad=0.00045738223707303405, Depth Loss=0.0000000]
Training progress:  12%|█▏        | 240/2000 [03:50<31:36,  1.08s/it, Loss=0.0095613, Gaussian number=182686, print grad=0.0004802319162990898, Depth Loss=0.0000000] 
Training progress:  12%|█▎        | 250/2000 [03:50<25:28,  1.14it/s, Loss=0.0095613, Gaussian number=182686, print grad=0.0004802319162990898, Depth Loss=0.0000000]
Training progress:  12%|█▎        | 250/2000 [03:54<25:28,  1.14it/s, Loss=0.0102765, Gaussian number=182686, print grad=0.0005007866420783103, Depth Loss=0.0000000]
Training progress:  13%|█▎        | 260/2000 [03:54<21:11,  1.37it/s, Loss=0.0102765, Gaussian number=182686, print grad=0.0005007866420783103, Depth Loss=0.0000000]
Training progress:  13%|█▎        | 260/2000 [03:58<21:11,  1.37it/s, Loss=0.0069116, Gaussian number=182686, print grad=0.000522420450579375, Depth Loss=0.0000000] 
Training progress:  14%|█▎        | 270/2000 [03:58<18:11,  1.59it/s, Loss=0.0069116, Gaussian number=182686, print grad=0.000522420450579375, Depth Loss=0.0000000]
Training progress:  14%|█▎        | 270/2000 [04:01<18:11,  1.59it/s, Loss=0.0089948, Gaussian number=182686, print grad=0.0005441877874545753, Depth Loss=0.0000000]
Training progress:  14%|█▍        | 280/2000 [04:01<16:04,  1.78it/s, Loss=0.0089948, Gaussian number=182686, print grad=0.0005441877874545753, Depth Loss=0.0000000]
Training progress:  14%|█▍        | 280/2000 [04:05<16:04,  1.78it/s, Loss=0.0091421, Gaussian number=182686, print grad=0.0005673886043950915, Depth Loss=0.0000000]
Training progress:  14%|█▍        | 290/2000 [04:05<14:35,  1.95it/s, Loss=0.0091421, Gaussian number=182686, print grad=0.0005673886043950915, Depth Loss=0.0000000]
Training progress:  14%|█▍        | 290/2000 [04:09<14:35,  1.95it/s, Loss=0.0085164, Gaussian number=182686, print grad=0.000591074931435287, Depth Loss=0.0000000] 
Training progress:  15%|█▌        | 300/2000 [04:09<13:32,  2.09it/s, Loss=0.0085164, Gaussian number=182686, print grad=0.000591074931435287, Depth Loss=0.0000000]
Training progress:  15%|█▌        | 300/2000 [05:18<13:32,  2.09it/s, Loss=0.0071590, Gaussian number=182686, print grad=0.0006136413430795074, Depth Loss=0.0000000]
Training progress:  16%|█▌        | 310/2000 [05:18<1:06:57,  2.38s/it, Loss=0.0071590, Gaussian number=182686, print grad=0.0006136413430795074, Depth Loss=0.0000000]
Training progress:  16%|█▌        | 310/2000 [05:22<1:06:57,  2.38s/it, Loss=0.0072720, Gaussian number=182686, print grad=0.0006324702990241349, Depth Loss=0.0000000]
Training progress:  16%|█▌        | 320/2000 [05:22<49:55,  1.78s/it, Loss=0.0072720, Gaussian number=182686, print grad=0.0006324702990241349, Depth Loss=0.0000000]  
Training progress:  16%|█▌        | 320/2000 [05:25<49:55,  1.78s/it, Loss=0.0096525, Gaussian number=182686, print grad=0.0006525007775053382, Depth Loss=0.0000000]
Training progress:  16%|█▋        | 330/2000 [05:25<38:03,  1.37s/it, Loss=0.0096525, Gaussian number=182686, print grad=0.0006525007775053382, Depth Loss=0.0000000]
Training progress:  16%|█▋        | 330/2000 [05:29<38:03,  1.37s/it, Loss=0.0070656, Gaussian number=182686, print grad=0.0006752640474587679, Depth Loss=0.0000000]
Training progress:  17%|█▋        | 340/2000 [05:29<29:47,  1.08s/it, Loss=0.0070656, Gaussian number=182686, print grad=0.0006752640474587679, Depth Loss=0.0000000]
Training progress:  17%|█▋        | 340/2000 [05:33<29:47,  1.08s/it, Loss=0.0072592, Gaussian number=182686, print grad=0.0006975320284254849, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 350/2000 [05:33<23:59,  1.15it/s, Loss=0.0072592, Gaussian number=182686, print grad=0.0006975320284254849, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 350/2000 [05:37<23:59,  1.15it/s, Loss=0.0073236, Gaussian number=182686, print grad=0.0007213904173113406, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 360/2000 [05:37<19:57,  1.37it/s, Loss=0.0073236, Gaussian number=182686, print grad=0.0007213904173113406, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 360/2000 [05:41<19:57,  1.37it/s, Loss=0.0066015, Gaussian number=182686, print grad=0.0007427306263707578, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 370/2000 [05:41<17:07,  1.59it/s, Loss=0.0066015, Gaussian number=182686, print grad=0.0007427306263707578, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 370/2000 [05:45<17:07,  1.59it/s, Loss=0.0094998, Gaussian number=182686, print grad=0.0007620891556143761, Depth Loss=0.0000000]
Training progress:  19%|█▉        | 380/2000 [05:45<15:08,  1.78it/s, Loss=0.0094998, Gaussian number=182686, print grad=0.0007620891556143761, Depth Loss=0.0000000]
Training progress:  19%|█▉        | 380/2000 [05:49<15:08,  1.78it/s, Loss=0.0079198, Gaussian number=182686, print grad=0.0007848884561099112, Depth Loss=0.0000000]
Training progress:  20%|█▉        | 390/2000 [05:49<13:44,  1.95it/s, Loss=0.0079198, Gaussian number=182686, print grad=0.0007848884561099112, Depth Loss=0.0000000]
Training progress:  20%|█▉        | 390/2000 [05:53<13:44,  1.95it/s, Loss=0.0098169, Gaussian number=182686, print grad=0.0008069965988397598, Depth Loss=0.0000000]
Training progress:  20%|██        | 400/2000 [05:53<12:43,  2.10it/s, Loss=0.0098169, Gaussian number=182686, print grad=0.0008069965988397598, Depth Loss=0.0000000]
Training progress:  20%|██        | 400/2000 [05:57<12:43,  2.10it/s, Loss=0.0081754, Gaussian number=182686, print grad=0.0008324476657435298, Depth Loss=0.0000000]
Training progress:  20%|██        | 410/2000 [05:57<12:01,  2.20it/s, Loss=0.0081754, Gaussian number=182686, print grad=0.0008324476657435298, Depth Loss=0.0000000]
Training progress:  20%|██        | 410/2000 [06:01<12:01,  2.20it/s, Loss=0.0072034, Gaussian number=182686, print grad=0.0008575056563131511, Depth Loss=0.0000000]
Training progress:  21%|██        | 420/2000 [06:01<11:30,  2.29it/s, Loss=0.0072034, Gaussian number=182686, print grad=0.0008575056563131511, Depth Loss=0.0000000]
Training progress:  21%|██        | 420/2000 [06:05<11:30,  2.29it/s, Loss=0.0090381, Gaussian number=182686, print grad=0.0008825851837173104, Depth Loss=0.0000000]
Training progress:  22%|██▏       | 430/2000 [06:05<11:07,  2.35it/s, Loss=0.0090381, Gaussian number=182686, print grad=0.0008825851837173104, Depth Loss=0.0000000]
Training progress:  22%|██▏       | 430/2000 [06:09<11:07,  2.35it/s, Loss=0.0070843, Gaussian number=182686, print grad=0.0009049109648913145, Depth Loss=0.0000000]
Training progress:  22%|██▏       | 440/2000 [06:09<10:50,  2.40it/s, Loss=0.0070843, Gaussian number=182686, print grad=0.0009049109648913145, Depth Loss=0.0000000]
Training progress:  22%|██▏       | 440/2000 [06:13<10:50,  2.40it/s, Loss=0.0083928, Gaussian number=182686, print grad=0.0009282003156840801, Depth Loss=0.0000000]
Training progress:  22%|██▎       | 450/2000 [06:13<10:37,  2.43it/s, Loss=0.0083928, Gaussian number=182686, print grad=0.0009282003156840801, Depth Loss=0.0000000]
Training progress:  22%|██▎       | 450/2000 [06:17<10:37,  2.43it/s, Loss=0.0089246, Gaussian number=182686, print grad=0.0009514685370959342, Depth Loss=0.0000000]
Training progress:  23%|██▎       | 460/2000 [06:17<10:27,  2.45it/s, Loss=0.0089246, Gaussian number=182686, print grad=0.0009514685370959342, Depth Loss=0.0000000]
Training progress:  23%|██▎       | 460/2000 [06:21<10:27,  2.45it/s, Loss=0.0100329, Gaussian number=182686, print grad=0.00097412004834041, Depth Loss=0.0000000]  
Training progress:  24%|██▎       | 470/2000 [06:21<10:19,  2.47it/s, Loss=0.0100329, Gaussian number=182686, print grad=0.00097412004834041, Depth Loss=0.0000000]
Training progress:  24%|██▎       | 470/2000 [06:25<10:19,  2.47it/s, Loss=0.0064868, Gaussian number=182686, print grad=0.000999281881377101, Depth Loss=0.0000000]
Training progress:  24%|██▍       | 480/2000 [06:25<10:11,  2.48it/s, Loss=0.0064868, Gaussian number=182686, print grad=0.000999281881377101, Depth Loss=0.0000000]
Training progress:  24%|██▍       | 480/2000 [06:29<10:11,  2.48it/s, Loss=0.0072226, Gaussian number=182686, print grad=0.0010220451513305306, Depth Loss=0.0000000]
Training progress:  24%|██▍       | 490/2000 [06:29<10:06,  2.49it/s, Loss=0.0072226, Gaussian number=182686, print grad=0.0010220451513305306, Depth Loss=0.0000000]
Training progress:  24%|██▍       | 490/2000 [06:33<10:06,  2.49it/s, Loss=0.0053145, Gaussian number=182686, print grad=0.00104527419898659, Depth Loss=0.0000000]  
Training progress:  25%|██▌       | 500/2000 [06:33<10:00,  2.50it/s, Loss=0.0053145, Gaussian number=182686, print grad=0.00104527419898659, Depth Loss=0.0000000]
Training progress:  25%|██▌       | 500/2000 [07:41<10:00,  2.50it/s, Loss=0.0063968, Gaussian number=182686, print grad=0.001068423269316554, Depth Loss=0.0000000]
Training progress:  26%|██▌       | 510/2000 [07:41<57:39,  2.32s/it, Loss=0.0063968, Gaussian number=182686, print grad=0.001068423269316554, Depth Loss=0.0000000]
Training progress:  26%|██▌       | 510/2000 [07:45<57:39,  2.32s/it, Loss=0.0071747, Gaussian number=182686, print grad=0.001092134159989655, Depth Loss=0.0000000]
Training progress:  26%|██▌       | 520/2000 [07:45<43:01,  1.74s/it, Loss=0.0071747, Gaussian number=182686, print grad=0.001092134159989655, Depth Loss=0.0000000]
Training progress:  26%|██▌       | 520/2000 [07:49<43:01,  1.74s/it, Loss=0.0049562, Gaussian number=182686, print grad=0.00111231894697994, Depth Loss=0.0000000] 
Training progress:  26%|██▋       | 530/2000 [07:49<32:49,  1.34s/it, Loss=0.0049562, Gaussian number=182686, print grad=0.00111231894697994, Depth Loss=0.0000000]
Training progress:  26%|██▋       | 530/2000 [07:53<32:49,  1.34s/it, Loss=0.0068746, Gaussian number=182686, print grad=0.0011344889644533396, Depth Loss=0.0000000]
Training progress:  27%|██▋       | 540/2000 [07:53<25:43,  1.06s/it, Loss=0.0068746, Gaussian number=182686, print grad=0.0011344889644533396, Depth Loss=0.0000000]
Training progress:  27%|██▋       | 540/2000 [07:57<25:43,  1.06s/it, Loss=0.0063406, Gaussian number=182686, print grad=0.0011591188376769423, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 550/2000 [07:57<20:45,  1.16it/s, Loss=0.0063406, Gaussian number=182686, print grad=0.0011591188376769423, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 550/2000 [08:01<20:45,  1.16it/s, Loss=0.0050911, Gaussian number=182686, print grad=0.0011808944400399923, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 560/2000 [08:01<17:17,  1.39it/s, Loss=0.0050911, Gaussian number=182686, print grad=0.0011808944400399923, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 560/2000 [08:05<17:17,  1.39it/s, Loss=0.0068908, Gaussian number=182686, print grad=0.001204193220473826, Depth Loss=0.0000000] 
Training progress:  28%|██▊       | 570/2000 [08:05<14:51,  1.60it/s, Loss=0.0068908, Gaussian number=182686, print grad=0.001204193220473826, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 570/2000 [08:09<14:51,  1.60it/s, Loss=0.0061120, Gaussian number=182686, print grad=0.001228559878654778, Depth Loss=0.0000000]
Training progress:  29%|██▉       | 580/2000 [08:09<13:08,  1.80it/s, Loss=0.0061120, Gaussian number=182686, print grad=0.001228559878654778, Depth Loss=0.0000000]
Training progress:  29%|██▉       | 580/2000 [08:13<13:08,  1.80it/s, Loss=0.0067134, Gaussian number=182686, print grad=0.001252095215022564, Depth Loss=0.0000000]
Training progress:  30%|██▉       | 590/2000 [08:13<11:55,  1.97it/s, Loss=0.0067134, Gaussian number=182686, print grad=0.001252095215022564, Depth Loss=0.0000000]
Training progress:  30%|██▉       | 590/2000 [08:17<11:55,  1.97it/s, Loss=0.0075777, Gaussian number=182686, print grad=0.0012744643026962876, Depth Loss=0.0000000]
Training progress:  30%|███       | 600/2000 [08:17<11:04,  2.11it/s, Loss=0.0075777, Gaussian number=182686, print grad=0.0012744643026962876, Depth Loss=0.0000000]
Training progress:  30%|███       | 600/2000 [08:21<11:04,  2.11it/s, Loss=0.0058525, Gaussian number=182679, print grad=2.0570154447341338e-05, Depth Loss=0.0000000]
Training progress:  30%|███       | 610/2000 [08:21<10:27,  2.21it/s, Loss=0.0058525, Gaussian number=182679, print grad=2.0570154447341338e-05, Depth Loss=0.0000000]
Training progress:  30%|███       | 610/2000 [08:25<10:27,  2.21it/s, Loss=0.0074687, Gaussian number=182679, print grad=4.407781671034172e-05, Depth Loss=0.0000000] 
Training progress:  31%|███       | 620/2000 [08:25<10:00,  2.30it/s, Loss=0.0074687, Gaussian number=182679, print grad=4.407781671034172e-05, Depth Loss=0.0000000]
Training progress:  31%|███       | 620/2000 [08:29<10:00,  2.30it/s, Loss=0.0053680, Gaussian number=182679, print grad=6.658844358753413e-05, Depth Loss=0.0000000]
Training progress:  32%|███▏      | 630/2000 [08:29<09:41,  2.36it/s, Loss=0.0053680, Gaussian number=182679, print grad=6.658844358753413e-05, Depth Loss=0.0000000]
Training progress:  32%|███▏      | 630/2000 [08:33<09:41,  2.36it/s, Loss=0.0059408, Gaussian number=182679, print grad=9.12149844225496e-05, Depth Loss=0.0000000] 
Training progress:  32%|███▏      | 640/2000 [08:33<09:25,  2.40it/s, Loss=0.0059408, Gaussian number=182679, print grad=9.12149844225496e-05, Depth Loss=0.0000000]
Training progress:  32%|███▏      | 640/2000 [08:37<09:25,  2.40it/s, Loss=0.0066300, Gaussian number=182679, print grad=0.00011354583693901077, Depth Loss=0.0000000]
Training progress:  32%|███▎      | 650/2000 [08:37<09:14,  2.43it/s, Loss=0.0066300, Gaussian number=182679, print grad=0.00011354583693901077, Depth Loss=0.0000000]
Training progress:  32%|███▎      | 650/2000 [08:41<09:14,  2.43it/s, Loss=0.0064028, Gaussian number=182679, print grad=0.0001379713648930192, Depth Loss=0.0000000] 
Training progress:  33%|███▎      | 660/2000 [08:41<09:05,  2.46it/s, Loss=0.0064028, Gaussian number=182679, print grad=0.0001379713648930192, Depth Loss=0.0000000]
Training progress:  33%|███▎      | 660/2000 [08:45<09:05,  2.46it/s, Loss=0.0061767, Gaussian number=182679, print grad=0.00015953533875290304, Depth Loss=0.0000000]
Training progress:  34%|███▎      | 670/2000 [08:45<08:57,  2.47it/s, Loss=0.0061767, Gaussian number=182679, print grad=0.00015953533875290304, Depth Loss=0.0000000]
Training progress:  34%|███▎      | 670/2000 [08:49<08:57,  2.47it/s, Loss=0.0054086, Gaussian number=182679, print grad=0.00018353090854361653, Depth Loss=0.0000000]
Training progress:  34%|███▍      | 680/2000 [08:49<08:50,  2.49it/s, Loss=0.0054086, Gaussian number=182679, print grad=0.00018353090854361653, Depth Loss=0.0000000]
Training progress:  34%|███▍      | 680/2000 [08:53<08:50,  2.49it/s, Loss=0.0071235, Gaussian number=182679, print grad=0.00020694390696007758, Depth Loss=0.0000000]
Training progress:  34%|███▍      | 690/2000 [08:53<08:44,  2.50it/s, Loss=0.0071235, Gaussian number=182679, print grad=0.00020694390696007758, Depth Loss=0.0000000]
Training progress:  34%|███▍      | 690/2000 [08:57<08:44,  2.50it/s, Loss=0.0069667, Gaussian number=182679, print grad=0.00022971586440689862, Depth Loss=0.0000000]
Training progress:  35%|███▌      | 700/2000 [08:57<08:39,  2.50it/s, Loss=0.0069667, Gaussian number=182679, print grad=0.00022971586440689862, Depth Loss=0.0000000]
Training progress:  35%|███▌      | 700/2000 [09:01<08:39,  2.50it/s, Loss=0.0057214, Gaussian number=182695, print grad=2.0292291083023883e-05, Depth Loss=0.0000000]
Training progress:  36%|███▌      | 710/2000 [09:01<08:35,  2.50it/s, Loss=0.0057214, Gaussian number=182695, print grad=2.0292291083023883e-05, Depth Loss=0.0000000]
Training progress:  36%|███▌      | 710/2000 [09:05<08:35,  2.50it/s, Loss=0.0055459, Gaussian number=182695, print grad=4.4043386878911406e-05, Depth Loss=0.0000000]
Training progress:  36%|███▌      | 720/2000 [09:05<08:30,  2.51it/s, Loss=0.0055459, Gaussian number=182695, print grad=4.4043386878911406e-05, Depth Loss=0.0000000]
Training progress:  36%|███▌      | 720/2000 [09:09<08:30,  2.51it/s, Loss=0.0071172, Gaussian number=182695, print grad=6.640844367211685e-05, Depth Loss=0.0000000] 
Training progress:  36%|███▋      | 730/2000 [09:09<08:25,  2.51it/s, Loss=0.0071172, Gaussian number=182695, print grad=6.640844367211685e-05, Depth Loss=0.0000000]
Training progress:  36%|███▋      | 730/2000 [09:13<08:25,  2.51it/s, Loss=0.0077884, Gaussian number=182695, print grad=9.075961133930832e-05, Depth Loss=0.0000000]
Training progress:  37%|███▋      | 740/2000 [09:13<08:21,  2.51it/s, Loss=0.0077884, Gaussian number=182695, print grad=9.075961133930832e-05, Depth Loss=0.0000000]
Training progress:  37%|███▋      | 740/2000 [09:17<08:21,  2.51it/s, Loss=0.0056891, Gaussian number=182695, print grad=0.00011424925469327718, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 750/2000 [09:17<08:16,  2.52it/s, Loss=0.0056891, Gaussian number=182695, print grad=0.00011424925469327718, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 750/2000 [09:20<08:16,  2.52it/s, Loss=0.0058546, Gaussian number=182695, print grad=0.00013731322542298585, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 760/2000 [09:20<08:12,  2.52it/s, Loss=0.0058546, Gaussian number=182695, print grad=0.00013731322542298585, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 760/2000 [09:24<08:12,  2.52it/s, Loss=0.0047774, Gaussian number=182695, print grad=0.0001614886859897524, Depth Loss=0.0000000] 
Training progress:  38%|███▊      | 770/2000 [09:24<08:08,  2.52it/s, Loss=0.0047774, Gaussian number=182695, print grad=0.0001614886859897524, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 770/2000 [09:28<08:08,  2.52it/s, Loss=0.0065638, Gaussian number=182695, print grad=0.00018383952556177974, Depth Loss=0.0000000]
Training progress:  39%|███▉      | 780/2000 [09:28<08:04,  2.52it/s, Loss=0.0065638, Gaussian number=182695, print grad=0.00018383952556177974, Depth Loss=0.0000000]
Training progress:  39%|███▉      | 780/2000 [09:32<08:04,  2.52it/s, Loss=0.0083074, Gaussian number=182695, print grad=0.0002075499651255086, Depth Loss=0.0000000] 
Training progress:  40%|███▉      | 790/2000 [09:32<08:00,  2.52it/s, Loss=0.0083074, Gaussian number=182695, print grad=0.0002075499651255086, Depth Loss=0.0000000]
Training progress:  40%|███▉      | 790/2000 [09:36<08:00,  2.52it/s, Loss=0.0062693, Gaussian number=182695, print grad=0.0002311668504262343, Depth Loss=0.0000000]
Training progress:  40%|████      | 800/2000 [09:36<07:56,  2.52it/s, Loss=0.0062693, Gaussian number=182695, print grad=0.0002311668504262343, Depth Loss=0.0000000]
Training progress:  40%|████      | 800/2000 [09:40<07:56,  2.52it/s, Loss=0.0057257, Gaussian number=182697, print grad=2.031740586971864e-05, Depth Loss=0.0000000]
Training progress:  40%|████      | 810/2000 [09:40<07:52,  2.52it/s, Loss=0.0057257, Gaussian number=182697, print grad=2.031740586971864e-05, Depth Loss=0.0000000]
Training progress:  40%|████      | 810/2000 [09:44<07:52,  2.52it/s, Loss=0.0059468, Gaussian number=182697, print grad=4.274557431926951e-05, Depth Loss=0.0000000]
Training progress:  41%|████      | 820/2000 [09:44<07:49,  2.51it/s, Loss=0.0059468, Gaussian number=182697, print grad=4.274557431926951e-05, Depth Loss=0.0000000]
Training progress:  41%|████      | 820/2000 [09:48<07:49,  2.51it/s, Loss=0.0044741, Gaussian number=182697, print grad=6.652150477748364e-05, Depth Loss=0.0000000]
Training progress:  42%|████▏     | 830/2000 [09:48<07:50,  2.49it/s, Loss=0.0044741, Gaussian number=182697, print grad=6.652150477748364e-05, Depth Loss=0.0000000]
Training progress:  42%|████▏     | 830/2000 [09:52<07:50,  2.49it/s, Loss=0.0053665, Gaussian number=182697, print grad=8.916877413867041e-05, Depth Loss=0.0000000]
Training progress:  42%|████▏     | 840/2000 [09:52<07:44,  2.50it/s, Loss=0.0053665, Gaussian number=182697, print grad=8.916877413867041e-05, Depth Loss=0.0000000]
Training progress:  42%|████▏     | 840/2000 [09:56<07:44,  2.50it/s, Loss=0.0054882, Gaussian number=182697, print grad=0.00011218664440093562, Depth Loss=0.0000000]
Training progress:  42%|████▎     | 850/2000 [09:56<07:39,  2.50it/s, Loss=0.0054882, Gaussian number=182697, print grad=0.00011218664440093562, Depth Loss=0.0000000]
Training progress:  42%|████▎     | 850/2000 [10:00<07:39,  2.50it/s, Loss=0.0050430, Gaussian number=182697, print grad=0.00013407850929070264, Depth Loss=0.0000000]
Training progress:  43%|████▎     | 860/2000 [10:00<07:34,  2.51it/s, Loss=0.0050430, Gaussian number=182697, print grad=0.00013407850929070264, Depth Loss=0.0000000]
Training progress:  43%|████▎     | 860/2000 [10:04<07:34,  2.51it/s, Loss=0.0062789, Gaussian number=182697, print grad=0.00015581693151034415, Depth Loss=0.0000000]
Training progress:  44%|████▎     | 870/2000 [10:04<07:30,  2.51it/s, Loss=0.0062789, Gaussian number=182697, print grad=0.00015581693151034415, Depth Loss=0.0000000]
Training progress:  44%|████▎     | 870/2000 [10:08<07:30,  2.51it/s, Loss=0.0061187, Gaussian number=182697, print grad=0.00017923621635418385, Depth Loss=0.0000000]
Training progress:  44%|████▍     | 880/2000 [10:08<07:26,  2.51it/s, Loss=0.0061187, Gaussian number=182697, print grad=0.00017923621635418385, Depth Loss=0.0000000]
Training progress:  44%|████▍     | 880/2000 [10:12<07:26,  2.51it/s, Loss=0.0050138, Gaussian number=182697, print grad=0.00020206869521643966, Depth Loss=0.0000000]
Training progress:  44%|████▍     | 890/2000 [10:12<07:21,  2.51it/s, Loss=0.0050138, Gaussian number=182697, print grad=0.00020206869521643966, Depth Loss=0.0000000]
Training progress:  44%|████▍     | 890/2000 [10:16<07:21,  2.51it/s, Loss=0.0060405, Gaussian number=182697, print grad=0.0002260083274450153, Depth Loss=0.0000000] 
Training progress:  45%|████▌     | 900/2000 [10:16<07:17,  2.51it/s, Loss=0.0060405, Gaussian number=182697, print grad=0.0002260083274450153, Depth Loss=0.0000000]
Training progress:  45%|████▌     | 900/2000 [10:20<07:17,  2.51it/s, Loss=0.0045319, Gaussian number=182695, print grad=1.946487645909656e-05, Depth Loss=0.0000000]
Training progress:  46%|████▌     | 910/2000 [10:20<07:13,  2.52it/s, Loss=0.0045319, Gaussian number=182695, print grad=1.946487645909656e-05, Depth Loss=0.0000000]
Training progress:  46%|████▌     | 910/2000 [10:24<07:13,  2.52it/s, Loss=0.0060305, Gaussian number=182695, print grad=3.9964550524018705e-05, Depth Loss=0.0000000]
Training progress:  46%|████▌     | 920/2000 [10:24<07:09,  2.52it/s, Loss=0.0060305, Gaussian number=182695, print grad=3.9964550524018705e-05, Depth Loss=0.0000000]
Training progress:  46%|████▌     | 920/2000 [10:28<07:09,  2.52it/s, Loss=0.0057600, Gaussian number=182695, print grad=6.343550194287673e-05, Depth Loss=0.0000000] 
Training progress:  46%|████▋     | 930/2000 [10:28<07:04,  2.52it/s, Loss=0.0057600, Gaussian number=182695, print grad=6.343550194287673e-05, Depth Loss=0.0000000]
Training progress:  46%|████▋     | 930/2000 [10:32<07:04,  2.52it/s, Loss=0.0053476, Gaussian number=182695, print grad=8.669675298733637e-05, Depth Loss=0.0000000]
Training progress:  47%|████▋     | 940/2000 [10:32<07:00,  2.52it/s, Loss=0.0053476, Gaussian number=182695, print grad=8.669675298733637e-05, Depth Loss=0.0000000]
Training progress:  47%|████▋     | 940/2000 [10:36<07:00,  2.52it/s, Loss=0.0052797, Gaussian number=182695, print grad=0.00010841698531294242, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 950/2000 [10:36<06:56,  2.52it/s, Loss=0.0052797, Gaussian number=182695, print grad=0.00010841698531294242, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 950/2000 [10:40<06:56,  2.52it/s, Loss=0.0050469, Gaussian number=182695, print grad=0.00013002271589357406, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 960/2000 [10:40<06:52,  2.52it/s, Loss=0.0050469, Gaussian number=182695, print grad=0.00013002271589357406, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 960/2000 [10:44<06:52,  2.52it/s, Loss=0.0067116, Gaussian number=182695, print grad=0.00015470809012185782, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 970/2000 [10:44<06:48,  2.52it/s, Loss=0.0067116, Gaussian number=182695, print grad=0.00015470809012185782, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 970/2000 [10:48<06:48,  2.52it/s, Loss=0.0042242, Gaussian number=182695, print grad=0.00017642154125496745, Depth Loss=0.0000000]
Training progress:  49%|████▉     | 980/2000 [10:48<06:44,  2.52it/s, Loss=0.0042242, Gaussian number=182695, print grad=0.00017642154125496745, Depth Loss=0.0000000]
Training progress:  49%|████▉     | 980/2000 [10:52<06:44,  2.52it/s, Loss=0.0046996, Gaussian number=182695, print grad=0.00019609261653386056, Depth Loss=0.0000000]
Training progress:  50%|████▉     | 990/2000 [10:52<06:40,  2.52it/s, Loss=0.0046996, Gaussian number=182695, print grad=0.00019609261653386056, Depth Loss=0.0000000]
Training progress:  50%|████▉     | 990/2000 [10:56<06:40,  2.52it/s, Loss=0.0056065, Gaussian number=182695, print grad=0.0002151717635570094, Depth Loss=0.0000000] 
Training progress:  50%|█████     | 1000/2000 [10:56<06:36,  2.52it/s, Loss=0.0056065, Gaussian number=182695, print grad=0.0002151717635570094, Depth Loss=0.0000000]
Training progress:  50%|█████     | 1000/2000 [12:04<06:36,  2.52it/s, Loss=0.0053457, Gaussian number=182690, print grad=1.964166403922718e-05, Depth Loss=0.0000000]
Training progress:  50%|█████     | 1010/2000 [12:04<38:15,  2.32s/it, Loss=0.0053457, Gaussian number=182690, print grad=1.964166403922718e-05, Depth Loss=0.0000000]
Training progress:  50%|█████     | 1010/2000 [12:08<38:15,  2.32s/it, Loss=0.0062737, Gaussian number=182690, print grad=4.4316097046248615e-05, Depth Loss=0.0000000]
Training progress:  51%|█████     | 1020/2000 [12:08<28:26,  1.74s/it, Loss=0.0062737, Gaussian number=182690, print grad=4.4316097046248615e-05, Depth Loss=0.0000000]
Training progress:  51%|█████     | 1020/2000 [12:12<28:26,  1.74s/it, Loss=0.0052248, Gaussian number=182690, print grad=6.838760600658134e-05, Depth Loss=0.0000000] 
Training progress:  52%|█████▏    | 1030/2000 [12:12<21:37,  1.34s/it, Loss=0.0052248, Gaussian number=182690, print grad=6.838760600658134e-05, Depth Loss=0.0000000]
Training progress:  52%|█████▏    | 1030/2000 [12:16<21:37,  1.34s/it, Loss=0.0053721, Gaussian number=182690, print grad=9.330640023108572e-05, Depth Loss=0.0000000]
Training progress:  52%|█████▏    | 1040/2000 [12:16<16:52,  1.05s/it, Loss=0.0053721, Gaussian number=182690, print grad=9.330640023108572e-05, Depth Loss=0.0000000]
Training progress:  52%|█████▏    | 1040/2000 [12:20<16:52,  1.05s/it, Loss=0.0052457, Gaussian number=182690, print grad=0.00011302837810944766, Depth Loss=0.0000000]
Training progress:  52%|█████▎    | 1050/2000 [12:20<13:34,  1.17it/s, Loss=0.0052457, Gaussian number=182690, print grad=0.00011302837810944766, Depth Loss=0.0000000]
Training progress:  52%|█████▎    | 1050/2000 [12:24<13:34,  1.17it/s, Loss=0.0045304, Gaussian number=182690, print grad=0.0001344180345768109, Depth Loss=0.0000000] 
Training progress:  53%|█████▎    | 1060/2000 [12:24<11:15,  1.39it/s, Loss=0.0045304, Gaussian number=182690, print grad=0.0001344180345768109, Depth Loss=0.0000000]
Training progress:  53%|█████▎    | 1060/2000 [12:28<11:15,  1.39it/s, Loss=0.0039598, Gaussian number=182690, print grad=0.00015681047807447612, Depth Loss=0.0000000]
Training progress:  54%|█████▎    | 1070/2000 [12:28<09:37,  1.61it/s, Loss=0.0039598, Gaussian number=182690, print grad=0.00015681047807447612, Depth Loss=0.0000000]
Training progress:  54%|█████▎    | 1070/2000 [12:32<09:37,  1.61it/s, Loss=0.0044355, Gaussian number=182690, print grad=0.00017810141434893012, Depth Loss=0.0000000]
Training progress:  54%|█████▍    | 1080/2000 [12:32<08:28,  1.81it/s, Loss=0.0044355, Gaussian number=182690, print grad=0.00017810141434893012, Depth Loss=0.0000000]
Training progress:  54%|█████▍    | 1080/2000 [12:36<08:28,  1.81it/s, Loss=0.0048317, Gaussian number=182690, print grad=0.0001998759835259989, Depth Loss=0.0000000] 
Training progress:  55%|█████▍    | 1090/2000 [12:36<07:40,  1.98it/s, Loss=0.0048317, Gaussian number=182690, print grad=0.0001998759835259989, Depth Loss=0.0000000]
Training progress:  55%|█████▍    | 1090/2000 [12:40<07:40,  1.98it/s, Loss=0.0056890, Gaussian number=182690, print grad=0.0002219507732661441, Depth Loss=0.0000000]
Training progress:  55%|█████▌    | 1100/2000 [12:40<07:05,  2.12it/s, Loss=0.0056890, Gaussian number=182690, print grad=0.0002219507732661441, Depth Loss=0.0000000]
Training progress:  55%|█████▌    | 1100/2000 [12:43<07:05,  2.12it/s, Loss=0.0052341, Gaussian number=182684, print grad=1.985789458558429e-05, Depth Loss=0.0000000]
Training progress:  56%|█████▌    | 1110/2000 [12:43<06:39,  2.23it/s, Loss=0.0052341, Gaussian number=182684, print grad=1.985789458558429e-05, Depth Loss=0.0000000]
Training progress:  56%|█████▌    | 1110/2000 [12:47<06:39,  2.23it/s, Loss=0.0049051, Gaussian number=182684, print grad=4.32574306614697e-05, Depth Loss=0.0000000] 
Training progress:  56%|█████▌    | 1120/2000 [12:47<06:21,  2.31it/s, Loss=0.0049051, Gaussian number=182684, print grad=4.32574306614697e-05, Depth Loss=0.0000000]
Training progress:  56%|█████▌    | 1120/2000 [12:51<06:21,  2.31it/s, Loss=0.0041563, Gaussian number=182684, print grad=6.645245593972504e-05, Depth Loss=0.0000000]
Training progress:  56%|█████▋    | 1130/2000 [12:51<06:07,  2.37it/s, Loss=0.0041563, Gaussian number=182684, print grad=6.645245593972504e-05, Depth Loss=0.0000000]
Training progress:  56%|█████▋    | 1130/2000 [12:55<06:07,  2.37it/s, Loss=0.0053590, Gaussian number=182684, print grad=9.031817899085581e-05, Depth Loss=0.0000000]
Training progress:  57%|█████▋    | 1140/2000 [12:55<05:55,  2.42it/s, Loss=0.0053590, Gaussian number=182684, print grad=9.031817899085581e-05, Depth Loss=0.0000000]
Training progress:  57%|█████▋    | 1140/2000 [12:59<05:55,  2.42it/s, Loss=0.0035456, Gaussian number=182684, print grad=0.00011309882393106818, Depth Loss=0.0000000]
Training progress:  57%|█████▊    | 1150/2000 [12:59<05:46,  2.45it/s, Loss=0.0035456, Gaussian number=182684, print grad=0.00011309882393106818, Depth Loss=0.0000000]
Training progress:  57%|█████▊    | 1150/2000 [13:03<05:46,  2.45it/s, Loss=0.0040605, Gaussian number=182684, print grad=0.00013439793838188052, Depth Loss=0.0000000]
Training progress:  58%|█████▊    | 1160/2000 [13:03<05:39,  2.48it/s, Loss=0.0040605, Gaussian number=182684, print grad=0.00013439793838188052, Depth Loss=0.0000000]
Training progress:  58%|█████▊    | 1160/2000 [13:07<05:39,  2.48it/s, Loss=0.0052200, Gaussian number=182684, print grad=0.00015661190263926983, Depth Loss=0.0000000]
Training progress:  58%|█████▊    | 1170/2000 [13:07<05:32,  2.49it/s, Loss=0.0052200, Gaussian number=182684, print grad=0.00015661190263926983, Depth Loss=0.0000000]
Training progress:  58%|█████▊    | 1170/2000 [13:11<05:32,  2.49it/s, Loss=0.0049052, Gaussian number=182684, print grad=0.00017756642773747444, Depth Loss=0.0000000]
Training progress:  59%|█████▉    | 1180/2000 [13:11<05:27,  2.51it/s, Loss=0.0049052, Gaussian number=182684, print grad=0.00017756642773747444, Depth Loss=0.0000000]
Training progress:  59%|█████▉    | 1180/2000 [13:15<05:27,  2.51it/s, Loss=0.0043978, Gaussian number=182684, print grad=0.00020157589460723102, Depth Loss=0.0000000]
Training progress:  60%|█████▉    | 1190/2000 [13:15<05:22,  2.51it/s, Loss=0.0043978, Gaussian number=182684, print grad=0.00020157589460723102, Depth Loss=0.0000000]
Training progress:  60%|█████▉    | 1190/2000 [13:19<05:22,  2.51it/s, Loss=0.0053715, Gaussian number=182684, print grad=0.00022091486607678235, Depth Loss=0.0000000]
Training progress:  60%|██████    | 1200/2000 [13:19<05:17,  2.52it/s, Loss=0.0053715, Gaussian number=182684, print grad=0.00022091486607678235, Depth Loss=0.0000000]
Training progress:  60%|██████    | 1200/2000 [13:23<05:17,  2.52it/s, Loss=0.0039950, Gaussian number=182676, print grad=2.007041075557936e-05, Depth Loss=0.0000000] 
Training progress:  60%|██████    | 1210/2000 [13:23<05:13,  2.52it/s, Loss=0.0039950, Gaussian number=182676, print grad=2.007041075557936e-05, Depth Loss=0.0000000]
Training progress:  60%|██████    | 1210/2000 [13:27<05:13,  2.52it/s, Loss=0.0033262, Gaussian number=182676, print grad=4.29826213803608e-05, Depth Loss=0.0000000] 
Training progress:  61%|██████    | 1220/2000 [13:27<05:08,  2.53it/s, Loss=0.0033262, Gaussian number=182676, print grad=4.29826213803608e-05, Depth Loss=0.0000000]
Training progress:  61%|██████    | 1220/2000 [13:31<05:08,  2.53it/s, Loss=0.0038861, Gaussian number=182676, print grad=6.332890916382894e-05, Depth Loss=0.0000000]
Training progress:  62%|██████▏   | 1230/2000 [13:31<05:04,  2.53it/s, Loss=0.0038861, Gaussian number=182676, print grad=6.332890916382894e-05, Depth Loss=0.0000000]
Training progress:  62%|██████▏   | 1230/2000 [13:35<05:04,  2.53it/s, Loss=0.0037621, Gaussian number=182676, print grad=8.520276605850086e-05, Depth Loss=0.0000000]
Training progress:  62%|██████▏   | 1240/2000 [13:35<05:00,  2.53it/s, Loss=0.0037621, Gaussian number=182676, print grad=8.520276605850086e-05, Depth Loss=0.0000000]
Training progress:  62%|██████▏   | 1240/2000 [13:39<05:00,  2.53it/s, Loss=0.0036479, Gaussian number=182676, print grad=0.00010526284313527867, Depth Loss=0.0000000]
Training progress:  62%|██████▎   | 1250/2000 [13:39<04:55,  2.53it/s, Loss=0.0036479, Gaussian number=182676, print grad=0.00010526284313527867, Depth Loss=0.0000000]
Training progress:  62%|██████▎   | 1250/2000 [13:43<04:55,  2.53it/s, Loss=0.0037687, Gaussian number=182676, print grad=0.0001253886875929311, Depth Loss=0.0000000] 
Training progress:  63%|██████▎   | 1260/2000 [13:43<04:51,  2.53it/s, Loss=0.0037687, Gaussian number=182676, print grad=0.0001253886875929311, Depth Loss=0.0000000]
Training progress:  63%|██████▎   | 1260/2000 [13:47<04:51,  2.53it/s, Loss=0.0052603, Gaussian number=182676, print grad=0.000147961123730056, Depth Loss=0.0000000] 
Training progress:  64%|██████▎   | 1270/2000 [13:47<04:48,  2.53it/s, Loss=0.0052603, Gaussian number=182676, print grad=0.000147961123730056, Depth Loss=0.0000000]
Training progress:  64%|██████▎   | 1270/2000 [13:51<04:48,  2.53it/s, Loss=0.0051476, Gaussian number=182676, print grad=0.0001692187215667218, Depth Loss=0.0000000]
Training progress:  64%|██████▍   | 1280/2000 [13:51<04:43,  2.54it/s, Loss=0.0051476, Gaussian number=182676, print grad=0.0001692187215667218, Depth Loss=0.0000000]
Training progress:  64%|██████▍   | 1280/2000 [13:54<04:43,  2.54it/s, Loss=0.0037608, Gaussian number=182676, print grad=0.00019266046001575887, Depth Loss=0.0000000]
Training progress:  64%|██████▍   | 1290/2000 [13:54<04:39,  2.54it/s, Loss=0.0037608, Gaussian number=182676, print grad=0.00019266046001575887, Depth Loss=0.0000000]
Training progress:  64%|██████▍   | 1290/2000 [13:58<04:39,  2.54it/s, Loss=0.0055493, Gaussian number=182676, print grad=0.00021334555640351027, Depth Loss=0.0000000]
Training progress:  65%|██████▌   | 1300/2000 [13:58<04:35,  2.54it/s, Loss=0.0055493, Gaussian number=182676, print grad=0.00021334555640351027, Depth Loss=0.0000000]
Training progress:  65%|██████▌   | 1300/2000 [14:02<04:35,  2.54it/s, Loss=0.0055837, Gaussian number=182654, print grad=2.1123265469213948e-05, Depth Loss=0.0000000]
Training progress:  66%|██████▌   | 1310/2000 [14:02<04:32,  2.53it/s, Loss=0.0055837, Gaussian number=182654, print grad=2.1123265469213948e-05, Depth Loss=0.0000000]
Training progress:  66%|██████▌   | 1310/2000 [14:06<04:32,  2.53it/s, Loss=0.0049854, Gaussian number=182654, print grad=4.194265420665033e-05, Depth Loss=0.0000000] 
Training progress:  66%|██████▌   | 1320/2000 [14:06<04:28,  2.53it/s, Loss=0.0049854, Gaussian number=182654, print grad=4.194265420665033e-05, Depth Loss=0.0000000]
Training progress:  66%|██████▌   | 1320/2000 [14:10<04:28,  2.53it/s, Loss=0.0038935, Gaussian number=182654, print grad=6.290274177445099e-05, Depth Loss=0.0000000]
Training progress:  66%|██████▋   | 1330/2000 [14:10<04:24,  2.53it/s, Loss=0.0038935, Gaussian number=182654, print grad=6.290274177445099e-05, Depth Loss=0.0000000]
Training progress:  66%|██████▋   | 1330/2000 [14:14<04:24,  2.53it/s, Loss=0.0043658, Gaussian number=182654, print grad=8.489012543577701e-05, Depth Loss=0.0000000]
Training progress:  67%|██████▋   | 1340/2000 [14:14<04:20,  2.53it/s, Loss=0.0043658, Gaussian number=182654, print grad=8.489012543577701e-05, Depth Loss=0.0000000]
Training progress:  67%|██████▋   | 1340/2000 [14:18<04:20,  2.53it/s, Loss=0.0059877, Gaussian number=182654, print grad=0.00010461521742399782, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1350/2000 [14:18<04:16,  2.53it/s, Loss=0.0059877, Gaussian number=182654, print grad=0.00010461521742399782, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1350/2000 [14:22<04:16,  2.53it/s, Loss=0.0039546, Gaussian number=182654, print grad=0.00012510106898844242, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1360/2000 [14:22<04:12,  2.53it/s, Loss=0.0039546, Gaussian number=182654, print grad=0.00012510106898844242, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1360/2000 [14:26<04:12,  2.53it/s, Loss=0.0062678, Gaussian number=182654, print grad=0.00014644228213001043, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1370/2000 [14:26<04:08,  2.53it/s, Loss=0.0062678, Gaussian number=182654, print grad=0.00014644228213001043, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1370/2000 [14:30<04:08,  2.53it/s, Loss=0.0041159, Gaussian number=182654, print grad=0.00016731423966120929, Depth Loss=0.0000000]
Training progress:  69%|██████▉   | 1380/2000 [14:30<04:04,  2.53it/s, Loss=0.0041159, Gaussian number=182654, print grad=0.00016731423966120929, Depth Loss=0.0000000]
Training progress:  69%|██████▉   | 1380/2000 [14:34<04:04,  2.53it/s, Loss=0.0039314, Gaussian number=182654, print grad=0.0001868684048531577, Depth Loss=0.0000000] 
Training progress:  70%|██████▉   | 1390/2000 [14:34<04:01,  2.53it/s, Loss=0.0039314, Gaussian number=182654, print grad=0.0001868684048531577, Depth Loss=0.0000000]
Training progress:  70%|██████▉   | 1390/2000 [14:38<04:01,  2.53it/s, Loss=0.0043121, Gaussian number=182654, print grad=0.00020816086907871068, Depth Loss=0.0000000]
Training progress:  70%|███████   | 1400/2000 [14:38<03:57,  2.53it/s, Loss=0.0043121, Gaussian number=182654, print grad=0.00020816086907871068, Depth Loss=0.0000000]
Training progress:  70%|███████   | 1400/2000 [14:42<03:57,  2.53it/s, Loss=0.0050542, Gaussian number=182656, print grad=2.0228557332302444e-05, Depth Loss=0.0000000]
Training progress:  70%|███████   | 1410/2000 [14:42<03:53,  2.53it/s, Loss=0.0050542, Gaussian number=182656, print grad=2.0228557332302444e-05, Depth Loss=0.0000000]
Training progress:  70%|███████   | 1410/2000 [14:46<03:53,  2.53it/s, Loss=0.0041727, Gaussian number=182656, print grad=4.336061829235405e-05, Depth Loss=0.0000000] 
Training progress:  71%|███████   | 1420/2000 [14:46<03:49,  2.53it/s, Loss=0.0041727, Gaussian number=182656, print grad=4.336061829235405e-05, Depth Loss=0.0000000]
Training progress:  71%|███████   | 1420/2000 [14:50<03:49,  2.53it/s, Loss=0.0043675, Gaussian number=182656, print grad=6.721305544488132e-05, Depth Loss=0.0000000]
Training progress:  72%|███████▏  | 1430/2000 [14:50<03:45,  2.53it/s, Loss=0.0043675, Gaussian number=182656, print grad=6.721305544488132e-05, Depth Loss=0.0000000]
Training progress:  72%|███████▏  | 1430/2000 [14:54<03:45,  2.53it/s, Loss=0.0042466, Gaussian number=182656, print grad=8.819066715659574e-05, Depth Loss=0.0000000]
Training progress:  72%|███████▏  | 1440/2000 [14:54<03:41,  2.53it/s, Loss=0.0042466, Gaussian number=182656, print grad=8.819066715659574e-05, Depth Loss=0.0000000]
Training progress:  72%|███████▏  | 1440/2000 [14:58<03:41,  2.53it/s, Loss=0.0037708, Gaussian number=182656, print grad=0.00010958257189486176, Depth Loss=0.0000000]
Training progress:  72%|███████▎  | 1450/2000 [14:58<03:37,  2.53it/s, Loss=0.0037708, Gaussian number=182656, print grad=0.00010958257189486176, Depth Loss=0.0000000]
Training progress:  72%|███████▎  | 1450/2000 [15:02<03:37,  2.53it/s, Loss=0.0033746, Gaussian number=182656, print grad=0.00013071633293293417, Depth Loss=0.0000000]
Training progress:  73%|███████▎  | 1460/2000 [15:02<03:33,  2.53it/s, Loss=0.0033746, Gaussian number=182656, print grad=0.00013071633293293417, Depth Loss=0.0000000]
Training progress:  73%|███████▎  | 1460/2000 [15:06<03:33,  2.53it/s, Loss=0.0043616, Gaussian number=182656, print grad=0.000152275271830149, Depth Loss=0.0000000]  
Training progress:  74%|███████▎  | 1470/2000 [15:06<03:29,  2.53it/s, Loss=0.0043616, Gaussian number=182656, print grad=0.000152275271830149, Depth Loss=0.0000000]
Training progress:  74%|███████▎  | 1470/2000 [15:10<03:29,  2.53it/s, Loss=0.0044379, Gaussian number=182656, print grad=0.00017441116506233811, Depth Loss=0.0000000]
Training progress:  74%|███████▍  | 1480/2000 [15:10<03:25,  2.53it/s, Loss=0.0044379, Gaussian number=182656, print grad=0.00017441116506233811, Depth Loss=0.0000000]
Training progress:  74%|███████▍  | 1480/2000 [15:13<03:25,  2.53it/s, Loss=0.0045662, Gaussian number=182656, print grad=0.00019608681031968445, Depth Loss=0.0000000]
Training progress:  74%|███████▍  | 1490/2000 [15:13<03:21,  2.53it/s, Loss=0.0045662, Gaussian number=182656, print grad=0.00019608681031968445, Depth Loss=0.0000000]
Training progress:  74%|███████▍  | 1490/2000 [15:17<03:21,  2.53it/s, Loss=0.0049114, Gaussian number=182656, print grad=0.0002184912736993283, Depth Loss=0.0000000] 
Training progress:  75%|███████▌  | 1500/2000 [15:17<03:17,  2.54it/s, Loss=0.0049114, Gaussian number=182656, print grad=0.0002184912736993283, Depth Loss=0.0000000]
Training progress:  75%|███████▌  | 1500/2000 [16:25<03:17,  2.54it/s, Loss=0.0051564, Gaussian number=182634, print grad=1.9282599168946035e-05, Depth Loss=0.0000000]
Training progress:  76%|███████▌  | 1510/2000 [16:25<18:53,  2.31s/it, Loss=0.0051564, Gaussian number=182634, print grad=1.9282599168946035e-05, Depth Loss=0.0000000]
Training progress:  76%|███████▌  | 1510/2000 [16:29<18:53,  2.31s/it, Loss=0.0042598, Gaussian number=182634, print grad=3.978334279963747e-05, Depth Loss=0.0000000] 
Training progress:  76%|███████▌  | 1520/2000 [16:29<13:54,  1.74s/it, Loss=0.0042598, Gaussian number=182634, print grad=3.978334279963747e-05, Depth Loss=0.0000000]
Training progress:  76%|███████▌  | 1520/2000 [16:33<13:54,  1.74s/it, Loss=0.0031072, Gaussian number=182634, print grad=6.167829997139052e-05, Depth Loss=0.0000000]
Training progress:  76%|███████▋  | 1530/2000 [16:33<10:27,  1.33s/it, Loss=0.0031072, Gaussian number=182634, print grad=6.167829997139052e-05, Depth Loss=0.0000000]
Training progress:  76%|███████▋  | 1530/2000 [16:37<10:27,  1.33s/it, Loss=0.0042145, Gaussian number=182634, print grad=8.2483580627013e-05, Depth Loss=0.0000000]  
Training progress:  77%|███████▋  | 1540/2000 [16:37<08:03,  1.05s/it, Loss=0.0042145, Gaussian number=182634, print grad=8.2483580627013e-05, Depth Loss=0.0000000]
Training progress:  77%|███████▋  | 1540/2000 [16:41<08:03,  1.05s/it, Loss=0.0041113, Gaussian number=182634, print grad=0.00010540339280851185, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1550/2000 [16:41<06:24,  1.17it/s, Loss=0.0041113, Gaussian number=182634, print grad=0.00010540339280851185, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1550/2000 [16:45<06:24,  1.17it/s, Loss=0.0039905, Gaussian number=182634, print grad=0.000128250612760894, Depth Loss=0.0000000]  
Training progress:  78%|███████▊  | 1560/2000 [16:45<05:15,  1.40it/s, Loss=0.0039905, Gaussian number=182634, print grad=0.000128250612760894, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1560/2000 [16:49<05:15,  1.40it/s, Loss=0.0038608, Gaussian number=182634, print grad=0.00014972855569794774, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1570/2000 [16:49<04:26,  1.61it/s, Loss=0.0038608, Gaussian number=182634, print grad=0.00014972855569794774, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1570/2000 [16:53<04:26,  1.61it/s, Loss=0.0026765, Gaussian number=182634, print grad=0.00016778521239757538, Depth Loss=0.0000000]
Training progress:  79%|███████▉  | 1580/2000 [16:53<03:51,  1.81it/s, Loss=0.0026765, Gaussian number=182634, print grad=0.00016778521239757538, Depth Loss=0.0000000]
Training progress:  79%|███████▉  | 1580/2000 [16:57<03:51,  1.81it/s, Loss=0.0038186, Gaussian number=182634, print grad=0.0001874115550890565, Depth Loss=0.0000000] 
Training progress:  80%|███████▉  | 1590/2000 [16:57<03:26,  1.98it/s, Loss=0.0038186, Gaussian number=182634, print grad=0.0001874115550890565, Depth Loss=0.0000000]
Training progress:  80%|███████▉  | 1590/2000 [17:01<03:26,  1.98it/s, Loss=0.0038135, Gaussian number=182634, print grad=0.00020893178589176387, Depth Loss=0.0000000]
Training progress:  80%|████████  | 1600/2000 [17:01<03:08,  2.12it/s, Loss=0.0038135, Gaussian number=182634, print grad=0.00020893178589176387, Depth Loss=0.0000000]
Training progress:  80%|████████  | 1600/2000 [17:05<03:08,  2.12it/s, Loss=0.0037352, Gaussian number=182609, print grad=2.0034627596032806e-05, Depth Loss=0.0000000]
Training progress:  80%|████████  | 1610/2000 [17:05<02:54,  2.23it/s, Loss=0.0037352, Gaussian number=182609, print grad=2.0034627596032806e-05, Depth Loss=0.0000000]
Training progress:  80%|████████  | 1610/2000 [17:09<02:54,  2.23it/s, Loss=0.0043975, Gaussian number=182609, print grad=4.2092156945727766e-05, Depth Loss=0.0000000]
Training progress:  81%|████████  | 1620/2000 [17:09<02:44,  2.32it/s, Loss=0.0043975, Gaussian number=182609, print grad=4.2092156945727766e-05, Depth Loss=0.0000000]
Training progress:  81%|████████  | 1620/2000 [17:13<02:44,  2.32it/s, Loss=0.0039004, Gaussian number=182609, print grad=6.274015322560444e-05, Depth Loss=0.0000000] 
Training progress:  82%|████████▏ | 1630/2000 [17:13<02:36,  2.36it/s, Loss=0.0039004, Gaussian number=182609, print grad=6.274015322560444e-05, Depth Loss=0.0000000]
Training progress:  82%|████████▏ | 1630/2000 [17:17<02:36,  2.36it/s, Loss=0.0027278, Gaussian number=182609, print grad=8.384205284528434e-05, Depth Loss=0.0000000]
Training progress:  82%|████████▏ | 1640/2000 [17:17<02:29,  2.41it/s, Loss=0.0027278, Gaussian number=182609, print grad=8.384205284528434e-05, Depth Loss=0.0000000]
Training progress:  82%|████████▏ | 1640/2000 [17:21<02:29,  2.41it/s, Loss=0.0038544, Gaussian number=182609, print grad=0.00010267554898746312, Depth Loss=0.0000000]
Training progress:  82%|████████▎ | 1650/2000 [17:21<02:22,  2.45it/s, Loss=0.0038544, Gaussian number=182609, print grad=0.00010267554898746312, Depth Loss=0.0000000]
Training progress:  82%|████████▎ | 1650/2000 [17:24<02:22,  2.45it/s, Loss=0.0036549, Gaussian number=182609, print grad=0.00012266391422599554, Depth Loss=0.0000000]
Training progress:  83%|████████▎ | 1660/2000 [17:24<02:17,  2.48it/s, Loss=0.0036549, Gaussian number=182609, print grad=0.00012266391422599554, Depth Loss=0.0000000]
Training progress:  83%|████████▎ | 1660/2000 [17:28<02:17,  2.48it/s, Loss=0.0034992, Gaussian number=182609, print grad=0.00014250278763938695, Depth Loss=0.0000000]
Training progress:  84%|████████▎ | 1670/2000 [17:28<02:12,  2.50it/s, Loss=0.0034992, Gaussian number=182609, print grad=0.00014250278763938695, Depth Loss=0.0000000]
Training progress:  84%|████████▎ | 1670/2000 [17:32<02:12,  2.50it/s, Loss=0.0030835, Gaussian number=182609, print grad=0.00016395002603530884, Depth Loss=0.0000000]
Training progress:  84%|████████▍ | 1680/2000 [17:32<02:07,  2.51it/s, Loss=0.0030835, Gaussian number=182609, print grad=0.00016395002603530884, Depth Loss=0.0000000]
Training progress:  84%|████████▍ | 1680/2000 [17:36<02:07,  2.51it/s, Loss=0.0039374, Gaussian number=182609, print grad=0.0001842023921199143, Depth Loss=0.0000000] 
Training progress:  84%|████████▍ | 1690/2000 [17:36<02:03,  2.52it/s, Loss=0.0039374, Gaussian number=182609, print grad=0.0001842023921199143, Depth Loss=0.0000000]
Training progress:  84%|████████▍ | 1690/2000 [17:40<02:03,  2.52it/s, Loss=0.0038448, Gaussian number=182609, print grad=0.0002029364404734224, Depth Loss=0.0000000]
Training progress:  85%|████████▌ | 1700/2000 [17:40<01:58,  2.52it/s, Loss=0.0038448, Gaussian number=182609, print grad=0.0002029364404734224, Depth Loss=0.0000000]
Training progress:  85%|████████▌ | 1700/2000 [17:44<01:58,  2.52it/s, Loss=0.0042899, Gaussian number=182591, print grad=2.0772613424924202e-05, Depth Loss=0.0000000]
Training progress:  86%|████████▌ | 1710/2000 [17:44<01:54,  2.53it/s, Loss=0.0042899, Gaussian number=182591, print grad=2.0772613424924202e-05, Depth Loss=0.0000000]
Training progress:  86%|████████▌ | 1710/2000 [17:48<01:54,  2.53it/s, Loss=0.0044170, Gaussian number=182591, print grad=3.9760980143910274e-05, Depth Loss=0.0000000]
Training progress:  86%|████████▌ | 1720/2000 [17:48<01:50,  2.53it/s, Loss=0.0044170, Gaussian number=182591, print grad=3.9760980143910274e-05, Depth Loss=0.0000000]
Training progress:  86%|████████▌ | 1720/2000 [17:52<01:50,  2.53it/s, Loss=0.0036368, Gaussian number=182591, print grad=6.091259638196789e-05, Depth Loss=0.0000000] 
Training progress:  86%|████████▋ | 1730/2000 [17:52<01:46,  2.53it/s, Loss=0.0036368, Gaussian number=182591, print grad=6.091259638196789e-05, Depth Loss=0.0000000]
Training progress:  86%|████████▋ | 1730/2000 [17:56<01:46,  2.53it/s, Loss=0.0047908, Gaussian number=182591, print grad=8.296562737086788e-05, Depth Loss=0.0000000]
Training progress:  87%|████████▋ | 1740/2000 [17:56<01:42,  2.53it/s, Loss=0.0047908, Gaussian number=182591, print grad=8.296562737086788e-05, Depth Loss=0.0000000]
Training progress:  87%|████████▋ | 1740/2000 [18:00<01:42,  2.53it/s, Loss=0.0047998, Gaussian number=182591, print grad=0.00010577891225693747, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1750/2000 [18:00<01:38,  2.53it/s, Loss=0.0047998, Gaussian number=182591, print grad=0.00010577891225693747, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1750/2000 [18:04<01:38,  2.53it/s, Loss=0.0039457, Gaussian number=182591, print grad=0.00012703065294772387, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1760/2000 [18:04<01:34,  2.53it/s, Loss=0.0039457, Gaussian number=182591, print grad=0.00012703065294772387, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1760/2000 [18:08<01:34,  2.53it/s, Loss=0.0032314, Gaussian number=182591, print grad=0.00014658525469712913, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1770/2000 [18:08<01:30,  2.54it/s, Loss=0.0032314, Gaussian number=182591, print grad=0.00014658525469712913, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1770/2000 [18:12<01:30,  2.54it/s, Loss=0.0040911, Gaussian number=182591, print grad=0.00016636641521472484, Depth Loss=0.0000000]
Training progress:  89%|████████▉ | 1780/2000 [18:12<01:26,  2.54it/s, Loss=0.0040911, Gaussian number=182591, print grad=0.00016636641521472484, Depth Loss=0.0000000]
Training progress:  89%|████████▉ | 1780/2000 [18:16<01:26,  2.54it/s, Loss=0.0032060, Gaussian number=182591, print grad=0.0001850052794907242, Depth Loss=0.0000000] 
Training progress:  90%|████████▉ | 1790/2000 [18:16<01:22,  2.54it/s, Loss=0.0032060, Gaussian number=182591, print grad=0.0001850052794907242, Depth Loss=0.0000000]
Training progress:  90%|████████▉ | 1790/2000 [18:20<01:22,  2.54it/s, Loss=0.0035146, Gaussian number=182591, print grad=0.00020680918532889336, Depth Loss=0.0000000]
Training progress:  90%|█████████ | 1800/2000 [18:20<01:18,  2.54it/s, Loss=0.0035146, Gaussian number=182591, print grad=0.00020680918532889336, Depth Loss=0.0000000]
Training progress:  90%|█████████ | 1800/2000 [18:24<01:18,  2.54it/s, Loss=0.0039699, Gaussian number=182549, print grad=2.0630208382499404e-05, Depth Loss=0.0000000]
Training progress:  90%|█████████ | 1810/2000 [18:24<01:14,  2.54it/s, Loss=0.0039699, Gaussian number=182549, print grad=2.0630208382499404e-05, Depth Loss=0.0000000]
Training progress:  90%|█████████ | 1810/2000 [18:28<01:14,  2.54it/s, Loss=0.0036823, Gaussian number=182549, print grad=4.226122109685093e-05, Depth Loss=0.0000000] 
Training progress:  91%|█████████ | 1820/2000 [18:28<01:10,  2.54it/s, Loss=0.0036823, Gaussian number=182549, print grad=4.226122109685093e-05, Depth Loss=0.0000000]
Training progress:  91%|█████████ | 1820/2000 [18:31<01:10,  2.54it/s, Loss=0.0028408, Gaussian number=182549, print grad=6.16583856754005e-05, Depth Loss=0.0000000] 
Training progress:  92%|█████████▏| 1830/2000 [18:31<01:07,  2.53it/s, Loss=0.0028408, Gaussian number=182549, print grad=6.16583856754005e-05, Depth Loss=0.0000000]
Training progress:  92%|█████████▏| 1830/2000 [18:35<01:07,  2.53it/s, Loss=0.0033260, Gaussian number=182549, print grad=8.390048606088385e-05, Depth Loss=0.0000000]
Training progress:  92%|█████████▏| 1840/2000 [18:35<01:03,  2.53it/s, Loss=0.0033260, Gaussian number=182549, print grad=8.390048606088385e-05, Depth Loss=0.0000000]
Training progress:  92%|█████████▏| 1840/2000 [18:39<01:03,  2.53it/s, Loss=0.0033476, Gaussian number=182549, print grad=0.00010451371781527996, Depth Loss=0.0000000]
Training progress:  92%|█████████▎| 1850/2000 [18:39<00:59,  2.53it/s, Loss=0.0033476, Gaussian number=182549, print grad=0.00010451371781527996, Depth Loss=0.0000000]
Training progress:  92%|█████████▎| 1850/2000 [18:43<00:59,  2.53it/s, Loss=0.0033272, Gaussian number=182549, print grad=0.00012254278408363461, Depth Loss=0.0000000]
Training progress:  93%|█████████▎| 1860/2000 [18:43<00:55,  2.53it/s, Loss=0.0033272, Gaussian number=182549, print grad=0.00012254278408363461, Depth Loss=0.0000000]
Training progress:  93%|█████████▎| 1860/2000 [18:47<00:55,  2.53it/s, Loss=0.0037757, Gaussian number=182549, print grad=0.00014494190691038966, Depth Loss=0.0000000]
Training progress:  94%|█████████▎| 1870/2000 [18:47<00:51,  2.54it/s, Loss=0.0037757, Gaussian number=182549, print grad=0.00014494190691038966, Depth Loss=0.0000000]
Training progress:  94%|█████████▎| 1870/2000 [18:51<00:51,  2.54it/s, Loss=0.0030508, Gaussian number=182549, print grad=0.0001656006061239168, Depth Loss=0.0000000] 
Training progress:  94%|█████████▍| 1880/2000 [18:51<00:47,  2.54it/s, Loss=0.0030508, Gaussian number=182549, print grad=0.0001656006061239168, Depth Loss=0.0000000]
Training progress:  94%|█████████▍| 1880/2000 [18:55<00:47,  2.54it/s, Loss=0.0035021, Gaussian number=182549, print grad=0.00018561874458100647, Depth Loss=0.0000000]
Training progress:  94%|█████████▍| 1890/2000 [18:55<00:43,  2.53it/s, Loss=0.0035021, Gaussian number=182549, print grad=0.00018561874458100647, Depth Loss=0.0000000]
Training progress:  94%|█████████▍| 1890/2000 [18:59<00:43,  2.53it/s, Loss=0.0041398, Gaussian number=182549, print grad=0.00020696919818874449, Depth Loss=0.0000000]
Training progress:  95%|█████████▌| 1900/2000 [18:59<00:39,  2.53it/s, Loss=0.0041398, Gaussian number=182549, print grad=0.00020696919818874449, Depth Loss=0.0000000]
Training progress:  95%|█████████▌| 1900/2000 [19:03<00:39,  2.53it/s, Loss=0.0039063, Gaussian number=182520, print grad=1.8185568478656933e-05, Depth Loss=0.0000000]
Training progress:  96%|█████████▌| 1910/2000 [19:03<00:35,  2.54it/s, Loss=0.0039063, Gaussian number=182520, print grad=1.8185568478656933e-05, Depth Loss=0.0000000]
Training progress:  96%|█████████▌| 1910/2000 [19:07<00:35,  2.54it/s, Loss=0.0028958, Gaussian number=182520, print grad=3.872293746098876e-05, Depth Loss=0.0000000] 
Training progress:  96%|█████████▌| 1920/2000 [19:07<00:31,  2.53it/s, Loss=0.0028958, Gaussian number=182520, print grad=3.872293746098876e-05, Depth Loss=0.0000000]
Training progress:  96%|█████████▌| 1920/2000 [19:11<00:31,  2.53it/s, Loss=0.0026652, Gaussian number=182520, print grad=5.8780613471753895e-05, Depth Loss=0.0000000]
Training progress:  96%|█████████▋| 1930/2000 [19:11<00:27,  2.54it/s, Loss=0.0026652, Gaussian number=182520, print grad=5.8780613471753895e-05, Depth Loss=0.0000000]
Training progress:  96%|█████████▋| 1930/2000 [19:15<00:27,  2.54it/s, Loss=0.0040097, Gaussian number=182520, print grad=7.881117198849097e-05, Depth Loss=0.0000000] 
Training progress:  97%|█████████▋| 1940/2000 [19:15<00:23,  2.54it/s, Loss=0.0040097, Gaussian number=182520, print grad=7.881117198849097e-05, Depth Loss=0.0000000]
Training progress:  97%|█████████▋| 1940/2000 [19:19<00:23,  2.54it/s, Loss=0.0029954, Gaussian number=182520, print grad=9.980635513784364e-05, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1950/2000 [19:19<00:19,  2.54it/s, Loss=0.0029954, Gaussian number=182520, print grad=9.980635513784364e-05, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1950/2000 [19:23<00:19,  2.54it/s, Loss=0.0048033, Gaussian number=182520, print grad=0.00011934497160837054, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1960/2000 [19:23<00:15,  2.54it/s, Loss=0.0048033, Gaussian number=182520, print grad=0.00011934497160837054, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1960/2000 [19:27<00:15,  2.54it/s, Loss=0.0038230, Gaussian number=182520, print grad=0.00014034814375918359, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1970/2000 [19:27<00:11,  2.54it/s, Loss=0.0038230, Gaussian number=182520, print grad=0.00014034814375918359, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1970/2000 [19:31<00:11,  2.54it/s, Loss=0.0035722, Gaussian number=182520, print grad=0.0001605340512469411, Depth Loss=0.0000000] 
Training progress:  99%|█████████▉| 1980/2000 [19:31<00:07,  2.54it/s, Loss=0.0035722, Gaussian number=182520, print grad=0.0001605340512469411, Depth Loss=0.0000000]
Training progress:  99%|█████████▉| 1980/2000 [19:35<00:07,  2.54it/s, Loss=0.0033344, Gaussian number=182520, print grad=0.0001837094168877229, Depth Loss=0.0000000]
Training progress: 100%|█████████▉| 1990/2000 [19:35<00:03,  2.54it/s, Loss=0.0033344, Gaussian number=182520, print grad=0.0001837094168877229, Depth Loss=0.0000000]
Training progress: 100%|█████████▉| 1990/2000 [19:38<00:03,  2.54it/s, Loss=0.0028302, Gaussian number=182520, print grad=0.00020554500224534422, Depth Loss=0.0000000]
Training progress: 100%|██████████| 2000/2000 [19:38<00:00,  2.54it/s, Loss=0.0028302, Gaussian number=182520, print grad=0.00020554500224534422, Depth Loss=0.0000000]
Training progress: 100%|██████████| 2000/2000 [19:38<00:00,  1.70it/s, Loss=0.0028302, Gaussian number=182520, print grad=0.00020554500224534422, Depth Loss=0.0000000]
Iteration 100 [03/12 21:49:56]

[ITER 100] Evaluating test: WD 0.022850, PSNR 12.4332,lpips 0.615981,ssim 0.423309 [03/12 21:50:53]

[ITER 100] Evaluating train: WD 0.023811, PSNR 12.7108,lpips 0.618069,ssim 0.441356 [03/12 21:51:00]
Gaussian number:182686,print gradients:2.50090647568868e-06 [03/12 21:51:00]
Iteration 200 [03/12 21:51:40]

[ITER 200] Evaluating test: WD 0.021920, PSNR 13.8309,lpips 0.571707,ssim 0.444683 [03/12 21:52:37]

[ITER 200] Evaluating train: WD 0.022420, PSNR 13.9890,lpips 0.561955,ssim 0.457548 [03/12 21:52:44]
Gaussian number:182686,print gradients:2.7684920951287495e-06 [03/12 21:52:45]
Iteration 300 [03/12 21:53:24]

[ITER 300] Evaluating test: WD 0.021172, PSNR 14.4109,lpips 0.542537,ssim 0.454623 [03/12 21:54:21]

[ITER 300] Evaluating train: WD 0.021702, PSNR 14.6913,lpips 0.531804,ssim 0.466470 [03/12 21:54:28]
Gaussian number:182686,print gradients:2.9153954983485164e-06 [03/12 21:54:28]
Iteration 400 [03/12 21:55:08]
Iteration 500 [03/12 21:55:48]

[ITER 500] Evaluating test: WD 0.019922, PSNR 15.0896,lpips 0.511783,ssim 0.467494 [03/12 21:56:45]

[ITER 500] Evaluating train: WD 0.021300, PSNR 15.0979,lpips 0.512082,ssim 0.473500 [03/12 21:56:52]
Gaussian number:182686,print gradients:3.093878831350594e-06 [03/12 21:56:52]
Iteration 600 [03/12 21:57:31]
Iteration 700 [03/12 21:58:11]
Iteration 800 [03/12 21:58:51]
Iteration 900 [03/12 21:59:31]
Iteration 1000 [03/12 22:00:10]

[ITER 1000] Evaluating test: WD 0.017707, PSNR 15.7472,lpips 0.461979,ssim 0.483743 [03/12 22:01:07]

[ITER 1000] Evaluating train: WD 0.018934, PSNR 15.7427,lpips 0.465081,ssim 0.493879 [03/12 22:01:15]
Gaussian number:182695,print gradients:3.3287594760622596e-06 [03/12 22:01:15]
Iteration 1100 [03/12 22:01:54]
Iteration 1200 [03/12 22:02:34]
Iteration 1300 [03/12 22:03:13]
Iteration 1400 [03/12 22:03:52]
Iteration 1500 [03/12 22:04:32]

[ITER 1500] Evaluating test: WD 0.016261, PSNR 16.0807,lpips 0.431529,ssim 0.492773 [03/12 22:05:29]

[ITER 1500] Evaluating train: WD 0.017142, PSNR 16.4260,lpips 0.431722,ssim 0.505633 [03/12 22:05:36]
Gaussian number:182656,print gradients:3.3209614684892586e-06 [03/12 22:05:36]
Iteration 1600 [03/12 22:06:15]
Iteration 1700 [03/12 22:06:55]
Iteration 1800 [03/12 22:07:34]
Iteration 1900 [03/12 22:08:14]
Iteration 2000 [03/12 22:08:53]

[ITER 2000] Evaluating test: WD 0.015209, PSNR 16.4129,lpips 0.412222,ssim 0.501555 [03/12 22:09:50]

[ITER 2000] Evaluating train: WD 0.016536, PSNR 16.7300,lpips 0.414789,ssim 0.508311 [03/12 22:09:57]
Gaussian number:182520,print gradients:3.157960009048111e-06 [03/12 22:09:57]

[ITER 2000] Saving Gaussians [03/12 22:09:57]

Training complete. [03/12 22:09:59]
