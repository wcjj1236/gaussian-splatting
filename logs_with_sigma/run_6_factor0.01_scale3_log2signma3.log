Optimizing /home/cw4287/gaussian-model/train_30k
Output folder: /home/cw4287/gaussian-model/train_30k [03/12 18:22:25]
Tensorboard not available: not logging progress [03/12 18:22:25]
------------LLFF HOLD------------- [03/12 18:22:26]

Reading camera 1/301
Reading camera 2/301
Reading camera 3/301
Reading camera 4/301
Reading camera 5/301
Reading camera 6/301
Reading camera 7/301
Reading camera 8/301
Reading camera 9/301
Reading camera 10/301
Reading camera 11/301
Reading camera 12/301
Reading camera 13/301
Reading camera 14/301
Reading camera 15/301
Reading camera 16/301
Reading camera 17/301
Reading camera 18/301
Reading camera 19/301
Reading camera 20/301
Reading camera 21/301
Reading camera 22/301
Reading camera 23/301
Reading camera 24/301
Reading camera 25/301
Reading camera 26/301
Reading camera 27/301
Reading camera 28/301
Reading camera 29/301
Reading camera 30/301
Reading camera 31/301
Reading camera 32/301
Reading camera 33/301
Reading camera 34/301
Reading camera 35/301
Reading camera 36/301
Reading camera 37/301
Reading camera 38/301
Reading camera 39/301
Reading camera 40/301
Reading camera 41/301
Reading camera 42/301
Reading camera 43/301
Reading camera 44/301
Reading camera 45/301
Reading camera 46/301
Reading camera 47/301
Reading camera 48/301
Reading camera 49/301
Reading camera 50/301
Reading camera 51/301
Reading camera 52/301
Reading camera 53/301
Reading camera 54/301
Reading camera 55/301
Reading camera 56/301
Reading camera 57/301
Reading camera 58/301
Reading camera 59/301
Reading camera 60/301
Reading camera 61/301
Reading camera 62/301
Reading camera 63/301
Reading camera 64/301
Reading camera 65/301
Reading camera 66/301
Reading camera 67/301
Reading camera 68/301
Reading camera 69/301
Reading camera 70/301
Reading camera 71/301
Reading camera 72/301
Reading camera 73/301
Reading camera 74/301
Reading camera 75/301
Reading camera 76/301
Reading camera 77/301
Reading camera 78/301
Reading camera 79/301
Reading camera 80/301
Reading camera 81/301
Reading camera 82/301
Reading camera 83/301
Reading camera 84/301
Reading camera 85/301
Reading camera 86/301
Reading camera 87/301
Reading camera 88/301
Reading camera 89/301
Reading camera 90/301
Reading camera 91/301
Reading camera 92/301
Reading camera 93/301
Reading camera 94/301
Reading camera 95/301
Reading camera 96/301
Reading camera 97/301
Reading camera 98/301
Reading camera 99/301
Reading camera 100/301
Reading camera 101/301
Reading camera 102/301
Reading camera 103/301
Reading camera 104/301
Reading camera 105/301
Reading camera 106/301
Reading camera 107/301
Reading camera 108/301
Reading camera 109/301
Reading camera 110/301
Reading camera 111/301
Reading camera 112/301
Reading camera 113/301
Reading camera 114/301
Reading camera 115/301
Reading camera 116/301
Reading camera 117/301
Reading camera 118/301
Reading camera 119/301
Reading camera 120/301
Reading camera 121/301
Reading camera 122/301
Reading camera 123/301
Reading camera 124/301
Reading camera 125/301
Reading camera 126/301
Reading camera 127/301
Reading camera 128/301
Reading camera 129/301
Reading camera 130/301
Reading camera 131/301
Reading camera 132/301
Reading camera 133/301
Reading camera 134/301
Reading camera 135/301
Reading camera 136/301
Reading camera 137/301
Reading camera 138/301
Reading camera 139/301
Reading camera 140/301
Reading camera 141/301
Reading camera 142/301
Reading camera 143/301
Reading camera 144/301
Reading camera 145/301
Reading camera 146/301
Reading camera 147/301
Reading camera 148/301
Reading camera 149/301
Reading camera 150/301
Reading camera 151/301
Reading camera 152/301
Reading camera 153/301
Reading camera 154/301
Reading camera 155/301
Reading camera 156/301
Reading camera 157/301
Reading camera 158/301
Reading camera 159/301
Reading camera 160/301
Reading camera 161/301
Reading camera 162/301
Reading camera 163/301
Reading camera 164/301
Reading camera 165/301
Reading camera 166/301
Reading camera 167/301
Reading camera 168/301
Reading camera 169/301
Reading camera 170/301
Reading camera 171/301
Reading camera 172/301
Reading camera 173/301
Reading camera 174/301
Reading camera 175/301
Reading camera 176/301
Reading camera 177/301
Reading camera 178/301
Reading camera 179/301
Reading camera 180/301
Reading camera 181/301
Reading camera 182/301
Reading camera 183/301
Reading camera 184/301
Reading camera 185/301
Reading camera 186/301
Reading camera 187/301
Reading camera 188/301
Reading camera 189/301
Reading camera 190/301
Reading camera 191/301
Reading camera 192/301
Reading camera 193/301
Reading camera 194/301
Reading camera 195/301
Reading camera 196/301
Reading camera 197/301
Reading camera 198/301
Reading camera 199/301
Reading camera 200/301
Reading camera 201/301
Reading camera 202/301
Reading camera 203/301
Reading camera 204/301
Reading camera 205/301
Reading camera 206/301
Reading camera 207/301
Reading camera 208/301
Reading camera 209/301
Reading camera 210/301
Reading camera 211/301
Reading camera 212/301
Reading camera 213/301
Reading camera 214/301
Reading camera 215/301
Reading camera 216/301
Reading camera 217/301
Reading camera 218/301
Reading camera 219/301
Reading camera 220/301
Reading camera 221/301
Reading camera 222/301
Reading camera 223/301
Reading camera 224/301
Reading camera 225/301
Reading camera 226/301
Reading camera 227/301
Reading camera 228/301
Reading camera 229/301
Reading camera 230/301
Reading camera 231/301
Reading camera 232/301
Reading camera 233/301
Reading camera 234/301
Reading camera 235/301
Reading camera 236/301
Reading camera 237/301
Reading camera 238/301
Reading camera 239/301
Reading camera 240/301
Reading camera 241/301
Reading camera 242/301
Reading camera 243/301
Reading camera 244/301
Reading camera 245/301
Reading camera 246/301
Reading camera 247/301
Reading camera 248/301
Reading camera 249/301
Reading camera 250/301
Reading camera 251/301
Reading camera 252/301
Reading camera 253/301
Reading camera 254/301
Reading camera 255/301
Reading camera 256/301
Reading camera 257/301
Reading camera 258/301
Reading camera 259/301
Reading camera 260/301
Reading camera 261/301
Reading camera 262/301
Reading camera 263/301
Reading camera 264/301
Reading camera 265/301
Reading camera 266/301
Reading camera 267/301
Reading camera 268/301
Reading camera 269/301
Reading camera 270/301
Reading camera 271/301
Reading camera 272/301
Reading camera 273/301
Reading camera 274/301
Reading camera 275/301
Reading camera 276/301
Reading camera 277/301
Reading camera 278/301
Reading camera 279/301
Reading camera 280/301
Reading camera 281/301
Reading camera 282/301
Reading camera 283/301
Reading camera 284/301
Reading camera 285/301
Reading camera 286/301
Reading camera 287/301
Reading camera 288/301
Reading camera 289/301
Reading camera 290/301
Reading camera 291/301
Reading camera 292/301
Reading camera 293/301
Reading camera 294/301
Reading camera 295/301
Reading camera 296/301
Reading camera 297/301
Reading camera 298/301
Reading camera 299/301
Reading camera 300/301
Reading camera 301/301 [03/12 18:22:26]
Loading Training Cameras [03/12 18:22:26]
Loading Test Cameras [03/12 18:22:49]
Number of points at initialisation :  182686 [03/12 18:22:52]

Training progress:   0%|          | 0/2000 [00:00<?, ?it/s]/ext3/conda/envs/3dgs/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/ext3/conda/envs/3dgs/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)

Training progress:   0%|          | 0/2000 [00:05<?, ?it/s, Loss=0.2327553, Gaussian number=182686, print grad=0.00011574923701118678, Depth Loss=0.0000000]
Training progress:   0%|          | 10/2000 [00:05<19:52,  1.67it/s, Loss=0.2327553, Gaussian number=182686, print grad=0.00011574923701118678, Depth Loss=0.0000000]
Training progress:   0%|          | 10/2000 [00:10<19:52,  1.67it/s, Loss=0.2158323, Gaussian number=182686, print grad=0.0002962469297926873, Depth Loss=0.0000000] 
Training progress:   1%|          | 20/2000 [00:10<16:00,  2.06it/s, Loss=0.2158323, Gaussian number=182686, print grad=0.0002962469297926873, Depth Loss=0.0000000]
Training progress:   1%|          | 20/2000 [00:14<16:00,  2.06it/s, Loss=0.2144174, Gaussian number=182686, print grad=0.0004672961658798158, Depth Loss=0.0000000]
Training progress:   2%|▏         | 30/2000 [00:14<14:42,  2.23it/s, Loss=0.2144174, Gaussian number=182686, print grad=0.0004672961658798158, Depth Loss=0.0000000]
Training progress:   2%|▏         | 30/2000 [00:18<14:42,  2.23it/s, Loss=0.2302084, Gaussian number=182686, print grad=0.000642683997284621, Depth Loss=0.0000000] 
Training progress:   2%|▏         | 40/2000 [00:18<14:04,  2.32it/s, Loss=0.2302084, Gaussian number=182686, print grad=0.000642683997284621, Depth Loss=0.0000000]
Training progress:   2%|▏         | 40/2000 [00:22<14:04,  2.32it/s, Loss=0.1764593, Gaussian number=182686, print grad=0.000789508456364274, Depth Loss=0.0000000]
Training progress:   2%|▎         | 50/2000 [00:22<13:41,  2.37it/s, Loss=0.1764593, Gaussian number=182686, print grad=0.000789508456364274, Depth Loss=0.0000000]
Training progress:   2%|▎         | 50/2000 [00:26<13:41,  2.37it/s, Loss=0.1929329, Gaussian number=182686, print grad=0.0010009465040639043, Depth Loss=0.0000000]
Training progress:   3%|▎         | 60/2000 [00:26<13:24,  2.41it/s, Loss=0.1929329, Gaussian number=182686, print grad=0.0010009465040639043, Depth Loss=0.0000000]
Training progress:   3%|▎         | 60/2000 [00:30<13:24,  2.41it/s, Loss=0.1725747, Gaussian number=182686, print grad=0.0012569997925311327, Depth Loss=0.0000000]
Training progress:   4%|▎         | 70/2000 [00:30<13:12,  2.43it/s, Loss=0.1725747, Gaussian number=182686, print grad=0.0012569997925311327, Depth Loss=0.0000000]
Training progress:   4%|▎         | 70/2000 [00:34<13:12,  2.43it/s, Loss=0.2151727, Gaussian number=182686, print grad=0.0014651623787358403, Depth Loss=0.0000000]
Training progress:   4%|▍         | 80/2000 [00:34<13:03,  2.45it/s, Loss=0.2151727, Gaussian number=182686, print grad=0.0014651623787358403, Depth Loss=0.0000000]
Training progress:   4%|▍         | 80/2000 [00:38<13:03,  2.45it/s, Loss=0.1812610, Gaussian number=182686, print grad=0.0016838370356708765, Depth Loss=0.0000000]
Training progress:   4%|▍         | 90/2000 [00:38<12:57,  2.46it/s, Loss=0.1812610, Gaussian number=182686, print grad=0.0016838370356708765, Depth Loss=0.0000000]
Training progress:   4%|▍         | 90/2000 [00:42<12:57,  2.46it/s, Loss=0.1724489, Gaussian number=182686, print grad=0.001935998210683465, Depth Loss=0.0000000] 
Training progress:   5%|▌         | 100/2000 [00:42<12:51,  2.46it/s, Loss=0.1724489, Gaussian number=182686, print grad=0.001935998210683465, Depth Loss=0.0000000]
Training progress:   5%|▌         | 100/2000 [01:51<12:51,  2.46it/s, Loss=0.2014536, Gaussian number=182686, print grad=0.002207299927249551, Depth Loss=0.0000000]
Training progress:   6%|▌         | 110/2000 [01:51<1:15:55,  2.41s/it, Loss=0.2014536, Gaussian number=182686, print grad=0.002207299927249551, Depth Loss=0.0000000]
Training progress:   6%|▌         | 110/2000 [01:55<1:15:55,  2.41s/it, Loss=0.1659814, Gaussian number=182686, print grad=0.002464063698425889, Depth Loss=0.0000000]
Training progress:   6%|▌         | 120/2000 [01:55<56:22,  1.80s/it, Loss=0.1659814, Gaussian number=182686, print grad=0.002464063698425889, Depth Loss=0.0000000]  
Training progress:   6%|▌         | 120/2000 [01:59<56:22,  1.80s/it, Loss=0.1896804, Gaussian number=182686, print grad=0.0027772618923336267, Depth Loss=0.0000000]
Training progress:   6%|▋         | 130/2000 [01:59<42:53,  1.38s/it, Loss=0.1896804, Gaussian number=182686, print grad=0.0027772618923336267, Depth Loss=0.0000000]
Training progress:   6%|▋         | 130/2000 [02:03<42:53,  1.38s/it, Loss=0.1715513, Gaussian number=182686, print grad=0.003093481296673417, Depth Loss=0.0000000] 
Training progress:   7%|▋         | 140/2000 [02:03<33:31,  1.08s/it, Loss=0.1715513, Gaussian number=182686, print grad=0.003093481296673417, Depth Loss=0.0000000]
Training progress:   7%|▋         | 140/2000 [02:07<33:31,  1.08s/it, Loss=0.1519414, Gaussian number=182686, print grad=0.003378432709723711, Depth Loss=0.0000000]
Training progress:   8%|▊         | 150/2000 [02:07<27:01,  1.14it/s, Loss=0.1519414, Gaussian number=182686, print grad=0.003378432709723711, Depth Loss=0.0000000]
Training progress:   8%|▊         | 150/2000 [02:11<27:01,  1.14it/s, Loss=0.1618682, Gaussian number=182686, print grad=0.003726493800058961, Depth Loss=0.0000000]
Training progress:   8%|▊         | 160/2000 [02:11<22:28,  1.36it/s, Loss=0.1618682, Gaussian number=182686, print grad=0.003726493800058961, Depth Loss=0.0000000]
Training progress:   8%|▊         | 160/2000 [02:15<22:28,  1.36it/s, Loss=0.1622664, Gaussian number=182686, print grad=0.0040192450396716595, Depth Loss=0.0000000]
Training progress:   8%|▊         | 170/2000 [02:15<19:18,  1.58it/s, Loss=0.1622664, Gaussian number=182686, print grad=0.0040192450396716595, Depth Loss=0.0000000]
Training progress:   8%|▊         | 170/2000 [02:19<19:18,  1.58it/s, Loss=0.1353462, Gaussian number=182686, print grad=0.004337985534220934, Depth Loss=0.0000000] 
Training progress:   9%|▉         | 180/2000 [02:19<17:05,  1.78it/s, Loss=0.1353462, Gaussian number=182686, print grad=0.004337985534220934, Depth Loss=0.0000000]
Training progress:   9%|▉         | 180/2000 [02:23<17:05,  1.78it/s, Loss=0.1761660, Gaussian number=182686, print grad=0.004628712777048349, Depth Loss=0.0000000]
Training progress:  10%|▉         | 190/2000 [02:23<15:31,  1.94it/s, Loss=0.1761660, Gaussian number=182686, print grad=0.004628712777048349, Depth Loss=0.0000000]
Training progress:  10%|▉         | 190/2000 [02:27<15:31,  1.94it/s, Loss=0.1503342, Gaussian number=182686, print grad=0.004973467905074358, Depth Loss=0.0000000]
Training progress:  10%|█         | 200/2000 [02:27<14:24,  2.08it/s, Loss=0.1503342, Gaussian number=182686, print grad=0.004973467905074358, Depth Loss=0.0000000]
Training progress:  10%|█         | 200/2000 [03:37<14:24,  2.08it/s, Loss=0.1702019, Gaussian number=182686, print grad=0.005322862882167101, Depth Loss=0.0000000]
Training progress:  10%|█         | 210/2000 [03:37<1:12:04,  2.42s/it, Loss=0.1702019, Gaussian number=182686, print grad=0.005322862882167101, Depth Loss=0.0000000]
Training progress:  10%|█         | 210/2000 [03:41<1:12:04,  2.42s/it, Loss=0.1370362, Gaussian number=182686, print grad=0.005640892777591944, Depth Loss=0.0000000]
Training progress:  11%|█         | 220/2000 [03:41<53:43,  1.81s/it, Loss=0.1370362, Gaussian number=182686, print grad=0.005640892777591944, Depth Loss=0.0000000]  
Training progress:  11%|█         | 220/2000 [03:45<53:43,  1.81s/it, Loss=0.1530051, Gaussian number=182686, print grad=0.005978981498628855, Depth Loss=0.0000000]
Training progress:  12%|█▏        | 230/2000 [03:45<40:55,  1.39s/it, Loss=0.1530051, Gaussian number=182686, print grad=0.005978981498628855, Depth Loss=0.0000000]
Training progress:  12%|█▏        | 230/2000 [03:49<40:55,  1.39s/it, Loss=0.1933531, Gaussian number=182686, print grad=0.006291352212429047, Depth Loss=0.0000000]
Training progress:  12%|█▏        | 240/2000 [03:49<31:59,  1.09s/it, Loss=0.1933531, Gaussian number=182686, print grad=0.006291352212429047, Depth Loss=0.0000000]
Training progress:  12%|█▏        | 240/2000 [03:53<31:59,  1.09s/it, Loss=0.1471004, Gaussian number=182686, print grad=0.006638613063842058, Depth Loss=0.0000000]
Training progress:  12%|█▎        | 250/2000 [03:53<25:44,  1.13it/s, Loss=0.1471004, Gaussian number=182686, print grad=0.006638613063842058, Depth Loss=0.0000000]
Training progress:  12%|█▎        | 250/2000 [03:57<25:44,  1.13it/s, Loss=0.1658829, Gaussian number=182686, print grad=0.006957105360925198, Depth Loss=0.0000000]
Training progress:  13%|█▎        | 260/2000 [03:57<21:22,  1.36it/s, Loss=0.1658829, Gaussian number=182686, print grad=0.006957105360925198, Depth Loss=0.0000000]
Training progress:  13%|█▎        | 260/2000 [04:01<21:22,  1.36it/s, Loss=0.1126749, Gaussian number=182686, print grad=0.007295843679457903, Depth Loss=0.0000000]
Training progress:  14%|█▎        | 270/2000 [04:01<18:19,  1.57it/s, Loss=0.1126749, Gaussian number=182686, print grad=0.007295843679457903, Depth Loss=0.0000000]
Training progress:  14%|█▎        | 270/2000 [04:05<18:19,  1.57it/s, Loss=0.1467551, Gaussian number=182686, print grad=0.007662955671548843, Depth Loss=0.0000000]
Training progress:  14%|█▍        | 280/2000 [04:05<16:10,  1.77it/s, Loss=0.1467551, Gaussian number=182686, print grad=0.007662955671548843, Depth Loss=0.0000000]
Training progress:  14%|█▍        | 280/2000 [04:09<16:10,  1.77it/s, Loss=0.1501994, Gaussian number=182686, print grad=0.008023242466151714, Depth Loss=0.0000000]
Training progress:  14%|█▍        | 290/2000 [04:09<14:39,  1.94it/s, Loss=0.1501994, Gaussian number=182686, print grad=0.008023242466151714, Depth Loss=0.0000000]
Training progress:  14%|█▍        | 290/2000 [04:13<14:39,  1.94it/s, Loss=0.1421743, Gaussian number=182686, print grad=0.008400371298193932, Depth Loss=0.0000000]
Training progress:  15%|█▌        | 300/2000 [04:13<13:35,  2.09it/s, Loss=0.1421743, Gaussian number=182686, print grad=0.008400371298193932, Depth Loss=0.0000000]
Training progress:  15%|█▌        | 300/2000 [05:22<13:35,  2.09it/s, Loss=0.1164721, Gaussian number=182686, print grad=0.008778346702456474, Depth Loss=0.0000000]
Training progress:  16%|█▌        | 310/2000 [05:22<1:07:59,  2.41s/it, Loss=0.1164721, Gaussian number=182686, print grad=0.008778346702456474, Depth Loss=0.0000000]
Training progress:  16%|█▌        | 310/2000 [05:26<1:07:59,  2.41s/it, Loss=0.1205745, Gaussian number=182686, print grad=0.009064620360732079, Depth Loss=0.0000000]
Training progress:  16%|█▌        | 320/2000 [05:26<50:38,  1.81s/it, Loss=0.1205745, Gaussian number=182686, print grad=0.009064620360732079, Depth Loss=0.0000000]  
Training progress:  16%|█▌        | 320/2000 [05:30<50:38,  1.81s/it, Loss=0.1615031, Gaussian number=182686, print grad=0.009391830302774906, Depth Loss=0.0000000]
Training progress:  16%|█▋        | 330/2000 [05:30<38:33,  1.39s/it, Loss=0.1615031, Gaussian number=182686, print grad=0.009391830302774906, Depth Loss=0.0000000]
Training progress:  16%|█▋        | 330/2000 [05:34<38:33,  1.39s/it, Loss=0.1145202, Gaussian number=182686, print grad=0.009773104451596737, Depth Loss=0.0000000]
Training progress:  17%|█▋        | 340/2000 [05:34<30:07,  1.09s/it, Loss=0.1145202, Gaussian number=182686, print grad=0.009773104451596737, Depth Loss=0.0000000]
Training progress:  17%|█▋        | 340/2000 [05:38<30:07,  1.09s/it, Loss=0.1219341, Gaussian number=182686, print grad=0.010119966231286526, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 350/2000 [05:38<24:13,  1.13it/s, Loss=0.1219341, Gaussian number=182686, print grad=0.010119966231286526, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 350/2000 [05:42<24:13,  1.13it/s, Loss=0.1184231, Gaussian number=182686, print grad=0.010524277575314045, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 360/2000 [05:42<20:06,  1.36it/s, Loss=0.1184231, Gaussian number=182686, print grad=0.010524277575314045, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 360/2000 [05:46<20:06,  1.36it/s, Loss=0.1109484, Gaussian number=182686, print grad=0.010883087292313576, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 370/2000 [05:46<17:13,  1.58it/s, Loss=0.1109484, Gaussian number=182686, print grad=0.010883087292313576, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 370/2000 [05:50<17:13,  1.58it/s, Loss=0.1559607, Gaussian number=182686, print grad=0.011199818924069405, Depth Loss=0.0000000]
Training progress:  19%|█▉        | 380/2000 [05:50<15:11,  1.78it/s, Loss=0.1559607, Gaussian number=182686, print grad=0.011199818924069405, Depth Loss=0.0000000]
Training progress:  19%|█▉        | 380/2000 [05:54<15:11,  1.78it/s, Loss=0.1355296, Gaussian number=182686, print grad=0.01158509124070406, Depth Loss=0.0000000] 
Training progress:  20%|█▉        | 390/2000 [05:54<13:45,  1.95it/s, Loss=0.1355296, Gaussian number=182686, print grad=0.01158509124070406, Depth Loss=0.0000000]
Training progress:  20%|█▉        | 390/2000 [05:58<13:45,  1.95it/s, Loss=0.1644210, Gaussian number=182686, print grad=0.011946027167141438, Depth Loss=0.0000000]
Training progress:  20%|██        | 400/2000 [05:58<12:43,  2.10it/s, Loss=0.1644210, Gaussian number=182686, print grad=0.011946027167141438, Depth Loss=0.0000000]
Training progress:  20%|██        | 400/2000 [06:02<12:43,  2.10it/s, Loss=0.1403713, Gaussian number=182686, print grad=0.012368375435471535, Depth Loss=0.0000000]
Training progress:  20%|██        | 410/2000 [06:02<12:00,  2.21it/s, Loss=0.1403713, Gaussian number=182686, print grad=0.012368375435471535, Depth Loss=0.0000000]
Training progress:  20%|██        | 410/2000 [06:06<12:00,  2.21it/s, Loss=0.1234460, Gaussian number=182686, print grad=0.012776115909218788, Depth Loss=0.0000000]
Training progress:  21%|██        | 420/2000 [06:06<11:31,  2.28it/s, Loss=0.1234460, Gaussian number=182686, print grad=0.012776115909218788, Depth Loss=0.0000000]
Training progress:  21%|██        | 420/2000 [06:09<11:31,  2.28it/s, Loss=0.1562077, Gaussian number=182686, print grad=0.013191248290240765, Depth Loss=0.0000000]
Training progress:  22%|██▏       | 430/2000 [06:09<11:07,  2.35it/s, Loss=0.1562077, Gaussian number=182686, print grad=0.013191248290240765, Depth Loss=0.0000000]
Training progress:  22%|██▏       | 430/2000 [06:13<11:07,  2.35it/s, Loss=0.1209592, Gaussian number=182686, print grad=0.013571348041296005, Depth Loss=0.0000000]
Training progress:  22%|██▏       | 440/2000 [06:13<10:50,  2.40it/s, Loss=0.1209592, Gaussian number=182686, print grad=0.013571348041296005, Depth Loss=0.0000000]
Training progress:  22%|██▏       | 440/2000 [06:17<10:50,  2.40it/s, Loss=0.1406711, Gaussian number=182686, print grad=0.01396252028644085, Depth Loss=0.0000000] 
Training progress:  22%|██▎       | 450/2000 [06:17<10:36,  2.44it/s, Loss=0.1406711, Gaussian number=182686, print grad=0.01396252028644085, Depth Loss=0.0000000]
Training progress:  22%|██▎       | 450/2000 [06:21<10:36,  2.44it/s, Loss=0.1477688, Gaussian number=182686, print grad=0.014350688084959984, Depth Loss=0.0000000]
Training progress:  23%|██▎       | 460/2000 [06:21<10:25,  2.46it/s, Loss=0.1477688, Gaussian number=182686, print grad=0.014350688084959984, Depth Loss=0.0000000]
Training progress:  23%|██▎       | 460/2000 [06:25<10:25,  2.46it/s, Loss=0.1737227, Gaussian number=182686, print grad=0.01472012884914875, Depth Loss=0.0000000] 
Training progress:  24%|██▎       | 470/2000 [06:25<10:16,  2.48it/s, Loss=0.1737227, Gaussian number=182686, print grad=0.01472012884914875, Depth Loss=0.0000000]
Training progress:  24%|██▎       | 470/2000 [06:29<10:16,  2.48it/s, Loss=0.1108074, Gaussian number=182686, print grad=0.015137829817831516, Depth Loss=0.0000000]
Training progress:  24%|██▍       | 480/2000 [06:29<10:09,  2.49it/s, Loss=0.1108074, Gaussian number=182686, print grad=0.015137829817831516, Depth Loss=0.0000000]
Training progress:  24%|██▍       | 480/2000 [06:33<10:09,  2.49it/s, Loss=0.1238251, Gaussian number=182686, print grad=0.015517495572566986, Depth Loss=0.0000000]
Training progress:  24%|██▍       | 490/2000 [06:33<10:03,  2.50it/s, Loss=0.1238251, Gaussian number=182686, print grad=0.015517495572566986, Depth Loss=0.0000000]
Training progress:  24%|██▍       | 490/2000 [06:37<10:03,  2.50it/s, Loss=0.0939401, Gaussian number=182686, print grad=0.015905866399407387, Depth Loss=0.0000000]
Training progress:  25%|██▌       | 500/2000 [06:37<09:58,  2.51it/s, Loss=0.0939401, Gaussian number=182686, print grad=0.015905866399407387, Depth Loss=0.0000000]
Training progress:  25%|██▌       | 500/2000 [07:47<09:58,  2.51it/s, Loss=0.1148078, Gaussian number=182686, print grad=0.016291074454784393, Depth Loss=0.0000000]
Training progress:  26%|██▌       | 510/2000 [07:47<58:42,  2.36s/it, Loss=0.1148078, Gaussian number=182686, print grad=0.016291074454784393, Depth Loss=0.0000000]
Training progress:  26%|██▌       | 510/2000 [07:51<58:42,  2.36s/it, Loss=0.1179733, Gaussian number=182686, print grad=0.0166994147002697, Depth Loss=0.0000000]  
Training progress:  26%|██▌       | 520/2000 [07:51<43:44,  1.77s/it, Loss=0.1179733, Gaussian number=182686, print grad=0.0166994147002697, Depth Loss=0.0000000]
Training progress:  26%|██▌       | 520/2000 [07:55<43:44,  1.77s/it, Loss=0.0895846, Gaussian number=182686, print grad=0.017053110525012016, Depth Loss=0.0000000]
Training progress:  26%|██▋       | 530/2000 [07:55<33:18,  1.36s/it, Loss=0.0895846, Gaussian number=182686, print grad=0.017053110525012016, Depth Loss=0.0000000]
Training progress:  26%|██▋       | 530/2000 [07:59<33:18,  1.36s/it, Loss=0.1230055, Gaussian number=182686, print grad=0.01744513213634491, Depth Loss=0.0000000] 
Training progress:  27%|██▋       | 540/2000 [07:59<26:03,  1.07s/it, Loss=0.1230055, Gaussian number=182686, print grad=0.01744513213634491, Depth Loss=0.0000000]
Training progress:  27%|██▋       | 540/2000 [08:03<26:03,  1.07s/it, Loss=0.1159330, Gaussian number=182686, print grad=0.01786157488822937, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 550/2000 [08:03<20:58,  1.15it/s, Loss=0.1159330, Gaussian number=182686, print grad=0.01786157488822937, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 550/2000 [08:07<20:58,  1.15it/s, Loss=0.0905546, Gaussian number=182686, print grad=0.018237385898828506, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 560/2000 [08:07<17:26,  1.38it/s, Loss=0.0905546, Gaussian number=182686, print grad=0.018237385898828506, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 560/2000 [08:10<17:26,  1.38it/s, Loss=0.1263612, Gaussian number=182686, print grad=0.01865413784980774, Depth Loss=0.0000000] 
Training progress:  28%|██▊       | 570/2000 [08:10<14:57,  1.59it/s, Loss=0.1263612, Gaussian number=182686, print grad=0.01865413784980774, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 570/2000 [08:14<14:57,  1.59it/s, Loss=0.1092772, Gaussian number=182686, print grad=0.019063783809542656, Depth Loss=0.0000000]
Training progress:  29%|██▉       | 580/2000 [08:14<13:12,  1.79it/s, Loss=0.1092772, Gaussian number=182686, print grad=0.019063783809542656, Depth Loss=0.0000000]
Training progress:  29%|██▉       | 580/2000 [08:18<13:12,  1.79it/s, Loss=0.1274067, Gaussian number=182686, print grad=0.019479546695947647, Depth Loss=0.0000000]
Training progress:  30%|██▉       | 590/2000 [08:18<11:58,  1.96it/s, Loss=0.1274067, Gaussian number=182686, print grad=0.019479546695947647, Depth Loss=0.0000000]
Training progress:  30%|██▉       | 590/2000 [08:22<11:58,  1.96it/s, Loss=0.1267636, Gaussian number=182686, print grad=0.019862154498696327, Depth Loss=0.0000000]
Training progress:  30%|███       | 600/2000 [08:22<11:04,  2.11it/s, Loss=0.1267636, Gaussian number=182686, print grad=0.019862154498696327, Depth Loss=0.0000000]
Training progress:  30%|███       | 600/2000 [08:26<11:04,  2.11it/s, Loss=0.1118474, Gaussian number=186945, print grad=0.0003733746416401118, Depth Loss=0.0000000]
Training progress:  30%|███       | 610/2000 [08:26<10:27,  2.22it/s, Loss=0.1118474, Gaussian number=186945, print grad=0.0003733746416401118, Depth Loss=0.0000000]
Training progress:  30%|███       | 610/2000 [08:30<10:27,  2.22it/s, Loss=0.1528515, Gaussian number=186945, print grad=0.0008171683293767273, Depth Loss=0.0000000]
Training progress:  31%|███       | 620/2000 [08:30<09:59,  2.30it/s, Loss=0.1528515, Gaussian number=186945, print grad=0.0008171683293767273, Depth Loss=0.0000000]
Training progress:  31%|███       | 620/2000 [08:34<09:59,  2.30it/s, Loss=0.1020048, Gaussian number=186945, print grad=0.0012213831068947911, Depth Loss=0.0000000]
Training progress:  32%|███▏      | 630/2000 [08:34<09:39,  2.36it/s, Loss=0.1020048, Gaussian number=186945, print grad=0.0012213831068947911, Depth Loss=0.0000000]
Training progress:  32%|███▏      | 630/2000 [08:38<09:39,  2.36it/s, Loss=0.1101218, Gaussian number=186945, print grad=0.0016773707466199994, Depth Loss=0.0000000]
Training progress:  32%|███▏      | 640/2000 [08:38<09:23,  2.41it/s, Loss=0.1101218, Gaussian number=186945, print grad=0.0016773707466199994, Depth Loss=0.0000000]
Training progress:  32%|███▏      | 640/2000 [08:42<09:23,  2.41it/s, Loss=0.1288533, Gaussian number=186945, print grad=0.002054264536127448, Depth Loss=0.0000000] 
Training progress:  32%|███▎      | 650/2000 [08:42<09:12,  2.44it/s, Loss=0.1288533, Gaussian number=186945, print grad=0.002054264536127448, Depth Loss=0.0000000]
Training progress:  32%|███▎      | 650/2000 [08:46<09:12,  2.44it/s, Loss=0.1259862, Gaussian number=186945, print grad=0.0024989305529743433, Depth Loss=0.0000000]
Training progress:  33%|███▎      | 660/2000 [08:46<09:03,  2.47it/s, Loss=0.1259862, Gaussian number=186945, print grad=0.0024989305529743433, Depth Loss=0.0000000]
Training progress:  33%|███▎      | 660/2000 [08:50<09:03,  2.47it/s, Loss=0.1117261, Gaussian number=186945, print grad=0.0028869472444057465, Depth Loss=0.0000000]
Training progress:  34%|███▎      | 670/2000 [08:50<08:54,  2.49it/s, Loss=0.1117261, Gaussian number=186945, print grad=0.0028869472444057465, Depth Loss=0.0000000]
Training progress:  34%|███▎      | 670/2000 [08:54<08:54,  2.49it/s, Loss=0.1026318, Gaussian number=186945, print grad=0.003309587948024273, Depth Loss=0.0000000] 
Training progress:  34%|███▍      | 680/2000 [08:54<08:48,  2.50it/s, Loss=0.1026318, Gaussian number=186945, print grad=0.003309587948024273, Depth Loss=0.0000000]
Training progress:  34%|███▍      | 680/2000 [08:58<08:48,  2.50it/s, Loss=0.1233690, Gaussian number=186945, print grad=0.003716615028679371, Depth Loss=0.0000000]
Training progress:  34%|███▍      | 690/2000 [08:58<08:42,  2.51it/s, Loss=0.1233690, Gaussian number=186945, print grad=0.003716615028679371, Depth Loss=0.0000000]
Training progress:  34%|███▍      | 690/2000 [09:02<08:42,  2.51it/s, Loss=0.1237572, Gaussian number=186945, print grad=0.004122803453356028, Depth Loss=0.0000000]
Training progress:  35%|███▌      | 700/2000 [09:02<08:37,  2.51it/s, Loss=0.1237572, Gaussian number=186945, print grad=0.004122803453356028, Depth Loss=0.0000000]
Training progress:  35%|███▌      | 700/2000 [09:06<08:37,  2.51it/s, Loss=0.1180068, Gaussian number=198041, print grad=0.0003885833139065653, Depth Loss=0.0000000]
Training progress:  36%|███▌      | 710/2000 [09:06<08:32,  2.52it/s, Loss=0.1180068, Gaussian number=198041, print grad=0.0003885833139065653, Depth Loss=0.0000000]
Training progress:  36%|███▌      | 710/2000 [09:10<08:32,  2.52it/s, Loss=0.1027681, Gaussian number=198041, print grad=0.0008166511543095112, Depth Loss=0.0000000]
Training progress:  36%|███▌      | 720/2000 [09:10<08:27,  2.52it/s, Loss=0.1027681, Gaussian number=198041, print grad=0.0008166511543095112, Depth Loss=0.0000000]
Training progress:  36%|███▌      | 720/2000 [09:14<08:27,  2.52it/s, Loss=0.1409031, Gaussian number=198041, print grad=0.0012180591002106667, Depth Loss=0.0000000]
Training progress:  36%|███▋      | 730/2000 [09:14<08:23,  2.52it/s, Loss=0.1409031, Gaussian number=198041, print grad=0.0012180591002106667, Depth Loss=0.0000000]
Training progress:  36%|███▋      | 730/2000 [09:18<08:23,  2.52it/s, Loss=0.1604331, Gaussian number=198041, print grad=0.001680863555520773, Depth Loss=0.0000000] 
Training progress:  37%|███▋      | 740/2000 [09:18<08:19,  2.52it/s, Loss=0.1604331, Gaussian number=198041, print grad=0.001680863555520773, Depth Loss=0.0000000]
Training progress:  37%|███▋      | 740/2000 [09:22<08:19,  2.52it/s, Loss=0.1081887, Gaussian number=198041, print grad=0.0021009263582527637, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 750/2000 [09:22<08:15,  2.52it/s, Loss=0.1081887, Gaussian number=198041, print grad=0.0021009263582527637, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 750/2000 [09:26<08:15,  2.52it/s, Loss=0.1063125, Gaussian number=198041, print grad=0.0025045806542038918, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 760/2000 [09:26<08:11,  2.52it/s, Loss=0.1063125, Gaussian number=198041, print grad=0.0025045806542038918, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 760/2000 [09:30<08:11,  2.52it/s, Loss=0.0937575, Gaussian number=198041, print grad=0.0029470494482666254, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 770/2000 [09:30<08:06,  2.53it/s, Loss=0.0937575, Gaussian number=198041, print grad=0.0029470494482666254, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 770/2000 [09:34<08:06,  2.53it/s, Loss=0.1320868, Gaussian number=198041, print grad=0.003346594050526619, Depth Loss=0.0000000] 
Training progress:  39%|███▉      | 780/2000 [09:34<08:02,  2.53it/s, Loss=0.1320868, Gaussian number=198041, print grad=0.003346594050526619, Depth Loss=0.0000000]
Training progress:  39%|███▉      | 780/2000 [09:38<08:02,  2.53it/s, Loss=0.1513976, Gaussian number=198041, print grad=0.0037574477028101683, Depth Loss=0.0000000]
Training progress:  40%|███▉      | 790/2000 [09:38<07:59,  2.52it/s, Loss=0.1513976, Gaussian number=198041, print grad=0.0037574477028101683, Depth Loss=0.0000000]
Training progress:  40%|███▉      | 790/2000 [09:42<07:59,  2.52it/s, Loss=0.1284744, Gaussian number=198041, print grad=0.004185968544334173, Depth Loss=0.0000000] 
Training progress:  40%|████      | 800/2000 [09:42<07:57,  2.51it/s, Loss=0.1284744, Gaussian number=198041, print grad=0.004185968544334173, Depth Loss=0.0000000]
Training progress:  40%|████      | 800/2000 [09:46<07:57,  2.51it/s, Loss=0.1297087, Gaussian number=210386, print grad=0.000383295671781525, Depth Loss=0.0000000]
Training progress:  40%|████      | 810/2000 [09:46<07:52,  2.52it/s, Loss=0.1297087, Gaussian number=210386, print grad=0.000383295671781525, Depth Loss=0.0000000]
Training progress:  40%|████      | 810/2000 [09:49<07:52,  2.52it/s, Loss=0.1239901, Gaussian number=210386, print grad=0.0008190132793970406, Depth Loss=0.0000000]
Training progress:  41%|████      | 820/2000 [09:49<07:48,  2.52it/s, Loss=0.1239901, Gaussian number=210386, print grad=0.0008190132793970406, Depth Loss=0.0000000]
Training progress:  41%|████      | 820/2000 [09:54<07:48,  2.52it/s, Loss=0.0981964, Gaussian number=210386, print grad=0.0013161454116925597, Depth Loss=0.0000000]
Training progress:  42%|████▏     | 830/2000 [09:54<07:46,  2.51it/s, Loss=0.0981964, Gaussian number=210386, print grad=0.0013161454116925597, Depth Loss=0.0000000]
Training progress:  42%|████▏     | 830/2000 [09:57<07:46,  2.51it/s, Loss=0.1081952, Gaussian number=210386, print grad=0.001745477900840342, Depth Loss=0.0000000] 
Training progress:  42%|████▏     | 840/2000 [09:57<07:41,  2.52it/s, Loss=0.1081952, Gaussian number=210386, print grad=0.001745477900840342, Depth Loss=0.0000000]
Training progress:  42%|████▏     | 840/2000 [10:01<07:41,  2.52it/s, Loss=0.1044793, Gaussian number=210386, print grad=0.0021757741924375296, Depth Loss=0.0000000]
Training progress:  42%|████▎     | 850/2000 [10:01<07:36,  2.52it/s, Loss=0.1044793, Gaussian number=210386, print grad=0.0021757741924375296, Depth Loss=0.0000000]
Training progress:  42%|████▎     | 850/2000 [10:05<07:36,  2.52it/s, Loss=0.1088617, Gaussian number=210386, print grad=0.0025691608898341656, Depth Loss=0.0000000]
Training progress:  43%|████▎     | 860/2000 [10:05<07:31,  2.52it/s, Loss=0.1088617, Gaussian number=210386, print grad=0.0025691608898341656, Depth Loss=0.0000000]
Training progress:  43%|████▎     | 860/2000 [10:09<07:31,  2.52it/s, Loss=0.1249507, Gaussian number=210386, print grad=0.002974068047478795, Depth Loss=0.0000000] 
Training progress:  44%|████▎     | 870/2000 [10:09<07:27,  2.53it/s, Loss=0.1249507, Gaussian number=210386, print grad=0.002974068047478795, Depth Loss=0.0000000]
Training progress:  44%|████▎     | 870/2000 [10:13<07:27,  2.53it/s, Loss=0.1148243, Gaussian number=210386, print grad=0.0033928598277270794, Depth Loss=0.0000000]
Training progress:  44%|████▍     | 880/2000 [10:13<07:23,  2.53it/s, Loss=0.1148243, Gaussian number=210386, print grad=0.0033928598277270794, Depth Loss=0.0000000]
Training progress:  44%|████▍     | 880/2000 [10:17<07:23,  2.53it/s, Loss=0.0904551, Gaussian number=210386, print grad=0.0038006457034498453, Depth Loss=0.0000000]
Training progress:  44%|████▍     | 890/2000 [10:17<07:18,  2.53it/s, Loss=0.0904551, Gaussian number=210386, print grad=0.0038006457034498453, Depth Loss=0.0000000]
Training progress:  44%|████▍     | 890/2000 [10:21<07:18,  2.53it/s, Loss=0.1236225, Gaussian number=210386, print grad=0.004221516661345959, Depth Loss=0.0000000] 
Training progress:  45%|████▌     | 900/2000 [10:21<07:14,  2.53it/s, Loss=0.1236225, Gaussian number=210386, print grad=0.004221516661345959, Depth Loss=0.0000000]
Training progress:  45%|████▌     | 900/2000 [10:25<07:14,  2.53it/s, Loss=0.1040284, Gaussian number=223807, print grad=0.0003678906650748104, Depth Loss=0.0000000]
Training progress:  46%|████▌     | 910/2000 [10:25<07:11,  2.53it/s, Loss=0.1040284, Gaussian number=223807, print grad=0.0003678906650748104, Depth Loss=0.0000000]
Training progress:  46%|████▌     | 910/2000 [10:29<07:11,  2.53it/s, Loss=0.1138381, Gaussian number=223807, print grad=0.0007572050089947879, Depth Loss=0.0000000]
Training progress:  46%|████▌     | 920/2000 [10:29<07:07,  2.53it/s, Loss=0.1138381, Gaussian number=223807, print grad=0.0007572050089947879, Depth Loss=0.0000000]
Training progress:  46%|████▌     | 920/2000 [10:33<07:07,  2.53it/s, Loss=0.1213904, Gaussian number=223807, print grad=0.0012249380815774202, Depth Loss=0.0000000]
Training progress:  46%|████▋     | 930/2000 [10:33<07:03,  2.52it/s, Loss=0.1213904, Gaussian number=223807, print grad=0.0012249380815774202, Depth Loss=0.0000000]
Training progress:  46%|████▋     | 930/2000 [10:37<07:03,  2.52it/s, Loss=0.1080222, Gaussian number=223807, print grad=0.0016251923516392708, Depth Loss=0.0000000]
Training progress:  47%|████▋     | 940/2000 [10:37<07:00,  2.52it/s, Loss=0.1080222, Gaussian number=223807, print grad=0.0016251923516392708, Depth Loss=0.0000000]
Training progress:  47%|████▋     | 940/2000 [10:41<07:00,  2.52it/s, Loss=0.1094162, Gaussian number=223807, print grad=0.0020300960168242455, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 950/2000 [10:41<06:56,  2.52it/s, Loss=0.1094162, Gaussian number=223807, print grad=0.0020300960168242455, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 950/2000 [10:45<06:56,  2.52it/s, Loss=0.1079530, Gaussian number=223807, print grad=0.002412848174571991, Depth Loss=0.0000000] 
Training progress:  48%|████▊     | 960/2000 [10:45<06:52,  2.52it/s, Loss=0.1079530, Gaussian number=223807, print grad=0.002412848174571991, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 960/2000 [10:49<06:52,  2.52it/s, Loss=0.1442284, Gaussian number=223807, print grad=0.0028544131200760603, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 970/2000 [10:49<06:48,  2.52it/s, Loss=0.1442284, Gaussian number=223807, print grad=0.0028544131200760603, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 970/2000 [10:53<06:48,  2.52it/s, Loss=0.0850431, Gaussian number=223807, print grad=0.0032588972244411707, Depth Loss=0.0000000]
Training progress:  49%|████▉     | 980/2000 [10:53<06:44,  2.52it/s, Loss=0.0850431, Gaussian number=223807, print grad=0.0032588972244411707, Depth Loss=0.0000000]
Training progress:  49%|████▉     | 980/2000 [10:57<06:44,  2.52it/s, Loss=0.0917287, Gaussian number=223807, print grad=0.0036108444910496473, Depth Loss=0.0000000]
Training progress:  50%|████▉     | 990/2000 [10:57<06:40,  2.52it/s, Loss=0.0917287, Gaussian number=223807, print grad=0.0036108444910496473, Depth Loss=0.0000000]
Training progress:  50%|████▉     | 990/2000 [11:01<06:40,  2.52it/s, Loss=0.1182663, Gaussian number=223807, print grad=0.00394490547478199, Depth Loss=0.0000000]  
Training progress:  50%|█████     | 1000/2000 [11:01<06:36,  2.52it/s, Loss=0.1182663, Gaussian number=223807, print grad=0.00394490547478199, Depth Loss=0.0000000]
Training progress:  50%|█████     | 1000/2000 [12:10<06:36,  2.52it/s, Loss=0.1193327, Gaussian number=237395, print grad=0.00035565291182138026, Depth Loss=0.0000000]
Training progress:  50%|█████     | 1010/2000 [12:10<38:53,  2.36s/it, Loss=0.1193327, Gaussian number=237395, print grad=0.00035565291182138026, Depth Loss=0.0000000]
Training progress:  50%|█████     | 1010/2000 [12:14<38:53,  2.36s/it, Loss=0.1486537, Gaussian number=237395, print grad=0.0008301193593069911, Depth Loss=0.0000000] 
Training progress:  51%|█████     | 1020/2000 [12:14<28:53,  1.77s/it, Loss=0.1486537, Gaussian number=237395, print grad=0.0008301193593069911, Depth Loss=0.0000000]
Training progress:  51%|█████     | 1020/2000 [12:18<28:53,  1.77s/it, Loss=0.1136241, Gaussian number=237395, print grad=0.0012623118236660957, Depth Loss=0.0000000]
Training progress:  52%|█████▏    | 1030/2000 [12:18<21:57,  1.36s/it, Loss=0.1136241, Gaussian number=237395, print grad=0.0012623118236660957, Depth Loss=0.0000000]
Training progress:  52%|█████▏    | 1030/2000 [12:22<21:57,  1.36s/it, Loss=0.1213179, Gaussian number=237395, print grad=0.0017148361075669527, Depth Loss=0.0000000]
Training progress:  52%|█████▏    | 1040/2000 [12:22<17:06,  1.07s/it, Loss=0.1213179, Gaussian number=237395, print grad=0.0017148361075669527, Depth Loss=0.0000000]
Training progress:  52%|█████▏    | 1040/2000 [12:26<17:06,  1.07s/it, Loss=0.1051169, Gaussian number=237395, print grad=0.0020661556627601385, Depth Loss=0.0000000]
Training progress:  52%|█████▎    | 1050/2000 [12:26<13:43,  1.15it/s, Loss=0.1051169, Gaussian number=237395, print grad=0.0020661556627601385, Depth Loss=0.0000000]
Training progress:  52%|█████▎    | 1050/2000 [12:30<13:43,  1.15it/s, Loss=0.0961435, Gaussian number=237395, print grad=0.0024543197359889746, Depth Loss=0.0000000]
Training progress:  53%|█████▎    | 1060/2000 [12:30<11:22,  1.38it/s, Loss=0.0961435, Gaussian number=237395, print grad=0.0024543197359889746, Depth Loss=0.0000000]
Training progress:  53%|█████▎    | 1060/2000 [12:34<11:22,  1.38it/s, Loss=0.0804893, Gaussian number=237395, print grad=0.002870799507945776, Depth Loss=0.0000000] 
Training progress:  54%|█████▎    | 1070/2000 [12:34<09:43,  1.59it/s, Loss=0.0804893, Gaussian number=237395, print grad=0.002870799507945776, Depth Loss=0.0000000]
Training progress:  54%|█████▎    | 1070/2000 [12:38<09:43,  1.59it/s, Loss=0.0865255, Gaussian number=237395, print grad=0.003245588159188628, Depth Loss=0.0000000]
Training progress:  54%|█████▍    | 1080/2000 [12:38<08:33,  1.79it/s, Loss=0.0865255, Gaussian number=237395, print grad=0.003245588159188628, Depth Loss=0.0000000]
Training progress:  54%|█████▍    | 1080/2000 [12:42<08:33,  1.79it/s, Loss=0.1088173, Gaussian number=237395, print grad=0.0036278977058827877, Depth Loss=0.0000000]
Training progress:  55%|█████▍    | 1090/2000 [12:42<07:43,  1.96it/s, Loss=0.1088173, Gaussian number=237395, print grad=0.0036278977058827877, Depth Loss=0.0000000]
Training progress:  55%|█████▍    | 1090/2000 [12:46<07:43,  1.96it/s, Loss=0.1108723, Gaussian number=237395, print grad=0.004000531975179911, Depth Loss=0.0000000] 
Training progress:  55%|█████▌    | 1100/2000 [12:46<07:08,  2.10it/s, Loss=0.1108723, Gaussian number=237395, print grad=0.004000531975179911, Depth Loss=0.0000000]
Training progress:  55%|█████▌    | 1100/2000 [12:50<07:08,  2.10it/s, Loss=0.1264780, Gaussian number=251958, print grad=0.00036434998037293553, Depth Loss=0.0000000]
Training progress:  56%|█████▌    | 1110/2000 [12:50<06:42,  2.21it/s, Loss=0.1264780, Gaussian number=251958, print grad=0.00036434998037293553, Depth Loss=0.0000000]
Training progress:  56%|█████▌    | 1110/2000 [12:54<06:42,  2.21it/s, Loss=0.1165878, Gaussian number=251958, print grad=0.0008048738236539066, Depth Loss=0.0000000] 
Training progress:  56%|█████▌    | 1120/2000 [12:54<06:22,  2.30it/s, Loss=0.1165878, Gaussian number=251958, print grad=0.0008048738236539066, Depth Loss=0.0000000]
Training progress:  56%|█████▌    | 1120/2000 [12:58<06:22,  2.30it/s, Loss=0.0866734, Gaussian number=251958, print grad=0.0012427984038367867, Depth Loss=0.0000000]
Training progress:  56%|█████▋    | 1130/2000 [12:58<06:08,  2.36it/s, Loss=0.0866734, Gaussian number=251958, print grad=0.0012427984038367867, Depth Loss=0.0000000]
Training progress:  56%|█████▋    | 1130/2000 [13:02<06:08,  2.36it/s, Loss=0.1105696, Gaussian number=251958, print grad=0.0016666431911289692, Depth Loss=0.0000000]
Training progress:  57%|█████▋    | 1140/2000 [13:02<05:56,  2.41it/s, Loss=0.1105696, Gaussian number=251958, print grad=0.0016666431911289692, Depth Loss=0.0000000]
Training progress:  57%|█████▋    | 1140/2000 [13:06<05:56,  2.41it/s, Loss=0.0761311, Gaussian number=251958, print grad=0.0020603539887815714, Depth Loss=0.0000000]
Training progress:  57%|█████▊    | 1150/2000 [13:06<05:47,  2.45it/s, Loss=0.0761311, Gaussian number=251958, print grad=0.0020603539887815714, Depth Loss=0.0000000]
Training progress:  57%|█████▊    | 1150/2000 [13:10<05:47,  2.45it/s, Loss=0.0847750, Gaussian number=251958, print grad=0.0024222901556640863, Depth Loss=0.0000000]
Training progress:  58%|█████▊    | 1160/2000 [13:10<05:40,  2.47it/s, Loss=0.0847750, Gaussian number=251958, print grad=0.0024222901556640863, Depth Loss=0.0000000]
Training progress:  58%|█████▊    | 1160/2000 [13:14<05:40,  2.47it/s, Loss=0.1025796, Gaussian number=251958, print grad=0.0028092300053685904, Depth Loss=0.0000000]
Training progress:  58%|█████▊    | 1170/2000 [13:14<05:33,  2.49it/s, Loss=0.1025796, Gaussian number=251958, print grad=0.0028092300053685904, Depth Loss=0.0000000]
Training progress:  58%|█████▊    | 1170/2000 [13:17<05:33,  2.49it/s, Loss=0.1100645, Gaussian number=251958, print grad=0.003182233776897192, Depth Loss=0.0000000] 
Training progress:  59%|█████▉    | 1180/2000 [13:17<05:27,  2.50it/s, Loss=0.1100645, Gaussian number=251958, print grad=0.003182233776897192, Depth Loss=0.0000000]
Training progress:  59%|█████▉    | 1180/2000 [13:21<05:27,  2.50it/s, Loss=0.0994209, Gaussian number=251958, print grad=0.0035858475603163242, Depth Loss=0.0000000]
Training progress:  60%|█████▉    | 1190/2000 [13:21<05:22,  2.51it/s, Loss=0.0994209, Gaussian number=251958, print grad=0.0035858475603163242, Depth Loss=0.0000000]
Training progress:  60%|█████▉    | 1190/2000 [13:25<05:22,  2.51it/s, Loss=0.1169180, Gaussian number=251958, print grad=0.003918937873095274, Depth Loss=0.0000000] 
Training progress:  60%|██████    | 1200/2000 [13:25<05:17,  2.52it/s, Loss=0.1169180, Gaussian number=251958, print grad=0.003918937873095274, Depth Loss=0.0000000]
Training progress:  60%|██████    | 1200/2000 [13:29<05:17,  2.52it/s, Loss=0.0903345, Gaussian number=267327, print grad=0.00037146557588130236, Depth Loss=0.0000000]
Training progress:  60%|██████    | 1210/2000 [13:29<05:12,  2.52it/s, Loss=0.0903345, Gaussian number=267327, print grad=0.00037146557588130236, Depth Loss=0.0000000]
Training progress:  60%|██████    | 1210/2000 [13:33<05:12,  2.52it/s, Loss=0.0783736, Gaussian number=267327, print grad=0.0008083264110609889, Depth Loss=0.0000000] 
Training progress:  61%|██████    | 1220/2000 [13:33<05:08,  2.53it/s, Loss=0.0783736, Gaussian number=267327, print grad=0.0008083264110609889, Depth Loss=0.0000000]
Training progress:  61%|██████    | 1220/2000 [13:37<05:08,  2.53it/s, Loss=0.0809215, Gaussian number=267327, print grad=0.001167183741927147, Depth Loss=0.0000000] 
Training progress:  62%|██████▏   | 1230/2000 [13:37<05:03,  2.54it/s, Loss=0.0809215, Gaussian number=267327, print grad=0.001167183741927147, Depth Loss=0.0000000]
Training progress:  62%|██████▏   | 1230/2000 [13:41<05:03,  2.54it/s, Loss=0.0795175, Gaussian number=267327, print grad=0.0015622887294739485, Depth Loss=0.0000000]
Training progress:  62%|██████▏   | 1240/2000 [13:41<04:58,  2.54it/s, Loss=0.0795175, Gaussian number=267327, print grad=0.0015622887294739485, Depth Loss=0.0000000]
Training progress:  62%|██████▏   | 1240/2000 [13:45<04:58,  2.54it/s, Loss=0.0783591, Gaussian number=267327, print grad=0.0019124660175293684, Depth Loss=0.0000000]
Training progress:  62%|██████▎   | 1250/2000 [13:45<04:54,  2.55it/s, Loss=0.0783591, Gaussian number=267327, print grad=0.0019124660175293684, Depth Loss=0.0000000]
Training progress:  62%|██████▎   | 1250/2000 [13:49<04:54,  2.55it/s, Loss=0.0818715, Gaussian number=267327, print grad=0.0022332454100251198, Depth Loss=0.0000000]
Training progress:  63%|██████▎   | 1260/2000 [13:49<04:50,  2.55it/s, Loss=0.0818715, Gaussian number=267327, print grad=0.0022332454100251198, Depth Loss=0.0000000]
Training progress:  63%|██████▎   | 1260/2000 [13:53<04:50,  2.55it/s, Loss=0.1054886, Gaussian number=267327, print grad=0.0026058154180645943, Depth Loss=0.0000000]
Training progress:  64%|██████▎   | 1270/2000 [13:53<04:46,  2.55it/s, Loss=0.1054886, Gaussian number=267327, print grad=0.0026058154180645943, Depth Loss=0.0000000]
Training progress:  64%|██████▎   | 1270/2000 [13:57<04:46,  2.55it/s, Loss=0.1006165, Gaussian number=267327, print grad=0.0029612891376018524, Depth Loss=0.0000000]
Training progress:  64%|██████▍   | 1280/2000 [13:57<04:42,  2.55it/s, Loss=0.1006165, Gaussian number=267327, print grad=0.0029612891376018524, Depth Loss=0.0000000]
Training progress:  64%|██████▍   | 1280/2000 [14:01<04:42,  2.55it/s, Loss=0.0786857, Gaussian number=267327, print grad=0.0033472892828285694, Depth Loss=0.0000000]
Training progress:  64%|██████▍   | 1290/2000 [14:01<04:38,  2.55it/s, Loss=0.0786857, Gaussian number=267327, print grad=0.0033472892828285694, Depth Loss=0.0000000]
Training progress:  64%|██████▍   | 1290/2000 [14:05<04:38,  2.55it/s, Loss=0.1220281, Gaussian number=267327, print grad=0.0036882320418953896, Depth Loss=0.0000000]
Training progress:  65%|██████▌   | 1300/2000 [14:05<04:34,  2.55it/s, Loss=0.1220281, Gaussian number=267327, print grad=0.0036882320418953896, Depth Loss=0.0000000]
Training progress:  65%|██████▌   | 1300/2000 [14:09<04:34,  2.55it/s, Loss=0.1206315, Gaussian number=282597, print grad=0.0003803728614002466, Depth Loss=0.0000000]
Training progress:  66%|██████▌   | 1310/2000 [14:09<04:31,  2.54it/s, Loss=0.1206315, Gaussian number=282597, print grad=0.0003803728614002466, Depth Loss=0.0000000]
Training progress:  66%|██████▌   | 1310/2000 [14:12<04:31,  2.54it/s, Loss=0.1238550, Gaussian number=282597, print grad=0.0007473817677237093, Depth Loss=0.0000000]
Training progress:  66%|██████▌   | 1320/2000 [14:12<04:27,  2.54it/s, Loss=0.1238550, Gaussian number=282597, print grad=0.0007473817677237093, Depth Loss=0.0000000]
Training progress:  66%|██████▌   | 1320/2000 [14:16<04:27,  2.54it/s, Loss=0.0955128, Gaussian number=282597, print grad=0.0011394714238122106, Depth Loss=0.0000000]
Training progress:  66%|██████▋   | 1330/2000 [14:16<04:24,  2.54it/s, Loss=0.0955128, Gaussian number=282597, print grad=0.0011394714238122106, Depth Loss=0.0000000]
Training progress:  66%|██████▋   | 1330/2000 [14:20<04:24,  2.54it/s, Loss=0.0958899, Gaussian number=282597, print grad=0.0015327321598306298, Depth Loss=0.0000000]
Training progress:  67%|██████▋   | 1340/2000 [14:20<04:20,  2.54it/s, Loss=0.0958899, Gaussian number=282597, print grad=0.0015327321598306298, Depth Loss=0.0000000]
Training progress:  67%|██████▋   | 1340/2000 [14:24<04:20,  2.54it/s, Loss=0.1301576, Gaussian number=282597, print grad=0.00187014346010983, Depth Loss=0.0000000]  
Training progress:  68%|██████▊   | 1350/2000 [14:24<04:15,  2.54it/s, Loss=0.1301576, Gaussian number=282597, print grad=0.00187014346010983, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1350/2000 [14:28<04:15,  2.54it/s, Loss=0.0799419, Gaussian number=282597, print grad=0.002203147392719984, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1360/2000 [14:28<04:12,  2.54it/s, Loss=0.0799419, Gaussian number=282597, print grad=0.002203147392719984, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1360/2000 [14:32<04:12,  2.54it/s, Loss=0.1512576, Gaussian number=282597, print grad=0.0025681830011308193, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1370/2000 [14:32<04:08,  2.54it/s, Loss=0.1512576, Gaussian number=282597, print grad=0.0025681830011308193, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1370/2000 [14:36<04:08,  2.54it/s, Loss=0.0923768, Gaussian number=282597, print grad=0.0028983866795897484, Depth Loss=0.0000000]
Training progress:  69%|██████▉   | 1380/2000 [14:36<04:04,  2.54it/s, Loss=0.0923768, Gaussian number=282597, print grad=0.0028983866795897484, Depth Loss=0.0000000]
Training progress:  69%|██████▉   | 1380/2000 [14:40<04:04,  2.54it/s, Loss=0.0804210, Gaussian number=282597, print grad=0.0032263281755149364, Depth Loss=0.0000000]
Training progress:  70%|██████▉   | 1390/2000 [14:40<04:00,  2.54it/s, Loss=0.0804210, Gaussian number=282597, print grad=0.0032263281755149364, Depth Loss=0.0000000]
Training progress:  70%|██████▉   | 1390/2000 [14:44<04:00,  2.54it/s, Loss=0.0927828, Gaussian number=282597, print grad=0.0035744747146964073, Depth Loss=0.0000000]
Training progress:  70%|███████   | 1400/2000 [14:44<03:56,  2.53it/s, Loss=0.0927828, Gaussian number=282597, print grad=0.0035744747146964073, Depth Loss=0.0000000]
Training progress:  70%|███████   | 1400/2000 [14:48<03:56,  2.53it/s, Loss=0.1129884, Gaussian number=297935, print grad=0.0003650770231615752, Depth Loss=0.0000000]
Training progress:  70%|███████   | 1410/2000 [14:48<03:53,  2.53it/s, Loss=0.1129884, Gaussian number=297935, print grad=0.0003650770231615752, Depth Loss=0.0000000]
Training progress:  70%|███████   | 1410/2000 [14:52<03:53,  2.53it/s, Loss=0.0944319, Gaussian number=297935, print grad=0.0007688254117965698, Depth Loss=0.0000000]
Training progress:  71%|███████   | 1420/2000 [14:52<03:50,  2.52it/s, Loss=0.0944319, Gaussian number=297935, print grad=0.0007688254117965698, Depth Loss=0.0000000]
Training progress:  71%|███████   | 1420/2000 [14:56<03:50,  2.52it/s, Loss=0.1011437, Gaussian number=297935, print grad=0.0011687963269650936, Depth Loss=0.0000000]
Training progress:  72%|███████▏  | 1430/2000 [14:56<03:46,  2.52it/s, Loss=0.1011437, Gaussian number=297935, print grad=0.0011687963269650936, Depth Loss=0.0000000]
Training progress:  72%|███████▏  | 1430/2000 [15:00<03:46,  2.52it/s, Loss=0.0878119, Gaussian number=297935, print grad=0.0015070156659930944, Depth Loss=0.0000000]
Training progress:  72%|███████▏  | 1440/2000 [15:00<03:42,  2.52it/s, Loss=0.0878119, Gaussian number=297935, print grad=0.0015070156659930944, Depth Loss=0.0000000]
Training progress:  72%|███████▏  | 1440/2000 [15:04<03:42,  2.52it/s, Loss=0.0817030, Gaussian number=297935, print grad=0.0018348876619711518, Depth Loss=0.0000000]
Training progress:  72%|███████▎  | 1450/2000 [15:04<03:38,  2.52it/s, Loss=0.0817030, Gaussian number=297935, print grad=0.0018348876619711518, Depth Loss=0.0000000]
Training progress:  72%|███████▎  | 1450/2000 [15:08<03:38,  2.52it/s, Loss=0.0720250, Gaussian number=297935, print grad=0.0021696118637919426, Depth Loss=0.0000000]
Training progress:  73%|███████▎  | 1460/2000 [15:08<03:34,  2.52it/s, Loss=0.0720250, Gaussian number=297935, print grad=0.0021696118637919426, Depth Loss=0.0000000]
Training progress:  73%|███████▎  | 1460/2000 [15:12<03:34,  2.52it/s, Loss=0.0970021, Gaussian number=297935, print grad=0.0025112454313784838, Depth Loss=0.0000000]
Training progress:  74%|███████▎  | 1470/2000 [15:12<03:31,  2.50it/s, Loss=0.0970021, Gaussian number=297935, print grad=0.0025112454313784838, Depth Loss=0.0000000]
Training progress:  74%|███████▎  | 1470/2000 [15:16<03:31,  2.50it/s, Loss=0.1007656, Gaussian number=297935, print grad=0.0028795721009373665, Depth Loss=0.0000000]
Training progress:  74%|███████▍  | 1480/2000 [15:16<03:27,  2.51it/s, Loss=0.1007656, Gaussian number=297935, print grad=0.0028795721009373665, Depth Loss=0.0000000]
Training progress:  74%|███████▍  | 1480/2000 [15:20<03:27,  2.51it/s, Loss=0.1025066, Gaussian number=297935, print grad=0.003249930217862129, Depth Loss=0.0000000] 
Training progress:  74%|███████▍  | 1490/2000 [15:20<03:23,  2.51it/s, Loss=0.1025066, Gaussian number=297935, print grad=0.003249930217862129, Depth Loss=0.0000000]
Training progress:  74%|███████▍  | 1490/2000 [15:24<03:23,  2.51it/s, Loss=0.0989560, Gaussian number=297935, print grad=0.003606741316616535, Depth Loss=0.0000000]
Training progress:  75%|███████▌  | 1500/2000 [15:24<03:19,  2.51it/s, Loss=0.0989560, Gaussian number=297935, print grad=0.003606741316616535, Depth Loss=0.0000000]
Training progress:  75%|███████▌  | 1500/2000 [16:33<03:19,  2.51it/s, Loss=0.1084719, Gaussian number=312921, print grad=0.00032419554190710187, Depth Loss=0.0000000]
Training progress:  76%|███████▌  | 1510/2000 [16:33<19:18,  2.37s/it, Loss=0.1084719, Gaussian number=312921, print grad=0.00032419554190710187, Depth Loss=0.0000000]
Training progress:  76%|███████▌  | 1510/2000 [16:37<19:18,  2.37s/it, Loss=0.1061775, Gaussian number=312921, print grad=0.0006685883272439241, Depth Loss=0.0000000] 
Training progress:  76%|███████▌  | 1520/2000 [16:37<14:12,  1.78s/it, Loss=0.1061775, Gaussian number=312921, print grad=0.0006685883272439241, Depth Loss=0.0000000]
Training progress:  76%|███████▌  | 1520/2000 [16:41<14:12,  1.78s/it, Loss=0.0568800, Gaussian number=312921, print grad=0.0010446353117004037, Depth Loss=0.0000000]
Training progress:  76%|███████▋  | 1530/2000 [16:41<10:40,  1.36s/it, Loss=0.0568800, Gaussian number=312921, print grad=0.0010446353117004037, Depth Loss=0.0000000]
Training progress:  76%|███████▋  | 1530/2000 [16:45<10:40,  1.36s/it, Loss=0.0809774, Gaussian number=312921, print grad=0.0013871794799342752, Depth Loss=0.0000000]
Training progress:  77%|███████▋  | 1540/2000 [16:45<08:13,  1.07s/it, Loss=0.0809774, Gaussian number=312921, print grad=0.0013871794799342752, Depth Loss=0.0000000]
Training progress:  77%|███████▋  | 1540/2000 [16:49<08:13,  1.07s/it, Loss=0.0943011, Gaussian number=312921, print grad=0.0017666966887190938, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1550/2000 [16:49<06:31,  1.15it/s, Loss=0.0943011, Gaussian number=312921, print grad=0.0017666966887190938, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1550/2000 [16:53<06:31,  1.15it/s, Loss=0.0954265, Gaussian number=312921, print grad=0.002142497571185231, Depth Loss=0.0000000] 
Training progress:  78%|███████▊  | 1560/2000 [16:53<05:20,  1.37it/s, Loss=0.0954265, Gaussian number=312921, print grad=0.002142497571185231, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1560/2000 [16:57<05:20,  1.37it/s, Loss=0.0822390, Gaussian number=312921, print grad=0.002485924167558551, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1570/2000 [16:57<04:30,  1.59it/s, Loss=0.0822390, Gaussian number=312921, print grad=0.002485924167558551, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1570/2000 [17:01<04:30,  1.59it/s, Loss=0.0601214, Gaussian number=312921, print grad=0.0027623320929706097, Depth Loss=0.0000000]
Training progress:  79%|███████▉  | 1580/2000 [17:01<03:55,  1.79it/s, Loss=0.0601214, Gaussian number=312921, print grad=0.0027623320929706097, Depth Loss=0.0000000]
Training progress:  79%|███████▉  | 1580/2000 [17:05<03:55,  1.79it/s, Loss=0.0813316, Gaussian number=312921, print grad=0.003084733383730054, Depth Loss=0.0000000] 
Training progress:  80%|███████▉  | 1590/2000 [17:05<03:29,  1.96it/s, Loss=0.0813316, Gaussian number=312921, print grad=0.003084733383730054, Depth Loss=0.0000000]
Training progress:  80%|███████▉  | 1590/2000 [17:09<03:29,  1.96it/s, Loss=0.0800187, Gaussian number=312921, print grad=0.0034349013585597277, Depth Loss=0.0000000]
Training progress:  80%|████████  | 1600/2000 [17:09<03:10,  2.10it/s, Loss=0.0800187, Gaussian number=312921, print grad=0.0034349013585597277, Depth Loss=0.0000000]
Training progress:  80%|████████  | 1600/2000 [17:13<03:10,  2.10it/s, Loss=0.0964758, Gaussian number=327576, print grad=0.0003511234826873988, Depth Loss=0.0000000]
Training progress:  80%|████████  | 1610/2000 [17:13<02:56,  2.21it/s, Loss=0.0964758, Gaussian number=327576, print grad=0.0003511234826873988, Depth Loss=0.0000000]
Training progress:  80%|████████  | 1610/2000 [17:17<02:56,  2.21it/s, Loss=0.0955522, Gaussian number=327576, print grad=0.0007463006768375635, Depth Loss=0.0000000]
Training progress:  81%|████████  | 1620/2000 [17:17<02:45,  2.29it/s, Loss=0.0955522, Gaussian number=327576, print grad=0.0007463006768375635, Depth Loss=0.0000000]
Training progress:  81%|████████  | 1620/2000 [17:21<02:45,  2.29it/s, Loss=0.0790802, Gaussian number=327576, print grad=0.0010814169654622674, Depth Loss=0.0000000]
Training progress:  82%|████████▏ | 1630/2000 [17:21<02:37,  2.35it/s, Loss=0.0790802, Gaussian number=327576, print grad=0.0010814169654622674, Depth Loss=0.0000000]
Training progress:  82%|████████▏ | 1630/2000 [17:25<02:37,  2.35it/s, Loss=0.0610987, Gaussian number=327576, print grad=0.0014129336923360825, Depth Loss=0.0000000]
Training progress:  82%|████████▏ | 1640/2000 [17:25<02:30,  2.40it/s, Loss=0.0610987, Gaussian number=327576, print grad=0.0014129336923360825, Depth Loss=0.0000000]
Training progress:  82%|████████▏ | 1640/2000 [17:29<02:30,  2.40it/s, Loss=0.0818613, Gaussian number=327576, print grad=0.0017227998469024897, Depth Loss=0.0000000]
Training progress:  82%|████████▎ | 1650/2000 [17:29<02:23,  2.43it/s, Loss=0.0818613, Gaussian number=327576, print grad=0.0017227998469024897, Depth Loss=0.0000000]
Training progress:  82%|████████▎ | 1650/2000 [17:33<02:23,  2.43it/s, Loss=0.0799539, Gaussian number=327576, print grad=0.0020422996021807194, Depth Loss=0.0000000]
Training progress:  83%|████████▎ | 1660/2000 [17:33<02:18,  2.46it/s, Loss=0.0799539, Gaussian number=327576, print grad=0.0020422996021807194, Depth Loss=0.0000000]
Training progress:  83%|████████▎ | 1660/2000 [17:37<02:18,  2.46it/s, Loss=0.0735115, Gaussian number=327576, print grad=0.0023594924714416265, Depth Loss=0.0000000]
Training progress:  84%|████████▎ | 1670/2000 [17:37<02:13,  2.48it/s, Loss=0.0735115, Gaussian number=327576, print grad=0.0023594924714416265, Depth Loss=0.0000000]
Training progress:  84%|████████▎ | 1670/2000 [17:41<02:13,  2.48it/s, Loss=0.0692048, Gaussian number=327576, print grad=0.002695318777114153, Depth Loss=0.0000000] 
Training progress:  84%|████████▍ | 1680/2000 [17:41<02:08,  2.49it/s, Loss=0.0692048, Gaussian number=327576, print grad=0.002695318777114153, Depth Loss=0.0000000]
Training progress:  84%|████████▍ | 1680/2000 [17:45<02:08,  2.49it/s, Loss=0.0803286, Gaussian number=327576, print grad=0.003017129609361291, Depth Loss=0.0000000]
Training progress:  84%|████████▍ | 1690/2000 [17:45<02:04,  2.50it/s, Loss=0.0803286, Gaussian number=327576, print grad=0.003017129609361291, Depth Loss=0.0000000]
Training progress:  84%|████████▍ | 1690/2000 [17:49<02:04,  2.50it/s, Loss=0.0875972, Gaussian number=327576, print grad=0.003312240121886134, Depth Loss=0.0000000]
Training progress:  85%|████████▌ | 1700/2000 [17:49<01:59,  2.51it/s, Loss=0.0875972, Gaussian number=327576, print grad=0.003312240121886134, Depth Loss=0.0000000]
Training progress:  85%|████████▌ | 1700/2000 [17:53<01:59,  2.51it/s, Loss=0.0913924, Gaussian number=341749, print grad=0.00034220004454255104, Depth Loss=0.0000000]
Training progress:  86%|████████▌ | 1710/2000 [17:53<01:55,  2.51it/s, Loss=0.0913924, Gaussian number=341749, print grad=0.00034220004454255104, Depth Loss=0.0000000]
Training progress:  86%|████████▌ | 1710/2000 [17:57<01:55,  2.51it/s, Loss=0.1033271, Gaussian number=341749, print grad=0.0006471310625784099, Depth Loss=0.0000000] 
Training progress:  86%|████████▌ | 1720/2000 [17:57<01:50,  2.52it/s, Loss=0.1033271, Gaussian number=341749, print grad=0.0006471310625784099, Depth Loss=0.0000000]
Training progress:  86%|████████▌ | 1720/2000 [18:01<01:50,  2.52it/s, Loss=0.0868466, Gaussian number=341749, print grad=0.0009724927949719131, Depth Loss=0.0000000]
Training progress:  86%|████████▋ | 1730/2000 [18:01<01:46,  2.53it/s, Loss=0.0868466, Gaussian number=341749, print grad=0.0009724927949719131, Depth Loss=0.0000000]
Training progress:  86%|████████▋ | 1730/2000 [18:05<01:46,  2.53it/s, Loss=0.1192964, Gaussian number=341749, print grad=0.0013341187732294202, Depth Loss=0.0000000]
Training progress:  87%|████████▋ | 1740/2000 [18:05<01:42,  2.53it/s, Loss=0.1192964, Gaussian number=341749, print grad=0.0013341187732294202, Depth Loss=0.0000000]
Training progress:  87%|████████▋ | 1740/2000 [18:09<01:42,  2.53it/s, Loss=0.1107552, Gaussian number=341749, print grad=0.0016836309805512428, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1750/2000 [18:09<01:38,  2.53it/s, Loss=0.1107552, Gaussian number=341749, print grad=0.0016836309805512428, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1750/2000 [18:13<01:38,  2.53it/s, Loss=0.0862934, Gaussian number=341749, print grad=0.0019891306292265654, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1760/2000 [18:13<01:34,  2.53it/s, Loss=0.0862934, Gaussian number=341749, print grad=0.0019891306292265654, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1760/2000 [18:17<01:34,  2.53it/s, Loss=0.0696377, Gaussian number=341749, print grad=0.0022873100824654102, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1770/2000 [18:17<01:30,  2.53it/s, Loss=0.0696377, Gaussian number=341749, print grad=0.0022873100824654102, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1770/2000 [18:21<01:30,  2.53it/s, Loss=0.0831973, Gaussian number=341749, print grad=0.0025851137470453978, Depth Loss=0.0000000]
Training progress:  89%|████████▉ | 1780/2000 [18:21<01:26,  2.53it/s, Loss=0.0831973, Gaussian number=341749, print grad=0.0025851137470453978, Depth Loss=0.0000000]
Training progress:  89%|████████▉ | 1780/2000 [18:24<01:26,  2.53it/s, Loss=0.0785164, Gaussian number=341749, print grad=0.0028339361306279898, Depth Loss=0.0000000]
Training progress:  90%|████████▉ | 1790/2000 [18:24<01:22,  2.53it/s, Loss=0.0785164, Gaussian number=341749, print grad=0.0028339361306279898, Depth Loss=0.0000000]
Training progress:  90%|████████▉ | 1790/2000 [18:28<01:22,  2.53it/s, Loss=0.0743148, Gaussian number=341749, print grad=0.003160776337608695, Depth Loss=0.0000000] 
Training progress:  90%|█████████ | 1800/2000 [18:28<01:18,  2.54it/s, Loss=0.0743148, Gaussian number=341749, print grad=0.003160776337608695, Depth Loss=0.0000000]
Training progress:  90%|█████████ | 1800/2000 [18:32<01:18,  2.54it/s, Loss=0.0909396, Gaussian number=356021, print grad=0.0003420912835281342, Depth Loss=0.0000000]
Training progress:  90%|█████████ | 1810/2000 [18:32<01:15,  2.53it/s, Loss=0.0909396, Gaussian number=356021, print grad=0.0003420912835281342, Depth Loss=0.0000000]
Training progress:  90%|█████████ | 1810/2000 [18:36<01:15,  2.53it/s, Loss=0.0752190, Gaussian number=356021, print grad=0.000694328045938164, Depth Loss=0.0000000] 
Training progress:  91%|█████████ | 1820/2000 [18:36<01:11,  2.52it/s, Loss=0.0752190, Gaussian number=356021, print grad=0.000694328045938164, Depth Loss=0.0000000]
Training progress:  91%|█████████ | 1820/2000 [18:40<01:11,  2.52it/s, Loss=0.0711312, Gaussian number=356021, print grad=0.0009791733464226127, Depth Loss=0.0000000]
Training progress:  92%|█████████▏| 1830/2000 [18:40<01:07,  2.52it/s, Loss=0.0711312, Gaussian number=356021, print grad=0.0009791733464226127, Depth Loss=0.0000000]
Training progress:  92%|█████████▏| 1830/2000 [18:44<01:07,  2.52it/s, Loss=0.0683628, Gaussian number=356021, print grad=0.0013004865031689405, Depth Loss=0.0000000]
Training progress:  92%|█████████▏| 1840/2000 [18:44<01:03,  2.51it/s, Loss=0.0683628, Gaussian number=356021, print grad=0.0013004865031689405, Depth Loss=0.0000000]
Training progress:  92%|█████████▏| 1840/2000 [18:48<01:03,  2.51it/s, Loss=0.0756545, Gaussian number=356021, print grad=0.001607417594641447, Depth Loss=0.0000000] 
Training progress:  92%|█████████▎| 1850/2000 [18:48<00:59,  2.51it/s, Loss=0.0756545, Gaussian number=356021, print grad=0.001607417594641447, Depth Loss=0.0000000]
Training progress:  92%|█████████▎| 1850/2000 [18:52<00:59,  2.51it/s, Loss=0.0832164, Gaussian number=356021, print grad=0.0018685613758862019, Depth Loss=0.0000000]
Training progress:  93%|█████████▎| 1860/2000 [18:52<00:55,  2.51it/s, Loss=0.0832164, Gaussian number=356021, print grad=0.0018685613758862019, Depth Loss=0.0000000]
Training progress:  93%|█████████▎| 1860/2000 [18:56<00:55,  2.51it/s, Loss=0.0905516, Gaussian number=356021, print grad=0.002210914855822921, Depth Loss=0.0000000] 
Training progress:  94%|█████████▎| 1870/2000 [18:56<00:51,  2.51it/s, Loss=0.0905516, Gaussian number=356021, print grad=0.002210914855822921, Depth Loss=0.0000000]
Training progress:  94%|█████████▎| 1870/2000 [19:00<00:51,  2.51it/s, Loss=0.0661040, Gaussian number=356021, print grad=0.002508315723389387, Depth Loss=0.0000000]
Training progress:  94%|█████████▍| 1880/2000 [19:00<00:47,  2.51it/s, Loss=0.0661040, Gaussian number=356021, print grad=0.002508315723389387, Depth Loss=0.0000000]
Training progress:  94%|█████████▍| 1880/2000 [19:04<00:47,  2.51it/s, Loss=0.0782540, Gaussian number=356021, print grad=0.0027996429707854986, Depth Loss=0.0000000]
Training progress:  94%|█████████▍| 1890/2000 [19:04<00:43,  2.51it/s, Loss=0.0782540, Gaussian number=356021, print grad=0.0027996429707854986, Depth Loss=0.0000000]
Training progress:  94%|█████████▍| 1890/2000 [19:08<00:43,  2.51it/s, Loss=0.1011013, Gaussian number=356021, print grad=0.003118254477158189, Depth Loss=0.0000000] 
Training progress:  95%|█████████▌| 1900/2000 [19:08<00:39,  2.51it/s, Loss=0.1011013, Gaussian number=356021, print grad=0.003118254477158189, Depth Loss=0.0000000]
Training progress:  95%|█████████▌| 1900/2000 [19:12<00:39,  2.51it/s, Loss=0.0869788, Gaussian number=371351, print grad=0.00028306522290222347, Depth Loss=0.0000000]
Training progress:  96%|█████████▌| 1910/2000 [19:12<00:35,  2.51it/s, Loss=0.0869788, Gaussian number=371351, print grad=0.00028306522290222347, Depth Loss=0.0000000]
Training progress:  96%|█████████▌| 1910/2000 [19:16<00:35,  2.51it/s, Loss=0.0749903, Gaussian number=371351, print grad=0.0005942705320194364, Depth Loss=0.0000000] 
Training progress:  96%|█████████▌| 1920/2000 [19:16<00:31,  2.50it/s, Loss=0.0749903, Gaussian number=371351, print grad=0.0005942705320194364, Depth Loss=0.0000000]
Training progress:  96%|█████████▌| 1920/2000 [19:20<00:31,  2.50it/s, Loss=0.0631539, Gaussian number=371351, print grad=0.0009212385048158467, Depth Loss=0.0000000]
Training progress:  96%|█████████▋| 1930/2000 [19:20<00:27,  2.50it/s, Loss=0.0631539, Gaussian number=371351, print grad=0.0009212385048158467, Depth Loss=0.0000000]
Training progress:  96%|█████████▋| 1930/2000 [19:24<00:27,  2.50it/s, Loss=0.0894294, Gaussian number=371351, print grad=0.0012165228836238384, Depth Loss=0.0000000]
Training progress:  97%|█████████▋| 1940/2000 [19:24<00:24,  2.50it/s, Loss=0.0894294, Gaussian number=371351, print grad=0.0012165228836238384, Depth Loss=0.0000000]
Training progress:  97%|█████████▋| 1940/2000 [19:28<00:24,  2.50it/s, Loss=0.0675464, Gaussian number=371351, print grad=0.001512794871814549, Depth Loss=0.0000000] 
Training progress:  98%|█████████▊| 1950/2000 [19:28<00:20,  2.50it/s, Loss=0.0675464, Gaussian number=371351, print grad=0.001512794871814549, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1950/2000 [19:32<00:20,  2.50it/s, Loss=0.1091886, Gaussian number=371351, print grad=0.0017854159232228994, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1960/2000 [19:32<00:16,  2.49it/s, Loss=0.1091886, Gaussian number=371351, print grad=0.0017854159232228994, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1960/2000 [19:36<00:16,  2.49it/s, Loss=0.0947109, Gaussian number=371351, print grad=0.0020824021194130182, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1970/2000 [19:36<00:12,  2.49it/s, Loss=0.0947109, Gaussian number=371351, print grad=0.0020824021194130182, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1970/2000 [19:40<00:12,  2.49it/s, Loss=0.0743208, Gaussian number=371351, print grad=0.002383846091106534, Depth Loss=0.0000000] 
Training progress:  99%|█████████▉| 1980/2000 [19:40<00:08,  2.49it/s, Loss=0.0743208, Gaussian number=371351, print grad=0.002383846091106534, Depth Loss=0.0000000]
Training progress:  99%|█████████▉| 1980/2000 [19:44<00:08,  2.49it/s, Loss=0.0723365, Gaussian number=371351, print grad=0.002718139672651887, Depth Loss=0.0000000]
Training progress: 100%|█████████▉| 1990/2000 [19:44<00:04,  2.49it/s, Loss=0.0723365, Gaussian number=371351, print grad=0.002718139672651887, Depth Loss=0.0000000]
Training progress: 100%|█████████▉| 1990/2000 [19:48<00:04,  2.49it/s, Loss=0.0561458, Gaussian number=371351, print grad=0.003032430773600936, Depth Loss=0.0000000]
Training progress: 100%|██████████| 2000/2000 [19:48<00:00,  2.49it/s, Loss=0.0561458, Gaussian number=371351, print grad=0.003032430773600936, Depth Loss=0.0000000]
Training progress: 100%|██████████| 2000/2000 [19:48<00:00,  1.68it/s, Loss=0.0561458, Gaussian number=371351, print grad=0.003032430773600936, Depth Loss=0.0000000]
Iteration 100 [03/12 18:23:34]

[ITER 100] Evaluating test: WD 0.199819, PSNR 12.9250,lpips 0.590498,ssim 0.452805 [03/12 18:24:33]

[ITER 100] Evaluating train: WD 0.208962, PSNR 13.2845,lpips 0.592214,ssim 0.470562 [03/12 18:24:40]
Gaussian number:182686,print gradients:2.8554095479194075e-05 [03/12 18:24:40]
Iteration 200 [03/12 18:25:20]

[ITER 200] Evaluating test: WD 0.177326, PSNR 14.2858,lpips 0.540603,ssim 0.488419 [03/12 18:26:18]

[ITER 200] Evaluating train: WD 0.179981, PSNR 14.4402,lpips 0.532918,ssim 0.502190 [03/12 18:26:26]
Gaussian number:182686,print gradients:3.617589027271606e-05 [03/12 18:26:26]
Iteration 300 [03/12 18:27:05]

[ITER 300] Evaluating test: WD 0.162829, PSNR 14.9959,lpips 0.508300,ssim 0.508798 [03/12 18:28:03]

[ITER 300] Evaluating train: WD 0.164757, PSNR 15.2398,lpips 0.497115,ssim 0.521994 [03/12 18:28:11]
Gaussian number:182686,print gradients:4.07434199587442e-05 [03/12 18:28:11]
Iteration 400 [03/12 18:28:50]
Iteration 500 [03/12 18:29:30]

[ITER 500] Evaluating test: WD 0.148803, PSNR 15.8534,lpips 0.474509,ssim 0.531245 [03/12 18:30:28]

[ITER 500] Evaluating train: WD 0.161484, PSNR 15.8322,lpips 0.474788,ssim 0.536054 [03/12 18:30:36]
Gaussian number:182686,print gradients:4.651641575037502e-05 [03/12 18:30:36]
Iteration 600 [03/12 18:31:15]
Iteration 700 [03/12 18:31:54]
Iteration 800 [03/12 18:32:34]
Iteration 900 [03/12 18:33:14]
Iteration 1000 [03/12 18:33:53]

[ITER 1000] Evaluating test: WD 0.130107, PSNR 16.7933,lpips 0.421172,ssim 0.554590 [03/12 18:34:51]

[ITER 1000] Evaluating train: WD 0.141860, PSNR 16.7795,lpips 0.424124,ssim 0.557343 [03/12 18:34:59]
Gaussian number:223807,print gradients:6.31250804872252e-05 [03/12 18:34:59]
Iteration 1100 [03/12 18:35:38]
Iteration 1200 [03/12 18:36:18]
Iteration 1300 [03/12 18:36:57]
Iteration 1400 [03/12 18:37:37]
Iteration 1500 [03/12 18:38:16]

[ITER 1500] Evaluating test: WD 0.117201, PSNR 17.2549,lpips 0.382926,ssim 0.565856 [03/12 18:39:15]

[ITER 1500] Evaluating train: WD 0.127712, PSNR 17.3539,lpips 0.387108,ssim 0.568615 [03/12 18:39:22]
Gaussian number:297935,print gradients:5.9321340813767165e-05 [03/12 18:39:22]
Iteration 1600 [03/12 18:40:02]
Iteration 1700 [03/12 18:40:41]
Iteration 1800 [03/12 18:41:21]
Iteration 1900 [03/12 18:42:01]
Iteration 2000 [03/12 18:42:41]

[ITER 2000] Evaluating test: WD 0.108371, PSNR 17.6401,lpips 0.358641,ssim 0.575727 [03/12 18:43:39]

[ITER 2000] Evaluating train: WD 0.123373, PSNR 18.0208,lpips 0.367603,ssim 0.577096 [03/12 18:43:47]
Gaussian number:371351,print gradients:nan [03/12 18:43:47]

[ITER 2000] Saving Gaussians [03/12 18:43:47]

Training complete. [03/12 18:43:50]
