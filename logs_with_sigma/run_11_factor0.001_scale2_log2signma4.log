Optimizing /home/cw4287/gaussian-model/train_30k
Output folder: /home/cw4287/gaussian-model/train_30k [03/12 20:06:10]
Tensorboard not available: not logging progress [03/12 20:06:10]
------------LLFF HOLD------------- [03/12 20:06:11]

Reading camera 1/301
Reading camera 2/301
Reading camera 3/301
Reading camera 4/301
Reading camera 5/301
Reading camera 6/301
Reading camera 7/301
Reading camera 8/301
Reading camera 9/301
Reading camera 10/301
Reading camera 11/301
Reading camera 12/301
Reading camera 13/301
Reading camera 14/301
Reading camera 15/301
Reading camera 16/301
Reading camera 17/301
Reading camera 18/301
Reading camera 19/301
Reading camera 20/301
Reading camera 21/301
Reading camera 22/301
Reading camera 23/301
Reading camera 24/301
Reading camera 25/301
Reading camera 26/301
Reading camera 27/301
Reading camera 28/301
Reading camera 29/301
Reading camera 30/301
Reading camera 31/301
Reading camera 32/301
Reading camera 33/301
Reading camera 34/301
Reading camera 35/301
Reading camera 36/301
Reading camera 37/301
Reading camera 38/301
Reading camera 39/301
Reading camera 40/301
Reading camera 41/301
Reading camera 42/301
Reading camera 43/301
Reading camera 44/301
Reading camera 45/301
Reading camera 46/301
Reading camera 47/301
Reading camera 48/301
Reading camera 49/301
Reading camera 50/301
Reading camera 51/301
Reading camera 52/301
Reading camera 53/301
Reading camera 54/301
Reading camera 55/301
Reading camera 56/301
Reading camera 57/301
Reading camera 58/301
Reading camera 59/301
Reading camera 60/301
Reading camera 61/301
Reading camera 62/301
Reading camera 63/301
Reading camera 64/301
Reading camera 65/301
Reading camera 66/301
Reading camera 67/301
Reading camera 68/301
Reading camera 69/301
Reading camera 70/301
Reading camera 71/301
Reading camera 72/301
Reading camera 73/301
Reading camera 74/301
Reading camera 75/301
Reading camera 76/301
Reading camera 77/301
Reading camera 78/301
Reading camera 79/301
Reading camera 80/301
Reading camera 81/301
Reading camera 82/301
Reading camera 83/301
Reading camera 84/301
Reading camera 85/301
Reading camera 86/301
Reading camera 87/301
Reading camera 88/301
Reading camera 89/301
Reading camera 90/301
Reading camera 91/301
Reading camera 92/301
Reading camera 93/301
Reading camera 94/301
Reading camera 95/301
Reading camera 96/301
Reading camera 97/301
Reading camera 98/301
Reading camera 99/301
Reading camera 100/301
Reading camera 101/301
Reading camera 102/301
Reading camera 103/301
Reading camera 104/301
Reading camera 105/301
Reading camera 106/301
Reading camera 107/301
Reading camera 108/301
Reading camera 109/301
Reading camera 110/301
Reading camera 111/301
Reading camera 112/301
Reading camera 113/301
Reading camera 114/301
Reading camera 115/301
Reading camera 116/301
Reading camera 117/301
Reading camera 118/301
Reading camera 119/301
Reading camera 120/301
Reading camera 121/301
Reading camera 122/301
Reading camera 123/301
Reading camera 124/301
Reading camera 125/301
Reading camera 126/301
Reading camera 127/301
Reading camera 128/301
Reading camera 129/301
Reading camera 130/301
Reading camera 131/301
Reading camera 132/301
Reading camera 133/301
Reading camera 134/301
Reading camera 135/301
Reading camera 136/301
Reading camera 137/301
Reading camera 138/301
Reading camera 139/301
Reading camera 140/301
Reading camera 141/301
Reading camera 142/301
Reading camera 143/301
Reading camera 144/301
Reading camera 145/301
Reading camera 146/301
Reading camera 147/301
Reading camera 148/301
Reading camera 149/301
Reading camera 150/301
Reading camera 151/301
Reading camera 152/301
Reading camera 153/301
Reading camera 154/301
Reading camera 155/301
Reading camera 156/301
Reading camera 157/301
Reading camera 158/301
Reading camera 159/301
Reading camera 160/301
Reading camera 161/301
Reading camera 162/301
Reading camera 163/301
Reading camera 164/301
Reading camera 165/301
Reading camera 166/301
Reading camera 167/301
Reading camera 168/301
Reading camera 169/301
Reading camera 170/301
Reading camera 171/301
Reading camera 172/301
Reading camera 173/301
Reading camera 174/301
Reading camera 175/301
Reading camera 176/301
Reading camera 177/301
Reading camera 178/301
Reading camera 179/301
Reading camera 180/301
Reading camera 181/301
Reading camera 182/301
Reading camera 183/301
Reading camera 184/301
Reading camera 185/301
Reading camera 186/301
Reading camera 187/301
Reading camera 188/301
Reading camera 189/301
Reading camera 190/301
Reading camera 191/301
Reading camera 192/301
Reading camera 193/301
Reading camera 194/301
Reading camera 195/301
Reading camera 196/301
Reading camera 197/301
Reading camera 198/301
Reading camera 199/301
Reading camera 200/301
Reading camera 201/301
Reading camera 202/301
Reading camera 203/301
Reading camera 204/301
Reading camera 205/301
Reading camera 206/301
Reading camera 207/301
Reading camera 208/301
Reading camera 209/301
Reading camera 210/301
Reading camera 211/301
Reading camera 212/301
Reading camera 213/301
Reading camera 214/301
Reading camera 215/301
Reading camera 216/301
Reading camera 217/301
Reading camera 218/301
Reading camera 219/301
Reading camera 220/301
Reading camera 221/301
Reading camera 222/301
Reading camera 223/301
Reading camera 224/301
Reading camera 225/301
Reading camera 226/301
Reading camera 227/301
Reading camera 228/301
Reading camera 229/301
Reading camera 230/301
Reading camera 231/301
Reading camera 232/301
Reading camera 233/301
Reading camera 234/301
Reading camera 235/301
Reading camera 236/301
Reading camera 237/301
Reading camera 238/301
Reading camera 239/301
Reading camera 240/301
Reading camera 241/301
Reading camera 242/301
Reading camera 243/301
Reading camera 244/301
Reading camera 245/301
Reading camera 246/301
Reading camera 247/301
Reading camera 248/301
Reading camera 249/301
Reading camera 250/301
Reading camera 251/301
Reading camera 252/301
Reading camera 253/301
Reading camera 254/301
Reading camera 255/301
Reading camera 256/301
Reading camera 257/301
Reading camera 258/301
Reading camera 259/301
Reading camera 260/301
Reading camera 261/301
Reading camera 262/301
Reading camera 263/301
Reading camera 264/301
Reading camera 265/301
Reading camera 266/301
Reading camera 267/301
Reading camera 268/301
Reading camera 269/301
Reading camera 270/301
Reading camera 271/301
Reading camera 272/301
Reading camera 273/301
Reading camera 274/301
Reading camera 275/301
Reading camera 276/301
Reading camera 277/301
Reading camera 278/301
Reading camera 279/301
Reading camera 280/301
Reading camera 281/301
Reading camera 282/301
Reading camera 283/301
Reading camera 284/301
Reading camera 285/301
Reading camera 286/301
Reading camera 287/301
Reading camera 288/301
Reading camera 289/301
Reading camera 290/301
Reading camera 291/301
Reading camera 292/301
Reading camera 293/301
Reading camera 294/301
Reading camera 295/301
Reading camera 296/301
Reading camera 297/301
Reading camera 298/301
Reading camera 299/301
Reading camera 300/301
Reading camera 301/301 [03/12 20:06:11]
Loading Training Cameras [03/12 20:06:11]
Loading Test Cameras [03/12 20:06:27]
Number of points at initialisation :  182686 [03/12 20:06:30]

Training progress:   0%|          | 0/2000 [00:00<?, ?it/s]/ext3/conda/envs/3dgs/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/ext3/conda/envs/3dgs/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)

Training progress:   0%|          | 0/2000 [00:05<?, ?it/s, Loss=0.0136834, Gaussian number=182686, print grad=7.04047670296859e-06, Depth Loss=0.0000000]
Training progress:   0%|          | 10/2000 [00:05<17:29,  1.90it/s, Loss=0.0136834, Gaussian number=182686, print grad=7.04047670296859e-06, Depth Loss=0.0000000]
Training progress:   0%|          | 10/2000 [00:08<17:29,  1.90it/s, Loss=0.0128847, Gaussian number=182686, print grad=1.739997969707474e-05, Depth Loss=0.0000000]
Training progress:   1%|          | 20/2000 [00:08<14:20,  2.30it/s, Loss=0.0128847, Gaussian number=182686, print grad=1.739997969707474e-05, Depth Loss=0.0000000]
Training progress:   1%|          | 20/2000 [00:12<14:20,  2.30it/s, Loss=0.0127497, Gaussian number=182686, print grad=2.7275462343823165e-05, Depth Loss=0.0000000]
Training progress:   2%|▏         | 30/2000 [00:12<13:15,  2.48it/s, Loss=0.0127497, Gaussian number=182686, print grad=2.7275462343823165e-05, Depth Loss=0.0000000]
Training progress:   2%|▏         | 30/2000 [00:16<13:15,  2.48it/s, Loss=0.0133316, Gaussian number=182686, print grad=3.715050115715712e-05, Depth Loss=0.0000000] 
Training progress:   2%|▏         | 40/2000 [00:16<12:44,  2.56it/s, Loss=0.0133316, Gaussian number=182686, print grad=3.715050115715712e-05, Depth Loss=0.0000000]
Training progress:   2%|▏         | 40/2000 [00:20<12:44,  2.56it/s, Loss=0.0101449, Gaussian number=182686, print grad=4.5227054215501994e-05, Depth Loss=0.0000000]
Training progress:   2%|▎         | 50/2000 [00:20<12:24,  2.62it/s, Loss=0.0101449, Gaussian number=182686, print grad=4.5227054215501994e-05, Depth Loss=0.0000000]
Training progress:   2%|▎         | 50/2000 [00:23<12:24,  2.62it/s, Loss=0.0111319, Gaussian number=182686, print grad=5.720585977542214e-05, Depth Loss=0.0000000] 
Training progress:   3%|▎         | 60/2000 [00:23<12:10,  2.65it/s, Loss=0.0111319, Gaussian number=182686, print grad=5.720585977542214e-05, Depth Loss=0.0000000]
Training progress:   3%|▎         | 60/2000 [00:27<12:10,  2.65it/s, Loss=0.0098216, Gaussian number=182686, print grad=7.089648715918884e-05, Depth Loss=0.0000000]
Training progress:   4%|▎         | 70/2000 [00:27<12:00,  2.68it/s, Loss=0.0098216, Gaussian number=182686, print grad=7.089648715918884e-05, Depth Loss=0.0000000]
Training progress:   4%|▎         | 70/2000 [00:30<12:00,  2.68it/s, Loss=0.0120414, Gaussian number=182686, print grad=8.202684693969786e-05, Depth Loss=0.0000000]
Training progress:   4%|▍         | 80/2000 [00:30<11:51,  2.70it/s, Loss=0.0120414, Gaussian number=182686, print grad=8.202684693969786e-05, Depth Loss=0.0000000]
Training progress:   4%|▍         | 80/2000 [00:34<11:51,  2.70it/s, Loss=0.0103303, Gaussian number=182686, print grad=9.393585787620395e-05, Depth Loss=0.0000000]
Training progress:   4%|▍         | 90/2000 [00:34<11:44,  2.71it/s, Loss=0.0103303, Gaussian number=182686, print grad=9.393585787620395e-05, Depth Loss=0.0000000]
Training progress:   4%|▍         | 90/2000 [00:38<11:44,  2.71it/s, Loss=0.0096273, Gaussian number=182686, print grad=0.00010790654050651938, Depth Loss=0.0000000]
Training progress:   5%|▌         | 100/2000 [00:38<11:38,  2.72it/s, Loss=0.0096273, Gaussian number=182686, print grad=0.00010790654050651938, Depth Loss=0.0000000]
Training progress:   5%|▌         | 100/2000 [01:44<11:38,  2.72it/s, Loss=0.0115565, Gaussian number=182686, print grad=0.00012254115426912904, Depth Loss=0.0000000]
Training progress:   6%|▌         | 110/2000 [01:44<1:12:06,  2.29s/it, Loss=0.0115565, Gaussian number=182686, print grad=0.00012254115426912904, Depth Loss=0.0000000]
Training progress:   6%|▌         | 110/2000 [01:48<1:12:06,  2.29s/it, Loss=0.0091707, Gaussian number=182686, print grad=0.00013670143380295485, Depth Loss=0.0000000]
Training progress:   6%|▌         | 120/2000 [01:48<53:21,  1.70s/it, Loss=0.0091707, Gaussian number=182686, print grad=0.00013670143380295485, Depth Loss=0.0000000]  
Training progress:   6%|▌         | 120/2000 [01:52<53:21,  1.70s/it, Loss=0.0105152, Gaussian number=182686, print grad=0.00015332955808844417, Depth Loss=0.0000000]
Training progress:   6%|▋         | 130/2000 [01:52<40:27,  1.30s/it, Loss=0.0105152, Gaussian number=182686, print grad=0.00015332955808844417, Depth Loss=0.0000000]
Training progress:   6%|▋         | 130/2000 [01:55<40:27,  1.30s/it, Loss=0.0093476, Gaussian number=182686, print grad=0.00017052446492016315, Depth Loss=0.0000000]
Training progress:   7%|▋         | 140/2000 [01:55<31:29,  1.02s/it, Loss=0.0093476, Gaussian number=182686, print grad=0.00017052446492016315, Depth Loss=0.0000000]
Training progress:   7%|▋         | 140/2000 [01:59<31:29,  1.02s/it, Loss=0.0080777, Gaussian number=182686, print grad=0.000185552125913091, Depth Loss=0.0000000]  
Training progress:   8%|▊         | 150/2000 [01:59<25:16,  1.22it/s, Loss=0.0080777, Gaussian number=182686, print grad=0.000185552125913091, Depth Loss=0.0000000]
Training progress:   8%|▊         | 150/2000 [02:02<25:16,  1.22it/s, Loss=0.0089035, Gaussian number=182686, print grad=0.0002047348243650049, Depth Loss=0.0000000]
Training progress:   8%|▊         | 160/2000 [02:02<20:53,  1.47it/s, Loss=0.0089035, Gaussian number=182686, print grad=0.0002047348243650049, Depth Loss=0.0000000]
Training progress:   8%|▊         | 160/2000 [02:06<20:53,  1.47it/s, Loss=0.0088298, Gaussian number=182686, print grad=0.00022026650549378246, Depth Loss=0.0000000]
Training progress:   8%|▊         | 170/2000 [02:06<17:51,  1.71it/s, Loss=0.0088298, Gaussian number=182686, print grad=0.00022026650549378246, Depth Loss=0.0000000]
Training progress:   8%|▊         | 170/2000 [02:10<17:51,  1.71it/s, Loss=0.0072859, Gaussian number=182686, print grad=0.0002374081959715113, Depth Loss=0.0000000] 
Training progress:   9%|▉         | 180/2000 [02:10<15:44,  1.93it/s, Loss=0.0072859, Gaussian number=182686, print grad=0.0002374081959715113, Depth Loss=0.0000000]
Training progress:   9%|▉         | 180/2000 [02:13<15:44,  1.93it/s, Loss=0.0092972, Gaussian number=182686, print grad=0.00025342413573525846, Depth Loss=0.0000000]
Training progress:  10%|▉         | 190/2000 [02:13<14:14,  2.12it/s, Loss=0.0092972, Gaussian number=182686, print grad=0.00025342413573525846, Depth Loss=0.0000000]
Training progress:  10%|▉         | 190/2000 [02:17<14:14,  2.12it/s, Loss=0.0081688, Gaussian number=182686, print grad=0.00027082895394414663, Depth Loss=0.0000000]
Training progress:  10%|█         | 200/2000 [02:17<13:10,  2.28it/s, Loss=0.0081688, Gaussian number=182686, print grad=0.00027082895394414663, Depth Loss=0.0000000]
Training progress:  10%|█         | 200/2000 [03:24<13:10,  2.28it/s, Loss=0.0089264, Gaussian number=182686, print grad=0.000289259449345991, Depth Loss=0.0000000]  
Training progress:  10%|█         | 210/2000 [03:24<1:09:05,  2.32s/it, Loss=0.0089264, Gaussian number=182686, print grad=0.000289259449345991, Depth Loss=0.0000000]
Training progress:  10%|█         | 210/2000 [03:27<1:09:05,  2.32s/it, Loss=0.0073183, Gaussian number=182686, print grad=0.00030636347946710885, Depth Loss=0.0000000]
Training progress:  11%|█         | 220/2000 [03:27<51:18,  1.73s/it, Loss=0.0073183, Gaussian number=182686, print grad=0.00030636347946710885, Depth Loss=0.0000000]  
Training progress:  11%|█         | 220/2000 [03:31<51:18,  1.73s/it, Loss=0.0081208, Gaussian number=182686, print grad=0.0003241930971853435, Depth Loss=0.0000000] 
Training progress:  12%|█▏        | 230/2000 [03:31<38:55,  1.32s/it, Loss=0.0081208, Gaussian number=182686, print grad=0.0003241930971853435, Depth Loss=0.0000000]
Training progress:  12%|█▏        | 230/2000 [03:35<38:55,  1.32s/it, Loss=0.0102149, Gaussian number=182686, print grad=0.00034081932972185314, Depth Loss=0.0000000]
Training progress:  12%|█▏        | 240/2000 [03:35<30:17,  1.03s/it, Loss=0.0102149, Gaussian number=182686, print grad=0.00034081932972185314, Depth Loss=0.0000000]
Training progress:  12%|█▏        | 240/2000 [03:38<30:17,  1.03s/it, Loss=0.0077861, Gaussian number=182686, print grad=0.0003600934869609773, Depth Loss=0.0000000] 
Training progress:  12%|█▎        | 250/2000 [03:38<24:14,  1.20it/s, Loss=0.0077861, Gaussian number=182686, print grad=0.0003600934869609773, Depth Loss=0.0000000]
Training progress:  12%|█▎        | 250/2000 [03:42<24:14,  1.20it/s, Loss=0.0085451, Gaussian number=182686, print grad=0.0003773928328882903, Depth Loss=0.0000000]
Training progress:  13%|█▎        | 260/2000 [03:42<20:00,  1.45it/s, Loss=0.0085451, Gaussian number=182686, print grad=0.0003773928328882903, Depth Loss=0.0000000]
Training progress:  13%|█▎        | 260/2000 [03:46<20:00,  1.45it/s, Loss=0.0059435, Gaussian number=182686, print grad=0.0003958439629059285, Depth Loss=0.0000000]
Training progress:  14%|█▎        | 270/2000 [03:46<17:03,  1.69it/s, Loss=0.0059435, Gaussian number=182686, print grad=0.0003958439629059285, Depth Loss=0.0000000]
Training progress:  14%|█▎        | 270/2000 [03:49<17:03,  1.69it/s, Loss=0.0078910, Gaussian number=182686, print grad=0.0004157102666795254, Depth Loss=0.0000000]
Training progress:  14%|█▍        | 280/2000 [03:49<14:58,  1.91it/s, Loss=0.0078910, Gaussian number=182686, print grad=0.0004157102666795254, Depth Loss=0.0000000]
Training progress:  14%|█▍        | 280/2000 [03:53<14:58,  1.91it/s, Loss=0.0076712, Gaussian number=182686, print grad=0.0004353186523076147, Depth Loss=0.0000000]
Training progress:  14%|█▍        | 290/2000 [03:53<13:30,  2.11it/s, Loss=0.0076712, Gaussian number=182686, print grad=0.0004353186523076147, Depth Loss=0.0000000]
Training progress:  14%|█▍        | 290/2000 [03:56<13:30,  2.11it/s, Loss=0.0071561, Gaussian number=182686, print grad=0.00045500366832129657, Depth Loss=0.0000000]
Training progress:  15%|█▌        | 300/2000 [03:56<12:28,  2.27it/s, Loss=0.0071561, Gaussian number=182686, print grad=0.00045500366832129657, Depth Loss=0.0000000]
Training progress:  15%|█▌        | 300/2000 [05:03<12:28,  2.27it/s, Loss=0.0060697, Gaussian number=182686, print grad=0.00047545184497721493, Depth Loss=0.0000000]
Training progress:  16%|█▌        | 310/2000 [05:03<1:05:11,  2.31s/it, Loss=0.0060697, Gaussian number=182686, print grad=0.00047545184497721493, Depth Loss=0.0000000]
Training progress:  16%|█▌        | 310/2000 [05:07<1:05:11,  2.31s/it, Loss=0.0061549, Gaussian number=182686, print grad=0.0004910287680104375, Depth Loss=0.0000000] 
Training progress:  16%|█▌        | 320/2000 [05:07<48:22,  1.73s/it, Loss=0.0061549, Gaussian number=182686, print grad=0.0004910287680104375, Depth Loss=0.0000000]  
Training progress:  16%|█▌        | 320/2000 [05:10<48:22,  1.73s/it, Loss=0.0081054, Gaussian number=182686, print grad=0.0005084275617264211, Depth Loss=0.0000000]
Training progress:  16%|█▋        | 330/2000 [05:10<36:40,  1.32s/it, Loss=0.0081054, Gaussian number=182686, print grad=0.0005084275617264211, Depth Loss=0.0000000]
Training progress:  16%|█▋        | 330/2000 [05:14<36:40,  1.32s/it, Loss=0.0061127, Gaussian number=182686, print grad=0.0005281831254251301, Depth Loss=0.0000000]
Training progress:  17%|█▋        | 340/2000 [05:14<28:31,  1.03s/it, Loss=0.0061127, Gaussian number=182686, print grad=0.0005281831254251301, Depth Loss=0.0000000]
Training progress:  17%|█▋        | 340/2000 [05:18<28:31,  1.03s/it, Loss=0.0062666, Gaussian number=182686, print grad=0.0005475230282172561, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 350/2000 [05:18<22:48,  1.21it/s, Loss=0.0062666, Gaussian number=182686, print grad=0.0005475230282172561, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 350/2000 [05:21<22:48,  1.21it/s, Loss=0.0060382, Gaussian number=182686, print grad=0.0005690278485417366, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 360/2000 [05:21<18:48,  1.45it/s, Loss=0.0060382, Gaussian number=182686, print grad=0.0005690278485417366, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 360/2000 [05:25<18:48,  1.45it/s, Loss=0.0057796, Gaussian number=182686, print grad=0.0005881835822947323, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 370/2000 [05:25<16:01,  1.70it/s, Loss=0.0057796, Gaussian number=182686, print grad=0.0005881835822947323, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 370/2000 [05:28<16:01,  1.70it/s, Loss=0.0078945, Gaussian number=182686, print grad=0.0006046518101356924, Depth Loss=0.0000000]
Training progress:  19%|█▉        | 380/2000 [05:28<14:03,  1.92it/s, Loss=0.0078945, Gaussian number=182686, print grad=0.0006046518101356924, Depth Loss=0.0000000]
Training progress:  19%|█▉        | 380/2000 [05:32<14:03,  1.92it/s, Loss=0.0067921, Gaussian number=182686, print grad=0.0006242706440389156, Depth Loss=0.0000000]
Training progress:  20%|█▉        | 390/2000 [05:32<12:42,  2.11it/s, Loss=0.0067921, Gaussian number=182686, print grad=0.0006242706440389156, Depth Loss=0.0000000]
Training progress:  20%|█▉        | 390/2000 [05:36<12:42,  2.11it/s, Loss=0.0085717, Gaussian number=182686, print grad=0.0006425806786864996, Depth Loss=0.0000000]
Training progress:  20%|██        | 400/2000 [05:36<11:42,  2.28it/s, Loss=0.0085717, Gaussian number=182686, print grad=0.0006425806786864996, Depth Loss=0.0000000]
Training progress:  20%|██        | 400/2000 [05:39<11:42,  2.28it/s, Loss=0.0071642, Gaussian number=182686, print grad=0.0006650041323155165, Depth Loss=0.0000000]
Training progress:  20%|██        | 410/2000 [05:39<11:01,  2.40it/s, Loss=0.0071642, Gaussian number=182686, print grad=0.0006650041323155165, Depth Loss=0.0000000]
Training progress:  20%|██        | 410/2000 [05:43<11:01,  2.40it/s, Loss=0.0062573, Gaussian number=182686, print grad=0.0006870469660498202, Depth Loss=0.0000000]
Training progress:  21%|██        | 420/2000 [05:43<10:30,  2.51it/s, Loss=0.0062573, Gaussian number=182686, print grad=0.0006870469660498202, Depth Loss=0.0000000]
Training progress:  21%|██        | 420/2000 [05:47<10:30,  2.51it/s, Loss=0.0078009, Gaussian number=182686, print grad=0.0007090666913427413, Depth Loss=0.0000000]
Training progress:  22%|██▏       | 430/2000 [05:47<10:09,  2.58it/s, Loss=0.0078009, Gaussian number=182686, print grad=0.0007090666913427413, Depth Loss=0.0000000]
Training progress:  22%|██▏       | 430/2000 [05:50<10:09,  2.58it/s, Loss=0.0062133, Gaussian number=182686, print grad=0.0007287549669854343, Depth Loss=0.0000000]
Training progress:  22%|██▏       | 440/2000 [05:50<09:51,  2.64it/s, Loss=0.0062133, Gaussian number=182686, print grad=0.0007287549669854343, Depth Loss=0.0000000]
Training progress:  22%|██▏       | 440/2000 [05:54<09:51,  2.64it/s, Loss=0.0068874, Gaussian number=182686, print grad=0.0007497216574847698, Depth Loss=0.0000000]
Training progress:  22%|██▎       | 450/2000 [05:54<09:38,  2.68it/s, Loss=0.0068874, Gaussian number=182686, print grad=0.0007497216574847698, Depth Loss=0.0000000]
Training progress:  22%|██▎       | 450/2000 [05:57<09:38,  2.68it/s, Loss=0.0072719, Gaussian number=182686, print grad=0.0007698267581872642, Depth Loss=0.0000000]
Training progress:  23%|██▎       | 460/2000 [05:57<09:28,  2.71it/s, Loss=0.0072719, Gaussian number=182686, print grad=0.0007698267581872642, Depth Loss=0.0000000]
Training progress:  23%|██▎       | 460/2000 [06:01<09:28,  2.71it/s, Loss=0.0083746, Gaussian number=182686, print grad=0.0007894431473687291, Depth Loss=0.0000000]
Training progress:  24%|██▎       | 470/2000 [06:01<09:19,  2.74it/s, Loss=0.0083746, Gaussian number=182686, print grad=0.0007894431473687291, Depth Loss=0.0000000]
Training progress:  24%|██▎       | 470/2000 [06:04<09:19,  2.74it/s, Loss=0.0056423, Gaussian number=182686, print grad=0.0008111139759421349, Depth Loss=0.0000000]
Training progress:  24%|██▍       | 480/2000 [06:04<09:12,  2.75it/s, Loss=0.0056423, Gaussian number=182686, print grad=0.0008111139759421349, Depth Loss=0.0000000]
Training progress:  24%|██▍       | 480/2000 [06:08<09:12,  2.75it/s, Loss=0.0060357, Gaussian number=182686, print grad=0.00083108467515558, Depth Loss=0.0000000]  
Training progress:  24%|██▍       | 490/2000 [06:08<09:06,  2.76it/s, Loss=0.0060357, Gaussian number=182686, print grad=0.00083108467515558, Depth Loss=0.0000000]
Training progress:  24%|██▍       | 490/2000 [06:12<09:06,  2.76it/s, Loss=0.0046230, Gaussian number=182686, print grad=0.0008512758649885654, Depth Loss=0.0000000]
Training progress:  25%|██▌       | 500/2000 [06:12<09:01,  2.77it/s, Loss=0.0046230, Gaussian number=182686, print grad=0.0008512758649885654, Depth Loss=0.0000000]
Training progress:  25%|██▌       | 500/2000 [07:18<09:01,  2.77it/s, Loss=0.0055306, Gaussian number=182686, print grad=0.0008721192716620862, Depth Loss=0.0000000]
Training progress:  26%|██▌       | 510/2000 [07:18<55:47,  2.25s/it, Loss=0.0055306, Gaussian number=182686, print grad=0.0008721192716620862, Depth Loss=0.0000000]
Training progress:  26%|██▌       | 510/2000 [07:22<55:47,  2.25s/it, Loss=0.0059683, Gaussian number=182686, print grad=0.0008931208285503089, Depth Loss=0.0000000]
Training progress:  26%|██▌       | 520/2000 [07:22<41:27,  1.68s/it, Loss=0.0059683, Gaussian number=182686, print grad=0.0008931208285503089, Depth Loss=0.0000000]
Training progress:  26%|██▌       | 520/2000 [07:25<41:27,  1.68s/it, Loss=0.0044104, Gaussian number=182686, print grad=0.000910777656827122, Depth Loss=0.0000000] 
Training progress:  26%|██▋       | 530/2000 [07:25<31:26,  1.28s/it, Loss=0.0044104, Gaussian number=182686, print grad=0.000910777656827122, Depth Loss=0.0000000]
Training progress:  26%|██▋       | 530/2000 [07:29<31:26,  1.28s/it, Loss=0.0060995, Gaussian number=182686, print grad=0.0009304615086875856, Depth Loss=0.0000000]
Training progress:  27%|██▋       | 540/2000 [07:29<24:28,  1.01s/it, Loss=0.0060995, Gaussian number=182686, print grad=0.0009304615086875856, Depth Loss=0.0000000]
Training progress:  27%|██▋       | 540/2000 [07:32<24:28,  1.01s/it, Loss=0.0056219, Gaussian number=182686, print grad=0.00095229537691921, Depth Loss=0.0000000]  
Training progress:  28%|██▊       | 550/2000 [07:32<19:36,  1.23it/s, Loss=0.0056219, Gaussian number=182686, print grad=0.00095229537691921, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 550/2000 [07:36<19:36,  1.23it/s, Loss=0.0045023, Gaussian number=182686, print grad=0.0009724328410811722, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 560/2000 [07:36<16:12,  1.48it/s, Loss=0.0045023, Gaussian number=182686, print grad=0.0009724328410811722, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 560/2000 [07:40<16:12,  1.48it/s, Loss=0.0059798, Gaussian number=182686, print grad=0.0009941839380189776, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 570/2000 [07:40<13:50,  1.72it/s, Loss=0.0059798, Gaussian number=182686, print grad=0.0009941839380189776, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 570/2000 [07:43<13:50,  1.72it/s, Loss=0.0052779, Gaussian number=182686, print grad=0.001015608897432685, Depth Loss=0.0000000] 
Training progress:  29%|██▉       | 580/2000 [07:43<12:09,  1.95it/s, Loss=0.0052779, Gaussian number=182686, print grad=0.001015608897432685, Depth Loss=0.0000000]
Training progress:  29%|██▉       | 580/2000 [07:47<12:09,  1.95it/s, Loss=0.0059189, Gaussian number=182686, print grad=0.0010366333881393075, Depth Loss=0.0000000]
Training progress:  30%|██▉       | 590/2000 [07:47<10:58,  2.14it/s, Loss=0.0059189, Gaussian number=182686, print grad=0.0010366333881393075, Depth Loss=0.0000000]
Training progress:  30%|██▉       | 590/2000 [07:50<10:58,  2.14it/s, Loss=0.0064847, Gaussian number=182686, print grad=0.0010561501840129495, Depth Loss=0.0000000]
Training progress:  30%|███       | 600/2000 [07:50<10:08,  2.30it/s, Loss=0.0064847, Gaussian number=182686, print grad=0.0010561501840129495, Depth Loss=0.0000000]
Training progress:  30%|███       | 600/2000 [07:54<10:08,  2.30it/s, Loss=0.0051508, Gaussian number=182672, print grad=1.8690561773837544e-05, Depth Loss=0.0000000]
Training progress:  30%|███       | 610/2000 [07:54<09:32,  2.43it/s, Loss=0.0051508, Gaussian number=182672, print grad=1.8690561773837544e-05, Depth Loss=0.0000000]
Training progress:  30%|███       | 610/2000 [07:58<09:32,  2.43it/s, Loss=0.0064581, Gaussian number=182672, print grad=3.988980097346939e-05, Depth Loss=0.0000000] 
Training progress:  31%|███       | 620/2000 [07:58<09:06,  2.53it/s, Loss=0.0064581, Gaussian number=182672, print grad=3.988980097346939e-05, Depth Loss=0.0000000]
Training progress:  31%|███       | 620/2000 [08:01<09:06,  2.53it/s, Loss=0.0046799, Gaussian number=182672, print grad=5.8943205658579245e-05, Depth Loss=0.0000000]
Training progress:  32%|███▏      | 630/2000 [08:01<08:46,  2.60it/s, Loss=0.0046799, Gaussian number=182672, print grad=5.8943205658579245e-05, Depth Loss=0.0000000]
Training progress:  32%|███▏      | 630/2000 [08:05<08:46,  2.60it/s, Loss=0.0052589, Gaussian number=182672, print grad=8.163342863554135e-05, Depth Loss=0.0000000] 
Training progress:  32%|███▏      | 640/2000 [08:05<08:31,  2.66it/s, Loss=0.0052589, Gaussian number=182672, print grad=8.163342863554135e-05, Depth Loss=0.0000000]
Training progress:  32%|███▏      | 640/2000 [08:08<08:31,  2.66it/s, Loss=0.0058552, Gaussian number=182672, print grad=0.00010070337884826586, Depth Loss=0.0000000]
Training progress:  32%|███▎      | 650/2000 [08:08<08:20,  2.70it/s, Loss=0.0058552, Gaussian number=182672, print grad=0.00010070337884826586, Depth Loss=0.0000000]
Training progress:  32%|███▎      | 650/2000 [08:12<08:20,  2.70it/s, Loss=0.0057269, Gaussian number=182672, print grad=0.00012258798233233392, Depth Loss=0.0000000]
Training progress:  33%|███▎      | 660/2000 [08:12<08:11,  2.72it/s, Loss=0.0057269, Gaussian number=182672, print grad=0.00012258798233233392, Depth Loss=0.0000000]
Training progress:  33%|███▎      | 660/2000 [08:15<08:11,  2.72it/s, Loss=0.0053348, Gaussian number=182672, print grad=0.00014176381228026003, Depth Loss=0.0000000]
Training progress:  34%|███▎      | 670/2000 [08:15<08:04,  2.74it/s, Loss=0.0053348, Gaussian number=182672, print grad=0.00014176381228026003, Depth Loss=0.0000000]
Training progress:  34%|███▎      | 670/2000 [08:19<08:04,  2.74it/s, Loss=0.0047316, Gaussian number=182672, print grad=0.00016343117749784142, Depth Loss=0.0000000]
Training progress:  34%|███▍      | 680/2000 [08:19<07:58,  2.76it/s, Loss=0.0047316, Gaussian number=182672, print grad=0.00016343117749784142, Depth Loss=0.0000000]
Training progress:  34%|███▍      | 680/2000 [08:23<07:58,  2.76it/s, Loss=0.0062910, Gaussian number=182672, print grad=0.00018404252477921546, Depth Loss=0.0000000]
Training progress:  34%|███▍      | 690/2000 [08:23<07:53,  2.77it/s, Loss=0.0062910, Gaussian number=182672, print grad=0.00018404252477921546, Depth Loss=0.0000000]
Training progress:  34%|███▍      | 690/2000 [08:26<07:53,  2.77it/s, Loss=0.0061082, Gaussian number=182672, print grad=0.00020369554113131016, Depth Loss=0.0000000]
Training progress:  35%|███▌      | 700/2000 [08:26<07:48,  2.77it/s, Loss=0.0061082, Gaussian number=182672, print grad=0.00020369554113131016, Depth Loss=0.0000000]
Training progress:  35%|███▌      | 700/2000 [08:30<07:48,  2.77it/s, Loss=0.0049245, Gaussian number=182679, print grad=1.7448213839088567e-05, Depth Loss=0.0000000]
Training progress:  36%|███▌      | 710/2000 [08:30<07:43,  2.78it/s, Loss=0.0049245, Gaussian number=182679, print grad=1.7448213839088567e-05, Depth Loss=0.0000000]
Training progress:  36%|███▌      | 710/2000 [08:33<07:43,  2.78it/s, Loss=0.0048385, Gaussian number=182679, print grad=3.837107215076685e-05, Depth Loss=0.0000000] 
Training progress:  36%|███▌      | 720/2000 [08:33<07:38,  2.79it/s, Loss=0.0048385, Gaussian number=182679, print grad=3.837107215076685e-05, Depth Loss=0.0000000]
Training progress:  36%|███▌      | 720/2000 [08:37<07:38,  2.79it/s, Loss=0.0059647, Gaussian number=182679, print grad=5.764663001173176e-05, Depth Loss=0.0000000]
Training progress:  36%|███▋      | 730/2000 [08:37<07:34,  2.80it/s, Loss=0.0059647, Gaussian number=182679, print grad=5.764663001173176e-05, Depth Loss=0.0000000]
Training progress:  36%|███▋      | 730/2000 [08:40<07:34,  2.80it/s, Loss=0.0068635, Gaussian number=182679, print grad=7.975967309903353e-05, Depth Loss=0.0000000]
Training progress:  37%|███▋      | 740/2000 [08:40<07:29,  2.80it/s, Loss=0.0068635, Gaussian number=182679, print grad=7.975967309903353e-05, Depth Loss=0.0000000]
Training progress:  37%|███▋      | 740/2000 [08:44<07:29,  2.80it/s, Loss=0.0050643, Gaussian number=182679, print grad=0.00010099280916620046, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 750/2000 [08:44<07:25,  2.81it/s, Loss=0.0050643, Gaussian number=182679, print grad=0.00010099280916620046, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 750/2000 [08:48<07:25,  2.81it/s, Loss=0.0050509, Gaussian number=182679, print grad=0.00012165511725470424, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 760/2000 [08:48<07:21,  2.81it/s, Loss=0.0050509, Gaussian number=182679, print grad=0.00012165511725470424, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 760/2000 [08:51<07:21,  2.81it/s, Loss=0.0042671, Gaussian number=182679, print grad=0.00014310228289104998, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 770/2000 [08:51<07:18,  2.80it/s, Loss=0.0042671, Gaussian number=182679, print grad=0.00014310228289104998, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 770/2000 [08:55<07:18,  2.80it/s, Loss=0.0056537, Gaussian number=182679, print grad=0.00016327940102200955, Depth Loss=0.0000000]
Training progress:  39%|███▉      | 780/2000 [08:55<07:14,  2.81it/s, Loss=0.0056537, Gaussian number=182679, print grad=0.00016327940102200955, Depth Loss=0.0000000]
Training progress:  39%|███▉      | 780/2000 [08:58<07:14,  2.81it/s, Loss=0.0071265, Gaussian number=182679, print grad=0.0001843170030042529, Depth Loss=0.0000000] 
Training progress:  40%|███▉      | 790/2000 [08:58<07:11,  2.81it/s, Loss=0.0071265, Gaussian number=182679, print grad=0.0001843170030042529, Depth Loss=0.0000000]
Training progress:  40%|███▉      | 790/2000 [09:02<07:11,  2.81it/s, Loss=0.0054815, Gaussian number=182679, print grad=0.00020616300753317773, Depth Loss=0.0000000]
Training progress:  40%|████      | 800/2000 [09:02<07:07,  2.81it/s, Loss=0.0054815, Gaussian number=182679, print grad=0.00020616300753317773, Depth Loss=0.0000000]
Training progress:  40%|████      | 800/2000 [09:05<07:07,  2.81it/s, Loss=0.0053572, Gaussian number=182664, print grad=1.878925831988454e-05, Depth Loss=0.0000000] 
Training progress:  40%|████      | 810/2000 [09:05<07:04,  2.80it/s, Loss=0.0053572, Gaussian number=182664, print grad=1.878925831988454e-05, Depth Loss=0.0000000]
Training progress:  40%|████      | 810/2000 [09:09<07:04,  2.80it/s, Loss=0.0053669, Gaussian number=182664, print grad=3.851797737297602e-05, Depth Loss=0.0000000]
Training progress:  41%|████      | 820/2000 [09:09<07:01,  2.80it/s, Loss=0.0053669, Gaussian number=182664, print grad=3.851797737297602e-05, Depth Loss=0.0000000]
Training progress:  41%|████      | 820/2000 [09:13<07:01,  2.80it/s, Loss=0.0040702, Gaussian number=182664, print grad=6.0795777244493365e-05, Depth Loss=0.0000000]
Training progress:  42%|████▏     | 830/2000 [09:13<06:57,  2.80it/s, Loss=0.0040702, Gaussian number=182664, print grad=6.0795777244493365e-05, Depth Loss=0.0000000]
Training progress:  42%|████▏     | 830/2000 [09:16<06:57,  2.80it/s, Loss=0.0046463, Gaussian number=182664, print grad=8.146843174472451e-05, Depth Loss=0.0000000] 
Training progress:  42%|████▏     | 840/2000 [09:16<06:53,  2.81it/s, Loss=0.0046463, Gaussian number=182664, print grad=8.146843174472451e-05, Depth Loss=0.0000000]
Training progress:  42%|████▏     | 840/2000 [09:20<06:53,  2.81it/s, Loss=0.0049862, Gaussian number=182664, print grad=0.00010293087689206004, Depth Loss=0.0000000]
Training progress:  42%|████▎     | 850/2000 [09:20<06:49,  2.81it/s, Loss=0.0049862, Gaussian number=182664, print grad=0.00010293087689206004, Depth Loss=0.0000000]
Training progress:  42%|████▎     | 850/2000 [09:23<06:49,  2.81it/s, Loss=0.0045455, Gaussian number=182664, print grad=0.0001229179324582219, Depth Loss=0.0000000] 
Training progress:  43%|████▎     | 860/2000 [09:23<06:46,  2.80it/s, Loss=0.0045455, Gaussian number=182664, print grad=0.0001229179324582219, Depth Loss=0.0000000]
Training progress:  43%|████▎     | 860/2000 [09:27<06:46,  2.80it/s, Loss=0.0055316, Gaussian number=182664, print grad=0.00014263266348280013, Depth Loss=0.0000000]
Training progress:  44%|████▎     | 870/2000 [09:27<06:42,  2.80it/s, Loss=0.0055316, Gaussian number=182664, print grad=0.00014263266348280013, Depth Loss=0.0000000]
Training progress:  44%|████▎     | 870/2000 [09:30<06:42,  2.80it/s, Loss=0.0054888, Gaussian number=182664, print grad=0.00016370635421480983, Depth Loss=0.0000000]
Training progress:  44%|████▍     | 880/2000 [09:30<06:39,  2.81it/s, Loss=0.0054888, Gaussian number=182664, print grad=0.00016370635421480983, Depth Loss=0.0000000]
Training progress:  44%|████▍     | 880/2000 [09:34<06:39,  2.81it/s, Loss=0.0043751, Gaussian number=182664, print grad=0.00018496651318855584, Depth Loss=0.0000000]
Training progress:  44%|████▍     | 890/2000 [09:34<06:35,  2.81it/s, Loss=0.0043751, Gaussian number=182664, print grad=0.00018496651318855584, Depth Loss=0.0000000]
Training progress:  44%|████▍     | 890/2000 [09:37<06:35,  2.81it/s, Loss=0.0053361, Gaussian number=182664, print grad=0.00020576961105689406, Depth Loss=0.0000000]
Training progress:  45%|████▌     | 900/2000 [09:37<06:32,  2.80it/s, Loss=0.0053361, Gaussian number=182664, print grad=0.00020576961105689406, Depth Loss=0.0000000]
Training progress:  45%|████▌     | 900/2000 [09:41<06:32,  2.80it/s, Loss=0.0038419, Gaussian number=182647, print grad=1.7981938071898185e-05, Depth Loss=0.0000000]
Training progress:  46%|████▌     | 910/2000 [09:41<06:29,  2.80it/s, Loss=0.0038419, Gaussian number=182647, print grad=1.7981938071898185e-05, Depth Loss=0.0000000]
Training progress:  46%|████▌     | 910/2000 [09:45<06:29,  2.80it/s, Loss=0.0053909, Gaussian number=182647, print grad=3.5715791455004364e-05, Depth Loss=0.0000000]
Training progress:  46%|████▌     | 920/2000 [09:45<06:25,  2.80it/s, Loss=0.0053909, Gaussian number=182647, print grad=3.5715791455004364e-05, Depth Loss=0.0000000]
Training progress:  46%|████▌     | 920/2000 [09:48<06:25,  2.80it/s, Loss=0.0052442, Gaussian number=182647, print grad=5.730220800614916e-05, Depth Loss=0.0000000] 
Training progress:  46%|████▋     | 930/2000 [09:48<06:23,  2.79it/s, Loss=0.0052442, Gaussian number=182647, print grad=5.730220800614916e-05, Depth Loss=0.0000000]
Training progress:  46%|████▋     | 930/2000 [09:52<06:23,  2.79it/s, Loss=0.0048805, Gaussian number=182647, print grad=7.807902875356376e-05, Depth Loss=0.0000000]
Training progress:  47%|████▋     | 940/2000 [09:52<06:19,  2.79it/s, Loss=0.0048805, Gaussian number=182647, print grad=7.807902875356376e-05, Depth Loss=0.0000000]
Training progress:  47%|████▋     | 940/2000 [09:55<06:19,  2.79it/s, Loss=0.0046256, Gaussian number=182647, print grad=9.78158277575858e-05, Depth Loss=0.0000000] 
Training progress:  48%|████▊     | 950/2000 [09:55<06:17,  2.78it/s, Loss=0.0046256, Gaussian number=182647, print grad=9.78158277575858e-05, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 950/2000 [09:59<06:17,  2.78it/s, Loss=0.0044868, Gaussian number=182647, print grad=0.00011758979235310107, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 960/2000 [09:59<06:13,  2.79it/s, Loss=0.0044868, Gaussian number=182647, print grad=0.00011758979235310107, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 960/2000 [10:03<06:13,  2.79it/s, Loss=0.0057573, Gaussian number=182647, print grad=0.0001396564330207184, Depth Loss=0.0000000] 
Training progress:  48%|████▊     | 970/2000 [10:03<06:09,  2.79it/s, Loss=0.0057573, Gaussian number=182647, print grad=0.0001396564330207184, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 970/2000 [10:06<06:09,  2.79it/s, Loss=0.0038173, Gaussian number=182647, print grad=0.000159457849804312, Depth Loss=0.0000000] 
Training progress:  49%|████▉     | 980/2000 [10:06<06:05,  2.79it/s, Loss=0.0038173, Gaussian number=182647, print grad=0.000159457849804312, Depth Loss=0.0000000]
Training progress:  49%|████▉     | 980/2000 [10:10<06:05,  2.79it/s, Loss=0.0040966, Gaussian number=182647, print grad=0.00017707282677292824, Depth Loss=0.0000000]
Training progress:  50%|████▉     | 990/2000 [10:10<06:01,  2.79it/s, Loss=0.0040966, Gaussian number=182647, print grad=0.00017707282677292824, Depth Loss=0.0000000]
Training progress:  50%|████▉     | 990/2000 [10:13<06:01,  2.79it/s, Loss=0.0050047, Gaussian number=182647, print grad=0.00019412832625675946, Depth Loss=0.0000000]
Training progress:  50%|█████     | 1000/2000 [10:13<05:57,  2.80it/s, Loss=0.0050047, Gaussian number=182647, print grad=0.00019412832625675946, Depth Loss=0.0000000]
Training progress:  50%|█████     | 1000/2000 [11:20<05:57,  2.80it/s, Loss=0.0046965, Gaussian number=182627, print grad=1.7487958757556044e-05, Depth Loss=0.0000000]
Training progress:  50%|█████     | 1010/2000 [11:20<36:55,  2.24s/it, Loss=0.0046965, Gaussian number=182627, print grad=1.7487958757556044e-05, Depth Loss=0.0000000]
Training progress:  50%|█████     | 1010/2000 [11:23<36:55,  2.24s/it, Loss=0.0056169, Gaussian number=182627, print grad=3.9848466258263215e-05, Depth Loss=0.0000000]
Training progress:  51%|█████     | 1020/2000 [11:23<27:19,  1.67s/it, Loss=0.0056169, Gaussian number=182627, print grad=3.9848466258263215e-05, Depth Loss=0.0000000]
Training progress:  51%|█████     | 1020/2000 [11:27<27:19,  1.67s/it, Loss=0.0046778, Gaussian number=182627, print grad=6.161128840176389e-05, Depth Loss=0.0000000] 
Training progress:  52%|█████▏    | 1030/2000 [11:27<20:40,  1.28s/it, Loss=0.0046778, Gaussian number=182627, print grad=6.161128840176389e-05, Depth Loss=0.0000000]
Training progress:  52%|█████▏    | 1030/2000 [11:30<20:40,  1.28s/it, Loss=0.0048450, Gaussian number=182627, print grad=8.447790605714545e-05, Depth Loss=0.0000000]
Training progress:  52%|█████▏    | 1040/2000 [11:30<16:01,  1.00s/it, Loss=0.0048450, Gaussian number=182627, print grad=8.447790605714545e-05, Depth Loss=0.0000000]
Training progress:  52%|█████▏    | 1040/2000 [11:34<16:01,  1.00s/it, Loss=0.0045235, Gaussian number=182627, print grad=0.00010216686496278271, Depth Loss=0.0000000]
Training progress:  52%|█████▎    | 1050/2000 [11:34<12:47,  1.24it/s, Loss=0.0045235, Gaussian number=182627, print grad=0.00010216686496278271, Depth Loss=0.0000000]
Training progress:  52%|█████▎    | 1050/2000 [11:37<12:47,  1.24it/s, Loss=0.0041327, Gaussian number=182627, print grad=0.00012180440535303205, Depth Loss=0.0000000]
Training progress:  53%|█████▎    | 1060/2000 [11:37<10:31,  1.49it/s, Loss=0.0041327, Gaussian number=182627, print grad=0.00012180440535303205, Depth Loss=0.0000000]
Training progress:  53%|█████▎    | 1060/2000 [11:41<10:31,  1.49it/s, Loss=0.0034754, Gaussian number=182627, print grad=0.0001426293601980433, Depth Loss=0.0000000] 
Training progress:  54%|█████▎    | 1070/2000 [11:41<08:56,  1.73it/s, Loss=0.0034754, Gaussian number=182627, print grad=0.0001426293601980433, Depth Loss=0.0000000]
Training progress:  54%|█████▎    | 1070/2000 [11:44<08:56,  1.73it/s, Loss=0.0039998, Gaussian number=182627, print grad=0.0001621166884433478, Depth Loss=0.0000000]
Training progress:  54%|█████▍    | 1080/2000 [11:44<07:49,  1.96it/s, Loss=0.0039998, Gaussian number=182627, print grad=0.0001621166884433478, Depth Loss=0.0000000]
Training progress:  54%|█████▍    | 1080/2000 [11:48<07:49,  1.96it/s, Loss=0.0043693, Gaussian number=182627, print grad=0.00018198495672550052, Depth Loss=0.0000000]
Training progress:  55%|█████▍    | 1090/2000 [11:48<07:02,  2.15it/s, Loss=0.0043693, Gaussian number=182627, print grad=0.00018198495672550052, Depth Loss=0.0000000]
Training progress:  55%|█████▍    | 1090/2000 [11:52<07:02,  2.15it/s, Loss=0.0050939, Gaussian number=182627, print grad=0.0002022763655986637, Depth Loss=0.0000000] 
Training progress:  55%|█████▌    | 1100/2000 [11:52<06:28,  2.31it/s, Loss=0.0050939, Gaussian number=182627, print grad=0.0002022763655986637, Depth Loss=0.0000000]
Training progress:  55%|█████▌    | 1100/2000 [11:55<06:28,  2.31it/s, Loss=0.0047333, Gaussian number=182593, print grad=1.812397749745287e-05, Depth Loss=0.0000000]
Training progress:  56%|█████▌    | 1110/2000 [11:55<06:04,  2.44it/s, Loss=0.0047333, Gaussian number=182593, print grad=1.812397749745287e-05, Depth Loss=0.0000000]
Training progress:  56%|█████▌    | 1110/2000 [11:59<06:04,  2.44it/s, Loss=0.0044475, Gaussian number=182593, print grad=3.883262616000138e-05, Depth Loss=0.0000000]
Training progress:  56%|█████▌    | 1120/2000 [11:59<05:46,  2.54it/s, Loss=0.0044475, Gaussian number=182593, print grad=3.883262616000138e-05, Depth Loss=0.0000000]
Training progress:  56%|█████▌    | 1120/2000 [12:02<05:46,  2.54it/s, Loss=0.0038354, Gaussian number=182593, print grad=6.053494871594012e-05, Depth Loss=0.0000000]
Training progress:  56%|█████▋    | 1130/2000 [12:02<05:32,  2.62it/s, Loss=0.0038354, Gaussian number=182593, print grad=6.053494871594012e-05, Depth Loss=0.0000000]
Training progress:  56%|█████▋    | 1130/2000 [12:06<05:32,  2.62it/s, Loss=0.0048058, Gaussian number=182593, print grad=8.240947499871254e-05, Depth Loss=0.0000000]
Training progress:  57%|█████▋    | 1140/2000 [12:06<05:22,  2.67it/s, Loss=0.0048058, Gaussian number=182593, print grad=8.240947499871254e-05, Depth Loss=0.0000000]
Training progress:  57%|█████▋    | 1140/2000 [12:09<05:22,  2.67it/s, Loss=0.0032847, Gaussian number=182593, print grad=0.00010329149517929181, Depth Loss=0.0000000]
Training progress:  57%|█████▊    | 1150/2000 [12:09<05:14,  2.70it/s, Loss=0.0032847, Gaussian number=182593, print grad=0.00010329149517929181, Depth Loss=0.0000000]
Training progress:  57%|█████▊    | 1150/2000 [12:13<05:14,  2.70it/s, Loss=0.0037197, Gaussian number=182593, print grad=0.00012263705139048398, Depth Loss=0.0000000]
Training progress:  58%|█████▊    | 1160/2000 [12:13<05:08,  2.73it/s, Loss=0.0037197, Gaussian number=182593, print grad=0.00012263705139048398, Depth Loss=0.0000000]
Training progress:  58%|█████▊    | 1160/2000 [12:17<05:08,  2.73it/s, Loss=0.0046069, Gaussian number=182593, print grad=0.0001429842523066327, Depth Loss=0.0000000] 
Training progress:  58%|█████▊    | 1170/2000 [12:17<05:02,  2.75it/s, Loss=0.0046069, Gaussian number=182593, print grad=0.0001429842523066327, Depth Loss=0.0000000]
Training progress:  58%|█████▊    | 1170/2000 [12:20<05:02,  2.75it/s, Loss=0.0044254, Gaussian number=182593, print grad=0.0001627288875170052, Depth Loss=0.0000000]
Training progress:  59%|█████▉    | 1180/2000 [12:20<04:56,  2.76it/s, Loss=0.0044254, Gaussian number=182593, print grad=0.0001627288875170052, Depth Loss=0.0000000]
Training progress:  59%|█████▉    | 1180/2000 [12:24<04:56,  2.76it/s, Loss=0.0041571, Gaussian number=182593, print grad=0.00018451170763000846, Depth Loss=0.0000000]
Training progress:  60%|█████▉    | 1190/2000 [12:24<04:52,  2.77it/s, Loss=0.0041571, Gaussian number=182593, print grad=0.00018451170763000846, Depth Loss=0.0000000]
Training progress:  60%|█████▉    | 1190/2000 [12:27<04:52,  2.77it/s, Loss=0.0047798, Gaussian number=182593, print grad=0.00020222505554556847, Depth Loss=0.0000000]
Training progress:  60%|██████    | 1200/2000 [12:27<04:47,  2.79it/s, Loss=0.0047798, Gaussian number=182593, print grad=0.00020222505554556847, Depth Loss=0.0000000]
Training progress:  60%|██████    | 1200/2000 [12:31<04:47,  2.79it/s, Loss=0.0037690, Gaussian number=182575, print grad=1.8844506485038437e-05, Depth Loss=0.0000000]
Training progress:  60%|██████    | 1210/2000 [12:31<04:43,  2.79it/s, Loss=0.0037690, Gaussian number=182575, print grad=1.8844506485038437e-05, Depth Loss=0.0000000]
Training progress:  60%|██████    | 1210/2000 [12:34<04:43,  2.79it/s, Loss=0.0030825, Gaussian number=182575, print grad=3.998726242571138e-05, Depth Loss=0.0000000] 
Training progress:  61%|██████    | 1220/2000 [12:34<04:39,  2.79it/s, Loss=0.0030825, Gaussian number=182575, print grad=3.998726242571138e-05, Depth Loss=0.0000000]
Training progress:  61%|██████    | 1220/2000 [12:38<04:39,  2.79it/s, Loss=0.0036109, Gaussian number=182575, print grad=5.940692062722519e-05, Depth Loss=0.0000000]
Training progress:  62%|██████▏   | 1230/2000 [12:38<04:35,  2.80it/s, Loss=0.0036109, Gaussian number=182575, print grad=5.940692062722519e-05, Depth Loss=0.0000000]
Training progress:  62%|██████▏   | 1230/2000 [12:42<04:35,  2.80it/s, Loss=0.0033608, Gaussian number=182575, print grad=7.961734081618488e-05, Depth Loss=0.0000000]
Training progress:  62%|██████▏   | 1240/2000 [12:42<04:31,  2.80it/s, Loss=0.0033608, Gaussian number=182575, print grad=7.961734081618488e-05, Depth Loss=0.0000000]
Training progress:  62%|██████▏   | 1240/2000 [12:45<04:31,  2.80it/s, Loss=0.0034042, Gaussian number=182575, print grad=9.797266829991713e-05, Depth Loss=0.0000000]
Training progress:  62%|██████▎   | 1250/2000 [12:45<04:27,  2.80it/s, Loss=0.0034042, Gaussian number=182575, print grad=9.797266829991713e-05, Depth Loss=0.0000000]
Training progress:  62%|██████▎   | 1250/2000 [12:49<04:27,  2.80it/s, Loss=0.0035398, Gaussian number=182575, print grad=0.00011628195352386683, Depth Loss=0.0000000]
Training progress:  63%|██████▎   | 1260/2000 [12:49<04:24,  2.80it/s, Loss=0.0035398, Gaussian number=182575, print grad=0.00011628195352386683, Depth Loss=0.0000000]
Training progress:  63%|██████▎   | 1260/2000 [12:52<04:24,  2.80it/s, Loss=0.0046489, Gaussian number=182575, print grad=0.00013672448403667659, Depth Loss=0.0000000]
Training progress:  64%|██████▎   | 1270/2000 [12:52<04:20,  2.80it/s, Loss=0.0046489, Gaussian number=182575, print grad=0.00013672448403667659, Depth Loss=0.0000000]
Training progress:  64%|██████▎   | 1270/2000 [12:56<04:20,  2.80it/s, Loss=0.0047094, Gaussian number=182575, print grad=0.00015619902114849538, Depth Loss=0.0000000]
Training progress:  64%|██████▍   | 1280/2000 [12:56<04:16,  2.80it/s, Loss=0.0047094, Gaussian number=182575, print grad=0.00015619902114849538, Depth Loss=0.0000000]
Training progress:  64%|██████▍   | 1280/2000 [12:59<04:16,  2.80it/s, Loss=0.0033965, Gaussian number=182575, print grad=0.0001776479184627533, Depth Loss=0.0000000] 
Training progress:  64%|██████▍   | 1290/2000 [12:59<04:13,  2.80it/s, Loss=0.0033965, Gaussian number=182575, print grad=0.0001776479184627533, Depth Loss=0.0000000]
Training progress:  64%|██████▍   | 1290/2000 [13:03<04:13,  2.80it/s, Loss=0.0051474, Gaussian number=182575, print grad=0.00019641172548290342, Depth Loss=0.0000000]
Training progress:  65%|██████▌   | 1300/2000 [13:03<04:09,  2.80it/s, Loss=0.0051474, Gaussian number=182575, print grad=0.00019641172548290342, Depth Loss=0.0000000]
Training progress:  65%|██████▌   | 1300/2000 [13:07<04:09,  2.80it/s, Loss=0.0050134, Gaussian number=182524, print grad=1.9438091840129346e-05, Depth Loss=0.0000000]
Training progress:  66%|██████▌   | 1310/2000 [13:07<04:05,  2.81it/s, Loss=0.0050134, Gaussian number=182524, print grad=1.9438091840129346e-05, Depth Loss=0.0000000]
Training progress:  66%|██████▌   | 1310/2000 [13:10<04:05,  2.81it/s, Loss=0.0046309, Gaussian number=182524, print grad=3.858103809761815e-05, Depth Loss=0.0000000] 
Training progress:  66%|██████▌   | 1320/2000 [13:10<04:01,  2.81it/s, Loss=0.0046309, Gaussian number=182524, print grad=3.858103809761815e-05, Depth Loss=0.0000000]
Training progress:  66%|██████▌   | 1320/2000 [13:14<04:01,  2.81it/s, Loss=0.0035176, Gaussian number=182524, print grad=5.837915887241252e-05, Depth Loss=0.0000000]
Training progress:  66%|██████▋   | 1330/2000 [13:14<03:57,  2.82it/s, Loss=0.0035176, Gaussian number=182524, print grad=5.837915887241252e-05, Depth Loss=0.0000000]
Training progress:  66%|██████▋   | 1330/2000 [13:17<03:57,  2.82it/s, Loss=0.0040015, Gaussian number=182524, print grad=7.88374527473934e-05, Depth Loss=0.0000000] 
Training progress:  67%|██████▋   | 1340/2000 [13:17<03:53,  2.82it/s, Loss=0.0040015, Gaussian number=182524, print grad=7.88374527473934e-05, Depth Loss=0.0000000]
Training progress:  67%|██████▋   | 1340/2000 [13:21<03:53,  2.82it/s, Loss=0.0055143, Gaussian number=182524, print grad=9.688825957709923e-05, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1350/2000 [13:21<03:49,  2.83it/s, Loss=0.0055143, Gaussian number=182524, print grad=9.688825957709923e-05, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1350/2000 [13:24<03:49,  2.83it/s, Loss=0.0034186, Gaussian number=182524, print grad=0.00011570281640160829, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1360/2000 [13:24<03:46,  2.83it/s, Loss=0.0034186, Gaussian number=182524, print grad=0.00011570281640160829, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1360/2000 [13:28<03:46,  2.83it/s, Loss=0.0057491, Gaussian number=182524, print grad=0.00013605151616502553, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1370/2000 [13:28<03:42,  2.83it/s, Loss=0.0057491, Gaussian number=182524, print grad=0.00013605151616502553, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1370/2000 [13:31<03:42,  2.83it/s, Loss=0.0037995, Gaussian number=182524, print grad=0.00015509570948779583, Depth Loss=0.0000000]
Training progress:  69%|██████▉   | 1380/2000 [13:31<03:39,  2.83it/s, Loss=0.0037995, Gaussian number=182524, print grad=0.00015509570948779583, Depth Loss=0.0000000]
Training progress:  69%|██████▉   | 1380/2000 [13:35<03:39,  2.83it/s, Loss=0.0036406, Gaussian number=182524, print grad=0.00017313686839770526, Depth Loss=0.0000000]
Training progress:  70%|██████▉   | 1390/2000 [13:35<03:35,  2.83it/s, Loss=0.0036406, Gaussian number=182524, print grad=0.00017313686839770526, Depth Loss=0.0000000]
Training progress:  70%|██████▉   | 1390/2000 [13:38<03:35,  2.83it/s, Loss=0.0039179, Gaussian number=182524, print grad=0.00019273943325970322, Depth Loss=0.0000000]
Training progress:  70%|███████   | 1400/2000 [13:38<03:32,  2.82it/s, Loss=0.0039179, Gaussian number=182524, print grad=0.00019273943325970322, Depth Loss=0.0000000]
Training progress:  70%|███████   | 1400/2000 [13:42<03:32,  2.82it/s, Loss=0.0044837, Gaussian number=182490, print grad=1.8894943423219956e-05, Depth Loss=0.0000000]
Training progress:  70%|███████   | 1410/2000 [13:42<03:30,  2.81it/s, Loss=0.0044837, Gaussian number=182490, print grad=1.8894943423219956e-05, Depth Loss=0.0000000]
Training progress:  70%|███████   | 1410/2000 [13:46<03:30,  2.81it/s, Loss=0.0038761, Gaussian number=182490, print grad=3.987746822531335e-05, Depth Loss=0.0000000] 
Training progress:  71%|███████   | 1420/2000 [13:46<03:26,  2.80it/s, Loss=0.0038761, Gaussian number=182490, print grad=3.987746822531335e-05, Depth Loss=0.0000000]
Training progress:  71%|███████   | 1420/2000 [13:49<03:26,  2.80it/s, Loss=0.0039920, Gaussian number=182490, print grad=6.246137490961701e-05, Depth Loss=0.0000000]
Training progress:  72%|███████▏  | 1430/2000 [13:49<03:23,  2.80it/s, Loss=0.0039920, Gaussian number=182490, print grad=6.246137490961701e-05, Depth Loss=0.0000000]
Training progress:  72%|███████▏  | 1430/2000 [13:53<03:23,  2.80it/s, Loss=0.0039246, Gaussian number=182490, print grad=8.192974928533658e-05, Depth Loss=0.0000000]
Training progress:  72%|███████▏  | 1440/2000 [13:53<03:19,  2.81it/s, Loss=0.0039246, Gaussian number=182490, print grad=8.192974928533658e-05, Depth Loss=0.0000000]
Training progress:  72%|███████▏  | 1440/2000 [13:56<03:19,  2.81it/s, Loss=0.0035162, Gaussian number=182490, print grad=0.00010185786231886595, Depth Loss=0.0000000]
Training progress:  72%|███████▎  | 1450/2000 [13:56<03:16,  2.80it/s, Loss=0.0035162, Gaussian number=182490, print grad=0.00010185786231886595, Depth Loss=0.0000000]
Training progress:  72%|███████▎  | 1450/2000 [14:00<03:16,  2.80it/s, Loss=0.0030812, Gaussian number=182490, print grad=0.00012131463154219091, Depth Loss=0.0000000]
Training progress:  73%|███████▎  | 1460/2000 [14:00<03:12,  2.80it/s, Loss=0.0030812, Gaussian number=182490, print grad=0.00012131463154219091, Depth Loss=0.0000000]
Training progress:  73%|███████▎  | 1460/2000 [14:03<03:12,  2.80it/s, Loss=0.0040639, Gaussian number=182490, print grad=0.00014150736387819052, Depth Loss=0.0000000]
Training progress:  74%|███████▎  | 1470/2000 [14:03<03:09,  2.80it/s, Loss=0.0040639, Gaussian number=182490, print grad=0.00014150736387819052, Depth Loss=0.0000000]
Training progress:  74%|███████▎  | 1470/2000 [14:07<03:09,  2.80it/s, Loss=0.0040684, Gaussian number=182490, print grad=0.00016180859529413283, Depth Loss=0.0000000]
Training progress:  74%|███████▍  | 1480/2000 [14:07<03:05,  2.80it/s, Loss=0.0040684, Gaussian number=182490, print grad=0.00016180859529413283, Depth Loss=0.0000000]
Training progress:  74%|███████▍  | 1480/2000 [14:10<03:05,  2.80it/s, Loss=0.0043494, Gaussian number=182490, print grad=0.00018176432058680803, Depth Loss=0.0000000]
Training progress:  74%|███████▍  | 1490/2000 [14:10<03:01,  2.80it/s, Loss=0.0043494, Gaussian number=182490, print grad=0.00018176432058680803, Depth Loss=0.0000000]
Training progress:  74%|███████▍  | 1490/2000 [14:14<03:01,  2.80it/s, Loss=0.0044582, Gaussian number=182490, print grad=0.00020260336168576032, Depth Loss=0.0000000]
Training progress:  75%|███████▌  | 1500/2000 [14:14<02:58,  2.80it/s, Loss=0.0044582, Gaussian number=182490, print grad=0.00020260336168576032, Depth Loss=0.0000000]
Training progress:  75%|███████▌  | 1500/2000 [15:20<02:58,  2.80it/s, Loss=0.0048254, Gaussian number=182446, print grad=1.818589589674957e-05, Depth Loss=0.0000000] 
Training progress:  76%|███████▌  | 1510/2000 [15:20<18:15,  2.24s/it, Loss=0.0048254, Gaussian number=182446, print grad=1.818589589674957e-05, Depth Loss=0.0000000]
Training progress:  76%|███████▌  | 1510/2000 [15:24<18:15,  2.24s/it, Loss=0.0039604, Gaussian number=182446, print grad=3.660396396298893e-05, Depth Loss=0.0000000]
Training progress:  76%|███████▌  | 1520/2000 [15:24<13:22,  1.67s/it, Loss=0.0039604, Gaussian number=182446, print grad=3.660396396298893e-05, Depth Loss=0.0000000]
Training progress:  76%|███████▌  | 1520/2000 [15:27<13:22,  1.67s/it, Loss=0.0026303, Gaussian number=182446, print grad=5.736515231546946e-05, Depth Loss=0.0000000]
Training progress:  76%|███████▋  | 1530/2000 [15:27<09:59,  1.28s/it, Loss=0.0026303, Gaussian number=182446, print grad=5.736515231546946e-05, Depth Loss=0.0000000]
Training progress:  76%|███████▋  | 1530/2000 [15:31<09:59,  1.28s/it, Loss=0.0037467, Gaussian number=182446, print grad=7.707722397753969e-05, Depth Loss=0.0000000]
Training progress:  77%|███████▋  | 1540/2000 [15:31<07:39,  1.00it/s, Loss=0.0037467, Gaussian number=182446, print grad=7.707722397753969e-05, Depth Loss=0.0000000]
Training progress:  77%|███████▋  | 1540/2000 [15:34<07:39,  1.00it/s, Loss=0.0037914, Gaussian number=182446, print grad=9.781356493476778e-05, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1550/2000 [15:34<06:02,  1.24it/s, Loss=0.0037914, Gaussian number=182446, print grad=9.781356493476778e-05, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1550/2000 [15:38<06:02,  1.24it/s, Loss=0.0038212, Gaussian number=182446, print grad=0.00011896318756043911, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1560/2000 [15:38<04:54,  1.49it/s, Loss=0.0038212, Gaussian number=182446, print grad=0.00011896318756043911, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1560/2000 [15:41<04:54,  1.49it/s, Loss=0.0035242, Gaussian number=182446, print grad=0.00013934542948845774, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1570/2000 [15:41<04:07,  1.74it/s, Loss=0.0035242, Gaussian number=182446, print grad=0.00013934542948845774, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1570/2000 [15:45<04:07,  1.74it/s, Loss=0.0025700, Gaussian number=182446, print grad=0.00015597973833791912, Depth Loss=0.0000000]
Training progress:  79%|███████▉  | 1580/2000 [15:45<03:33,  1.96it/s, Loss=0.0025700, Gaussian number=182446, print grad=0.00015597973833791912, Depth Loss=0.0000000]
Training progress:  79%|███████▉  | 1580/2000 [15:49<03:33,  1.96it/s, Loss=0.0036759, Gaussian number=182446, print grad=0.00017457592184655368, Depth Loss=0.0000000]
Training progress:  80%|███████▉  | 1590/2000 [15:49<03:09,  2.16it/s, Loss=0.0036759, Gaussian number=182446, print grad=0.00017457592184655368, Depth Loss=0.0000000]
Training progress:  80%|███████▉  | 1590/2000 [15:52<03:09,  2.16it/s, Loss=0.0034318, Gaussian number=182446, print grad=0.00019500059715937823, Depth Loss=0.0000000]
Training progress:  80%|████████  | 1600/2000 [15:52<02:52,  2.32it/s, Loss=0.0034318, Gaussian number=182446, print grad=0.00019500059715937823, Depth Loss=0.0000000]
Training progress:  80%|████████  | 1600/2000 [15:56<02:52,  2.32it/s, Loss=0.0035359, Gaussian number=182393, print grad=1.878151851997245e-05, Depth Loss=0.0000000] 
Training progress:  80%|████████  | 1610/2000 [15:56<02:39,  2.45it/s, Loss=0.0035359, Gaussian number=182393, print grad=1.878151851997245e-05, Depth Loss=0.0000000]
Training progress:  80%|████████  | 1610/2000 [15:59<02:39,  2.45it/s, Loss=0.0040831, Gaussian number=182393, print grad=3.9745442336425185e-05, Depth Loss=0.0000000]
Training progress:  81%|████████  | 1620/2000 [15:59<02:29,  2.55it/s, Loss=0.0040831, Gaussian number=182393, print grad=3.9745442336425185e-05, Depth Loss=0.0000000]
Training progress:  81%|████████  | 1620/2000 [16:03<02:29,  2.55it/s, Loss=0.0036103, Gaussian number=182393, print grad=5.9361518651712686e-05, Depth Loss=0.0000000]
Training progress:  82%|████████▏ | 1630/2000 [16:03<02:21,  2.62it/s, Loss=0.0036103, Gaussian number=182393, print grad=5.9361518651712686e-05, Depth Loss=0.0000000]
Training progress:  82%|████████▏ | 1630/2000 [16:06<02:21,  2.62it/s, Loss=0.0025607, Gaussian number=182393, print grad=7.938424096209928e-05, Depth Loss=0.0000000] 
Training progress:  82%|████████▏ | 1640/2000 [16:06<02:14,  2.67it/s, Loss=0.0025607, Gaussian number=182393, print grad=7.938424096209928e-05, Depth Loss=0.0000000]
Training progress:  82%|████████▏ | 1640/2000 [16:10<02:14,  2.67it/s, Loss=0.0035798, Gaussian number=182393, print grad=9.723975381348282e-05, Depth Loss=0.0000000]
Training progress:  82%|████████▎ | 1650/2000 [16:10<02:08,  2.71it/s, Loss=0.0035798, Gaussian number=182393, print grad=9.723975381348282e-05, Depth Loss=0.0000000]
Training progress:  82%|████████▎ | 1650/2000 [16:13<02:08,  2.71it/s, Loss=0.0033495, Gaussian number=182393, print grad=0.0001160429383162409, Depth Loss=0.0000000]
Training progress:  83%|████████▎ | 1660/2000 [16:13<02:03,  2.74it/s, Loss=0.0033495, Gaussian number=182393, print grad=0.0001160429383162409, Depth Loss=0.0000000]
Training progress:  83%|████████▎ | 1660/2000 [16:17<02:03,  2.74it/s, Loss=0.0033228, Gaussian number=182393, print grad=0.00013511689030565321, Depth Loss=0.0000000]
Training progress:  84%|████████▎ | 1670/2000 [16:17<01:59,  2.76it/s, Loss=0.0033228, Gaussian number=182393, print grad=0.00013511689030565321, Depth Loss=0.0000000]
Training progress:  84%|████████▎ | 1670/2000 [16:21<01:59,  2.76it/s, Loss=0.0028494, Gaussian number=182393, print grad=0.00015483758761547506, Depth Loss=0.0000000]
Training progress:  84%|████████▍ | 1680/2000 [16:21<01:55,  2.78it/s, Loss=0.0028494, Gaussian number=182393, print grad=0.00015483758761547506, Depth Loss=0.0000000]
Training progress:  84%|████████▍ | 1680/2000 [16:24<01:55,  2.78it/s, Loss=0.0036499, Gaussian number=182393, print grad=0.0001740064035402611, Depth Loss=0.0000000] 
Training progress:  84%|████████▍ | 1690/2000 [16:24<01:51,  2.79it/s, Loss=0.0036499, Gaussian number=182393, print grad=0.0001740064035402611, Depth Loss=0.0000000]
Training progress:  84%|████████▍ | 1690/2000 [16:28<01:51,  2.79it/s, Loss=0.0036505, Gaussian number=182393, print grad=0.00019141567463520914, Depth Loss=0.0000000]
Training progress:  85%|████████▌ | 1700/2000 [16:28<01:47,  2.79it/s, Loss=0.0036505, Gaussian number=182393, print grad=0.00019141567463520914, Depth Loss=0.0000000]
Training progress:  85%|████████▌ | 1700/2000 [16:31<01:47,  2.79it/s, Loss=0.0039845, Gaussian number=182366, print grad=2.0035115085192956e-05, Depth Loss=0.0000000]
Training progress:  86%|████████▌ | 1710/2000 [16:31<01:43,  2.79it/s, Loss=0.0039845, Gaussian number=182366, print grad=2.0035115085192956e-05, Depth Loss=0.0000000]
Training progress:  86%|████████▌ | 1710/2000 [16:35<01:43,  2.79it/s, Loss=0.0039088, Gaussian number=182366, print grad=3.788420872297138e-05, Depth Loss=0.0000000] 
Training progress:  86%|████████▌ | 1720/2000 [16:35<01:40,  2.79it/s, Loss=0.0039088, Gaussian number=182366, print grad=3.788420872297138e-05, Depth Loss=0.0000000]
Training progress:  86%|████████▌ | 1720/2000 [16:39<01:40,  2.79it/s, Loss=0.0035059, Gaussian number=182366, print grad=5.763130320701748e-05, Depth Loss=0.0000000]
Training progress:  86%|████████▋ | 1730/2000 [16:39<01:36,  2.79it/s, Loss=0.0035059, Gaussian number=182366, print grad=5.763130320701748e-05, Depth Loss=0.0000000]
Training progress:  86%|████████▋ | 1730/2000 [16:42<01:36,  2.79it/s, Loss=0.0044097, Gaussian number=182366, print grad=7.800121966283768e-05, Depth Loss=0.0000000]
Training progress:  87%|████████▋ | 1740/2000 [16:42<01:33,  2.79it/s, Loss=0.0044097, Gaussian number=182366, print grad=7.800121966283768e-05, Depth Loss=0.0000000]
Training progress:  87%|████████▋ | 1740/2000 [16:46<01:33,  2.79it/s, Loss=0.0044361, Gaussian number=182366, print grad=9.970170503947884e-05, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1750/2000 [16:46<01:29,  2.79it/s, Loss=0.0044361, Gaussian number=182366, print grad=9.970170503947884e-05, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1750/2000 [16:49<01:29,  2.79it/s, Loss=0.0036448, Gaussian number=182366, print grad=0.00011965043086092919, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1760/2000 [16:49<01:25,  2.79it/s, Loss=0.0036448, Gaussian number=182366, print grad=0.00011965043086092919, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1760/2000 [16:53<01:25,  2.79it/s, Loss=0.0030822, Gaussian number=182366, print grad=0.00013813933765050024, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1770/2000 [16:53<01:22,  2.80it/s, Loss=0.0030822, Gaussian number=182366, print grad=0.00013813933765050024, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1770/2000 [16:56<01:22,  2.80it/s, Loss=0.0038123, Gaussian number=182366, print grad=0.00015659164637327194, Depth Loss=0.0000000]
Training progress:  89%|████████▉ | 1780/2000 [16:56<01:18,  2.80it/s, Loss=0.0038123, Gaussian number=182366, print grad=0.00015659164637327194, Depth Loss=0.0000000]
Training progress:  89%|████████▉ | 1780/2000 [17:00<01:18,  2.80it/s, Loss=0.0031182, Gaussian number=182366, print grad=0.00017377537733409554, Depth Loss=0.0000000]
Training progress:  90%|████████▉ | 1790/2000 [17:00<01:15,  2.80it/s, Loss=0.0031182, Gaussian number=182366, print grad=0.00017377537733409554, Depth Loss=0.0000000]
Training progress:  90%|████████▉ | 1790/2000 [17:03<01:15,  2.80it/s, Loss=0.0033540, Gaussian number=182366, print grad=0.00019420542230363935, Depth Loss=0.0000000]
Training progress:  90%|█████████ | 1800/2000 [17:03<01:11,  2.80it/s, Loss=0.0033540, Gaussian number=182366, print grad=0.00019420542230363935, Depth Loss=0.0000000]
Training progress:  90%|█████████ | 1800/2000 [17:07<01:11,  2.80it/s, Loss=0.0036975, Gaussian number=182309, print grad=1.941320806508884e-05, Depth Loss=0.0000000] 
Training progress:  90%|█████████ | 1810/2000 [17:07<01:07,  2.80it/s, Loss=0.0036975, Gaussian number=182309, print grad=1.941320806508884e-05, Depth Loss=0.0000000]
Training progress:  90%|█████████ | 1810/2000 [17:11<01:07,  2.80it/s, Loss=0.0033859, Gaussian number=182309, print grad=4.0034086850937456e-05, Depth Loss=0.0000000]
Training progress:  91%|█████████ | 1820/2000 [17:11<01:04,  2.81it/s, Loss=0.0033859, Gaussian number=182309, print grad=4.0034086850937456e-05, Depth Loss=0.0000000]
Training progress:  91%|█████████ | 1820/2000 [17:14<01:04,  2.81it/s, Loss=0.0026868, Gaussian number=182309, print grad=5.749977572122589e-05, Depth Loss=0.0000000] 
Training progress:  92%|█████████▏| 1830/2000 [17:14<01:00,  2.81it/s, Loss=0.0026868, Gaussian number=182309, print grad=5.749977572122589e-05, Depth Loss=0.0000000]
Training progress:  92%|█████████▏| 1830/2000 [17:18<01:00,  2.81it/s, Loss=0.0031031, Gaussian number=182309, print grad=7.889293920015916e-05, Depth Loss=0.0000000]
Training progress:  92%|█████████▏| 1840/2000 [17:18<00:56,  2.81it/s, Loss=0.0031031, Gaussian number=182309, print grad=7.889293920015916e-05, Depth Loss=0.0000000]
Training progress:  92%|█████████▏| 1840/2000 [17:21<00:56,  2.81it/s, Loss=0.0032068, Gaussian number=182309, print grad=9.813116048462689e-05, Depth Loss=0.0000000]
Training progress:  92%|█████████▎| 1850/2000 [17:21<00:53,  2.81it/s, Loss=0.0032068, Gaussian number=182309, print grad=9.813116048462689e-05, Depth Loss=0.0000000]
Training progress:  92%|█████████▎| 1850/2000 [17:25<00:53,  2.81it/s, Loss=0.0032478, Gaussian number=182309, print grad=0.00011516693484736606, Depth Loss=0.0000000]
Training progress:  93%|█████████▎| 1860/2000 [17:25<00:49,  2.81it/s, Loss=0.0032478, Gaussian number=182309, print grad=0.00011516693484736606, Depth Loss=0.0000000]
Training progress:  93%|█████████▎| 1860/2000 [17:28<00:49,  2.81it/s, Loss=0.0035576, Gaussian number=182309, print grad=0.0001366958167636767, Depth Loss=0.0000000] 
Training progress:  94%|█████████▎| 1870/2000 [17:28<00:46,  2.81it/s, Loss=0.0035576, Gaussian number=182309, print grad=0.0001366958167636767, Depth Loss=0.0000000]
Training progress:  94%|█████████▎| 1870/2000 [17:32<00:46,  2.81it/s, Loss=0.0029636, Gaussian number=182309, print grad=0.00015673651068937033, Depth Loss=0.0000000]
Training progress:  94%|█████████▍| 1880/2000 [17:32<00:42,  2.81it/s, Loss=0.0029636, Gaussian number=182309, print grad=0.00015673651068937033, Depth Loss=0.0000000]
Training progress:  94%|█████████▍| 1880/2000 [17:35<00:42,  2.81it/s, Loss=0.0032958, Gaussian number=182309, print grad=0.00017545922310091555, Depth Loss=0.0000000]
Training progress:  94%|█████████▍| 1890/2000 [17:35<00:39,  2.81it/s, Loss=0.0032958, Gaussian number=182309, print grad=0.00017545922310091555, Depth Loss=0.0000000]
Training progress:  94%|█████████▍| 1890/2000 [17:39<00:39,  2.81it/s, Loss=0.0038555, Gaussian number=182309, print grad=0.0001952015736605972, Depth Loss=0.0000000] 
Training progress:  95%|█████████▌| 1900/2000 [17:39<00:35,  2.81it/s, Loss=0.0038555, Gaussian number=182309, print grad=0.0001952015736605972, Depth Loss=0.0000000]
Training progress:  95%|█████████▌| 1900/2000 [17:43<00:35,  2.81it/s, Loss=0.0036885, Gaussian number=182270, print grad=1.7554000805830583e-05, Depth Loss=0.0000000]
Training progress:  96%|█████████▌| 1910/2000 [17:43<00:31,  2.81it/s, Loss=0.0036885, Gaussian number=182270, print grad=1.7554000805830583e-05, Depth Loss=0.0000000]
Training progress:  96%|█████████▌| 1910/2000 [17:46<00:31,  2.81it/s, Loss=0.0027257, Gaussian number=182270, print grad=3.7119927583262324e-05, Depth Loss=0.0000000]
Training progress:  96%|█████████▌| 1920/2000 [17:46<00:28,  2.81it/s, Loss=0.0027257, Gaussian number=182270, print grad=3.7119927583262324e-05, Depth Loss=0.0000000]
Training progress:  96%|█████████▌| 1920/2000 [17:50<00:28,  2.81it/s, Loss=0.0024937, Gaussian number=182270, print grad=5.5880311265354976e-05, Depth Loss=0.0000000]
Training progress:  96%|█████████▋| 1930/2000 [17:50<00:24,  2.81it/s, Loss=0.0024937, Gaussian number=182270, print grad=5.5880311265354976e-05, Depth Loss=0.0000000]
Training progress:  96%|█████████▋| 1930/2000 [17:53<00:24,  2.81it/s, Loss=0.0036533, Gaussian number=182270, print grad=7.467152317985892e-05, Depth Loss=0.0000000] 
Training progress:  97%|█████████▋| 1940/2000 [17:53<00:21,  2.81it/s, Loss=0.0036533, Gaussian number=182270, print grad=7.467152317985892e-05, Depth Loss=0.0000000]
Training progress:  97%|█████████▋| 1940/2000 [17:57<00:21,  2.81it/s, Loss=0.0028741, Gaussian number=182270, print grad=9.387682803208008e-05, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1950/2000 [17:57<00:17,  2.80it/s, Loss=0.0028741, Gaussian number=182270, print grad=9.387682803208008e-05, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1950/2000 [18:00<00:17,  2.80it/s, Loss=0.0044679, Gaussian number=182270, print grad=0.00011244194320170209, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1960/2000 [18:00<00:14,  2.81it/s, Loss=0.0044679, Gaussian number=182270, print grad=0.00011244194320170209, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1960/2000 [18:04<00:14,  2.81it/s, Loss=0.0036065, Gaussian number=182270, print grad=0.00013157923240214586, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1970/2000 [18:04<00:10,  2.80it/s, Loss=0.0036065, Gaussian number=182270, print grad=0.00013157923240214586, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1970/2000 [18:08<00:10,  2.80it/s, Loss=0.0032348, Gaussian number=182270, print grad=0.00015097670257091522, Depth Loss=0.0000000]
Training progress:  99%|█████████▉| 1980/2000 [18:08<00:07,  2.81it/s, Loss=0.0032348, Gaussian number=182270, print grad=0.00015097670257091522, Depth Loss=0.0000000]
Training progress:  99%|█████████▉| 1980/2000 [18:11<00:07,  2.81it/s, Loss=0.0031694, Gaussian number=182270, print grad=0.00017301812476944178, Depth Loss=0.0000000]
Training progress: 100%|█████████▉| 1990/2000 [18:11<00:03,  2.81it/s, Loss=0.0031694, Gaussian number=182270, print grad=0.00017301812476944178, Depth Loss=0.0000000]
Training progress: 100%|█████████▉| 1990/2000 [18:15<00:03,  2.81it/s, Loss=0.0026748, Gaussian number=182270, print grad=0.0001944881078088656, Depth Loss=0.0000000] 
Training progress: 100%|██████████| 2000/2000 [18:15<00:00,  2.81it/s, Loss=0.0026748, Gaussian number=182270, print grad=0.0001944881078088656, Depth Loss=0.0000000]
Training progress: 100%|██████████| 2000/2000 [18:15<00:00,  1.83it/s, Loss=0.0026748, Gaussian number=182270, print grad=0.0001944881078088656, Depth Loss=0.0000000]
Iteration 100 [03/12 20:07:08]

[ITER 100] Evaluating test: WD 0.014196, PSNR 12.8082,lpips 0.600325,ssim 0.437160 [03/12 20:08:04]

[ITER 100] Evaluating train: WD 0.014542, PSNR 13.2325,lpips 0.605087,ssim 0.456242 [03/12 20:08:11]
Gaussian number:182686,print gradients:1.5925573961794726e-06 [03/12 20:08:11]
Iteration 200 [03/12 20:08:47]

[ITER 200] Evaluating test: WD 0.013271, PSNR 14.1813,lpips 0.548029,ssim 0.464344 [03/12 20:09:43]

[ITER 200] Evaluating train: WD 0.013319, PSNR 14.6014,lpips 0.538738,ssim 0.480123 [03/12 20:09:51]
Gaussian number:182686,print gradients:1.9617996258602943e-06 [03/12 20:09:51]
Iteration 300 [03/12 20:10:27]

[ITER 300] Evaluating test: WD 0.012610, PSNR 14.8605,lpips 0.512828,ssim 0.479443 [03/12 20:11:23]

[ITER 300] Evaluating train: WD 0.012715, PSNR 15.3715,lpips 0.500256,ssim 0.493010 [03/12 20:11:30]
Gaussian number:182686,print gradients:2.1925102373643313e-06 [03/12 20:11:30]
Iteration 400 [03/12 20:12:06]
Iteration 500 [03/12 20:12:42]

[ITER 500] Evaluating test: WD 0.011797, PSNR 15.6946,lpips 0.475865,ssim 0.495212 [03/12 20:13:38]

[ITER 500] Evaluating train: WD 0.012517, PSNR 15.9401,lpips 0.475131,ssim 0.501378 [03/12 20:13:45]
Gaussian number:182686,print gradients:2.4694561489013722e-06 [03/12 20:13:45]
Iteration 600 [03/12 20:14:21]
Iteration 700 [03/12 20:14:56]
Iteration 800 [03/12 20:15:32]
Iteration 900 [03/12 20:16:08]
Iteration 1000 [03/12 20:16:43]

[ITER 1000] Evaluating test: WD 0.010337, PSNR 16.4068,lpips 0.420087,ssim 0.516777 [03/12 20:17:39]

[ITER 1000] Evaluating train: WD 0.010895, PSNR 16.7263,lpips 0.419753,ssim 0.526952 [03/12 20:17:46]
Gaussian number:182647,print gradients:2.97935957860318e-06 [03/12 20:17:46]
Iteration 1100 [03/12 20:18:22]
Iteration 1200 [03/12 20:18:57]
Iteration 1300 [03/12 20:19:33]
Iteration 1400 [03/12 20:20:09]
Iteration 1500 [03/12 20:20:44]

[ITER 1500] Evaluating test: WD 0.009461, PSNR 16.7800,lpips 0.388641,ssim 0.530201 [03/12 20:21:40]

[ITER 1500] Evaluating train: WD 0.009811, PSNR 17.2242,lpips 0.381787,ssim 0.542077 [03/12 20:21:47]
Gaussian number:182490,print gradients:3.055831029996625e-06 [03/12 20:21:47]
Iteration 1600 [03/12 20:22:22]
Iteration 1700 [03/12 20:22:58]
Iteration 1800 [03/12 20:23:34]
Iteration 1900 [03/12 20:24:09]
Iteration 2000 [03/12 20:24:45]

[ITER 2000] Evaluating test: WD 0.008848, PSNR 17.0974,lpips 0.370843,ssim 0.540857 [03/12 20:25:41]

[ITER 2000] Evaluating train: WD 0.009450, PSNR 17.5007,lpips 0.371089,ssim 0.548470 [03/12 20:25:48]
Gaussian number:182270,print gradients:2.977905751322396e-06 [03/12 20:25:48]

[ITER 2000] Saving Gaussians [03/12 20:25:48]

Training complete. [03/12 20:25:49]
