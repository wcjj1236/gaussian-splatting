Optimizing /home/cw4287/gaussian-model/train_30k
Output folder: /home/cw4287/gaussian-model/train_30k [03/12 18:00:51]
Tensorboard not available: not logging progress [03/12 18:00:51]
------------LLFF HOLD------------- [03/12 18:00:52]

Reading camera 1/301
Reading camera 2/301
Reading camera 3/301
Reading camera 4/301
Reading camera 5/301
Reading camera 6/301
Reading camera 7/301
Reading camera 8/301
Reading camera 9/301
Reading camera 10/301
Reading camera 11/301
Reading camera 12/301
Reading camera 13/301
Reading camera 14/301
Reading camera 15/301
Reading camera 16/301
Reading camera 17/301
Reading camera 18/301
Reading camera 19/301
Reading camera 20/301
Reading camera 21/301
Reading camera 22/301
Reading camera 23/301
Reading camera 24/301
Reading camera 25/301
Reading camera 26/301
Reading camera 27/301
Reading camera 28/301
Reading camera 29/301
Reading camera 30/301
Reading camera 31/301
Reading camera 32/301
Reading camera 33/301
Reading camera 34/301
Reading camera 35/301
Reading camera 36/301
Reading camera 37/301
Reading camera 38/301
Reading camera 39/301
Reading camera 40/301
Reading camera 41/301
Reading camera 42/301
Reading camera 43/301
Reading camera 44/301
Reading camera 45/301
Reading camera 46/301
Reading camera 47/301
Reading camera 48/301
Reading camera 49/301
Reading camera 50/301
Reading camera 51/301
Reading camera 52/301
Reading camera 53/301
Reading camera 54/301
Reading camera 55/301
Reading camera 56/301
Reading camera 57/301
Reading camera 58/301
Reading camera 59/301
Reading camera 60/301
Reading camera 61/301
Reading camera 62/301
Reading camera 63/301
Reading camera 64/301
Reading camera 65/301
Reading camera 66/301
Reading camera 67/301
Reading camera 68/301
Reading camera 69/301
Reading camera 70/301
Reading camera 71/301
Reading camera 72/301
Reading camera 73/301
Reading camera 74/301
Reading camera 75/301
Reading camera 76/301
Reading camera 77/301
Reading camera 78/301
Reading camera 79/301
Reading camera 80/301
Reading camera 81/301
Reading camera 82/301
Reading camera 83/301
Reading camera 84/301
Reading camera 85/301
Reading camera 86/301
Reading camera 87/301
Reading camera 88/301
Reading camera 89/301
Reading camera 90/301
Reading camera 91/301
Reading camera 92/301
Reading camera 93/301
Reading camera 94/301
Reading camera 95/301
Reading camera 96/301
Reading camera 97/301
Reading camera 98/301
Reading camera 99/301
Reading camera 100/301
Reading camera 101/301
Reading camera 102/301
Reading camera 103/301
Reading camera 104/301
Reading camera 105/301
Reading camera 106/301
Reading camera 107/301
Reading camera 108/301
Reading camera 109/301
Reading camera 110/301
Reading camera 111/301
Reading camera 112/301
Reading camera 113/301
Reading camera 114/301
Reading camera 115/301
Reading camera 116/301
Reading camera 117/301
Reading camera 118/301
Reading camera 119/301
Reading camera 120/301
Reading camera 121/301
Reading camera 122/301
Reading camera 123/301
Reading camera 124/301
Reading camera 125/301
Reading camera 126/301
Reading camera 127/301
Reading camera 128/301
Reading camera 129/301
Reading camera 130/301
Reading camera 131/301
Reading camera 132/301
Reading camera 133/301
Reading camera 134/301
Reading camera 135/301
Reading camera 136/301
Reading camera 137/301
Reading camera 138/301
Reading camera 139/301
Reading camera 140/301
Reading camera 141/301
Reading camera 142/301
Reading camera 143/301
Reading camera 144/301
Reading camera 145/301
Reading camera 146/301
Reading camera 147/301
Reading camera 148/301
Reading camera 149/301
Reading camera 150/301
Reading camera 151/301
Reading camera 152/301
Reading camera 153/301
Reading camera 154/301
Reading camera 155/301
Reading camera 156/301
Reading camera 157/301
Reading camera 158/301
Reading camera 159/301
Reading camera 160/301
Reading camera 161/301
Reading camera 162/301
Reading camera 163/301
Reading camera 164/301
Reading camera 165/301
Reading camera 166/301
Reading camera 167/301
Reading camera 168/301
Reading camera 169/301
Reading camera 170/301
Reading camera 171/301
Reading camera 172/301
Reading camera 173/301
Reading camera 174/301
Reading camera 175/301
Reading camera 176/301
Reading camera 177/301
Reading camera 178/301
Reading camera 179/301
Reading camera 180/301
Reading camera 181/301
Reading camera 182/301
Reading camera 183/301
Reading camera 184/301
Reading camera 185/301
Reading camera 186/301
Reading camera 187/301
Reading camera 188/301
Reading camera 189/301
Reading camera 190/301
Reading camera 191/301
Reading camera 192/301
Reading camera 193/301
Reading camera 194/301
Reading camera 195/301
Reading camera 196/301
Reading camera 197/301
Reading camera 198/301
Reading camera 199/301
Reading camera 200/301
Reading camera 201/301
Reading camera 202/301
Reading camera 203/301
Reading camera 204/301
Reading camera 205/301
Reading camera 206/301
Reading camera 207/301
Reading camera 208/301
Reading camera 209/301
Reading camera 210/301
Reading camera 211/301
Reading camera 212/301
Reading camera 213/301
Reading camera 214/301
Reading camera 215/301
Reading camera 216/301
Reading camera 217/301
Reading camera 218/301
Reading camera 219/301
Reading camera 220/301
Reading camera 221/301
Reading camera 222/301
Reading camera 223/301
Reading camera 224/301
Reading camera 225/301
Reading camera 226/301
Reading camera 227/301
Reading camera 228/301
Reading camera 229/301
Reading camera 230/301
Reading camera 231/301
Reading camera 232/301
Reading camera 233/301
Reading camera 234/301
Reading camera 235/301
Reading camera 236/301
Reading camera 237/301
Reading camera 238/301
Reading camera 239/301
Reading camera 240/301
Reading camera 241/301
Reading camera 242/301
Reading camera 243/301
Reading camera 244/301
Reading camera 245/301
Reading camera 246/301
Reading camera 247/301
Reading camera 248/301
Reading camera 249/301
Reading camera 250/301
Reading camera 251/301
Reading camera 252/301
Reading camera 253/301
Reading camera 254/301
Reading camera 255/301
Reading camera 256/301
Reading camera 257/301
Reading camera 258/301
Reading camera 259/301
Reading camera 260/301
Reading camera 261/301
Reading camera 262/301
Reading camera 263/301
Reading camera 264/301
Reading camera 265/301
Reading camera 266/301
Reading camera 267/301
Reading camera 268/301
Reading camera 269/301
Reading camera 270/301
Reading camera 271/301
Reading camera 272/301
Reading camera 273/301
Reading camera 274/301
Reading camera 275/301
Reading camera 276/301
Reading camera 277/301
Reading camera 278/301
Reading camera 279/301
Reading camera 280/301
Reading camera 281/301
Reading camera 282/301
Reading camera 283/301
Reading camera 284/301
Reading camera 285/301
Reading camera 286/301
Reading camera 287/301
Reading camera 288/301
Reading camera 289/301
Reading camera 290/301
Reading camera 291/301
Reading camera 292/301
Reading camera 293/301
Reading camera 294/301
Reading camera 295/301
Reading camera 296/301
Reading camera 297/301
Reading camera 298/301
Reading camera 299/301
Reading camera 300/301
Reading camera 301/301 [03/12 18:00:52]
Loading Training Cameras [03/12 18:00:52]
Loading Test Cameras [03/12 18:01:16]
Number of points at initialisation :  182686 [03/12 18:01:19]

Training progress:   0%|          | 0/2000 [00:00<?, ?it/s]/ext3/conda/envs/3dgs/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/ext3/conda/envs/3dgs/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)

Training progress:   0%|          | 0/2000 [00:05<?, ?it/s, Loss=0.2378329, Gaussian number=182686, print grad=0.00011353847366990522, Depth Loss=0.0000000]
Training progress:   0%|          | 10/2000 [00:05<18:59,  1.75it/s, Loss=0.2378329, Gaussian number=182686, print grad=0.00011353847366990522, Depth Loss=0.0000000]
Training progress:   0%|          | 10/2000 [00:09<18:59,  1.75it/s, Loss=0.2231424, Gaussian number=182686, print grad=0.0002937519457191229, Depth Loss=0.0000000] 
Training progress:   1%|          | 20/2000 [00:09<15:38,  2.11it/s, Loss=0.2231424, Gaussian number=182686, print grad=0.0002937519457191229, Depth Loss=0.0000000]
Training progress:   1%|          | 20/2000 [00:13<15:38,  2.11it/s, Loss=0.2217249, Gaussian number=182686, print grad=0.00046221999218687415, Depth Loss=0.0000000]
Training progress:   2%|▏         | 30/2000 [00:13<14:31,  2.26it/s, Loss=0.2217249, Gaussian number=182686, print grad=0.00046221999218687415, Depth Loss=0.0000000]
Training progress:   2%|▏         | 30/2000 [00:17<14:31,  2.26it/s, Loss=0.2394536, Gaussian number=182686, print grad=0.0006382234860211611, Depth Loss=0.0000000] 
Training progress:   2%|▏         | 40/2000 [00:17<13:58,  2.34it/s, Loss=0.2394536, Gaussian number=182686, print grad=0.0006382234860211611, Depth Loss=0.0000000]
Training progress:   2%|▏         | 40/2000 [00:21<13:58,  2.34it/s, Loss=0.1833503, Gaussian number=182686, print grad=0.0007810068200342357, Depth Loss=0.0000000]
Training progress:   2%|▎         | 50/2000 [00:21<13:37,  2.38it/s, Loss=0.1833503, Gaussian number=182686, print grad=0.0007810068200342357, Depth Loss=0.0000000]
Training progress:   2%|▎         | 50/2000 [00:25<13:37,  2.38it/s, Loss=0.2038836, Gaussian number=182686, print grad=0.000988365733064711, Depth Loss=0.0000000] 
Training progress:   3%|▎         | 60/2000 [00:25<13:22,  2.42it/s, Loss=0.2038836, Gaussian number=182686, print grad=0.000988365733064711, Depth Loss=0.0000000]
Training progress:   3%|▎         | 60/2000 [00:29<13:22,  2.42it/s, Loss=0.1828265, Gaussian number=182686, print grad=0.0012495293049141765, Depth Loss=0.0000000]
Training progress:   4%|▎         | 70/2000 [00:29<13:12,  2.44it/s, Loss=0.1828265, Gaussian number=182686, print grad=0.0012495293049141765, Depth Loss=0.0000000]
Training progress:   4%|▎         | 70/2000 [00:34<13:12,  2.44it/s, Loss=0.2235202, Gaussian number=182686, print grad=0.0014550440246239305, Depth Loss=0.0000000]
Training progress:   4%|▍         | 80/2000 [00:34<13:04,  2.45it/s, Loss=0.2235202, Gaussian number=182686, print grad=0.0014550440246239305, Depth Loss=0.0000000]
Training progress:   4%|▍         | 80/2000 [00:38<13:04,  2.45it/s, Loss=0.1885859, Gaussian number=182686, print grad=0.0016664997674524784, Depth Loss=0.0000000]
Training progress:   4%|▍         | 90/2000 [00:38<12:57,  2.46it/s, Loss=0.1885859, Gaussian number=182686, print grad=0.0016664997674524784, Depth Loss=0.0000000]
Training progress:   4%|▍         | 90/2000 [00:42<12:57,  2.46it/s, Loss=0.1843887, Gaussian number=182686, print grad=0.001917919609695673, Depth Loss=0.0000000] 
Training progress:   5%|▌         | 100/2000 [00:42<12:52,  2.46it/s, Loss=0.1843887, Gaussian number=182686, print grad=0.001917919609695673, Depth Loss=0.0000000]
Training progress:   5%|▌         | 100/2000 [01:51<12:52,  2.46it/s, Loss=0.2132789, Gaussian number=182686, print grad=0.0021906537003815174, Depth Loss=0.0000000]
Training progress:   6%|▌         | 110/2000 [01:51<1:16:04,  2.42s/it, Loss=0.2132789, Gaussian number=182686, print grad=0.0021906537003815174, Depth Loss=0.0000000]
Training progress:   6%|▌         | 110/2000 [01:55<1:16:04,  2.42s/it, Loss=0.1783269, Gaussian number=182686, print grad=0.0024488838389515877, Depth Loss=0.0000000]
Training progress:   6%|▌         | 120/2000 [01:55<56:29,  1.80s/it, Loss=0.1783269, Gaussian number=182686, print grad=0.0024488838389515877, Depth Loss=0.0000000]  
Training progress:   6%|▌         | 120/2000 [01:59<56:29,  1.80s/it, Loss=0.2039829, Gaussian number=182686, print grad=0.0027729631401598454, Depth Loss=0.0000000]
Training progress:   6%|▋         | 130/2000 [01:59<42:58,  1.38s/it, Loss=0.2039829, Gaussian number=182686, print grad=0.0027729631401598454, Depth Loss=0.0000000]
Training progress:   6%|▋         | 130/2000 [02:03<42:58,  1.38s/it, Loss=0.1866695, Gaussian number=182686, print grad=0.0030975753907114267, Depth Loss=0.0000000]
Training progress:   7%|▋         | 140/2000 [02:03<33:36,  1.08s/it, Loss=0.1866695, Gaussian number=182686, print grad=0.0030975753907114267, Depth Loss=0.0000000]
Training progress:   7%|▋         | 140/2000 [02:07<33:36,  1.08s/it, Loss=0.1649976, Gaussian number=182686, print grad=0.0033900088164955378, Depth Loss=0.0000000]
Training progress:   8%|▊         | 150/2000 [02:07<27:04,  1.14it/s, Loss=0.1649976, Gaussian number=182686, print grad=0.0033900088164955378, Depth Loss=0.0000000]
Training progress:   8%|▊         | 150/2000 [02:11<27:04,  1.14it/s, Loss=0.1740027, Gaussian number=182686, print grad=0.0037572120781987906, Depth Loss=0.0000000]
Training progress:   8%|▊         | 160/2000 [02:11<22:30,  1.36it/s, Loss=0.1740027, Gaussian number=182686, print grad=0.0037572120781987906, Depth Loss=0.0000000]
Training progress:   8%|▊         | 160/2000 [02:15<22:30,  1.36it/s, Loss=0.1725424, Gaussian number=182686, print grad=0.00404866598546505, Depth Loss=0.0000000]  
Training progress:   8%|▊         | 170/2000 [02:15<19:20,  1.58it/s, Loss=0.1725424, Gaussian number=182686, print grad=0.00404866598546505, Depth Loss=0.0000000]
Training progress:   8%|▊         | 170/2000 [02:19<19:20,  1.58it/s, Loss=0.1481746, Gaussian number=182686, print grad=0.004382710438221693, Depth Loss=0.0000000]
Training progress:   9%|▉         | 180/2000 [02:19<17:06,  1.77it/s, Loss=0.1481746, Gaussian number=182686, print grad=0.004382710438221693, Depth Loss=0.0000000]
Training progress:   9%|▉         | 180/2000 [02:23<17:06,  1.77it/s, Loss=0.1909134, Gaussian number=182686, print grad=0.004673048388212919, Depth Loss=0.0000000]
Training progress:  10%|▉         | 190/2000 [02:23<15:32,  1.94it/s, Loss=0.1909134, Gaussian number=182686, print grad=0.004673048388212919, Depth Loss=0.0000000]
Training progress:  10%|▉         | 190/2000 [02:27<15:32,  1.94it/s, Loss=0.1660479, Gaussian number=182686, print grad=0.005032778717577457, Depth Loss=0.0000000]
Training progress:  10%|█         | 200/2000 [02:27<14:25,  2.08it/s, Loss=0.1660479, Gaussian number=182686, print grad=0.005032778717577457, Depth Loss=0.0000000]
Training progress:  10%|█         | 200/2000 [03:37<14:25,  2.08it/s, Loss=0.1876426, Gaussian number=182686, print grad=0.0053978413343429565, Depth Loss=0.0000000]
Training progress:  10%|█         | 210/2000 [03:37<1:12:16,  2.42s/it, Loss=0.1876426, Gaussian number=182686, print grad=0.0053978413343429565, Depth Loss=0.0000000]
Training progress:  10%|█         | 210/2000 [03:41<1:12:16,  2.42s/it, Loss=0.1528845, Gaussian number=182686, print grad=0.005726720672100782, Depth Loss=0.0000000] 
Training progress:  11%|█         | 220/2000 [03:41<53:51,  1.82s/it, Loss=0.1528845, Gaussian number=182686, print grad=0.005726720672100782, Depth Loss=0.0000000]  
Training progress:  11%|█         | 220/2000 [03:45<53:51,  1.82s/it, Loss=0.1712759, Gaussian number=182686, print grad=0.006070408038794994, Depth Loss=0.0000000]
Training progress:  12%|█▏        | 230/2000 [03:45<41:01,  1.39s/it, Loss=0.1712759, Gaussian number=182686, print grad=0.006070408038794994, Depth Loss=0.0000000]
Training progress:  12%|█▏        | 230/2000 [03:49<41:01,  1.39s/it, Loss=0.2093555, Gaussian number=182686, print grad=0.006394593510776758, Depth Loss=0.0000000]
Training progress:  12%|█▏        | 240/2000 [03:49<32:04,  1.09s/it, Loss=0.2093555, Gaussian number=182686, print grad=0.006394593510776758, Depth Loss=0.0000000]
Training progress:  12%|█▏        | 240/2000 [03:53<32:04,  1.09s/it, Loss=0.1619930, Gaussian number=182686, print grad=0.00675599928945303, Depth Loss=0.0000000] 
Training progress:  12%|█▎        | 250/2000 [03:53<25:48,  1.13it/s, Loss=0.1619930, Gaussian number=182686, print grad=0.00675599928945303, Depth Loss=0.0000000]
Training progress:  12%|█▎        | 250/2000 [03:57<25:48,  1.13it/s, Loss=0.1817641, Gaussian number=182686, print grad=0.0070922779850661755, Depth Loss=0.0000000]
Training progress:  13%|█▎        | 260/2000 [03:57<21:25,  1.35it/s, Loss=0.1817641, Gaussian number=182686, print grad=0.0070922779850661755, Depth Loss=0.0000000]
Training progress:  13%|█▎        | 260/2000 [04:01<21:25,  1.35it/s, Loss=0.1280807, Gaussian number=182686, print grad=0.007446163799613714, Depth Loss=0.0000000] 
Training progress:  14%|█▎        | 270/2000 [04:01<18:22,  1.57it/s, Loss=0.1280807, Gaussian number=182686, print grad=0.007446163799613714, Depth Loss=0.0000000]
Training progress:  14%|█▎        | 270/2000 [04:05<18:22,  1.57it/s, Loss=0.1641370, Gaussian number=182686, print grad=0.00785111915320158, Depth Loss=0.0000000] 
Training progress:  14%|█▍        | 280/2000 [04:05<16:12,  1.77it/s, Loss=0.1641370, Gaussian number=182686, print grad=0.00785111915320158, Depth Loss=0.0000000]
Training progress:  14%|█▍        | 280/2000 [04:09<16:12,  1.77it/s, Loss=0.1681871, Gaussian number=182686, print grad=0.00822900515049696, Depth Loss=0.0000000]
Training progress:  14%|█▍        | 290/2000 [04:09<14:42,  1.94it/s, Loss=0.1681871, Gaussian number=182686, print grad=0.00822900515049696, Depth Loss=0.0000000]
Training progress:  14%|█▍        | 290/2000 [04:13<14:42,  1.94it/s, Loss=0.1568581, Gaussian number=182686, print grad=0.008619287982583046, Depth Loss=0.0000000]
Training progress:  15%|█▌        | 300/2000 [04:13<13:38,  2.08it/s, Loss=0.1568581, Gaussian number=182686, print grad=0.008619287982583046, Depth Loss=0.0000000]
Training progress:  15%|█▌        | 300/2000 [05:22<13:38,  2.08it/s, Loss=0.1303898, Gaussian number=182686, print grad=0.009025881998240948, Depth Loss=0.0000000]
Training progress:  16%|█▌        | 310/2000 [05:22<1:08:11,  2.42s/it, Loss=0.1303898, Gaussian number=182686, print grad=0.009025881998240948, Depth Loss=0.0000000]
Training progress:  16%|█▌        | 310/2000 [05:26<1:08:11,  2.42s/it, Loss=0.1359697, Gaussian number=182686, print grad=0.009319738484919071, Depth Loss=0.0000000]
Training progress:  16%|█▌        | 320/2000 [05:26<50:47,  1.81s/it, Loss=0.1359697, Gaussian number=182686, print grad=0.009319738484919071, Depth Loss=0.0000000]  
Training progress:  16%|█▌        | 320/2000 [05:30<50:47,  1.81s/it, Loss=0.1792736, Gaussian number=182686, print grad=0.009671613574028015, Depth Loss=0.0000000]
Training progress:  16%|█▋        | 330/2000 [05:30<38:40,  1.39s/it, Loss=0.1792736, Gaussian number=182686, print grad=0.009671613574028015, Depth Loss=0.0000000]
Training progress:  16%|█▋        | 330/2000 [05:34<38:40,  1.39s/it, Loss=0.1301570, Gaussian number=182686, print grad=0.010072181932628155, Depth Loss=0.0000000]
Training progress:  17%|█▋        | 340/2000 [05:34<30:12,  1.09s/it, Loss=0.1301570, Gaussian number=182686, print grad=0.010072181932628155, Depth Loss=0.0000000]
Training progress:  17%|█▋        | 340/2000 [05:38<30:12,  1.09s/it, Loss=0.1380880, Gaussian number=182686, print grad=0.010445963591337204, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 350/2000 [05:38<24:18,  1.13it/s, Loss=0.1380880, Gaussian number=182686, print grad=0.010445963591337204, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 350/2000 [05:42<24:18,  1.13it/s, Loss=0.1321475, Gaussian number=182686, print grad=0.010891995392739773, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 360/2000 [05:42<20:09,  1.36it/s, Loss=0.1321475, Gaussian number=182686, print grad=0.010891995392739773, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 360/2000 [05:46<20:09,  1.36it/s, Loss=0.1288202, Gaussian number=182686, print grad=0.011284678243100643, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 370/2000 [05:46<17:16,  1.57it/s, Loss=0.1288202, Gaussian number=182686, print grad=0.011284678243100643, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 370/2000 [05:50<17:16,  1.57it/s, Loss=0.1730659, Gaussian number=182686, print grad=0.011615847237408161, Depth Loss=0.0000000]
Training progress:  19%|█▉        | 380/2000 [05:50<15:14,  1.77it/s, Loss=0.1730659, Gaussian number=182686, print grad=0.011615847237408161, Depth Loss=0.0000000]
Training progress:  19%|█▉        | 380/2000 [05:54<15:14,  1.77it/s, Loss=0.1530622, Gaussian number=182686, print grad=0.012026291340589523, Depth Loss=0.0000000]
Training progress:  20%|█▉        | 390/2000 [05:54<13:48,  1.94it/s, Loss=0.1530622, Gaussian number=182686, print grad=0.012026291340589523, Depth Loss=0.0000000]
Training progress:  20%|█▉        | 390/2000 [05:58<13:48,  1.94it/s, Loss=0.1843219, Gaussian number=182686, print grad=0.012408949434757233, Depth Loss=0.0000000]
Training progress:  20%|██        | 400/2000 [05:58<12:46,  2.09it/s, Loss=0.1843219, Gaussian number=182686, print grad=0.012408949434757233, Depth Loss=0.0000000]
Training progress:  20%|██        | 400/2000 [06:02<12:46,  2.09it/s, Loss=0.1567052, Gaussian number=182686, print grad=0.012863146141171455, Depth Loss=0.0000000]
Training progress:  20%|██        | 410/2000 [06:02<12:03,  2.20it/s, Loss=0.1567052, Gaussian number=182686, print grad=0.012863146141171455, Depth Loss=0.0000000]
Training progress:  20%|██        | 410/2000 [06:06<12:03,  2.20it/s, Loss=0.1401760, Gaussian number=182686, print grad=0.013292241841554642, Depth Loss=0.0000000]
Training progress:  21%|██        | 420/2000 [06:06<11:31,  2.28it/s, Loss=0.1401760, Gaussian number=182686, print grad=0.013292241841554642, Depth Loss=0.0000000]
Training progress:  21%|██        | 420/2000 [06:10<11:31,  2.28it/s, Loss=0.1757840, Gaussian number=182686, print grad=0.013734250329434872, Depth Loss=0.0000000]
Training progress:  22%|██▏       | 430/2000 [06:10<11:08,  2.35it/s, Loss=0.1757840, Gaussian number=182686, print grad=0.013734250329434872, Depth Loss=0.0000000]
Training progress:  22%|██▏       | 430/2000 [06:14<11:08,  2.35it/s, Loss=0.1368416, Gaussian number=182686, print grad=0.014150365255773067, Depth Loss=0.0000000]
Training progress:  22%|██▏       | 440/2000 [06:14<10:51,  2.40it/s, Loss=0.1368416, Gaussian number=182686, print grad=0.014150365255773067, Depth Loss=0.0000000]
Training progress:  22%|██▏       | 440/2000 [06:18<10:51,  2.40it/s, Loss=0.1581055, Gaussian number=182686, print grad=0.014582999981939793, Depth Loss=0.0000000]
Training progress:  22%|██▎       | 450/2000 [06:18<10:37,  2.43it/s, Loss=0.1581055, Gaussian number=182686, print grad=0.014582999981939793, Depth Loss=0.0000000]
Training progress:  22%|██▎       | 450/2000 [06:22<10:37,  2.43it/s, Loss=0.1625123, Gaussian number=182686, print grad=0.015002616681158543, Depth Loss=0.0000000]
Training progress:  23%|██▎       | 460/2000 [06:22<10:27,  2.45it/s, Loss=0.1625123, Gaussian number=182686, print grad=0.015002616681158543, Depth Loss=0.0000000]
Training progress:  23%|██▎       | 460/2000 [06:26<10:27,  2.45it/s, Loss=0.1928643, Gaussian number=182686, print grad=0.015400353819131851, Depth Loss=0.0000000]
Training progress:  24%|██▎       | 470/2000 [06:26<10:18,  2.47it/s, Loss=0.1928643, Gaussian number=182686, print grad=0.015400353819131851, Depth Loss=0.0000000]
Training progress:  24%|██▎       | 470/2000 [06:30<10:18,  2.47it/s, Loss=0.1254627, Gaussian number=182686, print grad=0.01585277169942856, Depth Loss=0.0000000] 
Training progress:  24%|██▍       | 480/2000 [06:30<10:11,  2.48it/s, Loss=0.1254627, Gaussian number=182686, print grad=0.01585277169942856, Depth Loss=0.0000000]
Training progress:  24%|██▍       | 480/2000 [06:34<10:11,  2.48it/s, Loss=0.1390797, Gaussian number=182686, print grad=0.01626448892056942, Depth Loss=0.0000000]
Training progress:  24%|██▍       | 490/2000 [06:34<10:05,  2.49it/s, Loss=0.1390797, Gaussian number=182686, print grad=0.01626448892056942, Depth Loss=0.0000000]
Training progress:  24%|██▍       | 490/2000 [06:38<10:05,  2.49it/s, Loss=0.1095019, Gaussian number=182686, print grad=0.016689574345946312, Depth Loss=0.0000000]
Training progress:  25%|██▌       | 500/2000 [06:38<09:59,  2.50it/s, Loss=0.1095019, Gaussian number=182686, print grad=0.016689574345946312, Depth Loss=0.0000000]
Training progress:  25%|██▌       | 500/2000 [07:47<09:59,  2.50it/s, Loss=0.1295595, Gaussian number=182686, print grad=0.017114795744419098, Depth Loss=0.0000000]
Training progress:  26%|██▌       | 510/2000 [07:47<58:45,  2.37s/it, Loss=0.1295595, Gaussian number=182686, print grad=0.017114795744419098, Depth Loss=0.0000000]
Training progress:  26%|██▌       | 510/2000 [07:51<58:45,  2.37s/it, Loss=0.1324632, Gaussian number=182686, print grad=0.017561161890625954, Depth Loss=0.0000000]
Training progress:  26%|██▌       | 520/2000 [07:51<43:47,  1.78s/it, Loss=0.1324632, Gaussian number=182686, print grad=0.017561161890625954, Depth Loss=0.0000000]
Training progress:  26%|██▌       | 520/2000 [07:55<43:47,  1.78s/it, Loss=0.1048374, Gaussian number=182686, print grad=0.017947949469089508, Depth Loss=0.0000000]
Training progress:  26%|██▋       | 530/2000 [07:55<33:20,  1.36s/it, Loss=0.1048374, Gaussian number=182686, print grad=0.017947949469089508, Depth Loss=0.0000000]
Training progress:  26%|██▋       | 530/2000 [07:59<33:20,  1.36s/it, Loss=0.1416176, Gaussian number=182686, print grad=0.018374385312199593, Depth Loss=0.0000000]
Training progress:  27%|██▋       | 540/2000 [07:59<26:04,  1.07s/it, Loss=0.1416176, Gaussian number=182686, print grad=0.018374385312199593, Depth Loss=0.0000000]
Training progress:  27%|██▋       | 540/2000 [08:03<26:04,  1.07s/it, Loss=0.1353208, Gaussian number=182686, print grad=0.01882970705628395, Depth Loss=0.0000000] 
Training progress:  28%|██▊       | 550/2000 [08:03<21:00,  1.15it/s, Loss=0.1353208, Gaussian number=182686, print grad=0.01882970705628395, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 550/2000 [08:07<21:00,  1.15it/s, Loss=0.1081157, Gaussian number=182686, print grad=0.0192498117685318, Depth Loss=0.0000000] 
Training progress:  28%|██▊       | 560/2000 [08:07<17:26,  1.38it/s, Loss=0.1081157, Gaussian number=182686, print grad=0.0192498117685318, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 560/2000 [08:11<17:26,  1.38it/s, Loss=0.1451782, Gaussian number=182686, print grad=0.019719883799552917, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 570/2000 [08:11<14:57,  1.59it/s, Loss=0.1451782, Gaussian number=182686, print grad=0.019719883799552917, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 570/2000 [08:15<14:57,  1.59it/s, Loss=0.1235108, Gaussian number=182686, print grad=0.020151635631918907, Depth Loss=0.0000000]
Training progress:  29%|██▉       | 580/2000 [08:15<13:12,  1.79it/s, Loss=0.1235108, Gaussian number=182686, print grad=0.020151635631918907, Depth Loss=0.0000000]
Training progress:  29%|██▉       | 580/2000 [08:19<13:12,  1.79it/s, Loss=0.1435889, Gaussian number=182686, print grad=0.020604567602276802, Depth Loss=0.0000000]
Training progress:  30%|██▉       | 590/2000 [08:19<11:58,  1.96it/s, Loss=0.1435889, Gaussian number=182686, print grad=0.020604567602276802, Depth Loss=0.0000000]
Training progress:  30%|██▉       | 590/2000 [08:23<11:58,  1.96it/s, Loss=0.1438142, Gaussian number=182686, print grad=0.021020079031586647, Depth Loss=0.0000000]
Training progress:  30%|███       | 600/2000 [08:23<11:06,  2.10it/s, Loss=0.1438142, Gaussian number=182686, print grad=0.021020079031586647, Depth Loss=0.0000000]
Training progress:  30%|███       | 600/2000 [08:27<11:06,  2.10it/s, Loss=0.1265792, Gaussian number=187705, print grad=0.000422703247750178, Depth Loss=0.0000000]
Training progress:  30%|███       | 610/2000 [08:27<10:28,  2.21it/s, Loss=0.1265792, Gaussian number=187705, print grad=0.000422703247750178, Depth Loss=0.0000000]
Training progress:  30%|███       | 610/2000 [08:31<10:28,  2.21it/s, Loss=0.1711733, Gaussian number=187705, print grad=0.0009228599374182522, Depth Loss=0.0000000]
Training progress:  31%|███       | 620/2000 [08:31<10:01,  2.30it/s, Loss=0.1711733, Gaussian number=187705, print grad=0.0009228599374182522, Depth Loss=0.0000000]
Training progress:  31%|███       | 620/2000 [08:35<10:01,  2.30it/s, Loss=0.1182402, Gaussian number=187705, print grad=0.0013465102529153228, Depth Loss=0.0000000]
Training progress:  32%|███▏      | 630/2000 [08:35<09:42,  2.35it/s, Loss=0.1182402, Gaussian number=187705, print grad=0.0013465102529153228, Depth Loss=0.0000000]
Training progress:  32%|███▏      | 630/2000 [08:39<09:42,  2.35it/s, Loss=0.1262058, Gaussian number=187705, print grad=0.0018664608942344785, Depth Loss=0.0000000]
Training progress:  32%|███▏      | 640/2000 [08:39<09:26,  2.40it/s, Loss=0.1262058, Gaussian number=187705, print grad=0.0018664608942344785, Depth Loss=0.0000000]
Training progress:  32%|███▏      | 640/2000 [08:43<09:26,  2.40it/s, Loss=0.1466138, Gaussian number=187705, print grad=0.002270758617669344, Depth Loss=0.0000000] 
Training progress:  32%|███▎      | 650/2000 [08:43<09:14,  2.43it/s, Loss=0.1466138, Gaussian number=187705, print grad=0.002270758617669344, Depth Loss=0.0000000]
Training progress:  32%|███▎      | 650/2000 [08:47<09:14,  2.43it/s, Loss=0.1490116, Gaussian number=187705, print grad=0.002759726718068123, Depth Loss=0.0000000]
Training progress:  33%|███▎      | 660/2000 [08:47<09:05,  2.46it/s, Loss=0.1490116, Gaussian number=187705, print grad=0.002759726718068123, Depth Loss=0.0000000]
Training progress:  33%|███▎      | 660/2000 [08:51<09:05,  2.46it/s, Loss=0.1277114, Gaussian number=187705, print grad=0.003198204329237342, Depth Loss=0.0000000]
Training progress:  34%|███▎      | 670/2000 [08:51<08:57,  2.48it/s, Loss=0.1277114, Gaussian number=187705, print grad=0.003198204329237342, Depth Loss=0.0000000]
Training progress:  34%|███▎      | 670/2000 [08:55<08:57,  2.48it/s, Loss=0.1202896, Gaussian number=187705, print grad=0.0036884681321680546, Depth Loss=0.0000000]
Training progress:  34%|███▍      | 680/2000 [08:55<08:50,  2.49it/s, Loss=0.1202896, Gaussian number=187705, print grad=0.0036884681321680546, Depth Loss=0.0000000]
Training progress:  34%|███▍      | 680/2000 [08:59<08:50,  2.49it/s, Loss=0.1406227, Gaussian number=187705, print grad=0.0041362144984304905, Depth Loss=0.0000000]
Training progress:  34%|███▍      | 690/2000 [08:59<08:44,  2.50it/s, Loss=0.1406227, Gaussian number=187705, print grad=0.0041362144984304905, Depth Loss=0.0000000]
Training progress:  34%|███▍      | 690/2000 [09:03<08:44,  2.50it/s, Loss=0.1409406, Gaussian number=187705, print grad=0.004572575446218252, Depth Loss=0.0000000] 
Training progress:  35%|███▌      | 700/2000 [09:03<08:39,  2.50it/s, Loss=0.1409406, Gaussian number=187705, print grad=0.004572575446218252, Depth Loss=0.0000000]
Training progress:  35%|███▌      | 700/2000 [09:07<08:39,  2.50it/s, Loss=0.1331621, Gaussian number=200766, print grad=0.00041927321581169963, Depth Loss=0.0000000]
Training progress:  36%|███▌      | 710/2000 [09:07<08:34,  2.51it/s, Loss=0.1331621, Gaussian number=200766, print grad=0.00041927321581169963, Depth Loss=0.0000000]
Training progress:  36%|███▌      | 710/2000 [09:11<08:34,  2.51it/s, Loss=0.1189326, Gaussian number=200766, print grad=0.0008984978194348514, Depth Loss=0.0000000] 
Training progress:  36%|███▌      | 720/2000 [09:11<08:29,  2.51it/s, Loss=0.1189326, Gaussian number=200766, print grad=0.0008984978194348514, Depth Loss=0.0000000]
Training progress:  36%|███▌      | 720/2000 [09:15<08:29,  2.51it/s, Loss=0.1565304, Gaussian number=200766, print grad=0.0013305227039381862, Depth Loss=0.0000000]
Training progress:  36%|███▋      | 730/2000 [09:15<08:24,  2.52it/s, Loss=0.1565304, Gaussian number=200766, print grad=0.0013305227039381862, Depth Loss=0.0000000]
Training progress:  36%|███▋      | 730/2000 [09:19<08:24,  2.52it/s, Loss=0.1828414, Gaussian number=200766, print grad=0.0018496158299967647, Depth Loss=0.0000000]
Training progress:  37%|███▋      | 740/2000 [09:19<08:19,  2.52it/s, Loss=0.1828414, Gaussian number=200766, print grad=0.0018496158299967647, Depth Loss=0.0000000]
Training progress:  37%|███▋      | 740/2000 [09:23<08:19,  2.52it/s, Loss=0.1277179, Gaussian number=200766, print grad=0.0023265068884938955, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 750/2000 [09:23<08:16,  2.52it/s, Loss=0.1277179, Gaussian number=200766, print grad=0.0023265068884938955, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 750/2000 [09:27<08:16,  2.52it/s, Loss=0.1222460, Gaussian number=200766, print grad=0.002775105182081461, Depth Loss=0.0000000] 
Training progress:  38%|███▊      | 760/2000 [09:27<08:11,  2.52it/s, Loss=0.1222460, Gaussian number=200766, print grad=0.002775105182081461, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 760/2000 [09:31<08:11,  2.52it/s, Loss=0.1113520, Gaussian number=200766, print grad=0.003255664836615324, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 770/2000 [09:31<08:07,  2.52it/s, Loss=0.1113520, Gaussian number=200766, print grad=0.003255664836615324, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 770/2000 [09:35<08:07,  2.52it/s, Loss=0.1519395, Gaussian number=200766, print grad=0.0036822734400629997, Depth Loss=0.0000000]
Training progress:  39%|███▉      | 780/2000 [09:35<08:03,  2.52it/s, Loss=0.1519395, Gaussian number=200766, print grad=0.0036822734400629997, Depth Loss=0.0000000]
Training progress:  39%|███▉      | 780/2000 [09:39<08:03,  2.52it/s, Loss=0.1707660, Gaussian number=200766, print grad=0.004130528308451176, Depth Loss=0.0000000] 
Training progress:  40%|███▉      | 790/2000 [09:39<07:59,  2.52it/s, Loss=0.1707660, Gaussian number=200766, print grad=0.004130528308451176, Depth Loss=0.0000000]
Training progress:  40%|███▉      | 790/2000 [09:43<07:59,  2.52it/s, Loss=0.1448718, Gaussian number=200766, print grad=0.004607814364135265, Depth Loss=0.0000000]
Training progress:  40%|████      | 800/2000 [09:43<07:55,  2.52it/s, Loss=0.1448718, Gaussian number=200766, print grad=0.004607814364135265, Depth Loss=0.0000000]
Training progress:  40%|████      | 800/2000 [09:46<07:55,  2.52it/s, Loss=0.1537427, Gaussian number=214856, print grad=0.000434338377090171, Depth Loss=0.0000000]
Training progress:  40%|████      | 810/2000 [09:46<07:51,  2.52it/s, Loss=0.1537427, Gaussian number=214856, print grad=0.000434338377090171, Depth Loss=0.0000000]
Training progress:  40%|████      | 810/2000 [09:50<07:51,  2.52it/s, Loss=0.1443141, Gaussian number=214856, print grad=0.0008946509915404022, Depth Loss=0.0000000]
Training progress:  41%|████      | 820/2000 [09:50<07:47,  2.52it/s, Loss=0.1443141, Gaussian number=214856, print grad=0.0008946509915404022, Depth Loss=0.0000000]
Training progress:  41%|████      | 820/2000 [09:54<07:47,  2.52it/s, Loss=0.1156687, Gaussian number=214856, print grad=0.0014415817568078637, Depth Loss=0.0000000]
Training progress:  42%|████▏     | 830/2000 [09:54<07:46,  2.51it/s, Loss=0.1156687, Gaussian number=214856, print grad=0.0014415817568078637, Depth Loss=0.0000000]
Training progress:  42%|████▏     | 830/2000 [09:58<07:46,  2.51it/s, Loss=0.1237828, Gaussian number=214856, print grad=0.0019077424658462405, Depth Loss=0.0000000]
Training progress:  42%|████▏     | 840/2000 [09:58<07:41,  2.51it/s, Loss=0.1237828, Gaussian number=214856, print grad=0.0019077424658462405, Depth Loss=0.0000000]
Training progress:  42%|████▏     | 840/2000 [10:02<07:41,  2.51it/s, Loss=0.1238694, Gaussian number=214856, print grad=0.0023815794847905636, Depth Loss=0.0000000]
Training progress:  42%|████▎     | 850/2000 [10:02<07:37,  2.52it/s, Loss=0.1238694, Gaussian number=214856, print grad=0.0023815794847905636, Depth Loss=0.0000000]
Training progress:  42%|████▎     | 850/2000 [10:06<07:37,  2.52it/s, Loss=0.1256669, Gaussian number=214856, print grad=0.0028139895293861628, Depth Loss=0.0000000]
Training progress:  43%|████▎     | 860/2000 [10:06<07:32,  2.52it/s, Loss=0.1256669, Gaussian number=214856, print grad=0.0028139895293861628, Depth Loss=0.0000000]
Training progress:  43%|████▎     | 860/2000 [10:10<07:32,  2.52it/s, Loss=0.1456198, Gaussian number=214856, print grad=0.003252787049859762, Depth Loss=0.0000000] 
Training progress:  44%|████▎     | 870/2000 [10:10<07:28,  2.52it/s, Loss=0.1456198, Gaussian number=214856, print grad=0.003252787049859762, Depth Loss=0.0000000]
Training progress:  44%|████▎     | 870/2000 [10:14<07:28,  2.52it/s, Loss=0.1351758, Gaussian number=214856, print grad=0.003690762212499976, Depth Loss=0.0000000]
Training progress:  44%|████▍     | 880/2000 [10:14<07:24,  2.52it/s, Loss=0.1351758, Gaussian number=214856, print grad=0.003690762212499976, Depth Loss=0.0000000]
Training progress:  44%|████▍     | 880/2000 [10:18<07:24,  2.52it/s, Loss=0.1082405, Gaussian number=214856, print grad=0.004141578450798988, Depth Loss=0.0000000]
Training progress:  44%|████▍     | 890/2000 [10:18<07:20,  2.52it/s, Loss=0.1082405, Gaussian number=214856, print grad=0.004141578450798988, Depth Loss=0.0000000]
Training progress:  44%|████▍     | 890/2000 [10:22<07:20,  2.52it/s, Loss=0.1397720, Gaussian number=214856, print grad=0.004586441908031702, Depth Loss=0.0000000]
Training progress:  45%|████▌     | 900/2000 [10:22<07:16,  2.52it/s, Loss=0.1397720, Gaussian number=214856, print grad=0.004586441908031702, Depth Loss=0.0000000]
Training progress:  45%|████▌     | 900/2000 [10:26<07:16,  2.52it/s, Loss=0.1200703, Gaussian number=229943, print grad=0.00041055859765037894, Depth Loss=0.0000000]
Training progress:  46%|████▌     | 910/2000 [10:26<07:13,  2.52it/s, Loss=0.1200703, Gaussian number=229943, print grad=0.00041055859765037894, Depth Loss=0.0000000]
Training progress:  46%|████▌     | 910/2000 [10:30<07:13,  2.52it/s, Loss=0.1331064, Gaussian number=229943, print grad=0.0008147209882736206, Depth Loss=0.0000000] 
Training progress:  46%|████▌     | 920/2000 [10:30<07:09,  2.51it/s, Loss=0.1331064, Gaussian number=229943, print grad=0.0008147209882736206, Depth Loss=0.0000000]
Training progress:  46%|████▌     | 920/2000 [10:34<07:09,  2.51it/s, Loss=0.1428562, Gaussian number=229943, print grad=0.001322904834523797, Depth Loss=0.0000000] 
Training progress:  46%|████▋     | 930/2000 [10:34<07:05,  2.51it/s, Loss=0.1428562, Gaussian number=229943, print grad=0.001322904834523797, Depth Loss=0.0000000]
Training progress:  46%|████▋     | 930/2000 [10:38<07:05,  2.51it/s, Loss=0.1249950, Gaussian number=229943, print grad=0.001745284185744822, Depth Loss=0.0000000]
Training progress:  47%|████▋     | 940/2000 [10:38<07:02,  2.51it/s, Loss=0.1249950, Gaussian number=229943, print grad=0.001745284185744822, Depth Loss=0.0000000]
Training progress:  47%|████▋     | 940/2000 [10:42<07:02,  2.51it/s, Loss=0.1243125, Gaussian number=229943, print grad=0.0021948914509266615, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 950/2000 [10:42<06:58,  2.51it/s, Loss=0.1243125, Gaussian number=229943, print grad=0.0021948914509266615, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 950/2000 [10:46<06:58,  2.51it/s, Loss=0.1253748, Gaussian number=229943, print grad=0.0026113176718354225, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 960/2000 [10:46<06:54,  2.51it/s, Loss=0.1253748, Gaussian number=229943, print grad=0.0026113176718354225, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 960/2000 [10:50<06:54,  2.51it/s, Loss=0.1622277, Gaussian number=229943, print grad=0.003086043754592538, Depth Loss=0.0000000] 
Training progress:  48%|████▊     | 970/2000 [10:50<06:50,  2.51it/s, Loss=0.1622277, Gaussian number=229943, print grad=0.003086043754592538, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 970/2000 [10:54<06:50,  2.51it/s, Loss=0.1023455, Gaussian number=229943, print grad=0.003523187479004264, Depth Loss=0.0000000]
Training progress:  49%|████▉     | 980/2000 [10:54<06:46,  2.51it/s, Loss=0.1023455, Gaussian number=229943, print grad=0.003523187479004264, Depth Loss=0.0000000]
Training progress:  49%|████▉     | 980/2000 [10:58<06:46,  2.51it/s, Loss=0.1060869, Gaussian number=229943, print grad=0.003910129424184561, Depth Loss=0.0000000]
Training progress:  50%|████▉     | 990/2000 [10:58<06:42,  2.51it/s, Loss=0.1060869, Gaussian number=229943, print grad=0.003910129424184561, Depth Loss=0.0000000]
Training progress:  50%|████▉     | 990/2000 [11:02<06:42,  2.51it/s, Loss=0.1382287, Gaussian number=229943, print grad=0.004278417676687241, Depth Loss=0.0000000]
Training progress:  50%|█████     | 1000/2000 [11:02<06:38,  2.51it/s, Loss=0.1382287, Gaussian number=229943, print grad=0.004278417676687241, Depth Loss=0.0000000]
Training progress:  50%|█████     | 1000/2000 [12:12<06:38,  2.51it/s, Loss=0.1398620, Gaussian number=245221, print grad=0.0003791006456594914, Depth Loss=0.0000000]
Training progress:  50%|█████     | 1010/2000 [12:12<39:05,  2.37s/it, Loss=0.1398620, Gaussian number=245221, print grad=0.0003791006456594914, Depth Loss=0.0000000]
Training progress:  50%|█████     | 1010/2000 [12:16<39:05,  2.37s/it, Loss=0.1719160, Gaussian number=245221, print grad=0.0008879648521542549, Depth Loss=0.0000000]
Training progress:  51%|█████     | 1020/2000 [12:16<29:02,  1.78s/it, Loss=0.1719160, Gaussian number=245221, print grad=0.0008879648521542549, Depth Loss=0.0000000]
Training progress:  51%|█████     | 1020/2000 [12:20<29:02,  1.78s/it, Loss=0.1341610, Gaussian number=245221, print grad=0.0013376438291743398, Depth Loss=0.0000000]
Training progress:  52%|█████▏    | 1030/2000 [12:20<22:03,  1.36s/it, Loss=0.1341610, Gaussian number=245221, print grad=0.0013376438291743398, Depth Loss=0.0000000]
Training progress:  52%|█████▏    | 1030/2000 [12:24<22:03,  1.36s/it, Loss=0.1383199, Gaussian number=245221, print grad=0.0018167317612096667, Depth Loss=0.0000000]
Training progress:  52%|█████▏    | 1040/2000 [12:24<17:10,  1.07s/it, Loss=0.1383199, Gaussian number=245221, print grad=0.0018167317612096667, Depth Loss=0.0000000]
Training progress:  52%|█████▏    | 1040/2000 [12:28<17:10,  1.07s/it, Loss=0.1266929, Gaussian number=245221, print grad=0.0021954237017780542, Depth Loss=0.0000000]
Training progress:  52%|█████▎    | 1050/2000 [12:28<13:47,  1.15it/s, Loss=0.1266929, Gaussian number=245221, print grad=0.0021954237017780542, Depth Loss=0.0000000]
Training progress:  52%|█████▎    | 1050/2000 [12:32<13:47,  1.15it/s, Loss=0.1189017, Gaussian number=245221, print grad=0.002611238742247224, Depth Loss=0.0000000] 
Training progress:  53%|█████▎    | 1060/2000 [12:32<11:24,  1.37it/s, Loss=0.1189017, Gaussian number=245221, print grad=0.002611238742247224, Depth Loss=0.0000000]
Training progress:  53%|█████▎    | 1060/2000 [12:36<11:24,  1.37it/s, Loss=0.0991559, Gaussian number=245221, print grad=0.0030730990692973137, Depth Loss=0.0000000]
Training progress:  54%|█████▎    | 1070/2000 [12:36<09:45,  1.59it/s, Loss=0.0991559, Gaussian number=245221, print grad=0.0030730990692973137, Depth Loss=0.0000000]
Training progress:  54%|█████▎    | 1070/2000 [12:40<09:45,  1.59it/s, Loss=0.1027865, Gaussian number=245221, print grad=0.003468316514045, Depth Loss=0.0000000]    
Training progress:  54%|█████▍    | 1080/2000 [12:40<08:35,  1.79it/s, Loss=0.1027865, Gaussian number=245221, print grad=0.003468316514045, Depth Loss=0.0000000]
Training progress:  54%|█████▍    | 1080/2000 [12:44<08:35,  1.79it/s, Loss=0.1305073, Gaussian number=245221, print grad=0.0038897795602679253, Depth Loss=0.0000000]
Training progress:  55%|█████▍    | 1090/2000 [12:44<07:45,  1.96it/s, Loss=0.1305073, Gaussian number=245221, print grad=0.0038897795602679253, Depth Loss=0.0000000]
Training progress:  55%|█████▍    | 1090/2000 [12:48<07:45,  1.96it/s, Loss=0.1296783, Gaussian number=245221, print grad=0.004298926331102848, Depth Loss=0.0000000] 
Training progress:  55%|█████▌    | 1100/2000 [12:48<07:09,  2.09it/s, Loss=0.1296783, Gaussian number=245221, print grad=0.004298926331102848, Depth Loss=0.0000000]
Training progress:  55%|█████▌    | 1100/2000 [12:52<07:09,  2.09it/s, Loss=0.1487578, Gaussian number=261632, print grad=0.0003719248343259096, Depth Loss=0.0000000]
Training progress:  56%|█████▌    | 1110/2000 [12:52<06:43,  2.20it/s, Loss=0.1487578, Gaussian number=261632, print grad=0.0003719248343259096, Depth Loss=0.0000000]
Training progress:  56%|█████▌    | 1110/2000 [12:56<06:43,  2.20it/s, Loss=0.1400850, Gaussian number=261632, print grad=0.0008278213790617883, Depth Loss=0.0000000]
Training progress:  56%|█████▌    | 1120/2000 [12:56<06:24,  2.29it/s, Loss=0.1400850, Gaussian number=261632, print grad=0.0008278213790617883, Depth Loss=0.0000000]
Training progress:  56%|█████▌    | 1120/2000 [12:59<06:24,  2.29it/s, Loss=0.1066935, Gaussian number=261632, print grad=0.0012966247741132975, Depth Loss=0.0000000]
Training progress:  56%|█████▋    | 1130/2000 [12:59<06:09,  2.36it/s, Loss=0.1066935, Gaussian number=261632, print grad=0.0012966247741132975, Depth Loss=0.0000000]
Training progress:  56%|█████▋    | 1130/2000 [13:03<06:09,  2.36it/s, Loss=0.1314046, Gaussian number=261632, print grad=0.0017406431725248694, Depth Loss=0.0000000]
Training progress:  57%|█████▋    | 1140/2000 [13:03<05:58,  2.40it/s, Loss=0.1314046, Gaussian number=261632, print grad=0.0017406431725248694, Depth Loss=0.0000000]
Training progress:  57%|█████▋    | 1140/2000 [13:07<05:58,  2.40it/s, Loss=0.0930417, Gaussian number=261632, print grad=0.002169722458347678, Depth Loss=0.0000000] 
Training progress:  57%|█████▊    | 1150/2000 [13:07<05:49,  2.44it/s, Loss=0.0930417, Gaussian number=261632, print grad=0.002169722458347678, Depth Loss=0.0000000]
Training progress:  57%|█████▊    | 1150/2000 [13:11<05:49,  2.44it/s, Loss=0.1006477, Gaussian number=261632, print grad=0.0025371836964040995, Depth Loss=0.0000000]
Training progress:  58%|█████▊    | 1160/2000 [13:11<05:41,  2.46it/s, Loss=0.1006477, Gaussian number=261632, print grad=0.0025371836964040995, Depth Loss=0.0000000]
Training progress:  58%|█████▊    | 1160/2000 [13:15<05:41,  2.46it/s, Loss=0.1229288, Gaussian number=261632, print grad=0.002950596157461405, Depth Loss=0.0000000] 
Training progress:  58%|█████▊    | 1170/2000 [13:15<05:35,  2.48it/s, Loss=0.1229288, Gaussian number=261632, print grad=0.002950596157461405, Depth Loss=0.0000000]
Training progress:  58%|█████▊    | 1170/2000 [13:19<05:35,  2.48it/s, Loss=0.1279123, Gaussian number=261632, print grad=0.003360630478709936, Depth Loss=0.0000000]
Training progress:  59%|█████▉    | 1180/2000 [13:19<05:29,  2.49it/s, Loss=0.1279123, Gaussian number=261632, print grad=0.003360630478709936, Depth Loss=0.0000000]
Training progress:  59%|█████▉    | 1180/2000 [13:23<05:29,  2.49it/s, Loss=0.1203514, Gaussian number=261632, print grad=0.0037937993183732033, Depth Loss=0.0000000]
Training progress:  60%|█████▉    | 1190/2000 [13:23<05:24,  2.50it/s, Loss=0.1203514, Gaussian number=261632, print grad=0.0037937993183732033, Depth Loss=0.0000000]
Training progress:  60%|█████▉    | 1190/2000 [13:27<05:24,  2.50it/s, Loss=0.1354252, Gaussian number=261632, print grad=0.004149195272475481, Depth Loss=0.0000000] 
Training progress:  60%|██████    | 1200/2000 [13:27<05:19,  2.50it/s, Loss=0.1354252, Gaussian number=261632, print grad=0.004149195272475481, Depth Loss=0.0000000]
Training progress:  60%|██████    | 1200/2000 [13:31<05:19,  2.50it/s, Loss=0.1102727, Gaussian number=278519, print grad=0.0003899404837284237, Depth Loss=0.0000000]
Training progress:  60%|██████    | 1210/2000 [13:31<05:15,  2.50it/s, Loss=0.1102727, Gaussian number=278519, print grad=0.0003899404837284237, Depth Loss=0.0000000]
Training progress:  60%|██████    | 1210/2000 [13:35<05:15,  2.50it/s, Loss=0.0991932, Gaussian number=278519, print grad=0.0008562527946196496, Depth Loss=0.0000000]
Training progress:  61%|██████    | 1220/2000 [13:35<05:11,  2.51it/s, Loss=0.0991932, Gaussian number=278519, print grad=0.0008562527946196496, Depth Loss=0.0000000]
Training progress:  61%|██████    | 1220/2000 [13:39<05:11,  2.51it/s, Loss=0.1009795, Gaussian number=278519, print grad=0.0012503928737714887, Depth Loss=0.0000000]
Training progress:  62%|██████▏   | 1230/2000 [13:39<05:06,  2.51it/s, Loss=0.1009795, Gaussian number=278519, print grad=0.0012503928737714887, Depth Loss=0.0000000]
Training progress:  62%|██████▏   | 1230/2000 [13:43<05:06,  2.51it/s, Loss=0.0982975, Gaussian number=278519, print grad=0.0016846286598592997, Depth Loss=0.0000000]
Training progress:  62%|██████▏   | 1240/2000 [13:43<05:02,  2.51it/s, Loss=0.0982975, Gaussian number=278519, print grad=0.0016846286598592997, Depth Loss=0.0000000]
Training progress:  62%|██████▏   | 1240/2000 [13:47<05:02,  2.51it/s, Loss=0.0972731, Gaussian number=278519, print grad=0.002051347168162465, Depth Loss=0.0000000] 
Training progress:  62%|██████▎   | 1250/2000 [13:47<04:58,  2.51it/s, Loss=0.0972731, Gaussian number=278519, print grad=0.002051347168162465, Depth Loss=0.0000000]
Training progress:  62%|██████▎   | 1250/2000 [13:51<04:58,  2.51it/s, Loss=0.1001173, Gaussian number=278519, print grad=0.0023960715625435114, Depth Loss=0.0000000]
Training progress:  63%|██████▎   | 1260/2000 [13:51<04:54,  2.52it/s, Loss=0.1001173, Gaussian number=278519, print grad=0.0023960715625435114, Depth Loss=0.0000000]
Training progress:  63%|██████▎   | 1260/2000 [13:55<04:54,  2.52it/s, Loss=0.1228391, Gaussian number=278519, print grad=0.0028007898945361376, Depth Loss=0.0000000]
Training progress:  64%|██████▎   | 1270/2000 [13:55<04:50,  2.52it/s, Loss=0.1228391, Gaussian number=278519, print grad=0.0028007898945361376, Depth Loss=0.0000000]
Training progress:  64%|██████▎   | 1270/2000 [13:59<04:50,  2.52it/s, Loss=0.1213434, Gaussian number=278519, print grad=0.0031634285114705563, Depth Loss=0.0000000]
Training progress:  64%|██████▍   | 1280/2000 [13:59<04:46,  2.52it/s, Loss=0.1213434, Gaussian number=278519, print grad=0.0031634285114705563, Depth Loss=0.0000000]
Training progress:  64%|██████▍   | 1280/2000 [14:03<04:46,  2.52it/s, Loss=0.0950916, Gaussian number=278519, print grad=0.003579143201932311, Depth Loss=0.0000000] 
Training progress:  64%|██████▍   | 1290/2000 [14:03<04:42,  2.51it/s, Loss=0.0950916, Gaussian number=278519, print grad=0.003579143201932311, Depth Loss=0.0000000]
Training progress:  64%|██████▍   | 1290/2000 [14:07<04:42,  2.51it/s, Loss=0.1455207, Gaussian number=278519, print grad=0.0039446367882192135, Depth Loss=0.0000000]
Training progress:  65%|██████▌   | 1300/2000 [14:07<04:38,  2.51it/s, Loss=0.1455207, Gaussian number=278519, print grad=0.0039446367882192135, Depth Loss=0.0000000]
Training progress:  65%|██████▌   | 1300/2000 [14:11<04:38,  2.51it/s, Loss=0.1418894, Gaussian number=296313, print grad=0.00041404180228710175, Depth Loss=0.0000000]
Training progress:  66%|██████▌   | 1310/2000 [14:11<04:34,  2.51it/s, Loss=0.1418894, Gaussian number=296313, print grad=0.00041404180228710175, Depth Loss=0.0000000]
Training progress:  66%|██████▌   | 1310/2000 [14:15<04:34,  2.51it/s, Loss=0.1447268, Gaussian number=296313, print grad=0.0008022022084333003, Depth Loss=0.0000000] 
Training progress:  66%|██████▌   | 1320/2000 [14:15<04:30,  2.51it/s, Loss=0.1447268, Gaussian number=296313, print grad=0.0008022022084333003, Depth Loss=0.0000000]
Training progress:  66%|██████▌   | 1320/2000 [14:19<04:30,  2.51it/s, Loss=0.1145534, Gaussian number=296313, print grad=0.0012173576978966594, Depth Loss=0.0000000]
Training progress:  66%|██████▋   | 1330/2000 [14:19<04:26,  2.51it/s, Loss=0.1145534, Gaussian number=296313, print grad=0.0012173576978966594, Depth Loss=0.0000000]
Training progress:  66%|██████▋   | 1330/2000 [14:23<04:26,  2.51it/s, Loss=0.1162492, Gaussian number=296313, print grad=0.0016274285735562444, Depth Loss=0.0000000]
Training progress:  67%|██████▋   | 1340/2000 [14:23<04:22,  2.51it/s, Loss=0.1162492, Gaussian number=296313, print grad=0.0016274285735562444, Depth Loss=0.0000000]
Training progress:  67%|██████▋   | 1340/2000 [14:27<04:22,  2.51it/s, Loss=0.1548783, Gaussian number=296313, print grad=0.0019728480838239193, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1350/2000 [14:27<04:18,  2.51it/s, Loss=0.1548783, Gaussian number=296313, print grad=0.0019728480838239193, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1350/2000 [14:31<04:18,  2.51it/s, Loss=0.0934809, Gaussian number=296313, print grad=0.0023302524350583553, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1360/2000 [14:31<04:14,  2.51it/s, Loss=0.0934809, Gaussian number=296313, print grad=0.0023302524350583553, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1360/2000 [14:35<04:14,  2.51it/s, Loss=0.1744909, Gaussian number=296313, print grad=0.0027315793558955193, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1370/2000 [14:35<04:10,  2.51it/s, Loss=0.1744909, Gaussian number=296313, print grad=0.0027315793558955193, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1370/2000 [14:39<04:10,  2.51it/s, Loss=0.1122424, Gaussian number=296313, print grad=0.003077153582125902, Depth Loss=0.0000000] 
Training progress:  69%|██████▉   | 1380/2000 [14:39<04:06,  2.51it/s, Loss=0.1122424, Gaussian number=296313, print grad=0.003077153582125902, Depth Loss=0.0000000]
Training progress:  69%|██████▉   | 1380/2000 [14:43<04:06,  2.51it/s, Loss=0.0996183, Gaussian number=296313, print grad=0.003424924099817872, Depth Loss=0.0000000]
Training progress:  70%|██████▉   | 1390/2000 [14:43<04:02,  2.51it/s, Loss=0.0996183, Gaussian number=296313, print grad=0.003424924099817872, Depth Loss=0.0000000]
Training progress:  70%|██████▉   | 1390/2000 [14:47<04:02,  2.51it/s, Loss=0.1109879, Gaussian number=296313, print grad=0.0037899103481322527, Depth Loss=0.0000000]
Training progress:  70%|███████   | 1400/2000 [14:47<03:59,  2.51it/s, Loss=0.1109879, Gaussian number=296313, print grad=0.0037899103481322527, Depth Loss=0.0000000]
Training progress:  70%|███████   | 1400/2000 [14:51<03:59,  2.51it/s, Loss=0.1361602, Gaussian number=313624, print grad=0.00039752983138896525, Depth Loss=0.0000000]
Training progress:  70%|███████   | 1410/2000 [14:51<03:54,  2.51it/s, Loss=0.1361602, Gaussian number=313624, print grad=0.00039752983138896525, Depth Loss=0.0000000]
Training progress:  70%|███████   | 1410/2000 [14:55<03:54,  2.51it/s, Loss=0.1151484, Gaussian number=313624, print grad=0.0008103979635052383, Depth Loss=0.0000000] 
Training progress:  71%|███████   | 1420/2000 [14:55<03:50,  2.51it/s, Loss=0.1151484, Gaussian number=313624, print grad=0.0008103979635052383, Depth Loss=0.0000000]
Training progress:  71%|███████   | 1420/2000 [14:59<03:50,  2.51it/s, Loss=0.1186064, Gaussian number=313624, print grad=0.001230908907018602, Depth Loss=0.0000000] 
Training progress:  72%|███████▏  | 1430/2000 [14:59<03:46,  2.52it/s, Loss=0.1186064, Gaussian number=313624, print grad=0.001230908907018602, Depth Loss=0.0000000]
Training progress:  72%|███████▏  | 1430/2000 [15:03<03:46,  2.52it/s, Loss=0.1076100, Gaussian number=313624, print grad=0.0015730179147794843, Depth Loss=0.0000000]
Training progress:  72%|███████▏  | 1440/2000 [15:03<03:42,  2.52it/s, Loss=0.1076100, Gaussian number=313624, print grad=0.0015730179147794843, Depth Loss=0.0000000]
Training progress:  72%|███████▏  | 1440/2000 [15:07<03:42,  2.52it/s, Loss=0.0943117, Gaussian number=313624, print grad=0.0019215538632124662, Depth Loss=0.0000000]
Training progress:  72%|███████▎  | 1450/2000 [15:07<03:38,  2.52it/s, Loss=0.0943117, Gaussian number=313624, print grad=0.0019215538632124662, Depth Loss=0.0000000]
Training progress:  72%|███████▎  | 1450/2000 [15:11<03:38,  2.52it/s, Loss=0.0856217, Gaussian number=313624, print grad=0.00227692280896008, Depth Loss=0.0000000]  
Training progress:  73%|███████▎  | 1460/2000 [15:11<03:34,  2.52it/s, Loss=0.0856217, Gaussian number=313624, print grad=0.00227692280896008, Depth Loss=0.0000000]
Training progress:  73%|███████▎  | 1460/2000 [15:15<03:34,  2.52it/s, Loss=0.1163277, Gaussian number=313624, print grad=0.0026399099733680487, Depth Loss=0.0000000]
Training progress:  74%|███████▎  | 1470/2000 [15:15<03:30,  2.52it/s, Loss=0.1163277, Gaussian number=313624, print grad=0.0026399099733680487, Depth Loss=0.0000000]
Training progress:  74%|███████▎  | 1470/2000 [15:19<03:30,  2.52it/s, Loss=0.1176604, Gaussian number=313624, print grad=0.003030064981430769, Depth Loss=0.0000000] 
Training progress:  74%|███████▍  | 1480/2000 [15:19<03:26,  2.52it/s, Loss=0.1176604, Gaussian number=313624, print grad=0.003030064981430769, Depth Loss=0.0000000]
Training progress:  74%|███████▍  | 1480/2000 [15:23<03:26,  2.52it/s, Loss=0.1241830, Gaussian number=313624, print grad=0.003415756393224001, Depth Loss=0.0000000]
Training progress:  74%|███████▍  | 1490/2000 [15:23<03:22,  2.52it/s, Loss=0.1241830, Gaussian number=313624, print grad=0.003415756393224001, Depth Loss=0.0000000]
Training progress:  74%|███████▍  | 1490/2000 [15:27<03:22,  2.52it/s, Loss=0.1183437, Gaussian number=313624, print grad=0.0037900076713413, Depth Loss=0.0000000]  
Training progress:  75%|███████▌  | 1500/2000 [15:27<03:18,  2.52it/s, Loss=0.1183437, Gaussian number=313624, print grad=0.0037900076713413, Depth Loss=0.0000000]
Training progress:  75%|███████▌  | 1500/2000 [16:37<03:18,  2.52it/s, Loss=0.1362147, Gaussian number=330960, print grad=0.00034906386281363666, Depth Loss=0.0000000]
Training progress:  76%|███████▌  | 1510/2000 [16:37<19:25,  2.38s/it, Loss=0.1362147, Gaussian number=330960, print grad=0.00034906386281363666, Depth Loss=0.0000000]
Training progress:  76%|███████▌  | 1510/2000 [16:41<19:25,  2.38s/it, Loss=0.1266413, Gaussian number=330960, print grad=0.0007083512027747929, Depth Loss=0.0000000] 
Training progress:  76%|███████▌  | 1520/2000 [16:41<14:16,  1.78s/it, Loss=0.1266413, Gaussian number=330960, print grad=0.0007083512027747929, Depth Loss=0.0000000]
Training progress:  76%|███████▌  | 1520/2000 [16:45<14:16,  1.78s/it, Loss=0.0715349, Gaussian number=330960, print grad=0.0011099273106083274, Depth Loss=0.0000000]
Training progress:  76%|███████▋  | 1530/2000 [16:45<10:42,  1.37s/it, Loss=0.0715349, Gaussian number=330960, print grad=0.0011099273106083274, Depth Loss=0.0000000]
Training progress:  76%|███████▋  | 1530/2000 [16:48<10:42,  1.37s/it, Loss=0.1008254, Gaussian number=330960, print grad=0.0014703117776662111, Depth Loss=0.0000000]
Training progress:  77%|███████▋  | 1540/2000 [16:48<08:14,  1.08s/it, Loss=0.1008254, Gaussian number=330960, print grad=0.0014703117776662111, Depth Loss=0.0000000]
Training progress:  77%|███████▋  | 1540/2000 [16:52<08:14,  1.08s/it, Loss=0.1135174, Gaussian number=330960, print grad=0.0018574261339381337, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1550/2000 [16:52<06:32,  1.15it/s, Loss=0.1135174, Gaussian number=330960, print grad=0.0018574261339381337, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1550/2000 [16:56<06:32,  1.15it/s, Loss=0.1143644, Gaussian number=330960, print grad=0.0022588325664401054, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1560/2000 [16:56<05:20,  1.37it/s, Loss=0.1143644, Gaussian number=330960, print grad=0.0022588325664401054, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1560/2000 [17:00<05:20,  1.37it/s, Loss=0.0998579, Gaussian number=330960, print grad=0.002629884984344244, Depth Loss=0.0000000] 
Training progress:  78%|███████▊  | 1570/2000 [17:00<04:30,  1.59it/s, Loss=0.0998579, Gaussian number=330960, print grad=0.002629884984344244, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1570/2000 [17:04<04:30,  1.59it/s, Loss=0.0743182, Gaussian number=330960, print grad=0.0029278763104230165, Depth Loss=0.0000000]
Training progress:  79%|███████▉  | 1580/2000 [17:04<03:54,  1.79it/s, Loss=0.0743182, Gaussian number=330960, print grad=0.0029278763104230165, Depth Loss=0.0000000]
Training progress:  79%|███████▉  | 1580/2000 [17:08<03:54,  1.79it/s, Loss=0.1042734, Gaussian number=330960, print grad=0.003265113802626729, Depth Loss=0.0000000] 
Training progress:  80%|███████▉  | 1590/2000 [17:08<03:29,  1.96it/s, Loss=0.1042734, Gaussian number=330960, print grad=0.003265113802626729, Depth Loss=0.0000000]
Training progress:  80%|███████▉  | 1590/2000 [17:12<03:29,  1.96it/s, Loss=0.0984332, Gaussian number=330960, print grad=0.0036409166641533375, Depth Loss=0.0000000]
Training progress:  80%|████████  | 1600/2000 [17:12<03:10,  2.10it/s, Loss=0.0984332, Gaussian number=330960, print grad=0.0036409166641533375, Depth Loss=0.0000000]
Training progress:  80%|████████  | 1600/2000 [17:16<03:10,  2.10it/s, Loss=0.1183663, Gaussian number=348392, print grad=0.00036746374098584056, Depth Loss=0.0000000]
Training progress:  80%|████████  | 1610/2000 [17:16<02:56,  2.21it/s, Loss=0.1183663, Gaussian number=348392, print grad=0.00036746374098584056, Depth Loss=0.0000000]
Training progress:  80%|████████  | 1610/2000 [17:20<02:56,  2.21it/s, Loss=0.1180773, Gaussian number=348392, print grad=0.0007907142862677574, Depth Loss=0.0000000] 
Training progress:  81%|████████  | 1620/2000 [17:20<02:46,  2.29it/s, Loss=0.1180773, Gaussian number=348392, print grad=0.0007907142862677574, Depth Loss=0.0000000]
Training progress:  81%|████████  | 1620/2000 [17:24<02:46,  2.29it/s, Loss=0.0996526, Gaussian number=348392, print grad=0.0011480761459097266, Depth Loss=0.0000000]
Training progress:  82%|████████▏ | 1630/2000 [17:24<02:38,  2.33it/s, Loss=0.0996526, Gaussian number=348392, print grad=0.0011480761459097266, Depth Loss=0.0000000]
Training progress:  82%|████████▏ | 1630/2000 [17:28<02:38,  2.33it/s, Loss=0.0787148, Gaussian number=348392, print grad=0.0014965576119720936, Depth Loss=0.0000000]
Training progress:  82%|████████▏ | 1640/2000 [17:28<02:31,  2.38it/s, Loss=0.0787148, Gaussian number=348392, print grad=0.0014965576119720936, Depth Loss=0.0000000]
Training progress:  82%|████████▏ | 1640/2000 [17:32<02:31,  2.38it/s, Loss=0.1002713, Gaussian number=348392, print grad=0.0018359695095568895, Depth Loss=0.0000000]
Training progress:  82%|████████▎ | 1650/2000 [17:32<02:25,  2.41it/s, Loss=0.1002713, Gaussian number=348392, print grad=0.0018359695095568895, Depth Loss=0.0000000]
Training progress:  82%|████████▎ | 1650/2000 [17:36<02:25,  2.41it/s, Loss=0.0985899, Gaussian number=348392, print grad=0.002170745749026537, Depth Loss=0.0000000] 
Training progress:  83%|████████▎ | 1660/2000 [17:36<02:19,  2.44it/s, Loss=0.0985899, Gaussian number=348392, print grad=0.002170745749026537, Depth Loss=0.0000000]
Training progress:  83%|████████▎ | 1660/2000 [17:40<02:19,  2.44it/s, Loss=0.0911334, Gaussian number=348392, print grad=0.002499833470210433, Depth Loss=0.0000000]
Training progress:  84%|████████▎ | 1670/2000 [17:40<02:14,  2.45it/s, Loss=0.0911334, Gaussian number=348392, print grad=0.002499833470210433, Depth Loss=0.0000000]
Training progress:  84%|████████▎ | 1670/2000 [17:44<02:14,  2.45it/s, Loss=0.0860955, Gaussian number=348392, print grad=0.0028477939777076244, Depth Loss=0.0000000]
Training progress:  84%|████████▍ | 1680/2000 [17:44<02:09,  2.46it/s, Loss=0.0860955, Gaussian number=348392, print grad=0.0028477939777076244, Depth Loss=0.0000000]
Training progress:  84%|████████▍ | 1680/2000 [17:48<02:09,  2.46it/s, Loss=0.0978444, Gaussian number=348392, print grad=0.0031953994184732437, Depth Loss=0.0000000]
Training progress:  84%|████████▍ | 1690/2000 [17:48<02:05,  2.47it/s, Loss=0.0978444, Gaussian number=348392, print grad=0.0031953994184732437, Depth Loss=0.0000000]
Training progress:  84%|████████▍ | 1690/2000 [17:52<02:05,  2.47it/s, Loss=0.1077949, Gaussian number=348392, print grad=0.0035158032551407814, Depth Loss=0.0000000]
Training progress:  85%|████████▌ | 1700/2000 [17:52<02:01,  2.48it/s, Loss=0.1077949, Gaussian number=348392, print grad=0.0035158032551407814, Depth Loss=0.0000000]
Training progress:  85%|████████▌ | 1700/2000 [17:56<02:01,  2.48it/s, Loss=0.1159147, Gaussian number=365069, print grad=0.00037339350092224777, Depth Loss=0.0000000]
Training progress:  86%|████████▌ | 1710/2000 [17:56<01:56,  2.48it/s, Loss=0.1159147, Gaussian number=365069, print grad=0.00037339350092224777, Depth Loss=0.0000000]
Training progress:  86%|████████▌ | 1710/2000 [18:00<01:56,  2.48it/s, Loss=0.1264916, Gaussian number=365069, print grad=0.0006965823122300208, Depth Loss=0.0000000] 
Training progress:  86%|████████▌ | 1720/2000 [18:00<01:52,  2.49it/s, Loss=0.1264916, Gaussian number=365069, print grad=0.0006965823122300208, Depth Loss=0.0000000]
Training progress:  86%|████████▌ | 1720/2000 [18:04<01:52,  2.49it/s, Loss=0.1117318, Gaussian number=365069, print grad=0.0010359177831560373, Depth Loss=0.0000000]
Training progress:  86%|████████▋ | 1730/2000 [18:04<01:48,  2.49it/s, Loss=0.1117318, Gaussian number=365069, print grad=0.0010359177831560373, Depth Loss=0.0000000]
Training progress:  86%|████████▋ | 1730/2000 [18:08<01:48,  2.49it/s, Loss=0.1452908, Gaussian number=365069, print grad=0.0014144619926810265, Depth Loss=0.0000000]
Training progress:  87%|████████▋ | 1740/2000 [18:08<01:44,  2.49it/s, Loss=0.1452908, Gaussian number=365069, print grad=0.0014144619926810265, Depth Loss=0.0000000]
Training progress:  87%|████████▋ | 1740/2000 [18:12<01:44,  2.49it/s, Loss=0.1340714, Gaussian number=365069, print grad=0.00177816825453192, Depth Loss=0.0000000]  
Training progress:  88%|████████▊ | 1750/2000 [18:12<01:40,  2.49it/s, Loss=0.1340714, Gaussian number=365069, print grad=0.00177816825453192, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1750/2000 [18:16<01:40,  2.49it/s, Loss=0.1077228, Gaussian number=365069, print grad=0.002098450902849436, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1760/2000 [18:16<01:36,  2.50it/s, Loss=0.1077228, Gaussian number=365069, print grad=0.002098450902849436, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1760/2000 [18:20<01:36,  2.50it/s, Loss=0.0865279, Gaussian number=365069, print grad=0.0024111969396471977, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1770/2000 [18:20<01:32,  2.50it/s, Loss=0.0865279, Gaussian number=365069, print grad=0.0024111969396471977, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1770/2000 [18:24<01:32,  2.50it/s, Loss=0.1017132, Gaussian number=365069, print grad=0.0027230139821767807, Depth Loss=0.0000000]
Training progress:  89%|████████▉ | 1780/2000 [18:24<01:28,  2.50it/s, Loss=0.1017132, Gaussian number=365069, print grad=0.0027230139821767807, Depth Loss=0.0000000]
Training progress:  89%|████████▉ | 1780/2000 [18:28<01:28,  2.50it/s, Loss=0.0962166, Gaussian number=365069, print grad=0.002991290297359228, Depth Loss=0.0000000] 
Training progress:  90%|████████▉ | 1790/2000 [18:28<01:24,  2.50it/s, Loss=0.0962166, Gaussian number=365069, print grad=0.002991290297359228, Depth Loss=0.0000000]
Training progress:  90%|████████▉ | 1790/2000 [18:32<01:24,  2.50it/s, Loss=0.0953679, Gaussian number=365069, print grad=0.0033431879710406065, Depth Loss=0.0000000]
Training progress:  90%|█████████ | 1800/2000 [18:32<01:20,  2.50it/s, Loss=0.0953679, Gaussian number=365069, print grad=0.0033431879710406065, Depth Loss=0.0000000]
Training progress:  90%|█████████ | 1800/2000 [18:36<01:20,  2.50it/s, Loss=0.1128554, Gaussian number=382534, print grad=0.000343108840752393, Depth Loss=0.0000000] 
Training progress:  90%|█████████ | 1810/2000 [18:36<01:16,  2.50it/s, Loss=0.1128554, Gaussian number=382534, print grad=0.000343108840752393, Depth Loss=0.0000000]
Training progress:  90%|█████████ | 1810/2000 [18:40<01:16,  2.50it/s, Loss=0.0971208, Gaussian number=382534, print grad=0.0007260541897267103, Depth Loss=0.0000000]
Training progress:  91%|█████████ | 1820/2000 [18:40<01:12,  2.50it/s, Loss=0.0971208, Gaussian number=382534, print grad=0.0007260541897267103, Depth Loss=0.0000000]
Training progress:  91%|█████████ | 1820/2000 [18:44<01:12,  2.50it/s, Loss=0.0862288, Gaussian number=382534, print grad=0.0010044281370937824, Depth Loss=0.0000000]
Training progress:  92%|█████████▏| 1830/2000 [18:44<01:08,  2.49it/s, Loss=0.0862288, Gaussian number=382534, print grad=0.0010044281370937824, Depth Loss=0.0000000]
Training progress:  92%|█████████▏| 1830/2000 [18:49<01:08,  2.49it/s, Loss=0.0865475, Gaussian number=382534, print grad=0.0013488831464201212, Depth Loss=0.0000000]
Training progress:  92%|█████████▏| 1840/2000 [18:49<01:04,  2.49it/s, Loss=0.0865475, Gaussian number=382534, print grad=0.0013488831464201212, Depth Loss=0.0000000]
Training progress:  92%|█████████▏| 1840/2000 [18:53<01:04,  2.49it/s, Loss=0.0945806, Gaussian number=382534, print grad=0.0016706669703125954, Depth Loss=0.0000000]
Training progress:  92%|█████████▎| 1850/2000 [18:53<01:00,  2.48it/s, Loss=0.0945806, Gaussian number=382534, print grad=0.0016706669703125954, Depth Loss=0.0000000]
Training progress:  92%|█████████▎| 1850/2000 [18:57<01:00,  2.48it/s, Loss=0.1014127, Gaussian number=382534, print grad=0.0019548386335372925, Depth Loss=0.0000000]
Training progress:  93%|█████████▎| 1860/2000 [18:57<00:56,  2.48it/s, Loss=0.1014127, Gaussian number=382534, print grad=0.0019548386335372925, Depth Loss=0.0000000]
Training progress:  93%|█████████▎| 1860/2000 [19:01<00:56,  2.48it/s, Loss=0.1134280, Gaussian number=382534, print grad=0.0023142609279602766, Depth Loss=0.0000000]
Training progress:  94%|█████████▎| 1870/2000 [19:01<00:52,  2.48it/s, Loss=0.1134280, Gaussian number=382534, print grad=0.0023142609279602766, Depth Loss=0.0000000]
Training progress:  94%|█████████▎| 1870/2000 [19:05<00:52,  2.48it/s, Loss=0.0840002, Gaussian number=382534, print grad=0.0026364033110439777, Depth Loss=0.0000000]
Training progress:  94%|█████████▍| 1880/2000 [19:05<00:48,  2.48it/s, Loss=0.0840002, Gaussian number=382534, print grad=0.0026364033110439777, Depth Loss=0.0000000]
Training progress:  94%|█████████▍| 1880/2000 [19:09<00:48,  2.48it/s, Loss=0.0981881, Gaussian number=382534, print grad=0.0029584644362330437, Depth Loss=0.0000000]
Training progress:  94%|█████████▍| 1890/2000 [19:09<00:44,  2.48it/s, Loss=0.0981881, Gaussian number=382534, print grad=0.0029584644362330437, Depth Loss=0.0000000]
Training progress:  94%|█████████▍| 1890/2000 [19:13<00:44,  2.48it/s, Loss=0.1191935, Gaussian number=382534, print grad=0.003292983630672097, Depth Loss=0.0000000] 
Training progress:  95%|█████████▌| 1900/2000 [19:13<00:40,  2.48it/s, Loss=0.1191935, Gaussian number=382534, print grad=0.003292983630672097, Depth Loss=0.0000000]
Training progress:  95%|█████████▌| 1900/2000 [19:17<00:40,  2.48it/s, Loss=0.1076651, Gaussian number=400823, print grad=0.00028470397228375077, Depth Loss=0.0000000]
Training progress:  96%|█████████▌| 1910/2000 [19:17<00:36,  2.48it/s, Loss=0.1076651, Gaussian number=400823, print grad=0.00028470397228375077, Depth Loss=0.0000000]
Training progress:  96%|█████████▌| 1910/2000 [19:21<00:36,  2.48it/s, Loss=0.0978957, Gaussian number=400823, print grad=0.0006120089674368501, Depth Loss=0.0000000] 
Training progress:  96%|█████████▌| 1920/2000 [19:21<00:32,  2.49it/s, Loss=0.0978957, Gaussian number=400823, print grad=0.0006120089674368501, Depth Loss=0.0000000]
Training progress:  96%|█████████▌| 1920/2000 [19:25<00:32,  2.49it/s, Loss=0.0804536, Gaussian number=400823, print grad=0.0009546488872729242, Depth Loss=0.0000000]
Training progress:  96%|█████████▋| 1930/2000 [19:25<00:28,  2.49it/s, Loss=0.0804536, Gaussian number=400823, print grad=0.0009546488872729242, Depth Loss=0.0000000]
Training progress:  96%|█████████▋| 1930/2000 [19:29<00:28,  2.49it/s, Loss=0.1099317, Gaussian number=400823, print grad=0.0012700670631602407, Depth Loss=0.0000000]
Training progress:  97%|█████████▋| 1940/2000 [19:29<00:24,  2.49it/s, Loss=0.1099317, Gaussian number=400823, print grad=0.0012700670631602407, Depth Loss=0.0000000]
Training progress:  97%|█████████▋| 1940/2000 [19:33<00:24,  2.49it/s, Loss=0.0851118, Gaussian number=400823, print grad=0.0015751769533380866, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1950/2000 [19:33<00:20,  2.49it/s, Loss=0.0851118, Gaussian number=400823, print grad=0.0015751769533380866, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1950/2000 [19:37<00:20,  2.49it/s, Loss=0.1320233, Gaussian number=400823, print grad=0.0018613537540659308, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1960/2000 [19:37<00:16,  2.50it/s, Loss=0.1320233, Gaussian number=400823, print grad=0.0018613537540659308, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1960/2000 [19:41<00:16,  2.50it/s, Loss=0.1121377, Gaussian number=400823, print grad=0.002168820472434163, Depth Loss=0.0000000] 
Training progress:  98%|█████████▊| 1970/2000 [19:41<00:12,  2.50it/s, Loss=0.1121377, Gaussian number=400823, print grad=0.002168820472434163, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1970/2000 [19:45<00:12,  2.50it/s, Loss=0.0940105, Gaussian number=400823, print grad=0.002488715574145317, Depth Loss=0.0000000]
Training progress:  99%|█████████▉| 1980/2000 [19:45<00:08,  2.50it/s, Loss=0.0940105, Gaussian number=400823, print grad=0.002488715574145317, Depth Loss=0.0000000]
Training progress:  99%|█████████▉| 1980/2000 [19:49<00:08,  2.50it/s, Loss=0.0922224, Gaussian number=400823, print grad=0.002829312812536955, Depth Loss=0.0000000]
Training progress: 100%|█████████▉| 1990/2000 [19:49<00:04,  2.50it/s, Loss=0.0922224, Gaussian number=400823, print grad=0.002829312812536955, Depth Loss=0.0000000]
Training progress: 100%|█████████▉| 1990/2000 [19:53<00:04,  2.50it/s, Loss=0.0719009, Gaussian number=400823, print grad=0.0031706783920526505, Depth Loss=0.0000000]
Training progress: 100%|██████████| 2000/2000 [19:53<00:00,  2.50it/s, Loss=0.0719009, Gaussian number=400823, print grad=0.0031706783920526505, Depth Loss=0.0000000]
Training progress: 100%|██████████| 2000/2000 [19:53<00:00,  1.68it/s, Loss=0.0719009, Gaussian number=400823, print grad=0.0031706783920526505, Depth Loss=0.0000000]
Iteration 100 [03/12 18:02:01]

[ITER 100] Evaluating test: WD 0.197875, PSNR 12.9387,lpips 0.587739,ssim 0.454989 [03/12 18:02:59]

[ITER 100] Evaluating train: WD 0.206107, PSNR 13.2964,lpips 0.590549,ssim 0.473341 [03/12 18:03:07]
Gaussian number:182686,print gradients:2.8089276383980177e-05 [03/12 18:03:07]
Iteration 200 [03/12 18:03:47]

[ITER 200] Evaluating test: WD 0.175216, PSNR 14.2250,lpips 0.540862,ssim 0.489980 [03/12 18:04:45]

[ITER 200] Evaluating train: WD 0.177949, PSNR 14.3876,lpips 0.534838,ssim 0.504053 [03/12 18:04:53]
Gaussian number:182686,print gradients:3.6251400160836056e-05 [03/12 18:04:53]
Iteration 300 [03/12 18:05:32]

[ITER 300] Evaluating test: WD 0.159950, PSNR 14.9512,lpips 0.508613,ssim 0.511834 [03/12 18:06:30]

[ITER 300] Evaluating train: WD 0.161915, PSNR 15.2173,lpips 0.499508,ssim 0.526510 [03/12 18:06:38]
Gaussian number:182686,print gradients:4.136149073019624e-05 [03/12 18:06:38]
Iteration 400 [03/12 18:07:17]
Iteration 500 [03/12 18:07:57]

[ITER 500] Evaluating test: WD 0.144227, PSNR 15.8265,lpips 0.473907,ssim 0.537248 [03/12 18:08:56]

[ITER 500] Evaluating train: WD 0.155502, PSNR 15.8612,lpips 0.475696,ssim 0.544639 [03/12 18:09:03]
Gaussian number:182686,print gradients:4.831147089134902e-05 [03/12 18:09:03]
Iteration 600 [03/12 18:09:42]
Iteration 700 [03/12 18:10:22]
Iteration 800 [03/12 18:11:02]
Iteration 900 [03/12 18:11:42]
Iteration 1000 [03/12 18:12:21]

[ITER 1000] Evaluating test: WD 0.124479, PSNR 16.8525,lpips 0.419753,ssim 0.569220 [03/12 18:13:20]

[ITER 1000] Evaluating train: WD 0.134651, PSNR 16.9458,lpips 0.427587,ssim 0.572558 [03/12 18:13:28]
Gaussian number:229943,print gradients:nan [03/12 18:13:28]
Iteration 1100 [03/12 18:14:07]
Iteration 1200 [03/12 18:14:47]
Iteration 1300 [03/12 18:15:26]
Iteration 1400 [03/12 18:16:06]
Iteration 1500 [03/12 18:16:46]

[ITER 1500] Evaluating test: WD 0.110353, PSNR 17.4370,lpips 0.377357,ssim 0.590778 [03/12 18:17:45]

[ITER 1500] Evaluating train: WD 0.119057, PSNR 17.7084,lpips 0.378992,ssim 0.595948 [03/12 18:17:52]
Gaussian number:313624,print gradients:nan [03/12 18:17:52]
Iteration 1600 [03/12 18:18:32]
Iteration 1700 [03/12 18:19:12]
Iteration 1800 [03/12 18:19:52]
Iteration 1900 [03/12 18:20:32]
Iteration 2000 [03/12 18:21:12]

[ITER 2000] Evaluating test: WD 0.100840, PSNR 17.8163,lpips 0.352949,ssim 0.604967 [03/12 18:22:11]

[ITER 2000] Evaluating train: WD 0.113902, PSNR 18.0107,lpips 0.362084,ssim 0.604361 [03/12 18:22:19]
Gaussian number:400823,print gradients:nan [03/12 18:22:19]

[ITER 2000] Saving Gaussians [03/12 18:22:19]

Training complete. [03/12 18:22:22]
