Optimizing /home/cw4287/gaussian-model/train_30k
Output folder: /home/cw4287/gaussian-model/train_30k [03/12 20:45:38]
Tensorboard not available: not logging progress [03/12 20:45:38]
------------LLFF HOLD------------- [03/12 20:45:39]

Reading camera 1/301
Reading camera 2/301
Reading camera 3/301
Reading camera 4/301
Reading camera 5/301
Reading camera 6/301
Reading camera 7/301
Reading camera 8/301
Reading camera 9/301
Reading camera 10/301
Reading camera 11/301
Reading camera 12/301
Reading camera 13/301
Reading camera 14/301
Reading camera 15/301
Reading camera 16/301
Reading camera 17/301
Reading camera 18/301
Reading camera 19/301
Reading camera 20/301
Reading camera 21/301
Reading camera 22/301
Reading camera 23/301
Reading camera 24/301
Reading camera 25/301
Reading camera 26/301
Reading camera 27/301
Reading camera 28/301
Reading camera 29/301
Reading camera 30/301
Reading camera 31/301
Reading camera 32/301
Reading camera 33/301
Reading camera 34/301
Reading camera 35/301
Reading camera 36/301
Reading camera 37/301
Reading camera 38/301
Reading camera 39/301
Reading camera 40/301
Reading camera 41/301
Reading camera 42/301
Reading camera 43/301
Reading camera 44/301
Reading camera 45/301
Reading camera 46/301
Reading camera 47/301
Reading camera 48/301
Reading camera 49/301
Reading camera 50/301
Reading camera 51/301
Reading camera 52/301
Reading camera 53/301
Reading camera 54/301
Reading camera 55/301
Reading camera 56/301
Reading camera 57/301
Reading camera 58/301
Reading camera 59/301
Reading camera 60/301
Reading camera 61/301
Reading camera 62/301
Reading camera 63/301
Reading camera 64/301
Reading camera 65/301
Reading camera 66/301
Reading camera 67/301
Reading camera 68/301
Reading camera 69/301
Reading camera 70/301
Reading camera 71/301
Reading camera 72/301
Reading camera 73/301
Reading camera 74/301
Reading camera 75/301
Reading camera 76/301
Reading camera 77/301
Reading camera 78/301
Reading camera 79/301
Reading camera 80/301
Reading camera 81/301
Reading camera 82/301
Reading camera 83/301
Reading camera 84/301
Reading camera 85/301
Reading camera 86/301
Reading camera 87/301
Reading camera 88/301
Reading camera 89/301
Reading camera 90/301
Reading camera 91/301
Reading camera 92/301
Reading camera 93/301
Reading camera 94/301
Reading camera 95/301
Reading camera 96/301
Reading camera 97/301
Reading camera 98/301
Reading camera 99/301
Reading camera 100/301
Reading camera 101/301
Reading camera 102/301
Reading camera 103/301
Reading camera 104/301
Reading camera 105/301
Reading camera 106/301
Reading camera 107/301
Reading camera 108/301
Reading camera 109/301
Reading camera 110/301
Reading camera 111/301
Reading camera 112/301
Reading camera 113/301
Reading camera 114/301
Reading camera 115/301
Reading camera 116/301
Reading camera 117/301
Reading camera 118/301
Reading camera 119/301
Reading camera 120/301
Reading camera 121/301
Reading camera 122/301
Reading camera 123/301
Reading camera 124/301
Reading camera 125/301
Reading camera 126/301
Reading camera 127/301
Reading camera 128/301
Reading camera 129/301
Reading camera 130/301
Reading camera 131/301
Reading camera 132/301
Reading camera 133/301
Reading camera 134/301
Reading camera 135/301
Reading camera 136/301
Reading camera 137/301
Reading camera 138/301
Reading camera 139/301
Reading camera 140/301
Reading camera 141/301
Reading camera 142/301
Reading camera 143/301
Reading camera 144/301
Reading camera 145/301
Reading camera 146/301
Reading camera 147/301
Reading camera 148/301
Reading camera 149/301
Reading camera 150/301
Reading camera 151/301
Reading camera 152/301
Reading camera 153/301
Reading camera 154/301
Reading camera 155/301
Reading camera 156/301
Reading camera 157/301
Reading camera 158/301
Reading camera 159/301
Reading camera 160/301
Reading camera 161/301
Reading camera 162/301
Reading camera 163/301
Reading camera 164/301
Reading camera 165/301
Reading camera 166/301
Reading camera 167/301
Reading camera 168/301
Reading camera 169/301
Reading camera 170/301
Reading camera 171/301
Reading camera 172/301
Reading camera 173/301
Reading camera 174/301
Reading camera 175/301
Reading camera 176/301
Reading camera 177/301
Reading camera 178/301
Reading camera 179/301
Reading camera 180/301
Reading camera 181/301
Reading camera 182/301
Reading camera 183/301
Reading camera 184/301
Reading camera 185/301
Reading camera 186/301
Reading camera 187/301
Reading camera 188/301
Reading camera 189/301
Reading camera 190/301
Reading camera 191/301
Reading camera 192/301
Reading camera 193/301
Reading camera 194/301
Reading camera 195/301
Reading camera 196/301
Reading camera 197/301
Reading camera 198/301
Reading camera 199/301
Reading camera 200/301
Reading camera 201/301
Reading camera 202/301
Reading camera 203/301
Reading camera 204/301
Reading camera 205/301
Reading camera 206/301
Reading camera 207/301
Reading camera 208/301
Reading camera 209/301
Reading camera 210/301
Reading camera 211/301
Reading camera 212/301
Reading camera 213/301
Reading camera 214/301
Reading camera 215/301
Reading camera 216/301
Reading camera 217/301
Reading camera 218/301
Reading camera 219/301
Reading camera 220/301
Reading camera 221/301
Reading camera 222/301
Reading camera 223/301
Reading camera 224/301
Reading camera 225/301
Reading camera 226/301
Reading camera 227/301
Reading camera 228/301
Reading camera 229/301
Reading camera 230/301
Reading camera 231/301
Reading camera 232/301
Reading camera 233/301
Reading camera 234/301
Reading camera 235/301
Reading camera 236/301
Reading camera 237/301
Reading camera 238/301
Reading camera 239/301
Reading camera 240/301
Reading camera 241/301
Reading camera 242/301
Reading camera 243/301
Reading camera 244/301
Reading camera 245/301
Reading camera 246/301
Reading camera 247/301
Reading camera 248/301
Reading camera 249/301
Reading camera 250/301
Reading camera 251/301
Reading camera 252/301
Reading camera 253/301
Reading camera 254/301
Reading camera 255/301
Reading camera 256/301
Reading camera 257/301
Reading camera 258/301
Reading camera 259/301
Reading camera 260/301
Reading camera 261/301
Reading camera 262/301
Reading camera 263/301
Reading camera 264/301
Reading camera 265/301
Reading camera 266/301
Reading camera 267/301
Reading camera 268/301
Reading camera 269/301
Reading camera 270/301
Reading camera 271/301
Reading camera 272/301
Reading camera 273/301
Reading camera 274/301
Reading camera 275/301
Reading camera 276/301
Reading camera 277/301
Reading camera 278/301
Reading camera 279/301
Reading camera 280/301
Reading camera 281/301
Reading camera 282/301
Reading camera 283/301
Reading camera 284/301
Reading camera 285/301
Reading camera 286/301
Reading camera 287/301
Reading camera 288/301
Reading camera 289/301
Reading camera 290/301
Reading camera 291/301
Reading camera 292/301
Reading camera 293/301
Reading camera 294/301
Reading camera 295/301
Reading camera 296/301
Reading camera 297/301
Reading camera 298/301
Reading camera 299/301
Reading camera 300/301
Reading camera 301/301 [03/12 20:45:39]
Loading Training Cameras [03/12 20:45:39]
Loading Test Cameras [03/12 20:46:00]
Number of points at initialisation :  182686 [03/12 20:46:03]

Training progress:   0%|          | 0/2000 [00:00<?, ?it/s]/ext3/conda/envs/3dgs/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/ext3/conda/envs/3dgs/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)

Training progress:   0%|          | 0/2000 [00:05<?, ?it/s, Loss=0.0237834, Gaussian number=182686, print grad=1.1355171409377363e-05, Depth Loss=0.0000000]
Training progress:   0%|          | 10/2000 [00:05<19:03,  1.74it/s, Loss=0.0237834, Gaussian number=182686, print grad=1.1355171409377363e-05, Depth Loss=0.0000000]
Training progress:   0%|          | 10/2000 [00:09<19:03,  1.74it/s, Loss=0.0223144, Gaussian number=182686, print grad=2.9378605177043937e-05, Depth Loss=0.0000000]
Training progress:   1%|          | 20/2000 [00:09<15:40,  2.10it/s, Loss=0.0223144, Gaussian number=182686, print grad=2.9378605177043937e-05, Depth Loss=0.0000000]
Training progress:   1%|          | 20/2000 [00:13<15:40,  2.10it/s, Loss=0.0221722, Gaussian number=182686, print grad=4.621829793904908e-05, Depth Loss=0.0000000] 
Training progress:   2%|▏         | 30/2000 [00:13<14:32,  2.26it/s, Loss=0.0221722, Gaussian number=182686, print grad=4.621829793904908e-05, Depth Loss=0.0000000]
Training progress:   2%|▏         | 30/2000 [00:17<14:32,  2.26it/s, Loss=0.0239458, Gaussian number=182686, print grad=6.382471474353224e-05, Depth Loss=0.0000000]
Training progress:   2%|▏         | 40/2000 [00:17<13:58,  2.34it/s, Loss=0.0239458, Gaussian number=182686, print grad=6.382471474353224e-05, Depth Loss=0.0000000]
Training progress:   2%|▏         | 40/2000 [00:21<13:58,  2.34it/s, Loss=0.0183349, Gaussian number=182686, print grad=7.809535600244999e-05, Depth Loss=0.0000000]
Training progress:   2%|▎         | 50/2000 [00:21<13:37,  2.38it/s, Loss=0.0183349, Gaussian number=182686, print grad=7.809535600244999e-05, Depth Loss=0.0000000]
Training progress:   2%|▎         | 50/2000 [00:25<13:37,  2.38it/s, Loss=0.0203898, Gaussian number=182686, print grad=9.883008897304535e-05, Depth Loss=0.0000000]
Training progress:   3%|▎         | 60/2000 [00:25<13:22,  2.42it/s, Loss=0.0203898, Gaussian number=182686, print grad=9.883008897304535e-05, Depth Loss=0.0000000]
Training progress:   3%|▎         | 60/2000 [00:30<13:22,  2.42it/s, Loss=0.0182835, Gaussian number=182686, print grad=0.00012493462418206036, Depth Loss=0.0000000]
Training progress:   4%|▎         | 70/2000 [00:30<13:12,  2.44it/s, Loss=0.0182835, Gaussian number=182686, print grad=0.00012493462418206036, Depth Loss=0.0000000]
Training progress:   4%|▎         | 70/2000 [00:34<13:12,  2.44it/s, Loss=0.0223515, Gaussian number=182686, print grad=0.00014547898899763823, Depth Loss=0.0000000]
Training progress:   4%|▍         | 80/2000 [00:34<13:04,  2.45it/s, Loss=0.0223515, Gaussian number=182686, print grad=0.00014547898899763823, Depth Loss=0.0000000]
Training progress:   4%|▍         | 80/2000 [00:38<13:04,  2.45it/s, Loss=0.0188604, Gaussian number=182686, print grad=0.00016661026165820658, Depth Loss=0.0000000]
Training progress:   4%|▍         | 90/2000 [00:38<12:58,  2.45it/s, Loss=0.0188604, Gaussian number=182686, print grad=0.00016661026165820658, Depth Loss=0.0000000]
Training progress:   4%|▍         | 90/2000 [00:42<12:58,  2.45it/s, Loss=0.0184451, Gaussian number=182686, print grad=0.00019178609363734722, Depth Loss=0.0000000]
Training progress:   5%|▌         | 100/2000 [00:42<12:51,  2.46it/s, Loss=0.0184451, Gaussian number=182686, print grad=0.00019178609363734722, Depth Loss=0.0000000]
Training progress:   5%|▌         | 100/2000 [01:50<12:51,  2.46it/s, Loss=0.0213321, Gaussian number=182686, print grad=0.00021905594621784985, Depth Loss=0.0000000]
Training progress:   6%|▌         | 110/2000 [01:50<1:14:32,  2.37s/it, Loss=0.0213321, Gaussian number=182686, print grad=0.00021905594621784985, Depth Loss=0.0000000]
Training progress:   6%|▌         | 110/2000 [01:54<1:14:32,  2.37s/it, Loss=0.0178410, Gaussian number=182686, print grad=0.00024490474606864154, Depth Loss=0.0000000]
Training progress:   6%|▌         | 120/2000 [01:54<55:25,  1.77s/it, Loss=0.0178410, Gaussian number=182686, print grad=0.00024490474606864154, Depth Loss=0.0000000]  
Training progress:   6%|▌         | 120/2000 [01:58<55:25,  1.77s/it, Loss=0.0203980, Gaussian number=182686, print grad=0.0002772871812339872, Depth Loss=0.0000000] 
Training progress:   6%|▋         | 130/2000 [01:58<42:13,  1.36s/it, Loss=0.0203980, Gaussian number=182686, print grad=0.0002772871812339872, Depth Loss=0.0000000]
Training progress:   6%|▋         | 130/2000 [02:02<42:13,  1.36s/it, Loss=0.0186759, Gaussian number=182686, print grad=0.0003097854205407202, Depth Loss=0.0000000]
Training progress:   7%|▋         | 140/2000 [02:02<33:05,  1.07s/it, Loss=0.0186759, Gaussian number=182686, print grad=0.0003097854205407202, Depth Loss=0.0000000]
Training progress:   7%|▋         | 140/2000 [02:06<33:05,  1.07s/it, Loss=0.0165169, Gaussian number=182686, print grad=0.0003389952180441469, Depth Loss=0.0000000]
Training progress:   8%|▊         | 150/2000 [02:06<26:43,  1.15it/s, Loss=0.0165169, Gaussian number=182686, print grad=0.0003389952180441469, Depth Loss=0.0000000]
Training progress:   8%|▊         | 150/2000 [02:10<26:43,  1.15it/s, Loss=0.0174068, Gaussian number=182686, print grad=0.0003756563237402588, Depth Loss=0.0000000]
Training progress:   8%|▊         | 160/2000 [02:10<22:16,  1.38it/s, Loss=0.0174068, Gaussian number=182686, print grad=0.0003756563237402588, Depth Loss=0.0000000]
Training progress:   8%|▊         | 160/2000 [02:14<22:16,  1.38it/s, Loss=0.0172783, Gaussian number=182686, print grad=0.00040477991569787264, Depth Loss=0.0000000]
Training progress:   8%|▊         | 170/2000 [02:14<19:10,  1.59it/s, Loss=0.0172783, Gaussian number=182686, print grad=0.00040477991569787264, Depth Loss=0.0000000]
Training progress:   8%|▊         | 170/2000 [02:18<19:10,  1.59it/s, Loss=0.0148289, Gaussian number=182686, print grad=0.0004381323524285108, Depth Loss=0.0000000] 
Training progress:   9%|▉         | 180/2000 [02:18<16:59,  1.78it/s, Loss=0.0148289, Gaussian number=182686, print grad=0.0004381323524285108, Depth Loss=0.0000000]
Training progress:   9%|▉         | 180/2000 [02:22<16:59,  1.78it/s, Loss=0.0191684, Gaussian number=182686, print grad=0.00046717748045921326, Depth Loss=0.0000000]
Training progress:  10%|▉         | 190/2000 [02:22<15:27,  1.95it/s, Loss=0.0191684, Gaussian number=182686, print grad=0.00046717748045921326, Depth Loss=0.0000000]
Training progress:  10%|▉         | 190/2000 [02:26<15:27,  1.95it/s, Loss=0.0166002, Gaussian number=182686, print grad=0.00050309335347265, Depth Loss=0.0000000]   
Training progress:  10%|█         | 200/2000 [02:26<14:21,  2.09it/s, Loss=0.0166002, Gaussian number=182686, print grad=0.00050309335347265, Depth Loss=0.0000000]
Training progress:  10%|█         | 200/2000 [03:34<14:21,  2.09it/s, Loss=0.0187510, Gaussian number=182686, print grad=0.000539561384357512, Depth Loss=0.0000000]
Training progress:  10%|█         | 210/2000 [03:34<1:10:45,  2.37s/it, Loss=0.0187510, Gaussian number=182686, print grad=0.000539561384357512, Depth Loss=0.0000000]
Training progress:  10%|█         | 210/2000 [03:38<1:10:45,  2.37s/it, Loss=0.0153092, Gaussian number=182686, print grad=0.0005725321243517101, Depth Loss=0.0000000]
Training progress:  11%|█         | 220/2000 [03:38<52:48,  1.78s/it, Loss=0.0153092, Gaussian number=182686, print grad=0.0005725321243517101, Depth Loss=0.0000000]  
Training progress:  11%|█         | 220/2000 [03:42<52:48,  1.78s/it, Loss=0.0171139, Gaussian number=182686, print grad=0.0006069387309253216, Depth Loss=0.0000000]
Training progress:  12%|█▏        | 230/2000 [03:42<40:17,  1.37s/it, Loss=0.0171139, Gaussian number=182686, print grad=0.0006069387309253216, Depth Loss=0.0000000]
Training progress:  12%|█▏        | 230/2000 [03:46<40:17,  1.37s/it, Loss=0.0210324, Gaussian number=182686, print grad=0.0006394099327735603, Depth Loss=0.0000000]
Training progress:  12%|█▏        | 240/2000 [03:46<31:33,  1.08s/it, Loss=0.0210324, Gaussian number=182686, print grad=0.0006394099327735603, Depth Loss=0.0000000]
Training progress:  12%|█▏        | 240/2000 [03:50<31:33,  1.08s/it, Loss=0.0161911, Gaussian number=182686, print grad=0.0006755261565558612, Depth Loss=0.0000000]
Training progress:  12%|█▎        | 250/2000 [03:50<25:26,  1.15it/s, Loss=0.0161911, Gaussian number=182686, print grad=0.0006755261565558612, Depth Loss=0.0000000]
Training progress:  12%|█▎        | 250/2000 [03:54<25:26,  1.15it/s, Loss=0.0182115, Gaussian number=182686, print grad=0.0007090262370184064, Depth Loss=0.0000000]
Training progress:  13%|█▎        | 260/2000 [03:54<21:10,  1.37it/s, Loss=0.0182115, Gaussian number=182686, print grad=0.0007090262370184064, Depth Loss=0.0000000]
Training progress:  13%|█▎        | 260/2000 [03:58<21:10,  1.37it/s, Loss=0.0128052, Gaussian number=182686, print grad=0.000744426273740828, Depth Loss=0.0000000] 
Training progress:  14%|█▎        | 270/2000 [03:58<18:11,  1.58it/s, Loss=0.0128052, Gaussian number=182686, print grad=0.000744426273740828, Depth Loss=0.0000000]
Training progress:  14%|█▎        | 270/2000 [04:02<18:11,  1.58it/s, Loss=0.0163811, Gaussian number=182686, print grad=0.0007848649984225631, Depth Loss=0.0000000]
Training progress:  14%|█▍        | 280/2000 [04:02<16:05,  1.78it/s, Loss=0.0163811, Gaussian number=182686, print grad=0.0007848649984225631, Depth Loss=0.0000000]
Training progress:  14%|█▍        | 280/2000 [04:06<16:05,  1.78it/s, Loss=0.0167611, Gaussian number=182686, print grad=0.0008225691271945834, Depth Loss=0.0000000]
Training progress:  14%|█▍        | 290/2000 [04:06<14:35,  1.95it/s, Loss=0.0167611, Gaussian number=182686, print grad=0.0008225691271945834, Depth Loss=0.0000000]
Training progress:  14%|█▍        | 290/2000 [04:10<14:35,  1.95it/s, Loss=0.0156789, Gaussian number=182686, print grad=0.0008616475388407707, Depth Loss=0.0000000]
Training progress:  15%|█▌        | 300/2000 [04:10<13:33,  2.09it/s, Loss=0.0156789, Gaussian number=182686, print grad=0.0008616475388407707, Depth Loss=0.0000000]
Training progress:  15%|█▌        | 300/2000 [05:18<13:33,  2.09it/s, Loss=0.0130427, Gaussian number=182686, print grad=0.0009024440078064799, Depth Loss=0.0000000]
Training progress:  16%|█▌        | 310/2000 [05:18<1:06:46,  2.37s/it, Loss=0.0130427, Gaussian number=182686, print grad=0.0009024440078064799, Depth Loss=0.0000000]
Training progress:  16%|█▌        | 310/2000 [05:21<1:06:46,  2.37s/it, Loss=0.0136209, Gaussian number=182686, print grad=0.0009316141367889941, Depth Loss=0.0000000]
Training progress:  16%|█▌        | 320/2000 [05:21<49:48,  1.78s/it, Loss=0.0136209, Gaussian number=182686, print grad=0.0009316141367889941, Depth Loss=0.0000000]  
Training progress:  16%|█▌        | 320/2000 [05:25<49:48,  1.78s/it, Loss=0.0179554, Gaussian number=182686, print grad=0.0009667842532508075, Depth Loss=0.0000000]
Training progress:  16%|█▋        | 330/2000 [05:25<37:58,  1.36s/it, Loss=0.0179554, Gaussian number=182686, print grad=0.0009667842532508075, Depth Loss=0.0000000]
Training progress:  16%|█▋        | 330/2000 [05:29<37:58,  1.36s/it, Loss=0.0129956, Gaussian number=182686, print grad=0.0010067109251394868, Depth Loss=0.0000000]
Training progress:  17%|█▋        | 340/2000 [05:29<29:43,  1.07s/it, Loss=0.0129956, Gaussian number=182686, print grad=0.0010067109251394868, Depth Loss=0.0000000]
Training progress:  17%|█▋        | 340/2000 [05:33<29:43,  1.07s/it, Loss=0.0138455, Gaussian number=182686, print grad=0.0010439492762088776, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 350/2000 [05:33<23:58,  1.15it/s, Loss=0.0138455, Gaussian number=182686, print grad=0.0010439492762088776, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 350/2000 [05:37<23:58,  1.15it/s, Loss=0.0131625, Gaussian number=182686, print grad=0.0010883043287321925, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 360/2000 [05:37<19:56,  1.37it/s, Loss=0.0131625, Gaussian number=182686, print grad=0.0010883043287321925, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 360/2000 [05:41<19:56,  1.37it/s, Loss=0.0128627, Gaussian number=182686, print grad=0.0011274514254182577, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 370/2000 [05:41<17:06,  1.59it/s, Loss=0.0128627, Gaussian number=182686, print grad=0.0011274514254182577, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 370/2000 [05:45<17:06,  1.59it/s, Loss=0.0172954, Gaussian number=182686, print grad=0.001160676940344274, Depth Loss=0.0000000] 
Training progress:  19%|█▉        | 380/2000 [05:45<15:06,  1.79it/s, Loss=0.0172954, Gaussian number=182686, print grad=0.001160676940344274, Depth Loss=0.0000000]
Training progress:  19%|█▉        | 380/2000 [05:49<15:06,  1.79it/s, Loss=0.0153661, Gaussian number=182686, print grad=0.0012013568775728345, Depth Loss=0.0000000]
Training progress:  20%|█▉        | 390/2000 [05:49<13:42,  1.96it/s, Loss=0.0153661, Gaussian number=182686, print grad=0.0012013568775728345, Depth Loss=0.0000000]
Training progress:  20%|█▉        | 390/2000 [05:53<13:42,  1.96it/s, Loss=0.0182885, Gaussian number=182686, print grad=0.0012396401725709438, Depth Loss=0.0000000]
Training progress:  20%|██        | 400/2000 [05:53<12:42,  2.10it/s, Loss=0.0182885, Gaussian number=182686, print grad=0.0012396401725709438, Depth Loss=0.0000000]
Training progress:  20%|██        | 400/2000 [05:57<12:42,  2.10it/s, Loss=0.0157016, Gaussian number=182686, print grad=0.0012852875515818596, Depth Loss=0.0000000]
Training progress:  20%|██        | 410/2000 [05:57<12:00,  2.21it/s, Loss=0.0157016, Gaussian number=182686, print grad=0.0012852875515818596, Depth Loss=0.0000000]
Training progress:  20%|██        | 410/2000 [06:01<12:00,  2.21it/s, Loss=0.0140148, Gaussian number=182686, print grad=0.0013283997541293502, Depth Loss=0.0000000]
Training progress:  21%|██        | 420/2000 [06:01<11:29,  2.29it/s, Loss=0.0140148, Gaussian number=182686, print grad=0.0013283997541293502, Depth Loss=0.0000000]
Training progress:  21%|██        | 420/2000 [06:05<11:29,  2.29it/s, Loss=0.0175199, Gaussian number=182686, print grad=0.0013727536424994469, Depth Loss=0.0000000]
Training progress:  22%|██▏       | 430/2000 [06:05<11:07,  2.35it/s, Loss=0.0175199, Gaussian number=182686, print grad=0.0013727536424994469, Depth Loss=0.0000000]
Training progress:  22%|██▏       | 430/2000 [06:09<11:07,  2.35it/s, Loss=0.0137062, Gaussian number=182686, print grad=0.0014142063446342945, Depth Loss=0.0000000]
Training progress:  22%|██▏       | 440/2000 [06:09<10:49,  2.40it/s, Loss=0.0137062, Gaussian number=182686, print grad=0.0014142063446342945, Depth Loss=0.0000000]
Training progress:  22%|██▏       | 440/2000 [06:13<10:49,  2.40it/s, Loss=0.0157731, Gaussian number=182686, print grad=0.0014570860657840967, Depth Loss=0.0000000]
Training progress:  22%|██▎       | 450/2000 [06:13<10:35,  2.44it/s, Loss=0.0157731, Gaussian number=182686, print grad=0.0014570860657840967, Depth Loss=0.0000000]
Training progress:  22%|██▎       | 450/2000 [06:17<10:35,  2.44it/s, Loss=0.0163443, Gaussian number=182686, print grad=0.0014989234041422606, Depth Loss=0.0000000]
Training progress:  23%|██▎       | 460/2000 [06:17<10:26,  2.46it/s, Loss=0.0163443, Gaussian number=182686, print grad=0.0014989234041422606, Depth Loss=0.0000000]
Training progress:  23%|██▎       | 460/2000 [06:21<10:26,  2.46it/s, Loss=0.0193552, Gaussian number=182686, print grad=0.0015386424493044615, Depth Loss=0.0000000]
Training progress:  24%|██▎       | 470/2000 [06:21<10:17,  2.48it/s, Loss=0.0193552, Gaussian number=182686, print grad=0.0015386424493044615, Depth Loss=0.0000000]
Training progress:  24%|██▎       | 470/2000 [06:25<10:17,  2.48it/s, Loss=0.0125477, Gaussian number=182686, print grad=0.0015840341802686453, Depth Loss=0.0000000]
Training progress:  24%|██▍       | 480/2000 [06:25<10:10,  2.49it/s, Loss=0.0125477, Gaussian number=182686, print grad=0.0015840341802686453, Depth Loss=0.0000000]
Training progress:  24%|██▍       | 480/2000 [06:29<10:10,  2.49it/s, Loss=0.0139501, Gaussian number=182686, print grad=0.0016251489287242293, Depth Loss=0.0000000]
Training progress:  24%|██▍       | 490/2000 [06:29<10:04,  2.50it/s, Loss=0.0139501, Gaussian number=182686, print grad=0.0016251489287242293, Depth Loss=0.0000000]
Training progress:  24%|██▍       | 490/2000 [06:33<10:04,  2.50it/s, Loss=0.0109579, Gaussian number=182686, print grad=0.00166724540758878, Depth Loss=0.0000000]  
Training progress:  25%|██▌       | 500/2000 [06:33<09:59,  2.50it/s, Loss=0.0109579, Gaussian number=182686, print grad=0.00166724540758878, Depth Loss=0.0000000]
Training progress:  25%|██▌       | 500/2000 [07:41<09:59,  2.50it/s, Loss=0.0129984, Gaussian number=182686, print grad=0.0017092883354052901, Depth Loss=0.0000000]
Training progress:  26%|██▌       | 510/2000 [07:41<57:29,  2.32s/it, Loss=0.0129984, Gaussian number=182686, print grad=0.0017092883354052901, Depth Loss=0.0000000]
Training progress:  26%|██▌       | 510/2000 [07:45<57:29,  2.32s/it, Loss=0.0132466, Gaussian number=182686, print grad=0.001753714052028954, Depth Loss=0.0000000] 
Training progress:  26%|██▌       | 520/2000 [07:45<42:54,  1.74s/it, Loss=0.0132466, Gaussian number=182686, print grad=0.001753714052028954, Depth Loss=0.0000000]
Training progress:  26%|██▌       | 520/2000 [07:49<42:54,  1.74s/it, Loss=0.0104847, Gaussian number=182686, print grad=0.0017921930411830544, Depth Loss=0.0000000]
Training progress:  26%|██▋       | 530/2000 [07:49<32:44,  1.34s/it, Loss=0.0104847, Gaussian number=182686, print grad=0.0017921930411830544, Depth Loss=0.0000000]
Training progress:  26%|██▋       | 530/2000 [07:53<32:44,  1.34s/it, Loss=0.0141773, Gaussian number=182686, print grad=0.0018347172299399972, Depth Loss=0.0000000]
Training progress:  27%|██▋       | 540/2000 [07:53<25:38,  1.05s/it, Loss=0.0141773, Gaussian number=182686, print grad=0.0018347172299399972, Depth Loss=0.0000000]
Training progress:  27%|██▋       | 540/2000 [07:57<25:38,  1.05s/it, Loss=0.0134910, Gaussian number=182686, print grad=0.0018801639089360833, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 550/2000 [07:57<20:42,  1.17it/s, Loss=0.0134910, Gaussian number=182686, print grad=0.0018801639089360833, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 550/2000 [08:01<20:42,  1.17it/s, Loss=0.0108382, Gaussian number=182686, print grad=0.0019221731927245855, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 560/2000 [08:01<17:14,  1.39it/s, Loss=0.0108382, Gaussian number=182686, print grad=0.0019221731927245855, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 560/2000 [08:05<17:14,  1.39it/s, Loss=0.0144208, Gaussian number=182686, print grad=0.0019693574868142605, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 570/2000 [08:05<14:49,  1.61it/s, Loss=0.0144208, Gaussian number=182686, print grad=0.0019693574868142605, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 570/2000 [08:09<14:49,  1.61it/s, Loss=0.0125180, Gaussian number=182686, print grad=0.0020127822645008564, Depth Loss=0.0000000]
Training progress:  29%|██▉       | 580/2000 [08:09<13:06,  1.80it/s, Loss=0.0125180, Gaussian number=182686, print grad=0.0020127822645008564, Depth Loss=0.0000000]
Training progress:  29%|██▉       | 580/2000 [08:13<13:06,  1.80it/s, Loss=0.0143909, Gaussian number=182686, print grad=0.0020578724797815084, Depth Loss=0.0000000]
Training progress:  30%|██▉       | 590/2000 [08:13<11:54,  1.97it/s, Loss=0.0143909, Gaussian number=182686, print grad=0.0020578724797815084, Depth Loss=0.0000000]
Training progress:  30%|██▉       | 590/2000 [08:16<11:54,  1.97it/s, Loss=0.0144114, Gaussian number=182686, print grad=0.002099924720823765, Depth Loss=0.0000000] 
Training progress:  30%|███       | 600/2000 [08:16<11:03,  2.11it/s, Loss=0.0144114, Gaussian number=182686, print grad=0.002099924720823765, Depth Loss=0.0000000]
Training progress:  30%|███       | 600/2000 [08:20<11:03,  2.11it/s, Loss=0.0118924, Gaussian number=182700, print grad=4.000795161118731e-05, Depth Loss=0.0000000]
Training progress:  30%|███       | 610/2000 [08:20<10:25,  2.22it/s, Loss=0.0118924, Gaussian number=182700, print grad=4.000795161118731e-05, Depth Loss=0.0000000]
Training progress:  30%|███       | 610/2000 [08:24<10:25,  2.22it/s, Loss=0.0159858, Gaussian number=182700, print grad=8.623850590083748e-05, Depth Loss=0.0000000]
Training progress:  31%|███       | 620/2000 [08:24<09:58,  2.31it/s, Loss=0.0159858, Gaussian number=182700, print grad=8.623850590083748e-05, Depth Loss=0.0000000]
Training progress:  31%|███       | 620/2000 [08:28<09:58,  2.31it/s, Loss=0.0112503, Gaussian number=182700, print grad=0.00012733560288324952, Depth Loss=0.0000000]
Training progress:  32%|███▏      | 630/2000 [08:28<09:38,  2.37it/s, Loss=0.0112503, Gaussian number=182700, print grad=0.00012733560288324952, Depth Loss=0.0000000]
Training progress:  32%|███▏      | 630/2000 [08:32<09:38,  2.37it/s, Loss=0.0121666, Gaussian number=182700, print grad=0.00017762546485755593, Depth Loss=0.0000000]
Training progress:  32%|███▏      | 640/2000 [08:32<09:23,  2.41it/s, Loss=0.0121666, Gaussian number=182700, print grad=0.00017762546485755593, Depth Loss=0.0000000]
Training progress:  32%|███▏      | 640/2000 [08:36<09:23,  2.41it/s, Loss=0.0144007, Gaussian number=182700, print grad=0.0002177726273657754, Depth Loss=0.0000000] 
Training progress:  32%|███▎      | 650/2000 [08:36<09:11,  2.45it/s, Loss=0.0144007, Gaussian number=182700, print grad=0.0002177726273657754, Depth Loss=0.0000000]
Training progress:  32%|███▎      | 650/2000 [08:40<09:11,  2.45it/s, Loss=0.0146676, Gaussian number=182700, print grad=0.00026612821966409683, Depth Loss=0.0000000]
Training progress:  33%|███▎      | 660/2000 [08:40<09:02,  2.47it/s, Loss=0.0146676, Gaussian number=182700, print grad=0.00026612821966409683, Depth Loss=0.0000000]
Training progress:  33%|███▎      | 660/2000 [08:44<09:02,  2.47it/s, Loss=0.0125993, Gaussian number=182700, print grad=0.00030963230528868735, Depth Loss=0.0000000]
Training progress:  34%|███▎      | 670/2000 [08:44<08:54,  2.49it/s, Loss=0.0125993, Gaussian number=182700, print grad=0.00030963230528868735, Depth Loss=0.0000000]
Training progress:  34%|███▎      | 670/2000 [08:48<08:54,  2.49it/s, Loss=0.0119061, Gaussian number=182700, print grad=0.0003579592448659241, Depth Loss=0.0000000] 
Training progress:  34%|███▍      | 680/2000 [08:48<08:48,  2.50it/s, Loss=0.0119061, Gaussian number=182700, print grad=0.0003579592448659241, Depth Loss=0.0000000]
Training progress:  34%|███▍      | 680/2000 [08:52<08:48,  2.50it/s, Loss=0.0140430, Gaussian number=182700, print grad=0.00040239057852886617, Depth Loss=0.0000000]
Training progress:  34%|███▍      | 690/2000 [08:52<08:42,  2.51it/s, Loss=0.0140430, Gaussian number=182700, print grad=0.00040239057852886617, Depth Loss=0.0000000]
Training progress:  34%|███▍      | 690/2000 [08:56<08:42,  2.51it/s, Loss=0.0140388, Gaussian number=182700, print grad=0.0004459558113012463, Depth Loss=0.0000000] 
Training progress:  35%|███▌      | 700/2000 [08:56<08:37,  2.51it/s, Loss=0.0140388, Gaussian number=182700, print grad=0.0004459558113012463, Depth Loss=0.0000000]
Training progress:  35%|███▌      | 700/2000 [09:00<08:37,  2.51it/s, Loss=0.0124738, Gaussian number=182814, print grad=3.9232872950378805e-05, Depth Loss=0.0000000]
Training progress:  36%|███▌      | 710/2000 [09:00<08:32,  2.52it/s, Loss=0.0124738, Gaussian number=182814, print grad=3.9232872950378805e-05, Depth Loss=0.0000000]
Training progress:  36%|███▌      | 710/2000 [09:04<08:32,  2.52it/s, Loss=0.0112706, Gaussian number=182814, print grad=8.378345955861732e-05, Depth Loss=0.0000000] 
Training progress:  36%|███▌      | 720/2000 [09:04<08:28,  2.52it/s, Loss=0.0112706, Gaussian number=182814, print grad=8.378345955861732e-05, Depth Loss=0.0000000]
Training progress:  36%|███▌      | 720/2000 [09:08<08:28,  2.52it/s, Loss=0.0149277, Gaussian number=182814, print grad=0.00012556744331959635, Depth Loss=0.0000000]
Training progress:  36%|███▋      | 730/2000 [09:08<08:23,  2.52it/s, Loss=0.0149277, Gaussian number=182814, print grad=0.00012556744331959635, Depth Loss=0.0000000]
Training progress:  36%|███▋      | 730/2000 [09:12<08:23,  2.52it/s, Loss=0.0174569, Gaussian number=182814, print grad=0.00017558275430928916, Depth Loss=0.0000000]
Training progress:  37%|███▋      | 740/2000 [09:12<08:19,  2.52it/s, Loss=0.0174569, Gaussian number=182814, print grad=0.00017558275430928916, Depth Loss=0.0000000]
Training progress:  37%|███▋      | 740/2000 [09:16<08:19,  2.52it/s, Loss=0.0125541, Gaussian number=182814, print grad=0.00022240144608076662, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 750/2000 [09:16<08:15,  2.52it/s, Loss=0.0125541, Gaussian number=182814, print grad=0.00022240144608076662, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 750/2000 [09:20<08:15,  2.52it/s, Loss=0.0118718, Gaussian number=182814, print grad=0.0002668273518793285, Depth Loss=0.0000000] 
Training progress:  38%|███▊      | 760/2000 [09:20<08:11,  2.52it/s, Loss=0.0118718, Gaussian number=182814, print grad=0.0002668273518793285, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 760/2000 [09:24<08:11,  2.52it/s, Loss=0.0110911, Gaussian number=182814, print grad=0.00031502946512773633, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 770/2000 [09:24<08:07,  2.52it/s, Loss=0.0110911, Gaussian number=182814, print grad=0.00031502946512773633, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 770/2000 [09:28<08:07,  2.52it/s, Loss=0.0149450, Gaussian number=182814, print grad=0.0003586805541999638, Depth Loss=0.0000000] 
Training progress:  39%|███▉      | 780/2000 [09:28<08:03,  2.52it/s, Loss=0.0149450, Gaussian number=182814, print grad=0.0003586805541999638, Depth Loss=0.0000000]
Training progress:  39%|███▉      | 780/2000 [09:32<08:03,  2.52it/s, Loss=0.0169218, Gaussian number=182814, print grad=0.000403796904720366, Depth Loss=0.0000000] 
Training progress:  40%|███▉      | 790/2000 [09:32<07:59,  2.52it/s, Loss=0.0169218, Gaussian number=182814, print grad=0.000403796904720366, Depth Loss=0.0000000]
Training progress:  40%|███▉      | 790/2000 [09:36<07:59,  2.52it/s, Loss=0.0145808, Gaussian number=182814, print grad=0.00045204395428299904, Depth Loss=0.0000000]
Training progress:  40%|████      | 800/2000 [09:36<07:55,  2.52it/s, Loss=0.0145808, Gaussian number=182814, print grad=0.00045204395428299904, Depth Loss=0.0000000]
Training progress:  40%|████      | 800/2000 [09:40<07:55,  2.52it/s, Loss=0.0137303, Gaussian number=182948, print grad=4.0712500776862726e-05, Depth Loss=0.0000000]
Training progress:  40%|████      | 810/2000 [09:40<07:51,  2.52it/s, Loss=0.0137303, Gaussian number=182948, print grad=4.0712500776862726e-05, Depth Loss=0.0000000]
Training progress:  40%|████      | 810/2000 [09:44<07:51,  2.52it/s, Loss=0.0134606, Gaussian number=182948, print grad=8.498778333887458e-05, Depth Loss=0.0000000] 
Training progress:  41%|████      | 820/2000 [09:44<07:48,  2.52it/s, Loss=0.0134606, Gaussian number=182948, print grad=8.498778333887458e-05, Depth Loss=0.0000000]
Training progress:  41%|████      | 820/2000 [09:48<07:48,  2.52it/s, Loss=0.0106898, Gaussian number=182948, print grad=0.00013877935998607427, Depth Loss=0.0000000]
Training progress:  42%|████▏     | 830/2000 [09:48<07:46,  2.51it/s, Loss=0.0106898, Gaussian number=182948, print grad=0.00013877935998607427, Depth Loss=0.0000000]
Training progress:  42%|████▏     | 830/2000 [09:52<07:46,  2.51it/s, Loss=0.0116183, Gaussian number=182948, print grad=0.00018569825624581426, Depth Loss=0.0000000]
Training progress:  42%|████▏     | 840/2000 [09:52<07:41,  2.51it/s, Loss=0.0116183, Gaussian number=182948, print grad=0.00018569825624581426, Depth Loss=0.0000000]
Training progress:  42%|████▏     | 840/2000 [09:56<07:41,  2.51it/s, Loss=0.0122439, Gaussian number=182948, print grad=0.00023458195209968835, Depth Loss=0.0000000]
Training progress:  42%|████▎     | 850/2000 [09:56<07:36,  2.52it/s, Loss=0.0122439, Gaussian number=182948, print grad=0.00023458195209968835, Depth Loss=0.0000000]
Training progress:  42%|████▎     | 850/2000 [10:00<07:36,  2.52it/s, Loss=0.0121989, Gaussian number=182948, print grad=0.00027934531681239605, Depth Loss=0.0000000]
Training progress:  43%|████▎     | 860/2000 [10:00<07:32,  2.52it/s, Loss=0.0121989, Gaussian number=182948, print grad=0.00027934531681239605, Depth Loss=0.0000000]
Training progress:  43%|████▎     | 860/2000 [10:03<07:32,  2.52it/s, Loss=0.0143955, Gaussian number=182948, print grad=0.0003253334725741297, Depth Loss=0.0000000] 
Training progress:  44%|████▎     | 870/2000 [10:03<07:27,  2.52it/s, Loss=0.0143955, Gaussian number=182948, print grad=0.0003253334725741297, Depth Loss=0.0000000]
Training progress:  44%|████▎     | 870/2000 [10:07<07:27,  2.52it/s, Loss=0.0133493, Gaussian number=182948, print grad=0.00037114910082891583, Depth Loss=0.0000000]
Training progress:  44%|████▍     | 880/2000 [10:07<07:23,  2.52it/s, Loss=0.0133493, Gaussian number=182948, print grad=0.00037114910082891583, Depth Loss=0.0000000]
Training progress:  44%|████▍     | 880/2000 [10:11<07:23,  2.52it/s, Loss=0.0107748, Gaussian number=182948, print grad=0.0004181800759397447, Depth Loss=0.0000000] 
Training progress:  44%|████▍     | 890/2000 [10:11<07:19,  2.53it/s, Loss=0.0107748, Gaussian number=182948, print grad=0.0004181800759397447, Depth Loss=0.0000000]
Training progress:  44%|████▍     | 890/2000 [10:15<07:19,  2.53it/s, Loss=0.0138268, Gaussian number=182948, print grad=0.00046478238073177636, Depth Loss=0.0000000]
Training progress:  45%|████▌     | 900/2000 [10:15<07:15,  2.52it/s, Loss=0.0138268, Gaussian number=182948, print grad=0.00046478238073177636, Depth Loss=0.0000000]
Training progress:  45%|████▌     | 900/2000 [10:19<07:15,  2.52it/s, Loss=0.0106925, Gaussian number=183077, print grad=4.0979892219183967e-05, Depth Loss=0.0000000]
Training progress:  46%|████▌     | 910/2000 [10:19<07:11,  2.53it/s, Loss=0.0106925, Gaussian number=183077, print grad=4.0979892219183967e-05, Depth Loss=0.0000000]
Training progress:  46%|████▌     | 910/2000 [10:23<07:11,  2.53it/s, Loss=0.0127460, Gaussian number=183077, print grad=8.104948210529983e-05, Depth Loss=0.0000000] 
Training progress:  46%|████▌     | 920/2000 [10:23<07:07,  2.53it/s, Loss=0.0127460, Gaussian number=183077, print grad=8.104948210529983e-05, Depth Loss=0.0000000]
Training progress:  46%|████▌     | 920/2000 [10:27<07:07,  2.53it/s, Loss=0.0134931, Gaussian number=183077, print grad=0.00013151971506886184, Depth Loss=0.0000000]
Training progress:  46%|████▋     | 930/2000 [10:27<07:03,  2.53it/s, Loss=0.0134931, Gaussian number=183077, print grad=0.00013151971506886184, Depth Loss=0.0000000]
Training progress:  46%|████▋     | 930/2000 [10:31<07:03,  2.53it/s, Loss=0.0122518, Gaussian number=183077, print grad=0.00017593419761396945, Depth Loss=0.0000000]
Training progress:  47%|████▋     | 940/2000 [10:31<06:59,  2.53it/s, Loss=0.0122518, Gaussian number=183077, print grad=0.00017593419761396945, Depth Loss=0.0000000]
Training progress:  47%|████▋     | 940/2000 [10:35<06:59,  2.53it/s, Loss=0.0117338, Gaussian number=183077, print grad=0.00022351962979882956, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 950/2000 [10:35<06:55,  2.53it/s, Loss=0.0117338, Gaussian number=183077, print grad=0.00022351962979882956, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 950/2000 [10:39<06:55,  2.53it/s, Loss=0.0122552, Gaussian number=183077, print grad=0.00026857119519263506, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 960/2000 [10:39<06:51,  2.53it/s, Loss=0.0122552, Gaussian number=183077, print grad=0.00026857119519263506, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 960/2000 [10:43<06:51,  2.53it/s, Loss=0.0156269, Gaussian number=183077, print grad=0.0003181940992362797, Depth Loss=0.0000000] 
Training progress:  48%|████▊     | 970/2000 [10:43<06:47,  2.53it/s, Loss=0.0156269, Gaussian number=183077, print grad=0.0003181940992362797, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 970/2000 [10:47<06:47,  2.53it/s, Loss=0.0104128, Gaussian number=183077, print grad=0.0003658727218862623, Depth Loss=0.0000000]
Training progress:  49%|████▉     | 980/2000 [10:47<06:43,  2.53it/s, Loss=0.0104128, Gaussian number=183077, print grad=0.0003658727218862623, Depth Loss=0.0000000]
Training progress:  49%|████▉     | 980/2000 [10:51<06:43,  2.53it/s, Loss=0.0105552, Gaussian number=183077, print grad=0.0004075914330314845, Depth Loss=0.0000000]
Training progress:  50%|████▉     | 990/2000 [10:51<06:39,  2.53it/s, Loss=0.0105552, Gaussian number=183077, print grad=0.0004075914330314845, Depth Loss=0.0000000]
Training progress:  50%|████▉     | 990/2000 [10:55<06:39,  2.53it/s, Loss=0.0138598, Gaussian number=183077, print grad=0.00044732456444762647, Depth Loss=0.0000000]
Training progress:  50%|█████     | 1000/2000 [10:55<06:35,  2.53it/s, Loss=0.0138598, Gaussian number=183077, print grad=0.00044732456444762647, Depth Loss=0.0000000]
Training progress:  50%|█████     | 1000/2000 [12:03<06:35,  2.53it/s, Loss=0.0124562, Gaussian number=183215, print grad=3.993805148638785e-05, Depth Loss=0.0000000] 
Training progress:  50%|█████     | 1010/2000 [12:03<38:07,  2.31s/it, Loss=0.0124562, Gaussian number=183215, print grad=3.993805148638785e-05, Depth Loss=0.0000000]
Training progress:  50%|█████     | 1010/2000 [12:07<38:07,  2.31s/it, Loss=0.0154916, Gaussian number=183215, print grad=9.398155816597864e-05, Depth Loss=0.0000000]
Training progress:  51%|█████     | 1020/2000 [12:07<28:21,  1.74s/it, Loss=0.0154916, Gaussian number=183215, print grad=9.398155816597864e-05, Depth Loss=0.0000000]
Training progress:  51%|█████     | 1020/2000 [12:11<28:21,  1.74s/it, Loss=0.0126972, Gaussian number=183215, print grad=0.00014276943693403155, Depth Loss=0.0000000]
Training progress:  52%|█████▏    | 1030/2000 [12:11<21:33,  1.33s/it, Loss=0.0126972, Gaussian number=183215, print grad=0.00014276943693403155, Depth Loss=0.0000000]
Training progress:  52%|█████▏    | 1030/2000 [12:15<21:33,  1.33s/it, Loss=0.0133945, Gaussian number=183215, print grad=0.0001950360310729593, Depth Loss=0.0000000] 
Training progress:  52%|█████▏    | 1040/2000 [12:15<16:49,  1.05s/it, Loss=0.0133945, Gaussian number=183215, print grad=0.0001950360310729593, Depth Loss=0.0000000]
Training progress:  52%|█████▏    | 1040/2000 [12:18<16:49,  1.05s/it, Loss=0.0124124, Gaussian number=183215, print grad=0.0002367538254475221, Depth Loss=0.0000000]
Training progress:  52%|█████▎    | 1050/2000 [12:18<13:31,  1.17it/s, Loss=0.0124124, Gaussian number=183215, print grad=0.0002367538254475221, Depth Loss=0.0000000]
Training progress:  52%|█████▎    | 1050/2000 [12:22<13:31,  1.17it/s, Loss=0.0116636, Gaussian number=183215, print grad=0.0002827343123499304, Depth Loss=0.0000000]
Training progress:  53%|█████▎    | 1060/2000 [12:22<11:13,  1.40it/s, Loss=0.0116636, Gaussian number=183215, print grad=0.0002827343123499304, Depth Loss=0.0000000]
Training progress:  53%|█████▎    | 1060/2000 [12:26<11:13,  1.40it/s, Loss=0.0097270, Gaussian number=183215, print grad=0.0003347440215293318, Depth Loss=0.0000000]
Training progress:  54%|█████▎    | 1070/2000 [12:26<09:36,  1.61it/s, Loss=0.0097270, Gaussian number=183215, print grad=0.0003347440215293318, Depth Loss=0.0000000]
Training progress:  54%|█████▎    | 1070/2000 [12:30<09:36,  1.61it/s, Loss=0.0104573, Gaussian number=183215, print grad=0.0003804476582445204, Depth Loss=0.0000000]
Training progress:  54%|█████▍    | 1080/2000 [12:30<08:28,  1.81it/s, Loss=0.0104573, Gaussian number=183215, print grad=0.0003804476582445204, Depth Loss=0.0000000]
Training progress:  54%|█████▍    | 1080/2000 [12:34<08:28,  1.81it/s, Loss=0.0133775, Gaussian number=183215, print grad=0.00042911304626613855, Depth Loss=0.0000000]
Training progress:  55%|█████▍    | 1090/2000 [12:34<07:39,  1.98it/s, Loss=0.0133775, Gaussian number=183215, print grad=0.00042911304626613855, Depth Loss=0.0000000]
Training progress:  55%|█████▍    | 1090/2000 [12:38<07:39,  1.98it/s, Loss=0.0128773, Gaussian number=183215, print grad=0.00047680040006525815, Depth Loss=0.0000000]
Training progress:  55%|█████▌    | 1100/2000 [12:38<07:04,  2.12it/s, Loss=0.0128773, Gaussian number=183215, print grad=0.00047680040006525815, Depth Loss=0.0000000]
Training progress:  55%|█████▌    | 1100/2000 [12:42<07:04,  2.12it/s, Loss=0.0140483, Gaussian number=183388, print grad=4.2266907257726416e-05, Depth Loss=0.0000000]
Training progress:  56%|█████▌    | 1110/2000 [12:42<06:39,  2.23it/s, Loss=0.0140483, Gaussian number=183388, print grad=4.2266907257726416e-05, Depth Loss=0.0000000]
Training progress:  56%|█████▌    | 1110/2000 [12:46<06:39,  2.23it/s, Loss=0.0126756, Gaussian number=183388, print grad=9.318437514593825e-05, Depth Loss=0.0000000] 
Training progress:  56%|█████▌    | 1120/2000 [12:46<06:20,  2.31it/s, Loss=0.0126756, Gaussian number=183388, print grad=9.318437514593825e-05, Depth Loss=0.0000000]
Training progress:  56%|█████▌    | 1120/2000 [12:50<06:20,  2.31it/s, Loss=0.0101028, Gaussian number=183388, print grad=0.0001449206320103258, Depth Loss=0.0000000]
Training progress:  56%|█████▋    | 1130/2000 [12:50<06:06,  2.37it/s, Loss=0.0101028, Gaussian number=183388, print grad=0.0001449206320103258, Depth Loss=0.0000000]
Training progress:  56%|█████▋    | 1130/2000 [12:54<06:06,  2.37it/s, Loss=0.0126534, Gaussian number=183388, print grad=0.00019581180822569877, Depth Loss=0.0000000]
Training progress:  57%|█████▋    | 1140/2000 [12:54<05:55,  2.42it/s, Loss=0.0126534, Gaussian number=183388, print grad=0.00019581180822569877, Depth Loss=0.0000000]
Training progress:  57%|█████▋    | 1140/2000 [12:58<05:55,  2.42it/s, Loss=0.0090820, Gaussian number=183388, print grad=0.00024535562261007726, Depth Loss=0.0000000]
Training progress:  57%|█████▊    | 1150/2000 [12:58<05:46,  2.45it/s, Loss=0.0090820, Gaussian number=183388, print grad=0.00024535562261007726, Depth Loss=0.0000000]
Training progress:  57%|█████▊    | 1150/2000 [13:02<05:46,  2.45it/s, Loss=0.0098606, Gaussian number=183388, print grad=0.00028880886384285986, Depth Loss=0.0000000]
Training progress:  58%|█████▊    | 1160/2000 [13:02<05:39,  2.47it/s, Loss=0.0098606, Gaussian number=183388, print grad=0.00028880886384285986, Depth Loss=0.0000000]
Training progress:  58%|█████▊    | 1160/2000 [13:06<05:39,  2.47it/s, Loss=0.0121797, Gaussian number=183388, print grad=0.00033685617381706834, Depth Loss=0.0000000]
Training progress:  58%|█████▊    | 1170/2000 [13:06<05:33,  2.49it/s, Loss=0.0121797, Gaussian number=183388, print grad=0.00033685617381706834, Depth Loss=0.0000000]
Training progress:  58%|█████▊    | 1170/2000 [13:10<05:33,  2.49it/s, Loss=0.0127500, Gaussian number=183388, print grad=0.0003860279393848032, Depth Loss=0.0000000] 
Training progress:  59%|█████▉    | 1180/2000 [13:10<05:27,  2.50it/s, Loss=0.0127500, Gaussian number=183388, print grad=0.0003860279393848032, Depth Loss=0.0000000]
Training progress:  59%|█████▉    | 1180/2000 [13:14<05:27,  2.50it/s, Loss=0.0120610, Gaussian number=183388, print grad=0.00043731433106586337, Depth Loss=0.0000000]
Training progress:  60%|█████▉    | 1190/2000 [13:14<05:22,  2.51it/s, Loss=0.0120610, Gaussian number=183388, print grad=0.00043731433106586337, Depth Loss=0.0000000]
Training progress:  60%|█████▉    | 1190/2000 [13:18<05:22,  2.51it/s, Loss=0.0136124, Gaussian number=183388, print grad=0.0004792012623511255, Depth Loss=0.0000000] 
Training progress:  60%|██████    | 1200/2000 [13:18<05:17,  2.52it/s, Loss=0.0136124, Gaussian number=183388, print grad=0.0004792012623511255, Depth Loss=0.0000000]
Training progress:  60%|██████    | 1200/2000 [13:22<05:17,  2.52it/s, Loss=0.0105068, Gaussian number=183549, print grad=4.631964475265704e-05, Depth Loss=0.0000000]
Training progress:  60%|██████    | 1210/2000 [13:22<05:13,  2.52it/s, Loss=0.0105068, Gaussian number=183549, print grad=4.631964475265704e-05, Depth Loss=0.0000000]
Training progress:  60%|██████    | 1210/2000 [13:26<05:13,  2.52it/s, Loss=0.0089294, Gaussian number=183549, print grad=9.943186159944162e-05, Depth Loss=0.0000000]
Training progress:  61%|██████    | 1220/2000 [13:26<05:09,  2.52it/s, Loss=0.0089294, Gaussian number=183549, print grad=9.943186159944162e-05, Depth Loss=0.0000000]
Training progress:  61%|██████    | 1220/2000 [13:30<05:09,  2.52it/s, Loss=0.0096889, Gaussian number=183549, print grad=0.00014535387163050473, Depth Loss=0.0000000]
Training progress:  62%|██████▏   | 1230/2000 [13:30<05:04,  2.53it/s, Loss=0.0096889, Gaussian number=183549, print grad=0.00014535387163050473, Depth Loss=0.0000000]
Training progress:  62%|██████▏   | 1230/2000 [13:34<05:04,  2.53it/s, Loss=0.0094788, Gaussian number=183549, print grad=0.000197619607206434, Depth Loss=0.0000000]  
Training progress:  62%|██████▏   | 1240/2000 [13:34<05:00,  2.53it/s, Loss=0.0094788, Gaussian number=183549, print grad=0.000197619607206434, Depth Loss=0.0000000]
Training progress:  62%|██████▏   | 1240/2000 [13:37<05:00,  2.53it/s, Loss=0.0095734, Gaussian number=183549, print grad=0.00024106306955218315, Depth Loss=0.0000000]
Training progress:  62%|██████▎   | 1250/2000 [13:37<04:56,  2.53it/s, Loss=0.0095734, Gaussian number=183549, print grad=0.00024106306955218315, Depth Loss=0.0000000]
Training progress:  62%|██████▎   | 1250/2000 [13:41<04:56,  2.53it/s, Loss=0.0099430, Gaussian number=183549, print grad=0.00028330739587545395, Depth Loss=0.0000000]
Training progress:  63%|██████▎   | 1260/2000 [13:41<04:52,  2.53it/s, Loss=0.0099430, Gaussian number=183549, print grad=0.00028330739587545395, Depth Loss=0.0000000]
Training progress:  63%|██████▎   | 1260/2000 [13:45<04:52,  2.53it/s, Loss=0.0121693, Gaussian number=183549, print grad=0.00033354084007442, Depth Loss=0.0000000]   
Training progress:  64%|██████▎   | 1270/2000 [13:45<04:48,  2.53it/s, Loss=0.0121693, Gaussian number=183549, print grad=0.00033354084007442, Depth Loss=0.0000000]
Training progress:  64%|██████▎   | 1270/2000 [13:49<04:48,  2.53it/s, Loss=0.0122912, Gaussian number=183549, print grad=0.00037797802360728383, Depth Loss=0.0000000]
Training progress:  64%|██████▍   | 1280/2000 [13:49<04:44,  2.53it/s, Loss=0.0122912, Gaussian number=183549, print grad=0.00037797802360728383, Depth Loss=0.0000000]
Training progress:  64%|██████▍   | 1280/2000 [13:53<04:44,  2.53it/s, Loss=0.0097433, Gaussian number=183549, print grad=0.0004294171812944114, Depth Loss=0.0000000] 
Training progress:  64%|██████▍   | 1290/2000 [13:53<04:40,  2.53it/s, Loss=0.0097433, Gaussian number=183549, print grad=0.0004294171812944114, Depth Loss=0.0000000]
Training progress:  64%|██████▍   | 1290/2000 [13:57<04:40,  2.53it/s, Loss=0.0144588, Gaussian number=183549, print grad=0.0004750194784719497, Depth Loss=0.0000000]
Training progress:  65%|██████▌   | 1300/2000 [13:57<04:36,  2.53it/s, Loss=0.0144588, Gaussian number=183549, print grad=0.0004750194784719497, Depth Loss=0.0000000]
Training progress:  65%|██████▌   | 1300/2000 [14:01<04:36,  2.53it/s, Loss=0.0134469, Gaussian number=183709, print grad=4.862589048570953e-05, Depth Loss=0.0000000]
Training progress:  66%|██████▌   | 1310/2000 [14:01<04:32,  2.53it/s, Loss=0.0134469, Gaussian number=183709, print grad=4.862589048570953e-05, Depth Loss=0.0000000]
Training progress:  66%|██████▌   | 1310/2000 [14:05<04:32,  2.53it/s, Loss=0.0132506, Gaussian number=183709, print grad=9.468688222113997e-05, Depth Loss=0.0000000]
Training progress:  66%|██████▌   | 1320/2000 [14:05<04:28,  2.53it/s, Loss=0.0132506, Gaussian number=183709, print grad=9.468688222113997e-05, Depth Loss=0.0000000]
Training progress:  66%|██████▌   | 1320/2000 [14:09<04:28,  2.53it/s, Loss=0.0104575, Gaussian number=183709, print grad=0.0001434083969797939, Depth Loss=0.0000000]
Training progress:  66%|██████▋   | 1330/2000 [14:09<04:24,  2.53it/s, Loss=0.0104575, Gaussian number=183709, print grad=0.0001434083969797939, Depth Loss=0.0000000]
Training progress:  66%|██████▋   | 1330/2000 [14:13<04:24,  2.53it/s, Loss=0.0113315, Gaussian number=183709, print grad=0.00019445766520220786, Depth Loss=0.0000000]
Training progress:  67%|██████▋   | 1340/2000 [14:13<04:20,  2.53it/s, Loss=0.0113315, Gaussian number=183709, print grad=0.00019445766520220786, Depth Loss=0.0000000]
Training progress:  67%|██████▋   | 1340/2000 [14:17<04:20,  2.53it/s, Loss=0.0152737, Gaussian number=183709, print grad=0.00023709621746093035, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1350/2000 [14:17<04:16,  2.53it/s, Loss=0.0152737, Gaussian number=183709, print grad=0.00023709621746093035, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1350/2000 [14:21<04:16,  2.53it/s, Loss=0.0092098, Gaussian number=183709, print grad=0.0002829527948051691, Depth Loss=0.0000000] 
Training progress:  68%|██████▊   | 1360/2000 [14:21<04:12,  2.54it/s, Loss=0.0092098, Gaussian number=183709, print grad=0.0002829527948051691, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1360/2000 [14:25<04:12,  2.54it/s, Loss=0.0171150, Gaussian number=183709, print grad=0.0003348898026160896, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1370/2000 [14:25<04:08,  2.53it/s, Loss=0.0171150, Gaussian number=183709, print grad=0.0003348898026160896, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1370/2000 [14:29<04:08,  2.53it/s, Loss=0.0110975, Gaussian number=183709, print grad=0.000380319805117324, Depth Loss=0.0000000] 
Training progress:  69%|██████▉   | 1380/2000 [14:29<04:04,  2.53it/s, Loss=0.0110975, Gaussian number=183709, print grad=0.000380319805117324, Depth Loss=0.0000000]
Training progress:  69%|██████▉   | 1380/2000 [14:33<04:04,  2.53it/s, Loss=0.0101203, Gaussian number=183709, print grad=0.000425392558099702, Depth Loss=0.0000000]
Training progress:  70%|██████▉   | 1390/2000 [14:33<04:01,  2.53it/s, Loss=0.0101203, Gaussian number=183709, print grad=0.000425392558099702, Depth Loss=0.0000000]
Training progress:  70%|██████▉   | 1390/2000 [14:37<04:01,  2.53it/s, Loss=0.0114059, Gaussian number=183709, print grad=0.0004743046301882714, Depth Loss=0.0000000]
Training progress:  70%|███████   | 1400/2000 [14:37<03:57,  2.53it/s, Loss=0.0114059, Gaussian number=183709, print grad=0.0004743046301882714, Depth Loss=0.0000000]
Training progress:  70%|███████   | 1400/2000 [14:41<03:57,  2.53it/s, Loss=0.0125392, Gaussian number=183903, print grad=5.087626414024271e-05, Depth Loss=0.0000000]
Training progress:  70%|███████   | 1410/2000 [14:41<03:53,  2.53it/s, Loss=0.0125392, Gaussian number=183903, print grad=5.087626414024271e-05, Depth Loss=0.0000000]
Training progress:  70%|███████   | 1410/2000 [14:45<03:53,  2.53it/s, Loss=0.0112221, Gaussian number=183903, print grad=0.00010299197310814634, Depth Loss=0.0000000]
Training progress:  71%|███████   | 1420/2000 [14:45<03:49,  2.53it/s, Loss=0.0112221, Gaussian number=183903, print grad=0.00010299197310814634, Depth Loss=0.0000000]
Training progress:  71%|███████   | 1420/2000 [14:49<03:49,  2.53it/s, Loss=0.0111904, Gaussian number=183903, print grad=0.0001576883951202035, Depth Loss=0.0000000] 
Training progress:  72%|███████▏  | 1430/2000 [14:49<03:45,  2.53it/s, Loss=0.0111904, Gaussian number=183903, print grad=0.0001576883951202035, Depth Loss=0.0000000]
Training progress:  72%|███████▏  | 1430/2000 [14:53<03:45,  2.53it/s, Loss=0.0107926, Gaussian number=183903, print grad=0.00020224554464221, Depth Loss=0.0000000]  
Training progress:  72%|███████▏  | 1440/2000 [14:53<03:41,  2.53it/s, Loss=0.0107926, Gaussian number=183903, print grad=0.00020224554464221, Depth Loss=0.0000000]
Training progress:  72%|███████▏  | 1440/2000 [14:56<03:41,  2.53it/s, Loss=0.0094739, Gaussian number=183903, print grad=0.00024772449978627264, Depth Loss=0.0000000]
Training progress:  72%|███████▎  | 1450/2000 [14:56<03:37,  2.53it/s, Loss=0.0094739, Gaussian number=183903, print grad=0.00024772449978627264, Depth Loss=0.0000000]
Training progress:  72%|███████▎  | 1450/2000 [15:00<03:37,  2.53it/s, Loss=0.0086027, Gaussian number=183903, print grad=0.0002958722470793873, Depth Loss=0.0000000] 
Training progress:  73%|███████▎  | 1460/2000 [15:00<03:33,  2.53it/s, Loss=0.0086027, Gaussian number=183903, print grad=0.0002958722470793873, Depth Loss=0.0000000]
Training progress:  73%|███████▎  | 1460/2000 [15:04<03:33,  2.53it/s, Loss=0.0114426, Gaussian number=183903, print grad=0.0003437528503127396, Depth Loss=0.0000000]
Training progress:  74%|███████▎  | 1470/2000 [15:04<03:29,  2.53it/s, Loss=0.0114426, Gaussian number=183903, print grad=0.0003437528503127396, Depth Loss=0.0000000]
Training progress:  74%|███████▎  | 1470/2000 [15:08<03:29,  2.53it/s, Loss=0.0117486, Gaussian number=183903, print grad=0.0003949332167394459, Depth Loss=0.0000000]
Training progress:  74%|███████▍  | 1480/2000 [15:08<03:25,  2.53it/s, Loss=0.0117486, Gaussian number=183903, print grad=0.0003949332167394459, Depth Loss=0.0000000]
Training progress:  74%|███████▍  | 1480/2000 [15:12<03:25,  2.53it/s, Loss=0.0123436, Gaussian number=183903, print grad=0.00044666469329968095, Depth Loss=0.0000000]
Training progress:  74%|███████▍  | 1490/2000 [15:12<03:21,  2.53it/s, Loss=0.0123436, Gaussian number=183903, print grad=0.00044666469329968095, Depth Loss=0.0000000]
Training progress:  74%|███████▍  | 1490/2000 [15:16<03:21,  2.53it/s, Loss=0.0117251, Gaussian number=183903, print grad=0.0004968892317265272, Depth Loss=0.0000000] 
Training progress:  75%|███████▌  | 1500/2000 [15:16<03:17,  2.53it/s, Loss=0.0117251, Gaussian number=183903, print grad=0.0004968892317265272, Depth Loss=0.0000000]
Training progress:  75%|███████▌  | 1500/2000 [16:24<03:17,  2.53it/s, Loss=0.0129707, Gaussian number=184077, print grad=4.3493681005202234e-05, Depth Loss=0.0000000]
Training progress:  76%|███████▌  | 1510/2000 [16:24<18:53,  2.31s/it, Loss=0.0129707, Gaussian number=184077, print grad=4.3493681005202234e-05, Depth Loss=0.0000000]
Training progress:  76%|███████▌  | 1510/2000 [16:28<18:53,  2.31s/it, Loss=0.0113880, Gaussian number=184077, print grad=8.953389624366537e-05, Depth Loss=0.0000000] 
Training progress:  76%|███████▌  | 1520/2000 [16:28<13:53,  1.74s/it, Loss=0.0113880, Gaussian number=184077, print grad=8.953389624366537e-05, Depth Loss=0.0000000]
Training progress:  76%|███████▌  | 1520/2000 [16:32<13:53,  1.74s/it, Loss=0.0072667, Gaussian number=184077, print grad=0.00014257787552196532, Depth Loss=0.0000000]
Training progress:  76%|███████▋  | 1530/2000 [16:32<10:27,  1.33s/it, Loss=0.0072667, Gaussian number=184077, print grad=0.00014257787552196532, Depth Loss=0.0000000]
Training progress:  76%|███████▋  | 1530/2000 [16:36<10:27,  1.33s/it, Loss=0.0098146, Gaussian number=184077, print grad=0.0001921575894812122, Depth Loss=0.0000000] 
Training progress:  77%|███████▋  | 1540/2000 [16:36<08:03,  1.05s/it, Loss=0.0098146, Gaussian number=184077, print grad=0.0001921575894812122, Depth Loss=0.0000000]
Training progress:  77%|███████▋  | 1540/2000 [16:40<08:03,  1.05s/it, Loss=0.0109059, Gaussian number=184077, print grad=0.00024401972768828273, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1550/2000 [16:40<06:24,  1.17it/s, Loss=0.0109059, Gaussian number=184077, print grad=0.00024401972768828273, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1550/2000 [16:44<06:24,  1.17it/s, Loss=0.0115129, Gaussian number=184077, print grad=0.00029875783366151154, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1560/2000 [16:44<05:15,  1.40it/s, Loss=0.0115129, Gaussian number=184077, print grad=0.00029875783366151154, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1560/2000 [16:48<05:15,  1.40it/s, Loss=0.0100093, Gaussian number=184077, print grad=0.0003507673682179302, Depth Loss=0.0000000] 
Training progress:  78%|███████▊  | 1570/2000 [16:48<04:26,  1.61it/s, Loss=0.0100093, Gaussian number=184077, print grad=0.0003507673682179302, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1570/2000 [16:52<04:26,  1.61it/s, Loss=0.0075952, Gaussian number=184077, print grad=0.000393053749576211, Depth Loss=0.0000000] 
Training progress:  79%|███████▉  | 1580/2000 [16:52<03:51,  1.81it/s, Loss=0.0075952, Gaussian number=184077, print grad=0.000393053749576211, Depth Loss=0.0000000]
Training progress:  79%|███████▉  | 1580/2000 [16:56<03:51,  1.81it/s, Loss=0.0107379, Gaussian number=184077, print grad=0.00043873037793673575, Depth Loss=0.0000000]
Training progress:  80%|███████▉  | 1590/2000 [16:56<03:26,  1.98it/s, Loss=0.0107379, Gaussian number=184077, print grad=0.00043873037793673575, Depth Loss=0.0000000]
Training progress:  80%|███████▉  | 1590/2000 [17:00<03:26,  1.98it/s, Loss=0.0103888, Gaussian number=184077, print grad=0.0004915143363177776, Depth Loss=0.0000000] 
Training progress:  80%|████████  | 1600/2000 [17:00<03:08,  2.12it/s, Loss=0.0103888, Gaussian number=184077, print grad=0.0004915143363177776, Depth Loss=0.0000000]
Training progress:  80%|████████  | 1600/2000 [17:03<03:08,  2.12it/s, Loss=0.0109729, Gaussian number=184253, print grad=5.005405910196714e-05, Depth Loss=0.0000000]
Training progress:  80%|████████  | 1610/2000 [17:03<02:54,  2.23it/s, Loss=0.0109729, Gaussian number=184253, print grad=5.005405910196714e-05, Depth Loss=0.0000000]
Training progress:  80%|████████  | 1610/2000 [17:07<02:54,  2.23it/s, Loss=0.0112072, Gaussian number=184253, print grad=0.00010598845256026834, Depth Loss=0.0000000]
Training progress:  81%|████████  | 1620/2000 [17:07<02:44,  2.32it/s, Loss=0.0112072, Gaussian number=184253, print grad=0.00010598845256026834, Depth Loss=0.0000000]
Training progress:  81%|████████  | 1620/2000 [17:11<02:44,  2.32it/s, Loss=0.0098954, Gaussian number=184253, print grad=0.00015485499170608819, Depth Loss=0.0000000]
Training progress:  82%|████████▏ | 1630/2000 [17:11<02:36,  2.37it/s, Loss=0.0098954, Gaussian number=184253, print grad=0.00015485499170608819, Depth Loss=0.0000000]
Training progress:  82%|████████▏ | 1630/2000 [17:15<02:36,  2.37it/s, Loss=0.0076481, Gaussian number=184253, print grad=0.00020429173309821635, Depth Loss=0.0000000]
Training progress:  82%|████████▏ | 1640/2000 [17:15<02:29,  2.42it/s, Loss=0.0076481, Gaussian number=184253, print grad=0.00020429173309821635, Depth Loss=0.0000000]
Training progress:  82%|████████▏ | 1640/2000 [17:19<02:29,  2.42it/s, Loss=0.0100631, Gaussian number=184253, print grad=0.00025187162100337446, Depth Loss=0.0000000]
Training progress:  82%|████████▎ | 1650/2000 [17:19<02:22,  2.45it/s, Loss=0.0100631, Gaussian number=184253, print grad=0.00025187162100337446, Depth Loss=0.0000000]
Training progress:  82%|████████▎ | 1650/2000 [17:23<02:22,  2.45it/s, Loss=0.0100265, Gaussian number=184253, print grad=0.00030001963023096323, Depth Loss=0.0000000]
Training progress:  83%|████████▎ | 1660/2000 [17:23<02:17,  2.48it/s, Loss=0.0100265, Gaussian number=184253, print grad=0.00030001963023096323, Depth Loss=0.0000000]
Training progress:  83%|████████▎ | 1660/2000 [17:27<02:17,  2.48it/s, Loss=0.0093405, Gaussian number=184253, print grad=0.0003478966245893389, Depth Loss=0.0000000] 
Training progress:  84%|████████▎ | 1670/2000 [17:27<02:12,  2.50it/s, Loss=0.0093405, Gaussian number=184253, print grad=0.0003478966245893389, Depth Loss=0.0000000]
Training progress:  84%|████████▎ | 1670/2000 [17:31<02:12,  2.50it/s, Loss=0.0087870, Gaussian number=184253, print grad=0.00039918115362524986, Depth Loss=0.0000000]
Training progress:  84%|████████▍ | 1680/2000 [17:31<02:07,  2.51it/s, Loss=0.0087870, Gaussian number=184253, print grad=0.00039918115362524986, Depth Loss=0.0000000]
Training progress:  84%|████████▍ | 1680/2000 [17:35<02:07,  2.51it/s, Loss=0.0101622, Gaussian number=184253, print grad=0.00045030712499283254, Depth Loss=0.0000000]
Training progress:  84%|████████▍ | 1690/2000 [17:35<02:03,  2.52it/s, Loss=0.0101622, Gaussian number=184253, print grad=0.00045030712499283254, Depth Loss=0.0000000]
Training progress:  84%|████████▍ | 1690/2000 [17:39<02:03,  2.52it/s, Loss=0.0110466, Gaussian number=184253, print grad=0.0004971064627170563, Depth Loss=0.0000000] 
Training progress:  85%|████████▌ | 1700/2000 [17:39<01:59,  2.52it/s, Loss=0.0110466, Gaussian number=184253, print grad=0.0004971064627170563, Depth Loss=0.0000000]
Training progress:  85%|████████▌ | 1700/2000 [17:43<01:59,  2.52it/s, Loss=0.0110405, Gaussian number=184462, print grad=5.1977589464513585e-05, Depth Loss=0.0000000]
Training progress:  86%|████████▌ | 1710/2000 [17:43<01:54,  2.52it/s, Loss=0.0110405, Gaussian number=184462, print grad=5.1977589464513585e-05, Depth Loss=0.0000000]
Training progress:  86%|████████▌ | 1710/2000 [17:47<01:54,  2.52it/s, Loss=0.0117153, Gaussian number=184462, print grad=9.654343011789024e-05, Depth Loss=0.0000000] 
Training progress:  86%|████████▌ | 1720/2000 [17:47<01:50,  2.53it/s, Loss=0.0117153, Gaussian number=184462, print grad=9.654343011789024e-05, Depth Loss=0.0000000]
Training progress:  86%|████████▌ | 1720/2000 [17:51<01:50,  2.53it/s, Loss=0.0105804, Gaussian number=184462, print grad=0.0001464585802750662, Depth Loss=0.0000000]
Training progress:  86%|████████▋ | 1730/2000 [17:51<01:46,  2.53it/s, Loss=0.0105804, Gaussian number=184462, print grad=0.0001464585802750662, Depth Loss=0.0000000]
Training progress:  86%|████████▋ | 1730/2000 [17:55<01:46,  2.53it/s, Loss=0.0133099, Gaussian number=184462, print grad=0.00020142037828918546, Depth Loss=0.0000000]
Training progress:  87%|████████▋ | 1740/2000 [17:55<01:42,  2.53it/s, Loss=0.0133099, Gaussian number=184462, print grad=0.00020142037828918546, Depth Loss=0.0000000]
Training progress:  87%|████████▋ | 1740/2000 [17:59<01:42,  2.53it/s, Loss=0.0129675, Gaussian number=184462, print grad=0.00025527842808514833, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1750/2000 [17:59<01:38,  2.54it/s, Loss=0.0129675, Gaussian number=184462, print grad=0.00025527842808514833, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1750/2000 [18:03<01:38,  2.54it/s, Loss=0.0109525, Gaussian number=184462, print grad=0.00030538946157321334, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1760/2000 [18:03<01:34,  2.54it/s, Loss=0.0109525, Gaussian number=184462, print grad=0.00030538946157321334, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1760/2000 [18:07<01:34,  2.54it/s, Loss=0.0088637, Gaussian number=184462, print grad=0.0003523711347952485, Depth Loss=0.0000000] 
Training progress:  88%|████████▊ | 1770/2000 [18:07<01:30,  2.54it/s, Loss=0.0088637, Gaussian number=184462, print grad=0.0003523711347952485, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1770/2000 [18:11<01:30,  2.54it/s, Loss=0.0104567, Gaussian number=184462, print grad=0.00039927821489982307, Depth Loss=0.0000000]
Training progress:  89%|████████▉ | 1780/2000 [18:11<01:26,  2.53it/s, Loss=0.0104567, Gaussian number=184462, print grad=0.00039927821489982307, Depth Loss=0.0000000]
Training progress:  89%|████████▉ | 1780/2000 [18:14<01:26,  2.53it/s, Loss=0.0096872, Gaussian number=184462, print grad=0.0004411899426486343, Depth Loss=0.0000000] 
Training progress:  90%|████████▉ | 1790/2000 [18:14<01:22,  2.54it/s, Loss=0.0096872, Gaussian number=184462, print grad=0.0004411899426486343, Depth Loss=0.0000000]
Training progress:  90%|████████▉ | 1790/2000 [18:18<01:22,  2.54it/s, Loss=0.0098013, Gaussian number=184462, print grad=0.0004951065639033914, Depth Loss=0.0000000]
Training progress:  90%|█████████ | 1800/2000 [18:18<01:18,  2.53it/s, Loss=0.0098013, Gaussian number=184462, print grad=0.0004951065639033914, Depth Loss=0.0000000]
Training progress:  90%|█████████ | 1800/2000 [18:22<01:18,  2.53it/s, Loss=0.0104498, Gaussian number=184625, print grad=4.9775451770983636e-05, Depth Loss=0.0000000]
Training progress:  90%|█████████ | 1810/2000 [18:22<01:15,  2.53it/s, Loss=0.0104498, Gaussian number=184625, print grad=4.9775451770983636e-05, Depth Loss=0.0000000]
Training progress:  90%|█████████ | 1810/2000 [18:26<01:15,  2.53it/s, Loss=0.0094018, Gaussian number=184625, print grad=0.00010573382314760238, Depth Loss=0.0000000]
Training progress:  91%|█████████ | 1820/2000 [18:26<01:11,  2.53it/s, Loss=0.0094018, Gaussian number=184625, print grad=0.00010573382314760238, Depth Loss=0.0000000]
Training progress:  91%|█████████ | 1820/2000 [18:30<01:11,  2.53it/s, Loss=0.0079701, Gaussian number=184625, print grad=0.00014843519602436572, Depth Loss=0.0000000]
Training progress:  92%|█████████▏| 1830/2000 [18:30<01:07,  2.53it/s, Loss=0.0079701, Gaussian number=184625, print grad=0.00014843519602436572, Depth Loss=0.0000000]
Training progress:  92%|█████████▏| 1830/2000 [18:34<01:07,  2.53it/s, Loss=0.0088604, Gaussian number=184625, print grad=0.0002020014071604237, Depth Loss=0.0000000] 
Training progress:  92%|█████████▏| 1840/2000 [18:34<01:03,  2.53it/s, Loss=0.0088604, Gaussian number=184625, print grad=0.0002020014071604237, Depth Loss=0.0000000]
Training progress:  92%|█████████▏| 1840/2000 [18:38<01:03,  2.53it/s, Loss=0.0096561, Gaussian number=184625, print grad=0.00025194286718033254, Depth Loss=0.0000000]
Training progress:  92%|█████████▎| 1850/2000 [18:38<00:59,  2.54it/s, Loss=0.0096561, Gaussian number=184625, print grad=0.00025194286718033254, Depth Loss=0.0000000]
Training progress:  92%|█████████▎| 1850/2000 [18:42<00:59,  2.54it/s, Loss=0.0101071, Gaussian number=184625, print grad=0.0002953501243609935, Depth Loss=0.0000000] 
Training progress:  93%|█████████▎| 1860/2000 [18:42<00:55,  2.54it/s, Loss=0.0101071, Gaussian number=184625, print grad=0.0002953501243609935, Depth Loss=0.0000000]
Training progress:  93%|█████████▎| 1860/2000 [18:46<00:55,  2.54it/s, Loss=0.0113443, Gaussian number=184625, print grad=0.00035232515074312687, Depth Loss=0.0000000]
Training progress:  94%|█████████▎| 1870/2000 [18:46<00:51,  2.54it/s, Loss=0.0113443, Gaussian number=184625, print grad=0.00035232515074312687, Depth Loss=0.0000000]
Training progress:  94%|█████████▎| 1870/2000 [18:50<00:51,  2.54it/s, Loss=0.0086169, Gaussian number=184625, print grad=0.00040233947220258415, Depth Loss=0.0000000]
Training progress:  94%|█████████▍| 1880/2000 [18:50<00:47,  2.54it/s, Loss=0.0086169, Gaussian number=184625, print grad=0.00040233947220258415, Depth Loss=0.0000000]
Training progress:  94%|█████████▍| 1880/2000 [18:54<00:47,  2.54it/s, Loss=0.0097484, Gaussian number=184625, print grad=0.00045261511695571244, Depth Loss=0.0000000]
Training progress:  94%|█████████▍| 1890/2000 [18:54<00:43,  2.53it/s, Loss=0.0097484, Gaussian number=184625, print grad=0.00045261511695571244, Depth Loss=0.0000000]
Training progress:  94%|█████████▍| 1890/2000 [18:58<00:43,  2.53it/s, Loss=0.0118947, Gaussian number=184625, print grad=0.000504344527143985, Depth Loss=0.0000000]  
Training progress:  95%|█████████▌| 1900/2000 [18:58<00:39,  2.53it/s, Loss=0.0118947, Gaussian number=184625, print grad=0.000504344527143985, Depth Loss=0.0000000]
Training progress:  95%|█████████▌| 1900/2000 [19:02<00:39,  2.53it/s, Loss=0.0109620, Gaussian number=184861, print grad=4.301983062759973e-05, Depth Loss=0.0000000]
Training progress:  96%|█████████▌| 1910/2000 [19:02<00:35,  2.53it/s, Loss=0.0109620, Gaussian number=184861, print grad=4.301983062759973e-05, Depth Loss=0.0000000]
Training progress:  96%|█████████▌| 1910/2000 [19:06<00:35,  2.53it/s, Loss=0.0084857, Gaussian number=184861, print grad=9.218382183462381e-05, Depth Loss=0.0000000]
Training progress:  96%|█████████▌| 1920/2000 [19:06<00:31,  2.53it/s, Loss=0.0084857, Gaussian number=184861, print grad=9.218382183462381e-05, Depth Loss=0.0000000]
Training progress:  96%|█████████▌| 1920/2000 [19:10<00:31,  2.53it/s, Loss=0.0076836, Gaussian number=184861, print grad=0.00014405351248569787, Depth Loss=0.0000000]
Training progress:  96%|█████████▋| 1930/2000 [19:10<00:27,  2.54it/s, Loss=0.0076836, Gaussian number=184861, print grad=0.00014405351248569787, Depth Loss=0.0000000]
Training progress:  96%|█████████▋| 1930/2000 [19:14<00:27,  2.54it/s, Loss=0.0108972, Gaussian number=184861, print grad=0.00019345445616636425, Depth Loss=0.0000000]
Training progress:  97%|█████████▋| 1940/2000 [19:14<00:23,  2.54it/s, Loss=0.0108972, Gaussian number=184861, print grad=0.00019345445616636425, Depth Loss=0.0000000]
Training progress:  97%|█████████▋| 1940/2000 [19:18<00:23,  2.54it/s, Loss=0.0083663, Gaussian number=184861, print grad=0.00024221300554927438, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1950/2000 [19:18<00:19,  2.53it/s, Loss=0.0083663, Gaussian number=184861, print grad=0.00024221300554927438, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1950/2000 [19:22<00:19,  2.53it/s, Loss=0.0131900, Gaussian number=184861, print grad=0.0002892775519285351, Depth Loss=0.0000000] 
Training progress:  98%|█████████▊| 1960/2000 [19:22<00:15,  2.53it/s, Loss=0.0131900, Gaussian number=184861, print grad=0.0002892775519285351, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1960/2000 [19:25<00:15,  2.53it/s, Loss=0.0110847, Gaussian number=184861, print grad=0.00033901381539180875, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1970/2000 [19:25<00:11,  2.54it/s, Loss=0.0110847, Gaussian number=184861, print grad=0.00033901381539180875, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1970/2000 [19:29<00:11,  2.54it/s, Loss=0.0096257, Gaussian number=184861, print grad=0.000389789289329201, Depth Loss=0.0000000]  
Training progress:  99%|█████████▉| 1980/2000 [19:29<00:07,  2.54it/s, Loss=0.0096257, Gaussian number=184861, print grad=0.000389789289329201, Depth Loss=0.0000000]
Training progress:  99%|█████████▉| 1980/2000 [19:33<00:07,  2.54it/s, Loss=0.0093015, Gaussian number=184861, print grad=0.0004442593199200928, Depth Loss=0.0000000]
Training progress: 100%|█████████▉| 1990/2000 [19:33<00:03,  2.54it/s, Loss=0.0093015, Gaussian number=184861, print grad=0.0004442593199200928, Depth Loss=0.0000000]
Training progress: 100%|█████████▉| 1990/2000 [19:37<00:03,  2.54it/s, Loss=0.0077885, Gaussian number=184861, print grad=0.0004990906454622746, Depth Loss=0.0000000]
Training progress: 100%|██████████| 2000/2000 [19:37<00:00,  2.54it/s, Loss=0.0077885, Gaussian number=184861, print grad=0.0004990906454622746, Depth Loss=0.0000000]
Training progress: 100%|██████████| 2000/2000 [19:37<00:00,  1.70it/s, Loss=0.0077885, Gaussian number=184861, print grad=0.0004990906454622746, Depth Loss=0.0000000]
Iteration 100 [03/12 20:46:45]

[ITER 100] Evaluating test: WD 0.019789, PSNR 12.9382,lpips 0.587850,ssim 0.454952 [03/12 20:47:42]

[ITER 100] Evaluating train: WD 0.020608, PSNR 13.2949,lpips 0.590658,ssim 0.473309 [03/12 20:47:49]
Gaussian number:182686,print gradients:2.808605131576769e-06 [03/12 20:47:49]
Iteration 200 [03/12 20:48:29]

[ITER 200] Evaluating test: WD 0.017525, PSNR 14.2260,lpips 0.540794,ssim 0.489982 [03/12 20:49:26]

[ITER 200] Evaluating train: WD 0.017797, PSNR 14.3954,lpips 0.534221,ssim 0.504121 [03/12 20:49:33]
Gaussian number:182686,print gradients:3.6234087019693106e-06 [03/12 20:49:33]
Iteration 300 [03/12 20:50:13]

[ITER 300] Evaluating test: WD 0.016007, PSNR 14.9478,lpips 0.508648,ssim 0.511671 [03/12 20:51:09]

[ITER 300] Evaluating train: WD 0.016180, PSNR 15.2186,lpips 0.498910,ssim 0.526610 [03/12 20:51:17]
Gaussian number:182686,print gradients:4.134934442845406e-06 [03/12 20:51:17]
Iteration 400 [03/12 20:51:56]
Iteration 500 [03/12 20:52:36]

[ITER 500] Evaluating test: WD 0.014444, PSNR 15.8250,lpips 0.474012,ssim 0.537176 [03/12 20:53:33]

[ITER 500] Evaluating train: WD 0.015537, PSNR 15.8565,lpips 0.474597,ssim 0.545034 [03/12 20:53:40]
Gaussian number:182686,print gradients:4.826689746550983e-06 [03/12 20:53:40]
Iteration 600 [03/12 20:54:20]
Iteration 700 [03/12 20:54:59]
Iteration 800 [03/12 20:55:39]
Iteration 900 [03/12 20:56:18]
Iteration 1000 [03/12 20:56:58]

[ITER 1000] Evaluating test: WD 0.012606, PSNR 16.6164,lpips 0.425697,ssim 0.567741 [03/12 20:57:55]

[ITER 1000] Evaluating train: WD 0.013677, PSNR 16.5825,lpips 0.430256,ssim 0.571899 [03/12 20:58:02]
Gaussian number:183077,print gradients:6.863486760266824e-06 [03/12 20:58:02]
Iteration 1100 [03/12 20:58:41]
Iteration 1200 [03/12 20:59:21]
Iteration 1300 [03/12 21:00:00]
Iteration 1400 [03/12 21:00:40]
Iteration 1500 [03/12 21:01:19]

[ITER 1500] Evaluating test: WD 0.011234, PSNR 17.1840,lpips 0.391132,ssim 0.590007 [03/12 21:02:16]

[ITER 1500] Evaluating train: WD 0.011843, PSNR 17.3833,lpips 0.388295,ssim 0.598237 [03/12 21:02:24]
Gaussian number:183903,print gradients:7.5329403443902265e-06 [03/12 21:02:24]
Iteration 1600 [03/12 21:03:03]
Iteration 1700 [03/12 21:03:42]
Iteration 1800 [03/12 21:04:21]
Iteration 1900 [03/12 21:05:01]
Iteration 2000 [03/12 21:05:40]

[ITER 2000] Evaluating test: WD 0.010454, PSNR 17.6194,lpips 0.371412,ssim 0.605833 [03/12 21:06:37]

[ITER 2000] Evaluating train: WD 0.011537, PSNR 17.8682,lpips 0.374579,ssim 0.605892 [03/12 21:06:45]
Gaussian number:184861,print gradients:7.647792699572165e-06 [03/12 21:06:45]

[ITER 2000] Saving Gaussians [03/12 21:06:45]

Training complete. [03/12 21:06:46]
