Optimizing /home/cw4287/gaussian-model/train1
Output folder: /home/cw4287/gaussian-model/train1 [15/11 01:07:35]
Tensorboard not available: not logging progress [15/11 01:07:35]
------------LLFF HOLD------------- [15/11 01:07:36]

Reading camera 1/301
Reading camera 2/301
Reading camera 3/301
Reading camera 4/301
Reading camera 5/301
Reading camera 6/301
Reading camera 7/301
Reading camera 8/301
Reading camera 9/301
Reading camera 10/301
Reading camera 11/301
Reading camera 12/301
Reading camera 13/301
Reading camera 14/301
Reading camera 15/301
Reading camera 16/301
Reading camera 17/301
Reading camera 18/301
Reading camera 19/301
Reading camera 20/301
Reading camera 21/301
Reading camera 22/301
Reading camera 23/301
Reading camera 24/301
Reading camera 25/301
Reading camera 26/301
Reading camera 27/301
Reading camera 28/301
Reading camera 29/301
Reading camera 30/301
Reading camera 31/301
Reading camera 32/301
Reading camera 33/301
Reading camera 34/301
Reading camera 35/301
Reading camera 36/301
Reading camera 37/301
Reading camera 38/301
Reading camera 39/301
Reading camera 40/301
Reading camera 41/301
Reading camera 42/301
Reading camera 43/301
Reading camera 44/301
Reading camera 45/301
Reading camera 46/301
Reading camera 47/301
Reading camera 48/301
Reading camera 49/301
Reading camera 50/301
Reading camera 51/301
Reading camera 52/301
Reading camera 53/301
Reading camera 54/301
Reading camera 55/301
Reading camera 56/301
Reading camera 57/301
Reading camera 58/301
Reading camera 59/301
Reading camera 60/301
Reading camera 61/301
Reading camera 62/301
Reading camera 63/301
Reading camera 64/301
Reading camera 65/301
Reading camera 66/301
Reading camera 67/301
Reading camera 68/301
Reading camera 69/301
Reading camera 70/301
Reading camera 71/301
Reading camera 72/301
Reading camera 73/301
Reading camera 74/301
Reading camera 75/301
Reading camera 76/301
Reading camera 77/301
Reading camera 78/301
Reading camera 79/301
Reading camera 80/301
Reading camera 81/301
Reading camera 82/301
Reading camera 83/301
Reading camera 84/301
Reading camera 85/301
Reading camera 86/301
Reading camera 87/301
Reading camera 88/301
Reading camera 89/301
Reading camera 90/301
Reading camera 91/301
Reading camera 92/301
Reading camera 93/301
Reading camera 94/301
Reading camera 95/301
Reading camera 96/301
Reading camera 97/301
Reading camera 98/301
Reading camera 99/301
Reading camera 100/301
Reading camera 101/301
Reading camera 102/301
Reading camera 103/301
Reading camera 104/301
Reading camera 105/301
Reading camera 106/301
Reading camera 107/301
Reading camera 108/301
Reading camera 109/301
Reading camera 110/301
Reading camera 111/301
Reading camera 112/301
Reading camera 113/301
Reading camera 114/301
Reading camera 115/301
Reading camera 116/301
Reading camera 117/301
Reading camera 118/301
Reading camera 119/301
Reading camera 120/301
Reading camera 121/301
Reading camera 122/301
Reading camera 123/301
Reading camera 124/301
Reading camera 125/301
Reading camera 126/301
Reading camera 127/301
Reading camera 128/301
Reading camera 129/301
Reading camera 130/301
Reading camera 131/301
Reading camera 132/301
Reading camera 133/301
Reading camera 134/301
Reading camera 135/301
Reading camera 136/301
Reading camera 137/301
Reading camera 138/301
Reading camera 139/301
Reading camera 140/301
Reading camera 141/301
Reading camera 142/301
Reading camera 143/301
Reading camera 144/301
Reading camera 145/301
Reading camera 146/301
Reading camera 147/301
Reading camera 148/301
Reading camera 149/301
Reading camera 150/301
Reading camera 151/301
Reading camera 152/301
Reading camera 153/301
Reading camera 154/301
Reading camera 155/301
Reading camera 156/301
Reading camera 157/301
Reading camera 158/301
Reading camera 159/301
Reading camera 160/301
Reading camera 161/301
Reading camera 162/301
Reading camera 163/301
Reading camera 164/301
Reading camera 165/301
Reading camera 166/301
Reading camera 167/301
Reading camera 168/301
Reading camera 169/301
Reading camera 170/301
Reading camera 171/301
Reading camera 172/301
Reading camera 173/301
Reading camera 174/301
Reading camera 175/301
Reading camera 176/301
Reading camera 177/301
Reading camera 178/301
Reading camera 179/301
Reading camera 180/301
Reading camera 181/301
Reading camera 182/301
Reading camera 183/301
Reading camera 184/301
Reading camera 185/301
Reading camera 186/301
Reading camera 187/301
Reading camera 188/301
Reading camera 189/301
Reading camera 190/301
Reading camera 191/301
Reading camera 192/301
Reading camera 193/301
Reading camera 194/301
Reading camera 195/301
Reading camera 196/301
Reading camera 197/301
Reading camera 198/301
Reading camera 199/301
Reading camera 200/301
Reading camera 201/301
Reading camera 202/301
Reading camera 203/301
Reading camera 204/301
Reading camera 205/301
Reading camera 206/301
Reading camera 207/301
Reading camera 208/301
Reading camera 209/301
Reading camera 210/301
Reading camera 211/301
Reading camera 212/301
Reading camera 213/301
Reading camera 214/301
Reading camera 215/301
Reading camera 216/301
Reading camera 217/301
Reading camera 218/301
Reading camera 219/301
Reading camera 220/301
Reading camera 221/301
Reading camera 222/301
Reading camera 223/301
Reading camera 224/301
Reading camera 225/301
Reading camera 226/301
Reading camera 227/301
Reading camera 228/301
Reading camera 229/301
Reading camera 230/301
Reading camera 231/301
Reading camera 232/301
Reading camera 233/301
Reading camera 234/301
Reading camera 235/301
Reading camera 236/301
Reading camera 237/301
Reading camera 238/301
Reading camera 239/301
Reading camera 240/301
Reading camera 241/301
Reading camera 242/301
Reading camera 243/301
Reading camera 244/301
Reading camera 245/301
Reading camera 246/301
Reading camera 247/301
Reading camera 248/301
Reading camera 249/301
Reading camera 250/301
Reading camera 251/301
Reading camera 252/301
Reading camera 253/301
Reading camera 254/301
Reading camera 255/301
Reading camera 256/301
Reading camera 257/301
Reading camera 258/301
Reading camera 259/301
Reading camera 260/301
Reading camera 261/301
Reading camera 262/301
Reading camera 263/301
Reading camera 264/301
Reading camera 265/301
Reading camera 266/301
Reading camera 267/301
Reading camera 268/301
Reading camera 269/301
Reading camera 270/301
Reading camera 271/301
Reading camera 272/301
Reading camera 273/301
Reading camera 274/301
Reading camera 275/301
Reading camera 276/301
Reading camera 277/301
Reading camera 278/301
Reading camera 279/301
Reading camera 280/301
Reading camera 281/301
Reading camera 282/301
Reading camera 283/301
Reading camera 284/301
Reading camera 285/301
Reading camera 286/301
Reading camera 287/301
Reading camera 288/301
Reading camera 289/301
Reading camera 290/301
Reading camera 291/301
Reading camera 292/301
Reading camera 293/301
Reading camera 294/301
Reading camera 295/301
Reading camera 296/301
Reading camera 297/301
Reading camera 298/301
Reading camera 299/301
Reading camera 300/301
Reading camera 301/301 [15/11 01:07:36]
Loading Training Cameras [15/11 01:07:36]
Loading Test Cameras [15/11 01:07:48]
Number of points at initialisation :  182686 [15/11 01:07:50]

Training progress:   0%|          | 0/2000 [00:00<?, ?it/s]/ext3/conda/envs/3dgs/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/ext3/conda/envs/3dgs/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)

Training progress:   0%|          | 0/2000 [00:05<?, ?it/s, Loss=0.0001518, Gaussian number=182686, print grad=6.169256039356696e-08, Depth Loss=0.0000000]
Training progress:   0%|          | 10/2000 [00:05<17:51,  1.86it/s, Loss=0.0001518, Gaussian number=182686, print grad=6.169256039356696e-08, Depth Loss=0.0000000]
Training progress:   0%|          | 10/2000 [00:09<17:51,  1.86it/s, Loss=0.0001471, Gaussian number=182686, print grad=1.637419586586475e-07, Depth Loss=0.0000000]
Training progress:   1%|          | 20/2000 [00:09<14:26,  2.28it/s, Loss=0.0001471, Gaussian number=182686, print grad=1.637419586586475e-07, Depth Loss=0.0000000]
Training progress:   1%|          | 20/2000 [00:12<14:26,  2.28it/s, Loss=0.0001460, Gaussian number=182686, print grad=2.5972914841077e-07, Depth Loss=0.0000000]  
Training progress:   2%|▏         | 30/2000 [00:12<13:19,  2.46it/s, Loss=0.0001460, Gaussian number=182686, print grad=2.5972914841077e-07, Depth Loss=0.0000000]
Training progress:   2%|▏         | 30/2000 [00:16<13:19,  2.46it/s, Loss=0.0001573, Gaussian number=182686, print grad=3.62636569661845e-07, Depth Loss=0.0000000]
Training progress:   2%|▏         | 40/2000 [00:16<12:45,  2.56it/s, Loss=0.0001573, Gaussian number=182686, print grad=3.62636569661845e-07, Depth Loss=0.0000000]
Training progress:   2%|▏         | 40/2000 [00:20<12:45,  2.56it/s, Loss=0.0001199, Gaussian number=182686, print grad=4.4183198610880936e-07, Depth Loss=0.0000000]
Training progress:   2%|▎         | 50/2000 [00:20<12:24,  2.62it/s, Loss=0.0001199, Gaussian number=182686, print grad=4.4183198610880936e-07, Depth Loss=0.0000000]
Training progress:   2%|▎         | 50/2000 [00:23<12:24,  2.62it/s, Loss=0.0001377, Gaussian number=182686, print grad=5.654533197230194e-07, Depth Loss=0.0000000] 
Training progress:   3%|▎         | 60/2000 [00:23<12:09,  2.66it/s, Loss=0.0001377, Gaussian number=182686, print grad=5.654533197230194e-07, Depth Loss=0.0000000]
Training progress:   3%|▎         | 60/2000 [00:27<12:09,  2.66it/s, Loss=0.0001241, Gaussian number=182686, print grad=7.25337258700165e-07, Depth Loss=0.0000000] 
Training progress:   4%|▎         | 70/2000 [00:27<11:59,  2.68it/s, Loss=0.0001241, Gaussian number=182686, print grad=7.25337258700165e-07, Depth Loss=0.0000000]
Training progress:   4%|▎         | 70/2000 [00:31<11:59,  2.68it/s, Loss=0.0001437, Gaussian number=182686, print grad=8.413331897827447e-07, Depth Loss=0.0000000]
Training progress:   4%|▍         | 80/2000 [00:31<11:51,  2.70it/s, Loss=0.0001437, Gaussian number=182686, print grad=8.413331897827447e-07, Depth Loss=0.0000000]
Training progress:   4%|▍         | 80/2000 [00:34<11:51,  2.70it/s, Loss=0.0001236, Gaussian number=182686, print grad=9.61729256232502e-07, Depth Loss=0.0000000] 
Training progress:   4%|▍         | 90/2000 [00:34<11:45,  2.71it/s, Loss=0.0001236, Gaussian number=182686, print grad=9.61729256232502e-07, Depth Loss=0.0000000]
Training progress:   4%|▍         | 90/2000 [00:38<11:45,  2.71it/s, Loss=0.0001235, Gaussian number=182686, print grad=1.107683146983618e-06, Depth Loss=0.0000000]
Training progress:   5%|▌         | 100/2000 [00:38<11:40,  2.71it/s, Loss=0.0001235, Gaussian number=182686, print grad=1.107683146983618e-06, Depth Loss=0.0000000]
Training progress:   5%|▌         | 100/2000 [00:47<11:40,  2.71it/s, Loss=0.0001443, Gaussian number=182686, print grad=1.2687252137766336e-06, Depth Loss=0.0000000]
Training progress:   6%|▌         | 110/2000 [00:47<16:59,  1.85it/s, Loss=0.0001443, Gaussian number=182686, print grad=1.2687252137766336e-06, Depth Loss=0.0000000]
Training progress:   6%|▌         | 110/2000 [00:51<16:59,  1.85it/s, Loss=0.0001197, Gaussian number=182686, print grad=1.4248487332224613e-06, Depth Loss=0.0000000]
Training progress:   6%|▌         | 120/2000 [00:51<15:13,  2.06it/s, Loss=0.0001197, Gaussian number=182686, print grad=1.4248487332224613e-06, Depth Loss=0.0000000]
Training progress:   6%|▌         | 120/2000 [00:54<15:13,  2.06it/s, Loss=0.0001397, Gaussian number=182686, print grad=1.6252100749625242e-06, Depth Loss=0.0000000]
Training progress:   6%|▋         | 130/2000 [00:54<14:00,  2.23it/s, Loss=0.0001397, Gaussian number=182686, print grad=1.6252100749625242e-06, Depth Loss=0.0000000]
Training progress:   6%|▋         | 130/2000 [00:58<14:00,  2.23it/s, Loss=0.0001269, Gaussian number=182686, print grad=1.8294859955858556e-06, Depth Loss=0.0000000]
Training progress:   7%|▋         | 140/2000 [00:58<13:08,  2.36it/s, Loss=0.0001269, Gaussian number=182686, print grad=1.8294859955858556e-06, Depth Loss=0.0000000]
Training progress:   7%|▋         | 140/2000 [01:02<13:08,  2.36it/s, Loss=0.0001100, Gaussian number=182686, print grad=2.008090177696431e-06, Depth Loss=0.0000000] 
Training progress:   8%|▊         | 150/2000 [01:02<12:31,  2.46it/s, Loss=0.0001100, Gaussian number=182686, print grad=2.008090177696431e-06, Depth Loss=0.0000000]
Training progress:   8%|▊         | 150/2000 [01:05<12:31,  2.46it/s, Loss=0.0001174, Gaussian number=182686, print grad=2.247016254841583e-06, Depth Loss=0.0000000]
Training progress:   8%|▊         | 160/2000 [01:05<12:02,  2.55it/s, Loss=0.0001174, Gaussian number=182686, print grad=2.247016254841583e-06, Depth Loss=0.0000000]
Training progress:   8%|▊         | 160/2000 [01:09<12:02,  2.55it/s, Loss=0.0001160, Gaussian number=182686, print grad=2.419533984721056e-06, Depth Loss=0.0000000]
Training progress:   8%|▊         | 170/2000 [01:09<11:43,  2.60it/s, Loss=0.0001160, Gaussian number=182686, print grad=2.419533984721056e-06, Depth Loss=0.0000000]
Training progress:   8%|▊         | 170/2000 [01:13<11:43,  2.60it/s, Loss=0.0001022, Gaussian number=182686, print grad=2.633779104144196e-06, Depth Loss=0.0000000]
Training progress:   9%|▉         | 180/2000 [01:13<11:28,  2.64it/s, Loss=0.0001022, Gaussian number=182686, print grad=2.633779104144196e-06, Depth Loss=0.0000000]
Training progress:   9%|▉         | 180/2000 [01:16<11:28,  2.64it/s, Loss=0.0001288, Gaussian number=182686, print grad=2.8105289402446942e-06, Depth Loss=0.0000000]
Training progress:  10%|▉         | 190/2000 [01:16<11:16,  2.68it/s, Loss=0.0001288, Gaussian number=182686, print grad=2.8105289402446942e-06, Depth Loss=0.0000000]
Training progress:  10%|▉         | 190/2000 [01:20<11:16,  2.68it/s, Loss=0.0001156, Gaussian number=182686, print grad=3.0344631340994965e-06, Depth Loss=0.0000000]
Training progress:  10%|█         | 200/2000 [01:20<11:06,  2.70it/s, Loss=0.0001156, Gaussian number=182686, print grad=3.0344631340994965e-06, Depth Loss=0.0000000]
Training progress:  10%|█         | 200/2000 [01:29<11:06,  2.70it/s, Loss=0.0001283, Gaussian number=182686, print grad=3.2729737995396135e-06, Depth Loss=0.0000000]
Training progress:  10%|█         | 210/2000 [01:29<16:00,  1.86it/s, Loss=0.0001283, Gaussian number=182686, print grad=3.2729737995396135e-06, Depth Loss=0.0000000]
Training progress:  10%|█         | 210/2000 [01:33<16:00,  1.86it/s, Loss=0.0001073, Gaussian number=182686, print grad=3.4825693546736147e-06, Depth Loss=0.0000000]
Training progress:  11%|█         | 220/2000 [01:33<14:22,  2.06it/s, Loss=0.0001073, Gaussian number=182686, print grad=3.4825693546736147e-06, Depth Loss=0.0000000]
Training progress:  11%|█         | 220/2000 [01:36<14:22,  2.06it/s, Loss=0.0001184, Gaussian number=182686, print grad=3.6952699247194687e-06, Depth Loss=0.0000000]
Training progress:  12%|█▏        | 230/2000 [01:36<13:12,  2.23it/s, Loss=0.0001184, Gaussian number=182686, print grad=3.6952699247194687e-06, Depth Loss=0.0000000]
Training progress:  12%|█▏        | 230/2000 [01:40<13:12,  2.23it/s, Loss=0.0001426, Gaussian number=182686, print grad=3.902679509337759e-06, Depth Loss=0.0000000] 
Training progress:  12%|█▏        | 240/2000 [01:40<12:23,  2.37it/s, Loss=0.0001426, Gaussian number=182686, print grad=3.902679509337759e-06, Depth Loss=0.0000000]
Training progress:  12%|█▏        | 240/2000 [01:44<12:23,  2.37it/s, Loss=0.0001095, Gaussian number=182686, print grad=4.141495992371347e-06, Depth Loss=0.0000000]
Training progress:  12%|█▎        | 250/2000 [01:44<11:47,  2.47it/s, Loss=0.0001095, Gaussian number=182686, print grad=4.141495992371347e-06, Depth Loss=0.0000000]
Training progress:  12%|█▎        | 250/2000 [01:47<11:47,  2.47it/s, Loss=0.0001235, Gaussian number=182686, print grad=4.362175332062179e-06, Depth Loss=0.0000000]
Training progress:  13%|█▎        | 260/2000 [01:47<11:21,  2.55it/s, Loss=0.0001235, Gaussian number=182686, print grad=4.362175332062179e-06, Depth Loss=0.0000000]
Training progress:  13%|█▎        | 260/2000 [01:51<11:21,  2.55it/s, Loss=0.0000912, Gaussian number=182686, print grad=4.592280674842186e-06, Depth Loss=0.0000000]
Training progress:  14%|█▎        | 270/2000 [01:51<11:02,  2.61it/s, Loss=0.0000912, Gaussian number=182686, print grad=4.592280674842186e-06, Depth Loss=0.0000000]
Training progress:  14%|█▎        | 270/2000 [01:55<11:02,  2.61it/s, Loss=0.0001175, Gaussian number=182686, print grad=4.877755600318778e-06, Depth Loss=0.0000000]
Training progress:  14%|█▍        | 280/2000 [01:55<10:47,  2.66it/s, Loss=0.0001175, Gaussian number=182686, print grad=4.877755600318778e-06, Depth Loss=0.0000000]
Training progress:  14%|█▍        | 280/2000 [01:58<10:47,  2.66it/s, Loss=0.0001145, Gaussian number=182686, print grad=5.130556019139476e-06, Depth Loss=0.0000000]
Training progress:  14%|█▍        | 290/2000 [01:58<10:36,  2.69it/s, Loss=0.0001145, Gaussian number=182686, print grad=5.130556019139476e-06, Depth Loss=0.0000000]
Training progress:  14%|█▍        | 290/2000 [02:02<10:36,  2.69it/s, Loss=0.0001067, Gaussian number=182686, print grad=5.380043148761615e-06, Depth Loss=0.0000000]
Training progress:  15%|█▌        | 300/2000 [02:02<10:27,  2.71it/s, Loss=0.0001067, Gaussian number=182686, print grad=5.380043148761615e-06, Depth Loss=0.0000000]
Training progress:  15%|█▌        | 300/2000 [02:11<10:27,  2.71it/s, Loss=0.0000907, Gaussian number=182686, print grad=5.6625767683726735e-06, Depth Loss=0.0000000]
Training progress:  16%|█▌        | 310/2000 [02:11<15:05,  1.87it/s, Loss=0.0000907, Gaussian number=182686, print grad=5.6625767683726735e-06, Depth Loss=0.0000000]
Training progress:  16%|█▌        | 310/2000 [02:15<15:05,  1.87it/s, Loss=0.0000943, Gaussian number=182686, print grad=5.848665750818327e-06, Depth Loss=0.0000000] 
Training progress:  16%|█▌        | 320/2000 [02:15<13:32,  2.07it/s, Loss=0.0000943, Gaussian number=182686, print grad=5.848665750818327e-06, Depth Loss=0.0000000]
Training progress:  16%|█▌        | 320/2000 [02:18<13:32,  2.07it/s, Loss=0.0001225, Gaussian number=182686, print grad=6.090315764595289e-06, Depth Loss=0.0000000]
Training progress:  16%|█▋        | 330/2000 [02:18<12:26,  2.24it/s, Loss=0.0001225, Gaussian number=182686, print grad=6.090315764595289e-06, Depth Loss=0.0000000]
Training progress:  16%|█▋        | 330/2000 [02:22<12:26,  2.24it/s, Loss=0.0000922, Gaussian number=182686, print grad=6.355589903250802e-06, Depth Loss=0.0000000]
Training progress:  17%|█▋        | 340/2000 [02:22<11:38,  2.38it/s, Loss=0.0000922, Gaussian number=182686, print grad=6.355589903250802e-06, Depth Loss=0.0000000]
Training progress:  17%|█▋        | 340/2000 [02:25<11:38,  2.38it/s, Loss=0.0000950, Gaussian number=182686, print grad=6.613837285840418e-06, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 350/2000 [02:25<11:04,  2.48it/s, Loss=0.0000950, Gaussian number=182686, print grad=6.613837285840418e-06, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 350/2000 [02:29<11:04,  2.48it/s, Loss=0.0000906, Gaussian number=182686, print grad=6.925809884705814e-06, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 360/2000 [02:29<10:39,  2.57it/s, Loss=0.0000906, Gaussian number=182686, print grad=6.925809884705814e-06, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 360/2000 [02:33<10:39,  2.57it/s, Loss=0.0000925, Gaussian number=182686, print grad=7.203200311778346e-06, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 370/2000 [02:33<10:20,  2.63it/s, Loss=0.0000925, Gaussian number=182686, print grad=7.203200311778346e-06, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 370/2000 [02:36<10:20,  2.63it/s, Loss=0.0001181, Gaussian number=182686, print grad=7.422824637615122e-06, Depth Loss=0.0000000]
Training progress:  19%|█▉        | 380/2000 [02:36<10:06,  2.67it/s, Loss=0.0001181, Gaussian number=182686, print grad=7.422824637615122e-06, Depth Loss=0.0000000]
Training progress:  19%|█▉        | 380/2000 [02:40<10:06,  2.67it/s, Loss=0.0001082, Gaussian number=182686, print grad=7.695111889916006e-06, Depth Loss=0.0000000]
Training progress:  20%|█▉        | 390/2000 [02:40<09:56,  2.70it/s, Loss=0.0001082, Gaussian number=182686, print grad=7.695111889916006e-06, Depth Loss=0.0000000]
Training progress:  20%|█▉        | 390/2000 [02:43<09:56,  2.70it/s, Loss=0.0001267, Gaussian number=182686, print grad=7.945869583636522e-06, Depth Loss=0.0000000]
Training progress:  20%|██        | 400/2000 [02:43<09:46,  2.73it/s, Loss=0.0001267, Gaussian number=182686, print grad=7.945869583636522e-06, Depth Loss=0.0000000]
Training progress:  20%|██        | 400/2000 [02:53<09:46,  2.73it/s, Loss=0.0001086, Gaussian number=182686, print grad=8.25923325464828e-06, Depth Loss=0.0000000] 
Training progress:  20%|██        | 410/2000 [02:53<14:08,  1.87it/s, Loss=0.0001086, Gaussian number=182686, print grad=8.25923325464828e-06, Depth Loss=0.0000000]
Training progress:  20%|██        | 410/2000 [02:56<14:08,  1.87it/s, Loss=0.0000977, Gaussian number=182686, print grad=8.552256986149587e-06, Depth Loss=0.0000000]
Training progress:  21%|██        | 420/2000 [02:56<12:40,  2.08it/s, Loss=0.0000977, Gaussian number=182686, print grad=8.552256986149587e-06, Depth Loss=0.0000000]
Training progress:  21%|██        | 420/2000 [03:00<12:40,  2.08it/s, Loss=0.0001205, Gaussian number=182686, print grad=8.855666237650439e-06, Depth Loss=0.0000000]
Training progress:  22%|██▏       | 430/2000 [03:00<11:38,  2.25it/s, Loss=0.0001205, Gaussian number=182686, print grad=8.855666237650439e-06, Depth Loss=0.0000000]
Training progress:  22%|██▏       | 430/2000 [03:03<11:38,  2.25it/s, Loss=0.0000959, Gaussian number=182686, print grad=9.139061148744076e-06, Depth Loss=0.0000000]
Training progress:  22%|██▏       | 440/2000 [03:03<10:54,  2.39it/s, Loss=0.0000959, Gaussian number=182686, print grad=9.139061148744076e-06, Depth Loss=0.0000000]
Training progress:  22%|██▏       | 440/2000 [03:07<10:54,  2.39it/s, Loss=0.0001068, Gaussian number=182686, print grad=9.443606359127443e-06, Depth Loss=0.0000000]
Training progress:  22%|██▎       | 450/2000 [03:07<10:21,  2.49it/s, Loss=0.0001068, Gaussian number=182686, print grad=9.443606359127443e-06, Depth Loss=0.0000000]
Training progress:  22%|██▎       | 450/2000 [03:11<10:21,  2.49it/s, Loss=0.0001079, Gaussian number=182686, print grad=9.730547390063293e-06, Depth Loss=0.0000000]
Training progress:  23%|██▎       | 460/2000 [03:11<09:58,  2.57it/s, Loss=0.0001079, Gaussian number=182686, print grad=9.730547390063293e-06, Depth Loss=0.0000000]
Training progress:  23%|██▎       | 460/2000 [03:14<09:58,  2.57it/s, Loss=0.0001294, Gaussian number=182686, print grad=9.999719623010606e-06, Depth Loss=0.0000000]
Training progress:  24%|██▎       | 470/2000 [03:14<09:40,  2.63it/s, Loss=0.0001294, Gaussian number=182686, print grad=9.999719623010606e-06, Depth Loss=0.0000000]
Training progress:  24%|██▎       | 470/2000 [03:18<09:40,  2.63it/s, Loss=0.0000886, Gaussian number=182686, print grad=1.0306152944394853e-05, Depth Loss=0.0000000]
Training progress:  24%|██▍       | 480/2000 [03:18<09:27,  2.68it/s, Loss=0.0000886, Gaussian number=182686, print grad=1.0306152944394853e-05, Depth Loss=0.0000000]
Training progress:  24%|██▍       | 480/2000 [03:21<09:27,  2.68it/s, Loss=0.0000937, Gaussian number=182686, print grad=1.0587365977698937e-05, Depth Loss=0.0000000]
Training progress:  24%|██▍       | 490/2000 [03:21<09:17,  2.71it/s, Loss=0.0000937, Gaussian number=182686, print grad=1.0587365977698937e-05, Depth Loss=0.0000000]
Training progress:  24%|██▍       | 490/2000 [03:25<09:17,  2.71it/s, Loss=0.0000770, Gaussian number=182686, print grad=1.0874864528886974e-05, Depth Loss=0.0000000]
Training progress:  25%|██▌       | 500/2000 [03:25<09:09,  2.73it/s, Loss=0.0000770, Gaussian number=182686, print grad=1.0874864528886974e-05, Depth Loss=0.0000000]
Training progress:  25%|██▌       | 500/2000 [03:34<09:09,  2.73it/s, Loss=0.0000887, Gaussian number=182686, print grad=1.1169102435815148e-05, Depth Loss=0.0000000]
Training progress:  26%|██▌       | 510/2000 [03:34<13:13,  1.88it/s, Loss=0.0000887, Gaussian number=182686, print grad=1.1169102435815148e-05, Depth Loss=0.0000000]
Training progress:  26%|██▌       | 510/2000 [03:38<13:13,  1.88it/s, Loss=0.0000908, Gaussian number=182686, print grad=1.1480276043585036e-05, Depth Loss=0.0000000]
Training progress:  26%|██▌       | 520/2000 [03:38<11:50,  2.08it/s, Loss=0.0000908, Gaussian number=182686, print grad=1.1480276043585036e-05, Depth Loss=0.0000000]
Training progress:  26%|██▌       | 520/2000 [03:41<11:50,  2.08it/s, Loss=0.0000740, Gaussian number=182686, print grad=1.1742666174541228e-05, Depth Loss=0.0000000]
Training progress:  26%|██▋       | 530/2000 [03:41<10:51,  2.26it/s, Loss=0.0000740, Gaussian number=182686, print grad=1.1742666174541228e-05, Depth Loss=0.0000000]
Training progress:  26%|██▋       | 530/2000 [03:45<10:51,  2.26it/s, Loss=0.0000996, Gaussian number=182686, print grad=1.2034368410240859e-05, Depth Loss=0.0000000]
Training progress:  27%|██▋       | 540/2000 [03:45<10:09,  2.39it/s, Loss=0.0000996, Gaussian number=182686, print grad=1.2034368410240859e-05, Depth Loss=0.0000000]
Training progress:  27%|██▋       | 540/2000 [03:48<10:09,  2.39it/s, Loss=0.0000947, Gaussian number=182686, print grad=1.2352959856798407e-05, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 550/2000 [03:48<09:39,  2.50it/s, Loss=0.0000947, Gaussian number=182686, print grad=1.2352959856798407e-05, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 550/2000 [03:52<09:39,  2.50it/s, Loss=0.0000774, Gaussian number=182686, print grad=1.265468199562747e-05, Depth Loss=0.0000000] 
Training progress:  28%|██▊       | 560/2000 [03:52<09:17,  2.58it/s, Loss=0.0000774, Gaussian number=182686, print grad=1.265468199562747e-05, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 560/2000 [03:56<09:17,  2.58it/s, Loss=0.0000992, Gaussian number=182686, print grad=1.2998122656426858e-05, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 570/2000 [03:56<09:01,  2.64it/s, Loss=0.0000992, Gaussian number=182686, print grad=1.2998122656426858e-05, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 570/2000 [03:59<09:01,  2.64it/s, Loss=0.0000855, Gaussian number=182686, print grad=1.3296767974679824e-05, Depth Loss=0.0000000]
Training progress:  29%|██▉       | 580/2000 [03:59<08:49,  2.68it/s, Loss=0.0000855, Gaussian number=182686, print grad=1.3296767974679824e-05, Depth Loss=0.0000000]
Training progress:  29%|██▉       | 580/2000 [04:03<08:49,  2.68it/s, Loss=0.0000973, Gaussian number=182686, print grad=1.3611945178126916e-05, Depth Loss=0.0000000]
Training progress:  30%|██▉       | 590/2000 [04:03<08:40,  2.71it/s, Loss=0.0000973, Gaussian number=182686, print grad=1.3611945178126916e-05, Depth Loss=0.0000000]
Training progress:  30%|██▉       | 590/2000 [04:06<08:40,  2.71it/s, Loss=0.0000994, Gaussian number=182686, print grad=1.3905668311053887e-05, Depth Loss=0.0000000]
Training progress:  30%|███       | 600/2000 [04:06<08:31,  2.74it/s, Loss=0.0000994, Gaussian number=182686, print grad=1.3905668311053887e-05, Depth Loss=0.0000000]
Training progress:  30%|███       | 600/2000 [04:16<08:31,  2.74it/s, Loss=0.0000839, Gaussian number=182631, print grad=2.890917301101581e-07, Depth Loss=0.0000000] 
Training progress:  30%|███       | 610/2000 [04:16<12:19,  1.88it/s, Loss=0.0000839, Gaussian number=182631, print grad=2.890917301101581e-07, Depth Loss=0.0000000]
Training progress:  30%|███       | 610/2000 [04:19<12:19,  1.88it/s, Loss=0.0001082, Gaussian number=182631, print grad=6.185666165947623e-07, Depth Loss=0.0000000]
Training progress:  31%|███       | 620/2000 [04:19<11:02,  2.08it/s, Loss=0.0001082, Gaussian number=182631, print grad=6.185666165947623e-07, Depth Loss=0.0000000]
Training progress:  31%|███       | 620/2000 [04:23<11:02,  2.08it/s, Loss=0.0000792, Gaussian number=182631, print grad=8.928597594604071e-07, Depth Loss=0.0000000]
Training progress:  32%|███▏      | 630/2000 [04:23<10:07,  2.26it/s, Loss=0.0000792, Gaussian number=182631, print grad=8.928597594604071e-07, Depth Loss=0.0000000]
Training progress:  32%|███▏      | 630/2000 [04:26<10:07,  2.26it/s, Loss=0.0000859, Gaussian number=182631, print grad=1.2601092294062255e-06, Depth Loss=0.0000000]
Training progress:  32%|███▏      | 640/2000 [04:26<09:27,  2.40it/s, Loss=0.0000859, Gaussian number=182631, print grad=1.2601092294062255e-06, Depth Loss=0.0000000]
Training progress:  32%|███▏      | 640/2000 [04:30<09:27,  2.40it/s, Loss=0.0000979, Gaussian number=182631, print grad=1.5351071169789066e-06, Depth Loss=0.0000000]
Training progress:  32%|███▎      | 650/2000 [04:30<08:59,  2.50it/s, Loss=0.0000979, Gaussian number=182631, print grad=1.5351071169789066e-06, Depth Loss=0.0000000]
Training progress:  32%|███▎      | 650/2000 [04:33<08:59,  2.50it/s, Loss=0.0001032, Gaussian number=182631, print grad=1.875700263553881e-06, Depth Loss=0.0000000] 
Training progress:  33%|███▎      | 660/2000 [04:33<08:38,  2.58it/s, Loss=0.0001032, Gaussian number=182631, print grad=1.875700263553881e-06, Depth Loss=0.0000000]
Training progress:  33%|███▎      | 660/2000 [04:37<08:38,  2.58it/s, Loss=0.0000880, Gaussian number=182631, print grad=2.1836829091625987e-06, Depth Loss=0.0000000]
Training progress:  34%|███▎      | 670/2000 [04:37<08:22,  2.65it/s, Loss=0.0000880, Gaussian number=182631, print grad=2.1836829091625987e-06, Depth Loss=0.0000000]
Training progress:  34%|███▎      | 670/2000 [04:41<08:22,  2.65it/s, Loss=0.0000841, Gaussian number=182631, print grad=2.536609599701478e-06, Depth Loss=0.0000000] 
Training progress:  34%|███▍      | 680/2000 [04:41<08:10,  2.69it/s, Loss=0.0000841, Gaussian number=182631, print grad=2.536609599701478e-06, Depth Loss=0.0000000]
Training progress:  34%|███▍      | 680/2000 [04:44<08:10,  2.69it/s, Loss=0.0000988, Gaussian number=182631, print grad=2.8450338049879065e-06, Depth Loss=0.0000000]
Training progress:  34%|███▍      | 690/2000 [04:44<08:00,  2.73it/s, Loss=0.0000988, Gaussian number=182631, print grad=2.8450338049879065e-06, Depth Loss=0.0000000]
Training progress:  34%|███▍      | 690/2000 [04:48<08:00,  2.73it/s, Loss=0.0000993, Gaussian number=182631, print grad=3.140358330711024e-06, Depth Loss=0.0000000] 
Training progress:  35%|███▌      | 700/2000 [04:48<07:53,  2.75it/s, Loss=0.0000993, Gaussian number=182631, print grad=3.140358330711024e-06, Depth Loss=0.0000000]
Training progress:  35%|███▌      | 700/2000 [04:57<07:53,  2.75it/s, Loss=0.0000838, Gaussian number=182593, print grad=2.669568459623406e-07, Depth Loss=0.0000000]
Training progress:  36%|███▌      | 710/2000 [04:57<11:24,  1.89it/s, Loss=0.0000838, Gaussian number=182593, print grad=2.669568459623406e-07, Depth Loss=0.0000000]
Training progress:  36%|███▌      | 710/2000 [05:01<11:24,  1.89it/s, Loss=0.0000780, Gaussian number=182593, print grad=5.785830694549077e-07, Depth Loss=0.0000000]
Training progress:  36%|███▌      | 720/2000 [05:01<10:12,  2.09it/s, Loss=0.0000780, Gaussian number=182593, print grad=5.785830694549077e-07, Depth Loss=0.0000000]
Training progress:  36%|███▌      | 720/2000 [05:04<10:12,  2.09it/s, Loss=0.0000977, Gaussian number=182593, print grad=8.654697580823267e-07, Depth Loss=0.0000000]
Training progress:  36%|███▋      | 730/2000 [05:04<09:21,  2.26it/s, Loss=0.0000977, Gaussian number=182593, print grad=8.654697580823267e-07, Depth Loss=0.0000000]
Training progress:  36%|███▋      | 730/2000 [05:08<09:21,  2.26it/s, Loss=0.0001221, Gaussian number=182593, print grad=1.2225447107994114e-06, Depth Loss=0.0000000]
Training progress:  37%|███▋      | 740/2000 [05:08<08:44,  2.40it/s, Loss=0.0001221, Gaussian number=182593, print grad=1.2225447107994114e-06, Depth Loss=0.0000000]
Training progress:  37%|███▋      | 740/2000 [05:11<08:44,  2.40it/s, Loss=0.0000885, Gaussian number=182593, print grad=1.5620795466020354e-06, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 750/2000 [05:11<08:18,  2.51it/s, Loss=0.0000885, Gaussian number=182593, print grad=1.5620795466020354e-06, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 750/2000 [05:15<08:18,  2.51it/s, Loss=0.0000819, Gaussian number=182593, print grad=1.8806348407451878e-06, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 760/2000 [05:15<07:58,  2.59it/s, Loss=0.0000819, Gaussian number=182593, print grad=1.8806348407451878e-06, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 760/2000 [05:18<07:58,  2.59it/s, Loss=0.0000776, Gaussian number=182593, print grad=2.214510232079192e-06, Depth Loss=0.0000000] 
Training progress:  38%|███▊      | 770/2000 [05:18<07:45,  2.64it/s, Loss=0.0000776, Gaussian number=182593, print grad=2.214510232079192e-06, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 770/2000 [05:22<07:45,  2.64it/s, Loss=0.0000992, Gaussian number=182593, print grad=2.520442649256438e-06, Depth Loss=0.0000000]
Training progress:  39%|███▉      | 780/2000 [05:22<07:33,  2.69it/s, Loss=0.0000992, Gaussian number=182593, print grad=2.520442649256438e-06, Depth Loss=0.0000000]
Training progress:  39%|███▉      | 780/2000 [05:26<07:33,  2.69it/s, Loss=0.0001134, Gaussian number=182593, print grad=2.84013663076621e-06, Depth Loss=0.0000000] 
Training progress:  40%|███▉      | 790/2000 [05:26<07:24,  2.72it/s, Loss=0.0001134, Gaussian number=182593, print grad=2.84013663076621e-06, Depth Loss=0.0000000]
Training progress:  40%|███▉      | 790/2000 [05:29<07:24,  2.72it/s, Loss=0.0000980, Gaussian number=182593, print grad=3.1926163046591682e-06, Depth Loss=0.0000000]
Training progress:  40%|████      | 800/2000 [05:29<07:16,  2.75it/s, Loss=0.0000980, Gaussian number=182593, print grad=3.1926163046591682e-06, Depth Loss=0.0000000]
Training progress:  40%|████      | 800/2000 [05:38<07:16,  2.75it/s, Loss=0.0000956, Gaussian number=182557, print grad=2.997658725689689e-07, Depth Loss=0.0000000] 
Training progress:  40%|████      | 810/2000 [05:38<10:31,  1.89it/s, Loss=0.0000956, Gaussian number=182557, print grad=2.997658725689689e-07, Depth Loss=0.0000000]
Training progress:  40%|████      | 810/2000 [05:42<10:31,  1.89it/s, Loss=0.0000928, Gaussian number=182557, print grad=6.076995191506285e-07, Depth Loss=0.0000000]
Training progress:  41%|████      | 820/2000 [05:42<09:23,  2.09it/s, Loss=0.0000928, Gaussian number=182557, print grad=6.076995191506285e-07, Depth Loss=0.0000000]
Training progress:  41%|████      | 820/2000 [05:45<09:23,  2.09it/s, Loss=0.0000755, Gaussian number=182557, print grad=9.939055871655e-07, Depth Loss=0.0000000]   
Training progress:  42%|████▏     | 830/2000 [05:45<08:36,  2.27it/s, Loss=0.0000755, Gaussian number=182557, print grad=9.939055871655e-07, Depth Loss=0.0000000]
Training progress:  42%|████▏     | 830/2000 [05:49<08:36,  2.27it/s, Loss=0.0000789, Gaussian number=182557, print grad=1.3288532727528946e-06, Depth Loss=0.0000000]
Training progress:  42%|████▏     | 840/2000 [05:49<08:01,  2.41it/s, Loss=0.0000789, Gaussian number=182557, print grad=1.3288532727528946e-06, Depth Loss=0.0000000]
Training progress:  42%|████▏     | 840/2000 [05:53<08:01,  2.41it/s, Loss=0.0000891, Gaussian number=182557, print grad=1.6880288740139804e-06, Depth Loss=0.0000000]
Training progress:  42%|████▎     | 850/2000 [05:53<07:37,  2.52it/s, Loss=0.0000891, Gaussian number=182557, print grad=1.6880288740139804e-06, Depth Loss=0.0000000]
Training progress:  42%|████▎     | 850/2000 [05:56<07:37,  2.52it/s, Loss=0.0000827, Gaussian number=182557, print grad=2.015098516494618e-06, Depth Loss=0.0000000] 
Training progress:  43%|████▎     | 860/2000 [05:56<07:19,  2.60it/s, Loss=0.0000827, Gaussian number=182557, print grad=2.015098516494618e-06, Depth Loss=0.0000000]
Training progress:  43%|████▎     | 860/2000 [06:00<07:19,  2.60it/s, Loss=0.0000995, Gaussian number=182557, print grad=2.342959760426311e-06, Depth Loss=0.0000000]
Training progress:  44%|████▎     | 870/2000 [06:00<07:05,  2.66it/s, Loss=0.0000995, Gaussian number=182557, print grad=2.342959760426311e-06, Depth Loss=0.0000000]
Training progress:  44%|████▎     | 870/2000 [06:03<07:05,  2.66it/s, Loss=0.0000951, Gaussian number=182557, print grad=2.6630254978954326e-06, Depth Loss=0.0000000]
Training progress:  44%|████▍     | 880/2000 [06:03<06:54,  2.70it/s, Loss=0.0000951, Gaussian number=182557, print grad=2.6630254978954326e-06, Depth Loss=0.0000000]
Training progress:  44%|████▍     | 880/2000 [06:07<06:54,  2.70it/s, Loss=0.0000753, Gaussian number=182557, print grad=3.0115361369098537e-06, Depth Loss=0.0000000]
Training progress:  44%|████▍     | 890/2000 [06:07<06:45,  2.74it/s, Loss=0.0000753, Gaussian number=182557, print grad=3.0115361369098537e-06, Depth Loss=0.0000000]
Training progress:  44%|████▍     | 890/2000 [06:10<06:45,  2.74it/s, Loss=0.0000937, Gaussian number=182557, print grad=3.3334595173073467e-06, Depth Loss=0.0000000]
Training progress:  45%|████▌     | 900/2000 [06:10<06:38,  2.76it/s, Loss=0.0000937, Gaussian number=182557, print grad=3.3334595173073467e-06, Depth Loss=0.0000000]
Training progress:  45%|████▌     | 900/2000 [06:19<06:38,  2.76it/s, Loss=0.0000718, Gaussian number=182519, print grad=2.919638006915193e-07, Depth Loss=0.0000000] 
Training progress:  46%|████▌     | 910/2000 [06:19<09:36,  1.89it/s, Loss=0.0000718, Gaussian number=182519, print grad=2.919638006915193e-07, Depth Loss=0.0000000]
Training progress:  46%|████▌     | 910/2000 [06:23<09:36,  1.89it/s, Loss=0.0000892, Gaussian number=182519, print grad=5.596332925961178e-07, Depth Loss=0.0000000]
Training progress:  46%|████▌     | 920/2000 [06:23<08:34,  2.10it/s, Loss=0.0000892, Gaussian number=182519, print grad=5.596332925961178e-07, Depth Loss=0.0000000]
Training progress:  46%|████▌     | 920/2000 [06:27<08:34,  2.10it/s, Loss=0.0000932, Gaussian number=182519, print grad=9.220593142345024e-07, Depth Loss=0.0000000]
Training progress:  46%|████▋     | 930/2000 [06:27<07:51,  2.27it/s, Loss=0.0000932, Gaussian number=182519, print grad=9.220593142345024e-07, Depth Loss=0.0000000]
Training progress:  46%|████▋     | 930/2000 [06:30<07:51,  2.27it/s, Loss=0.0000861, Gaussian number=182519, print grad=1.2338332453509793e-06, Depth Loss=0.0000000]
Training progress:  47%|████▋     | 940/2000 [06:30<07:19,  2.41it/s, Loss=0.0000861, Gaussian number=182519, print grad=1.2338332453509793e-06, Depth Loss=0.0000000]
Training progress:  47%|████▋     | 940/2000 [06:34<07:19,  2.41it/s, Loss=0.0000781, Gaussian number=182519, print grad=1.5777935686855926e-06, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 950/2000 [06:34<06:56,  2.52it/s, Loss=0.0000781, Gaussian number=182519, print grad=1.5777935686855926e-06, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 950/2000 [06:37<06:56,  2.52it/s, Loss=0.0000839, Gaussian number=182519, print grad=1.9033461740036728e-06, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 960/2000 [06:37<06:39,  2.60it/s, Loss=0.0000839, Gaussian number=182519, print grad=1.9033461740036728e-06, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 960/2000 [06:41<06:39,  2.60it/s, Loss=0.0001034, Gaussian number=182519, print grad=2.251095111205359e-06, Depth Loss=0.0000000] 
Training progress:  48%|████▊     | 970/2000 [06:41<06:26,  2.66it/s, Loss=0.0001034, Gaussian number=182519, print grad=2.251095111205359e-06, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 970/2000 [06:44<06:26,  2.66it/s, Loss=0.0000722, Gaussian number=182519, print grad=2.5884648948704125e-06, Depth Loss=0.0000000]
Training progress:  49%|████▉     | 980/2000 [06:44<06:16,  2.71it/s, Loss=0.0000722, Gaussian number=182519, print grad=2.5884648948704125e-06, Depth Loss=0.0000000]
Training progress:  49%|████▉     | 980/2000 [06:48<06:16,  2.71it/s, Loss=0.0000726, Gaussian number=182519, print grad=2.884149125748081e-06, Depth Loss=0.0000000] 
Training progress:  50%|████▉     | 990/2000 [06:48<06:08,  2.74it/s, Loss=0.0000726, Gaussian number=182519, print grad=2.884149125748081e-06, Depth Loss=0.0000000]
Training progress:  50%|████▉     | 990/2000 [06:51<06:08,  2.74it/s, Loss=0.0000941, Gaussian number=182519, print grad=3.1677175229560817e-06, Depth Loss=0.0000000]
Training progress:  50%|█████     | 1000/2000 [06:51<06:01,  2.77it/s, Loss=0.0000941, Gaussian number=182519, print grad=3.1677175229560817e-06, Depth Loss=0.0000000]
Training progress:  50%|█████     | 1000/2000 [07:01<06:01,  2.77it/s, Loss=0.0000847, Gaussian number=182470, print grad=2.7310687755743857e-07, Depth Loss=0.0000000]
Training progress:  50%|█████     | 1010/2000 [07:01<08:44,  1.89it/s, Loss=0.0000847, Gaussian number=182470, print grad=2.7310687755743857e-07, Depth Loss=0.0000000]
Training progress:  50%|█████     | 1010/2000 [07:04<08:44,  1.89it/s, Loss=0.0001030, Gaussian number=182470, print grad=6.499396363324195e-07, Depth Loss=0.0000000] 
Training progress:  51%|█████     | 1020/2000 [07:04<07:48,  2.09it/s, Loss=0.0001030, Gaussian number=182470, print grad=6.499396363324195e-07, Depth Loss=0.0000000]
Training progress:  51%|█████     | 1020/2000 [07:08<07:48,  2.09it/s, Loss=0.0000885, Gaussian number=182470, print grad=9.983012887460063e-07, Depth Loss=0.0000000]
Training progress:  52%|█████▏    | 1030/2000 [07:08<07:08,  2.27it/s, Loss=0.0000885, Gaussian number=182470, print grad=9.983012887460063e-07, Depth Loss=0.0000000]
Training progress:  52%|█████▏    | 1030/2000 [07:11<07:08,  2.27it/s, Loss=0.0000917, Gaussian number=182470, print grad=1.3721773939323612e-06, Depth Loss=0.0000000]
Training progress:  52%|█████▏    | 1040/2000 [07:11<06:39,  2.41it/s, Loss=0.0000917, Gaussian number=182470, print grad=1.3721773939323612e-06, Depth Loss=0.0000000]
Training progress:  52%|█████▏    | 1040/2000 [07:15<06:39,  2.41it/s, Loss=0.0000828, Gaussian number=182470, print grad=1.6635860902169952e-06, Depth Loss=0.0000000]
Training progress:  52%|█████▎    | 1050/2000 [07:15<06:17,  2.52it/s, Loss=0.0000828, Gaussian number=182470, print grad=1.6635860902169952e-06, Depth Loss=0.0000000]
Training progress:  52%|█████▎    | 1050/2000 [07:18<06:17,  2.52it/s, Loss=0.0000828, Gaussian number=182470, print grad=1.9908093236153945e-06, Depth Loss=0.0000000]
Training progress:  53%|█████▎    | 1060/2000 [07:18<06:01,  2.60it/s, Loss=0.0000828, Gaussian number=182470, print grad=1.9908093236153945e-06, Depth Loss=0.0000000]
Training progress:  53%|█████▎    | 1060/2000 [07:22<06:01,  2.60it/s, Loss=0.0000682, Gaussian number=182470, print grad=2.369038156757597e-06, Depth Loss=0.0000000] 
Training progress:  54%|█████▎    | 1070/2000 [07:22<05:49,  2.66it/s, Loss=0.0000682, Gaussian number=182470, print grad=2.369038156757597e-06, Depth Loss=0.0000000]
Training progress:  54%|█████▎    | 1070/2000 [07:26<05:49,  2.66it/s, Loss=0.0000731, Gaussian number=182470, print grad=2.6906607217824785e-06, Depth Loss=0.0000000]
Training progress:  54%|█████▍    | 1080/2000 [07:26<05:40,  2.70it/s, Loss=0.0000731, Gaussian number=182470, print grad=2.6906607217824785e-06, Depth Loss=0.0000000]
Training progress:  54%|█████▍    | 1080/2000 [07:29<05:40,  2.70it/s, Loss=0.0000890, Gaussian number=182470, print grad=3.0436353881668765e-06, Depth Loss=0.0000000]
Training progress:  55%|█████▍    | 1090/2000 [07:29<05:32,  2.73it/s, Loss=0.0000890, Gaussian number=182470, print grad=3.0436353881668765e-06, Depth Loss=0.0000000]
Training progress:  55%|█████▍    | 1090/2000 [07:33<05:32,  2.73it/s, Loss=0.0000889, Gaussian number=182470, print grad=3.3875169265229488e-06, Depth Loss=0.0000000]
Training progress:  55%|█████▌    | 1100/2000 [07:33<05:26,  2.75it/s, Loss=0.0000889, Gaussian number=182470, print grad=3.3875169265229488e-06, Depth Loss=0.0000000]
Training progress:  55%|█████▌    | 1100/2000 [07:36<05:26,  2.75it/s, Loss=0.0000906, Gaussian number=182421, print grad=2.874907920613623e-07, Depth Loss=0.0000000] 
Training progress:  56%|█████▌    | 1110/2000 [07:36<05:21,  2.77it/s, Loss=0.0000906, Gaussian number=182421, print grad=2.874907920613623e-07, Depth Loss=0.0000000]
Training progress:  56%|█████▌    | 1110/2000 [07:40<05:21,  2.77it/s, Loss=0.0000860, Gaussian number=182421, print grad=6.331084136945719e-07, Depth Loss=0.0000000]
Training progress:  56%|█████▌    | 1120/2000 [07:40<05:16,  2.78it/s, Loss=0.0000860, Gaussian number=182421, print grad=6.331084136945719e-07, Depth Loss=0.0000000]
Training progress:  56%|█████▌    | 1120/2000 [07:43<05:16,  2.78it/s, Loss=0.0000712, Gaussian number=182421, print grad=1.006081902232836e-06, Depth Loss=0.0000000]
Training progress:  56%|█████▋    | 1130/2000 [07:43<05:11,  2.79it/s, Loss=0.0000712, Gaussian number=182421, print grad=1.006081902232836e-06, Depth Loss=0.0000000]
Training progress:  56%|█████▋    | 1130/2000 [07:47<05:11,  2.79it/s, Loss=0.0000862, Gaussian number=182421, print grad=1.364404283776821e-06, Depth Loss=0.0000000]
Training progress:  57%|█████▋    | 1140/2000 [07:47<05:07,  2.80it/s, Loss=0.0000862, Gaussian number=182421, print grad=1.364404283776821e-06, Depth Loss=0.0000000]
Training progress:  57%|█████▋    | 1140/2000 [07:50<05:07,  2.80it/s, Loss=0.0000648, Gaussian number=182421, print grad=1.7288168692175532e-06, Depth Loss=0.0000000]
Training progress:  57%|█████▊    | 1150/2000 [07:50<05:03,  2.80it/s, Loss=0.0000648, Gaussian number=182421, print grad=1.7288168692175532e-06, Depth Loss=0.0000000]
Training progress:  57%|█████▊    | 1150/2000 [07:54<05:03,  2.80it/s, Loss=0.0000694, Gaussian number=182421, print grad=2.028996050285059e-06, Depth Loss=0.0000000] 
Training progress:  58%|█████▊    | 1160/2000 [07:54<04:59,  2.81it/s, Loss=0.0000694, Gaussian number=182421, print grad=2.028996050285059e-06, Depth Loss=0.0000000]
Training progress:  58%|█████▊    | 1160/2000 [07:58<04:59,  2.81it/s, Loss=0.0000845, Gaussian number=182421, print grad=2.374262066950905e-06, Depth Loss=0.0000000]
Training progress:  58%|█████▊    | 1170/2000 [07:58<04:55,  2.81it/s, Loss=0.0000845, Gaussian number=182421, print grad=2.374262066950905e-06, Depth Loss=0.0000000]
Training progress:  58%|█████▊    | 1170/2000 [08:01<04:55,  2.81it/s, Loss=0.0000832, Gaussian number=182421, print grad=2.735383986873785e-06, Depth Loss=0.0000000]
Training progress:  59%|█████▉    | 1180/2000 [08:01<04:52,  2.81it/s, Loss=0.0000832, Gaussian number=182421, print grad=2.735383986873785e-06, Depth Loss=0.0000000]
Training progress:  59%|█████▉    | 1180/2000 [08:05<04:52,  2.81it/s, Loss=0.0000847, Gaussian number=182421, print grad=3.098811248491984e-06, Depth Loss=0.0000000]
Training progress:  60%|█████▉    | 1190/2000 [08:05<04:48,  2.81it/s, Loss=0.0000847, Gaussian number=182421, print grad=3.098811248491984e-06, Depth Loss=0.0000000]
Training progress:  60%|█████▉    | 1190/2000 [08:08<04:48,  2.81it/s, Loss=0.0000928, Gaussian number=182421, print grad=3.393768793102936e-06, Depth Loss=0.0000000]
Training progress:  60%|██████    | 1200/2000 [08:08<04:44,  2.81it/s, Loss=0.0000928, Gaussian number=182421, print grad=3.393768793102936e-06, Depth Loss=0.0000000]
Training progress:  60%|██████    | 1200/2000 [08:12<04:44,  2.81it/s, Loss=0.0000740, Gaussian number=182375, print grad=3.285225034233008e-07, Depth Loss=0.0000000]
Training progress:  60%|██████    | 1210/2000 [08:12<04:41,  2.81it/s, Loss=0.0000740, Gaussian number=182375, print grad=3.285225034233008e-07, Depth Loss=0.0000000]
Training progress:  60%|██████    | 1210/2000 [08:15<04:41,  2.81it/s, Loss=0.0000634, Gaussian number=182375, print grad=7.068456397973932e-07, Depth Loss=0.0000000]
Training progress:  61%|██████    | 1220/2000 [08:15<04:37,  2.81it/s, Loss=0.0000634, Gaussian number=182375, print grad=7.068456397973932e-07, Depth Loss=0.0000000]
Training progress:  61%|██████    | 1220/2000 [08:19<04:37,  2.81it/s, Loss=0.0000691, Gaussian number=182375, print grad=1.0414875077913166e-06, Depth Loss=0.0000000]
Training progress:  62%|██████▏   | 1230/2000 [08:19<04:33,  2.81it/s, Loss=0.0000691, Gaussian number=182375, print grad=1.0414875077913166e-06, Depth Loss=0.0000000]
Training progress:  62%|██████▏   | 1230/2000 [08:22<04:33,  2.81it/s, Loss=0.0000661, Gaussian number=182375, print grad=1.4191591617418453e-06, Depth Loss=0.0000000]
Training progress:  62%|██████▏   | 1240/2000 [08:22<04:30,  2.81it/s, Loss=0.0000661, Gaussian number=182375, print grad=1.4191591617418453e-06, Depth Loss=0.0000000]
Training progress:  62%|██████▏   | 1240/2000 [08:26<04:30,  2.81it/s, Loss=0.0000681, Gaussian number=182375, print grad=1.7276698827117798e-06, Depth Loss=0.0000000]
Training progress:  62%|██████▎   | 1250/2000 [08:26<04:27,  2.81it/s, Loss=0.0000681, Gaussian number=182375, print grad=1.7276698827117798e-06, Depth Loss=0.0000000]
Training progress:  62%|██████▎   | 1250/2000 [08:30<04:27,  2.81it/s, Loss=0.0000706, Gaussian number=182375, print grad=2.0312390915933065e-06, Depth Loss=0.0000000]
Training progress:  63%|██████▎   | 1260/2000 [08:30<04:23,  2.81it/s, Loss=0.0000706, Gaussian number=182375, print grad=2.0312390915933065e-06, Depth Loss=0.0000000]
Training progress:  63%|██████▎   | 1260/2000 [08:33<04:23,  2.81it/s, Loss=0.0000836, Gaussian number=182375, print grad=2.3943482574395603e-06, Depth Loss=0.0000000]
Training progress:  64%|██████▎   | 1270/2000 [08:33<04:19,  2.81it/s, Loss=0.0000836, Gaussian number=182375, print grad=2.3943482574395603e-06, Depth Loss=0.0000000]
Training progress:  64%|██████▎   | 1270/2000 [08:37<04:19,  2.81it/s, Loss=0.0000869, Gaussian number=182375, print grad=2.7108967515232507e-06, Depth Loss=0.0000000]
Training progress:  64%|██████▍   | 1280/2000 [08:37<04:16,  2.81it/s, Loss=0.0000869, Gaussian number=182375, print grad=2.7108967515232507e-06, Depth Loss=0.0000000]
Training progress:  64%|██████▍   | 1280/2000 [08:40<04:16,  2.81it/s, Loss=0.0000679, Gaussian number=182375, print grad=3.082857347180834e-06, Depth Loss=0.0000000] 
Training progress:  64%|██████▍   | 1290/2000 [08:40<04:12,  2.81it/s, Loss=0.0000679, Gaussian number=182375, print grad=3.082857347180834e-06, Depth Loss=0.0000000]
Training progress:  64%|██████▍   | 1290/2000 [08:44<04:12,  2.81it/s, Loss=0.0001009, Gaussian number=182375, print grad=3.4110958040400874e-06, Depth Loss=0.0000000]
Training progress:  65%|██████▌   | 1300/2000 [08:44<04:09,  2.81it/s, Loss=0.0001009, Gaussian number=182375, print grad=3.4110958040400874e-06, Depth Loss=0.0000000]
Training progress:  65%|██████▌   | 1300/2000 [08:47<04:09,  2.81it/s, Loss=0.0000921, Gaussian number=182334, print grad=3.4951807492689113e-07, Depth Loss=0.0000000]
Training progress:  66%|██████▌   | 1310/2000 [08:47<04:05,  2.81it/s, Loss=0.0000921, Gaussian number=182334, print grad=3.4951807492689113e-07, Depth Loss=0.0000000]
Training progress:  66%|██████▌   | 1310/2000 [08:51<04:05,  2.81it/s, Loss=0.0000897, Gaussian number=182334, print grad=6.79511970247404e-07, Depth Loss=0.0000000]  
Training progress:  66%|██████▌   | 1320/2000 [08:51<04:02,  2.81it/s, Loss=0.0000897, Gaussian number=182334, print grad=6.79511970247404e-07, Depth Loss=0.0000000]
Training progress:  66%|██████▌   | 1320/2000 [08:55<04:02,  2.81it/s, Loss=0.0000711, Gaussian number=182334, print grad=1.0336221976103843e-06, Depth Loss=0.0000000]
Training progress:  66%|██████▋   | 1330/2000 [08:55<03:58,  2.81it/s, Loss=0.0000711, Gaussian number=182334, print grad=1.0336221976103843e-06, Depth Loss=0.0000000]
Training progress:  66%|██████▋   | 1330/2000 [08:58<03:58,  2.81it/s, Loss=0.0000796, Gaussian number=182334, print grad=1.3914635701439693e-06, Depth Loss=0.0000000]
Training progress:  67%|██████▋   | 1340/2000 [08:58<03:55,  2.81it/s, Loss=0.0000796, Gaussian number=182334, print grad=1.3914635701439693e-06, Depth Loss=0.0000000]
Training progress:  67%|██████▋   | 1340/2000 [09:02<03:55,  2.81it/s, Loss=0.0001056, Gaussian number=182334, print grad=1.6855890407896368e-06, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1350/2000 [09:02<03:51,  2.81it/s, Loss=0.0001056, Gaussian number=182334, print grad=1.6855890407896368e-06, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1350/2000 [09:05<03:51,  2.81it/s, Loss=0.0000646, Gaussian number=182334, print grad=2.007497641898226e-06, Depth Loss=0.0000000] 
Training progress:  68%|██████▊   | 1360/2000 [09:05<03:47,  2.81it/s, Loss=0.0000646, Gaussian number=182334, print grad=2.007497641898226e-06, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1360/2000 [09:09<03:47,  2.81it/s, Loss=0.0001134, Gaussian number=182334, print grad=2.3955308279255405e-06, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1370/2000 [09:09<03:44,  2.81it/s, Loss=0.0001134, Gaussian number=182334, print grad=2.3955308279255405e-06, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1370/2000 [09:12<03:44,  2.81it/s, Loss=0.0000775, Gaussian number=182334, print grad=2.721750206546858e-06, Depth Loss=0.0000000] 
Training progress:  69%|██████▉   | 1380/2000 [09:12<03:40,  2.81it/s, Loss=0.0000775, Gaussian number=182334, print grad=2.721750206546858e-06, Depth Loss=0.0000000]
Training progress:  69%|██████▉   | 1380/2000 [09:16<03:40,  2.81it/s, Loss=0.0000729, Gaussian number=182334, print grad=3.0471585432678694e-06, Depth Loss=0.0000000]
Training progress:  70%|██████▉   | 1390/2000 [09:16<03:37,  2.81it/s, Loss=0.0000729, Gaussian number=182334, print grad=3.0471585432678694e-06, Depth Loss=0.0000000]
Training progress:  70%|██████▉   | 1390/2000 [09:19<03:37,  2.81it/s, Loss=0.0000803, Gaussian number=182334, print grad=3.3946864732570248e-06, Depth Loss=0.0000000]
Training progress:  70%|███████   | 1400/2000 [09:19<03:33,  2.81it/s, Loss=0.0000803, Gaussian number=182334, print grad=3.3946864732570248e-06, Depth Loss=0.0000000]
Training progress:  70%|███████   | 1400/2000 [09:23<03:33,  2.81it/s, Loss=0.0000869, Gaussian number=182291, print grad=3.6246669310457946e-07, Depth Loss=0.0000000]
Training progress:  70%|███████   | 1410/2000 [09:23<03:30,  2.80it/s, Loss=0.0000869, Gaussian number=182291, print grad=3.6246669310457946e-07, Depth Loss=0.0000000]
Training progress:  70%|███████   | 1410/2000 [09:27<03:30,  2.80it/s, Loss=0.0000769, Gaussian number=182291, print grad=7.208484475995647e-07, Depth Loss=0.0000000] 
Training progress:  71%|███████   | 1420/2000 [09:27<03:26,  2.80it/s, Loss=0.0000769, Gaussian number=182291, print grad=7.208484475995647e-07, Depth Loss=0.0000000]
Training progress:  71%|███████   | 1420/2000 [09:30<03:26,  2.80it/s, Loss=0.0000751, Gaussian number=182291, print grad=1.1183362857991597e-06, Depth Loss=0.0000000]
Training progress:  72%|███████▏  | 1430/2000 [09:30<03:23,  2.81it/s, Loss=0.0000751, Gaussian number=182291, print grad=1.1183362857991597e-06, Depth Loss=0.0000000]
Training progress:  72%|███████▏  | 1430/2000 [09:34<03:23,  2.81it/s, Loss=0.0000752, Gaussian number=182291, print grad=1.4355771327245748e-06, Depth Loss=0.0000000]
Training progress:  72%|███████▏  | 1440/2000 [09:34<03:19,  2.81it/s, Loss=0.0000752, Gaussian number=182291, print grad=1.4355771327245748e-06, Depth Loss=0.0000000]
Training progress:  72%|███████▏  | 1440/2000 [09:37<03:19,  2.81it/s, Loss=0.0000660, Gaussian number=182291, print grad=1.7644956642470788e-06, Depth Loss=0.0000000]
Training progress:  72%|███████▎  | 1450/2000 [09:37<03:15,  2.81it/s, Loss=0.0000660, Gaussian number=182291, print grad=1.7644956642470788e-06, Depth Loss=0.0000000]
Training progress:  72%|███████▎  | 1450/2000 [09:41<03:15,  2.81it/s, Loss=0.0000604, Gaussian number=182291, print grad=2.114500148309162e-06, Depth Loss=0.0000000] 
Training progress:  73%|███████▎  | 1460/2000 [09:41<03:12,  2.81it/s, Loss=0.0000604, Gaussian number=182291, print grad=2.114500148309162e-06, Depth Loss=0.0000000]
Training progress:  73%|███████▎  | 1460/2000 [09:44<03:12,  2.81it/s, Loss=0.0000816, Gaussian number=182291, print grad=2.4687749373697443e-06, Depth Loss=0.0000000]
Training progress:  74%|███████▎  | 1470/2000 [09:44<03:08,  2.81it/s, Loss=0.0000816, Gaussian number=182291, print grad=2.4687749373697443e-06, Depth Loss=0.0000000]
Training progress:  74%|███████▎  | 1470/2000 [09:48<03:08,  2.81it/s, Loss=0.0000821, Gaussian number=182291, print grad=2.8383660719555337e-06, Depth Loss=0.0000000]
Training progress:  74%|███████▍  | 1480/2000 [09:48<03:05,  2.81it/s, Loss=0.0000821, Gaussian number=182291, print grad=2.8383660719555337e-06, Depth Loss=0.0000000]
Training progress:  74%|███████▍  | 1480/2000 [09:52<03:05,  2.81it/s, Loss=0.0000871, Gaussian number=182291, print grad=3.205215307389153e-06, Depth Loss=0.0000000] 
Training progress:  74%|███████▍  | 1490/2000 [09:52<03:01,  2.80it/s, Loss=0.0000871, Gaussian number=182291, print grad=3.205215307389153e-06, Depth Loss=0.0000000]
Training progress:  74%|███████▍  | 1490/2000 [09:55<03:01,  2.80it/s, Loss=0.0000822, Gaussian number=182291, print grad=3.567825388017809e-06, Depth Loss=0.0000000]
Training progress:  75%|███████▌  | 1500/2000 [09:55<02:58,  2.80it/s, Loss=0.0000822, Gaussian number=182291, print grad=3.567825388017809e-06, Depth Loss=0.0000000]
Training progress:  75%|███████▌  | 1500/2000 [10:04<02:58,  2.80it/s, Loss=0.0000916, Gaussian number=182235, print grad=3.169602109664993e-07, Depth Loss=0.0000000]
Training progress:  76%|███████▌  | 1510/2000 [10:04<04:17,  1.90it/s, Loss=0.0000916, Gaussian number=182235, print grad=3.169602109664993e-07, Depth Loss=0.0000000]
Training progress:  76%|███████▌  | 1510/2000 [10:08<04:17,  1.90it/s, Loss=0.0000789, Gaussian number=182235, print grad=6.38765698113275e-07, Depth Loss=0.0000000] 
Training progress:  76%|███████▌  | 1520/2000 [10:08<03:47,  2.11it/s, Loss=0.0000789, Gaussian number=182235, print grad=6.38765698113275e-07, Depth Loss=0.0000000]
Training progress:  76%|███████▌  | 1520/2000 [10:11<03:47,  2.11it/s, Loss=0.0000512, Gaussian number=182235, print grad=1.0306008562110947e-06, Depth Loss=0.0000000]
Training progress:  76%|███████▋  | 1530/2000 [10:11<03:26,  2.28it/s, Loss=0.0000512, Gaussian number=182235, print grad=1.0306008562110947e-06, Depth Loss=0.0000000]
Training progress:  76%|███████▋  | 1530/2000 [10:15<03:26,  2.28it/s, Loss=0.0000682, Gaussian number=182235, print grad=1.392548711010022e-06, Depth Loss=0.0000000] 
Training progress:  77%|███████▋  | 1540/2000 [10:15<03:10,  2.41it/s, Loss=0.0000682, Gaussian number=182235, print grad=1.392548711010022e-06, Depth Loss=0.0000000]
Training progress:  77%|███████▋  | 1540/2000 [10:19<03:10,  2.41it/s, Loss=0.0000771, Gaussian number=182235, print grad=1.7589626395420055e-06, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1550/2000 [10:19<02:58,  2.52it/s, Loss=0.0000771, Gaussian number=182235, print grad=1.7589626395420055e-06, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1550/2000 [10:22<02:58,  2.52it/s, Loss=0.0000820, Gaussian number=182235, print grad=2.1613514036289416e-06, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1560/2000 [10:22<02:49,  2.60it/s, Loss=0.0000820, Gaussian number=182235, print grad=2.1613514036289416e-06, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1560/2000 [10:26<02:49,  2.60it/s, Loss=0.0000712, Gaussian number=182235, print grad=2.549098780946224e-06, Depth Loss=0.0000000] 
Training progress:  78%|███████▊  | 1570/2000 [10:26<02:41,  2.66it/s, Loss=0.0000712, Gaussian number=182235, print grad=2.549098780946224e-06, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1570/2000 [10:29<02:41,  2.66it/s, Loss=0.0000542, Gaussian number=182235, print grad=2.8523706987471087e-06, Depth Loss=0.0000000]
Training progress:  79%|███████▉  | 1580/2000 [10:29<02:35,  2.70it/s, Loss=0.0000542, Gaussian number=182235, print grad=2.8523706987471087e-06, Depth Loss=0.0000000]
Training progress:  79%|███████▉  | 1580/2000 [10:33<02:35,  2.70it/s, Loss=0.0000774, Gaussian number=182235, print grad=3.185767809554818e-06, Depth Loss=0.0000000] 
Training progress:  80%|███████▉  | 1590/2000 [10:33<02:29,  2.73it/s, Loss=0.0000774, Gaussian number=182235, print grad=3.185767809554818e-06, Depth Loss=0.0000000]
Training progress:  80%|███████▉  | 1590/2000 [10:36<02:29,  2.73it/s, Loss=0.0000705, Gaussian number=182235, print grad=3.5620016660686815e-06, Depth Loss=0.0000000]
Training progress:  80%|████████  | 1600/2000 [10:36<02:25,  2.76it/s, Loss=0.0000705, Gaussian number=182235, print grad=3.5620016660686815e-06, Depth Loss=0.0000000]
Training progress:  80%|████████  | 1600/2000 [10:40<02:25,  2.76it/s, Loss=0.0000769, Gaussian number=182175, print grad=3.5152746136191126e-07, Depth Loss=0.0000000]
Training progress:  80%|████████  | 1610/2000 [10:40<02:20,  2.77it/s, Loss=0.0000769, Gaussian number=182175, print grad=3.5152746136191126e-07, Depth Loss=0.0000000]
Training progress:  80%|████████  | 1610/2000 [10:43<02:20,  2.77it/s, Loss=0.0000785, Gaussian number=182175, print grad=7.586655783597962e-07, Depth Loss=0.0000000] 
Training progress:  81%|████████  | 1620/2000 [10:43<02:16,  2.78it/s, Loss=0.0000785, Gaussian number=182175, print grad=7.586655783597962e-07, Depth Loss=0.0000000]
Training progress:  81%|████████  | 1620/2000 [10:47<02:16,  2.78it/s, Loss=0.0000710, Gaussian number=182175, print grad=1.1132486861242796e-06, Depth Loss=0.0000000]
Training progress:  82%|████████▏ | 1630/2000 [10:47<02:12,  2.79it/s, Loss=0.0000710, Gaussian number=182175, print grad=1.1132486861242796e-06, Depth Loss=0.0000000]
Training progress:  82%|████████▏ | 1630/2000 [10:51<02:12,  2.79it/s, Loss=0.0000542, Gaussian number=182175, print grad=1.4738157005922403e-06, Depth Loss=0.0000000]
Training progress:  82%|████████▏ | 1640/2000 [10:51<02:08,  2.80it/s, Loss=0.0000542, Gaussian number=182175, print grad=1.4738157005922403e-06, Depth Loss=0.0000000]
Training progress:  82%|████████▏ | 1640/2000 [10:54<02:08,  2.80it/s, Loss=0.0000707, Gaussian number=182175, print grad=1.8261242757944274e-06, Depth Loss=0.0000000]
Training progress:  82%|████████▎ | 1650/2000 [10:54<02:04,  2.81it/s, Loss=0.0000707, Gaussian number=182175, print grad=1.8261242757944274e-06, Depth Loss=0.0000000]
Training progress:  82%|████████▎ | 1650/2000 [10:58<02:04,  2.81it/s, Loss=0.0000693, Gaussian number=182175, print grad=2.1601238131552236e-06, Depth Loss=0.0000000]
Training progress:  83%|████████▎ | 1660/2000 [10:58<02:00,  2.81it/s, Loss=0.0000693, Gaussian number=182175, print grad=2.1601238131552236e-06, Depth Loss=0.0000000]
Training progress:  83%|████████▎ | 1660/2000 [11:01<02:00,  2.81it/s, Loss=0.0000667, Gaussian number=182175, print grad=2.5065153295145137e-06, Depth Loss=0.0000000]
Training progress:  84%|████████▎ | 1670/2000 [11:01<01:57,  2.81it/s, Loss=0.0000667, Gaussian number=182175, print grad=2.5065153295145137e-06, Depth Loss=0.0000000]
Training progress:  84%|████████▎ | 1670/2000 [11:05<01:57,  2.81it/s, Loss=0.0000622, Gaussian number=182175, print grad=2.8613567337743007e-06, Depth Loss=0.0000000]
Training progress:  84%|████████▍ | 1680/2000 [11:05<01:53,  2.82it/s, Loss=0.0000622, Gaussian number=182175, print grad=2.8613567337743007e-06, Depth Loss=0.0000000]
Training progress:  84%|████████▍ | 1680/2000 [11:08<01:53,  2.82it/s, Loss=0.0000719, Gaussian number=182175, print grad=3.241855438318453e-06, Depth Loss=0.0000000] 
Training progress:  84%|████████▍ | 1690/2000 [11:08<01:50,  2.82it/s, Loss=0.0000719, Gaussian number=182175, print grad=3.241855438318453e-06, Depth Loss=0.0000000]
Training progress:  84%|████████▍ | 1690/2000 [11:12<01:50,  2.82it/s, Loss=0.0000778, Gaussian number=182175, print grad=3.5789878438663436e-06, Depth Loss=0.0000000]
Training progress:  85%|████████▌ | 1700/2000 [11:12<01:46,  2.82it/s, Loss=0.0000778, Gaussian number=182175, print grad=3.5789878438663436e-06, Depth Loss=0.0000000]
Training progress:  85%|████████▌ | 1700/2000 [11:15<01:46,  2.82it/s, Loss=0.0000787, Gaussian number=182116, print grad=3.8161871884767606e-07, Depth Loss=0.0000000]
Training progress:  86%|████████▌ | 1710/2000 [11:15<01:43,  2.81it/s, Loss=0.0000787, Gaussian number=182116, print grad=3.8161871884767606e-07, Depth Loss=0.0000000]
Training progress:  86%|████████▌ | 1710/2000 [11:19<01:43,  2.81it/s, Loss=0.0000765, Gaussian number=182116, print grad=6.973797326281783e-07, Depth Loss=0.0000000] 
Training progress:  86%|████████▌ | 1720/2000 [11:19<01:39,  2.82it/s, Loss=0.0000765, Gaussian number=182116, print grad=6.973797326281783e-07, Depth Loss=0.0000000]
Training progress:  86%|████████▌ | 1720/2000 [11:23<01:39,  2.82it/s, Loss=0.0000764, Gaussian number=182116, print grad=1.0542572681515594e-06, Depth Loss=0.0000000]
Training progress:  86%|████████▋ | 1730/2000 [11:23<01:35,  2.81it/s, Loss=0.0000764, Gaussian number=182116, print grad=1.0542572681515594e-06, Depth Loss=0.0000000]
Training progress:  86%|████████▋ | 1730/2000 [11:26<01:35,  2.81it/s, Loss=0.0000892, Gaussian number=182116, print grad=1.4367835774464766e-06, Depth Loss=0.0000000]
Training progress:  87%|████████▋ | 1740/2000 [11:26<01:32,  2.81it/s, Loss=0.0000892, Gaussian number=182116, print grad=1.4367835774464766e-06, Depth Loss=0.0000000]
Training progress:  87%|████████▋ | 1740/2000 [11:30<01:32,  2.81it/s, Loss=0.0000900, Gaussian number=182116, print grad=1.819993030949263e-06, Depth Loss=0.0000000] 
Training progress:  88%|████████▊ | 1750/2000 [11:30<01:28,  2.81it/s, Loss=0.0000900, Gaussian number=182116, print grad=1.819993030949263e-06, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1750/2000 [11:33<01:28,  2.81it/s, Loss=0.0000777, Gaussian number=182116, print grad=2.1896469206694746e-06, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1760/2000 [11:33<01:25,  2.81it/s, Loss=0.0000777, Gaussian number=182116, print grad=2.1896469206694746e-06, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1760/2000 [11:37<01:25,  2.81it/s, Loss=0.0000631, Gaussian number=182116, print grad=2.526127673263545e-06, Depth Loss=0.0000000] 
Training progress:  88%|████████▊ | 1770/2000 [11:37<01:21,  2.81it/s, Loss=0.0000631, Gaussian number=182116, print grad=2.526127673263545e-06, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1770/2000 [11:40<01:21,  2.81it/s, Loss=0.0000737, Gaussian number=182116, print grad=2.868807086997549e-06, Depth Loss=0.0000000]
Training progress:  89%|████████▉ | 1780/2000 [11:40<01:18,  2.81it/s, Loss=0.0000737, Gaussian number=182116, print grad=2.868807086997549e-06, Depth Loss=0.0000000]
Training progress:  89%|████████▉ | 1780/2000 [11:44<01:18,  2.81it/s, Loss=0.0000678, Gaussian number=182116, print grad=3.1711524570710026e-06, Depth Loss=0.0000000]
Training progress:  90%|████████▉ | 1790/2000 [11:44<01:14,  2.81it/s, Loss=0.0000678, Gaussian number=182116, print grad=3.1711524570710026e-06, Depth Loss=0.0000000]
Training progress:  90%|████████▉ | 1790/2000 [11:47<01:14,  2.81it/s, Loss=0.0000707, Gaussian number=182116, print grad=3.5583279895945452e-06, Depth Loss=0.0000000]
Training progress:  90%|█████████ | 1800/2000 [11:47<01:11,  2.81it/s, Loss=0.0000707, Gaussian number=182116, print grad=3.5583279895945452e-06, Depth Loss=0.0000000]
Training progress:  90%|█████████ | 1800/2000 [11:51<01:11,  2.81it/s, Loss=0.0000731, Gaussian number=182077, print grad=3.448465406563628e-07, Depth Loss=0.0000000] 
Training progress:  90%|█████████ | 1810/2000 [11:51<01:07,  2.81it/s, Loss=0.0000731, Gaussian number=182077, print grad=3.448465406563628e-07, Depth Loss=0.0000000]
Training progress:  90%|█████████ | 1810/2000 [11:55<01:07,  2.81it/s, Loss=0.0000668, Gaussian number=182077, print grad=7.488034157177026e-07, Depth Loss=0.0000000]
Training progress:  91%|█████████ | 1820/2000 [11:55<01:04,  2.81it/s, Loss=0.0000668, Gaussian number=182077, print grad=7.488034157177026e-07, Depth Loss=0.0000000]
Training progress:  91%|█████████ | 1820/2000 [11:58<01:04,  2.81it/s, Loss=0.0000555, Gaussian number=182077, print grad=1.041814471136604e-06, Depth Loss=0.0000000]
Training progress:  92%|█████████▏| 1830/2000 [11:58<01:00,  2.81it/s, Loss=0.0000555, Gaussian number=182077, print grad=1.041814471136604e-06, Depth Loss=0.0000000]
Training progress:  92%|█████████▏| 1830/2000 [12:02<01:00,  2.81it/s, Loss=0.0000636, Gaussian number=182077, print grad=1.4366664800036233e-06, Depth Loss=0.0000000]
Training progress:  92%|█████████▏| 1840/2000 [12:02<00:56,  2.81it/s, Loss=0.0000636, Gaussian number=182077, print grad=1.4366664800036233e-06, Depth Loss=0.0000000]
Training progress:  92%|█████████▏| 1840/2000 [12:05<00:56,  2.81it/s, Loss=0.0000676, Gaussian number=182077, print grad=1.7944787487067515e-06, Depth Loss=0.0000000]
Training progress:  92%|█████████▎| 1850/2000 [12:05<00:53,  2.81it/s, Loss=0.0000676, Gaussian number=182077, print grad=1.7944787487067515e-06, Depth Loss=0.0000000]
Training progress:  92%|█████████▎| 1850/2000 [12:09<00:53,  2.81it/s, Loss=0.0000690, Gaussian number=182077, print grad=2.1151042801648146e-06, Depth Loss=0.0000000]
Training progress:  93%|█████████▎| 1860/2000 [12:09<00:49,  2.81it/s, Loss=0.0000690, Gaussian number=182077, print grad=2.1151042801648146e-06, Depth Loss=0.0000000]
Training progress:  93%|█████████▎| 1860/2000 [12:12<00:49,  2.81it/s, Loss=0.0000801, Gaussian number=182077, print grad=2.532409780542366e-06, Depth Loss=0.0000000] 
Training progress:  94%|█████████▎| 1870/2000 [12:12<00:46,  2.81it/s, Loss=0.0000801, Gaussian number=182077, print grad=2.532409780542366e-06, Depth Loss=0.0000000]
Training progress:  94%|█████████▎| 1870/2000 [12:16<00:46,  2.81it/s, Loss=0.0000632, Gaussian number=182077, print grad=2.9040918434475316e-06, Depth Loss=0.0000000]
Training progress:  94%|█████████▍| 1880/2000 [12:16<00:42,  2.81it/s, Loss=0.0000632, Gaussian number=182077, print grad=2.9040918434475316e-06, Depth Loss=0.0000000]
Training progress:  94%|█████████▍| 1880/2000 [12:20<00:42,  2.81it/s, Loss=0.0000692, Gaussian number=182077, print grad=3.271117520853295e-06, Depth Loss=0.0000000] 
Training progress:  94%|█████████▍| 1890/2000 [12:20<00:39,  2.81it/s, Loss=0.0000692, Gaussian number=182077, print grad=3.271117520853295e-06, Depth Loss=0.0000000]
Training progress:  94%|█████████▍| 1890/2000 [12:23<00:39,  2.81it/s, Loss=0.0000812, Gaussian number=182077, print grad=3.640215481937048e-06, Depth Loss=0.0000000]
Training progress:  95%|█████████▌| 1900/2000 [12:23<00:35,  2.81it/s, Loss=0.0000812, Gaussian number=182077, print grad=3.640215481937048e-06, Depth Loss=0.0000000]
Training progress:  95%|█████████▌| 1900/2000 [12:27<00:35,  2.81it/s, Loss=0.0000758, Gaussian number=182032, print grad=2.992183283367922e-07, Depth Loss=0.0000000]
Training progress:  96%|█████████▌| 1910/2000 [12:27<00:32,  2.81it/s, Loss=0.0000758, Gaussian number=182032, print grad=2.992183283367922e-07, Depth Loss=0.0000000]
Training progress:  96%|█████████▌| 1910/2000 [12:30<00:32,  2.81it/s, Loss=0.0000585, Gaussian number=182032, print grad=6.542052801705722e-07, Depth Loss=0.0000000]
Training progress:  96%|█████████▌| 1920/2000 [12:30<00:28,  2.82it/s, Loss=0.0000585, Gaussian number=182032, print grad=6.542052801705722e-07, Depth Loss=0.0000000]
Training progress:  96%|█████████▌| 1920/2000 [12:34<00:28,  2.82it/s, Loss=0.0000539, Gaussian number=182032, print grad=1.021894831865211e-06, Depth Loss=0.0000000]
Training progress:  96%|█████████▋| 1930/2000 [12:34<00:24,  2.82it/s, Loss=0.0000539, Gaussian number=182032, print grad=1.021894831865211e-06, Depth Loss=0.0000000]
Training progress:  96%|█████████▋| 1930/2000 [12:37<00:24,  2.82it/s, Loss=0.0000749, Gaussian number=182032, print grad=1.3837690175932948e-06, Depth Loss=0.0000000]
Training progress:  97%|█████████▋| 1940/2000 [12:37<00:21,  2.82it/s, Loss=0.0000749, Gaussian number=182032, print grad=1.3837690175932948e-06, Depth Loss=0.0000000]
Training progress:  97%|█████████▋| 1940/2000 [12:41<00:21,  2.82it/s, Loss=0.0000603, Gaussian number=182032, print grad=1.7354138890368631e-06, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1950/2000 [12:41<00:17,  2.82it/s, Loss=0.0000603, Gaussian number=182032, print grad=1.7354138890368631e-06, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1950/2000 [12:44<00:17,  2.82it/s, Loss=0.0000913, Gaussian number=182032, print grad=2.0795068849110976e-06, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1960/2000 [12:44<00:14,  2.82it/s, Loss=0.0000913, Gaussian number=182032, print grad=2.0795068849110976e-06, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1960/2000 [12:48<00:14,  2.82it/s, Loss=0.0000761, Gaussian number=182032, print grad=2.435237547615543e-06, Depth Loss=0.0000000] 
Training progress:  98%|█████████▊| 1970/2000 [12:48<00:10,  2.82it/s, Loss=0.0000761, Gaussian number=182032, print grad=2.435237547615543e-06, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1970/2000 [12:51<00:10,  2.82it/s, Loss=0.0000666, Gaussian number=182032, print grad=2.8127267341915285e-06, Depth Loss=0.0000000]
Training progress:  99%|█████████▉| 1980/2000 [12:51<00:07,  2.83it/s, Loss=0.0000666, Gaussian number=182032, print grad=2.8127267341915285e-06, Depth Loss=0.0000000]
Training progress:  99%|█████████▉| 1980/2000 [12:55<00:07,  2.83it/s, Loss=0.0000660, Gaussian number=182032, print grad=3.199120328645222e-06, Depth Loss=0.0000000] 
Training progress: 100%|█████████▉| 1990/2000 [12:55<00:03,  2.83it/s, Loss=0.0000660, Gaussian number=182032, print grad=3.199120328645222e-06, Depth Loss=0.0000000]
Training progress: 100%|█████████▉| 1990/2000 [12:58<00:03,  2.83it/s, Loss=0.0000565, Gaussian number=182032, print grad=3.6110593555349624e-06, Depth Loss=0.0000000]
Training progress: 100%|██████████| 2000/2000 [12:58<00:00,  2.83it/s, Loss=0.0000565, Gaussian number=182032, print grad=3.6110593555349624e-06, Depth Loss=0.0000000]
Training progress: 100%|██████████| 2000/2000 [12:58<00:00,  2.57it/s, Loss=0.0000565, Gaussian number=182032, print grad=3.6110593555349624e-06, Depth Loss=0.0000000]
Iteration 100 [15/11 01:08:28]

[ITER 100] Evaluating test: WD 0.000132, PSNR 12.8686 [15/11 01:08:33]

[ITER 100] Evaluating train: WD 0.000135, PSNR 13.2666 [15/11 01:08:34]
Gaussian number:182686,print gradients:1.59478634742527e-08 [15/11 01:08:34]
Iteration 200 [15/11 01:09:10]

[ITER 200] Evaluating test: WD 0.000119, PSNR 14.1786 [15/11 01:09:15]

[ITER 200] Evaluating train: WD 0.000119, PSNR 14.6018 [15/11 01:09:16]
Gaussian number:182686,print gradients:2.14139763698995e-08 [15/11 01:09:16]
Iteration 300 [15/11 01:09:52]

[ITER 300] Evaluating test: WD 0.000110, PSNR 14.9678 [15/11 01:09:57]

[ITER 300] Evaluating train: WD 0.000110, PSNR 15.5143 [15/11 01:09:58]
Gaussian number:182686,print gradients:2.5287894445114034e-08 [15/11 01:09:58]
Iteration 400 [15/11 01:10:33]

[ITER 400] Evaluating test: WD 0.000105, PSNR 15.4938 [15/11 01:10:39]

[ITER 400] Evaluating train: WD 0.000104, PSNR 16.1983 [15/11 01:10:39]
Gaussian number:182686,print gradients:2.8030864740458128e-08 [15/11 01:10:39]
Iteration 500 [15/11 01:11:15]

[ITER 500] Evaluating test: WD 0.000099, PSNR 15.9547 [15/11 01:11:20]

[ITER 500] Evaluating train: WD 0.000104, PSNR 16.2113 [15/11 01:11:21]
Gaussian number:182686,print gradients:3.087551547764633e-08 [15/11 01:11:21]
Iteration 600 [15/11 01:11:56]

[ITER 600] Evaluating test: WD 0.000095, PSNR 16.2364 [15/11 01:12:02]

[ITER 600] Evaluating train: WD 0.000098, PSNR 16.5209 [15/11 01:12:02]
Gaussian number:182686,print gradients:3.303351192585069e-08 [15/11 01:12:02]
Iteration 700 [15/11 01:12:38]

[ITER 700] Evaluating test: WD 0.000094, PSNR 16.3741 [15/11 01:12:43]

[ITER 700] Evaluating train: WD 0.000096, PSNR 16.7001 [15/11 01:12:44]
Gaussian number:182631,print gradients:4.69754084519991e-08 [15/11 01:12:44]
Iteration 800 [15/11 01:13:19]

[ITER 800] Evaluating test: WD 0.000089, PSNR 16.6123 [15/11 01:13:24]

[ITER 800] Evaluating train: WD 0.000092, PSNR 16.9445 [15/11 01:13:25]
Gaussian number:182593,print gradients:4.6514362139760124e-08 [15/11 01:13:25]
Iteration 900 [15/11 01:14:00]

[ITER 900] Evaluating test: WD 0.000088, PSNR 16.7218 [15/11 01:14:05]

[ITER 900] Evaluating train: WD 0.000093, PSNR 17.0412 [15/11 01:14:06]
Gaussian number:182557,print gradients:4.885306736923667e-08 [15/11 01:14:06]
Iteration 1000 [15/11 01:14:41]

[ITER 1000] Evaluating test: WD 0.000087, PSNR 16.8598 [15/11 01:14:47]

[ITER 1000] Evaluating train: WD 0.000093, PSNR 17.0725 [15/11 01:14:47]
Gaussian number:182519,print gradients:4.788175900216629e-08 [15/11 01:14:47]
Iteration 1100 [15/11 01:15:22]
Iteration 1200 [15/11 01:15:58]
Iteration 1300 [15/11 01:16:34]
Iteration 1400 [15/11 01:17:09]
Iteration 1500 [15/11 01:17:45]

[ITER 1500] Evaluating test: WD 0.000078, PSNR 17.4063 [15/11 01:17:50]

[ITER 1500] Evaluating train: WD 0.000083, PSNR 17.6599 [15/11 01:17:51]
Gaussian number:182291,print gradients:5.3362107621524046e-08 [15/11 01:17:51]
Iteration 1600 [15/11 01:18:26]
Iteration 1700 [15/11 01:19:02]
Iteration 1800 [15/11 01:19:37]
Iteration 1900 [15/11 01:20:13]
Iteration 2000 [15/11 01:20:48]

[ITER 2000] Evaluating test: WD 0.000072, PSNR 17.7708 [15/11 01:20:54]

[ITER 2000] Evaluating train: WD 0.000079, PSNR 18.0431 [15/11 01:20:54]
Gaussian number:182032,print gradients:5.4738592325520585e-08 [15/11 01:20:54]

[ITER 2000] Saving Gaussians [15/11 01:20:54]

Training complete. [15/11 01:20:56]
