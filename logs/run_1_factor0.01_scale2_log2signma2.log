Optimizing /home/cw4287/gaussian-model/train_30k
Output folder: /home/cw4287/gaussian-model/train_30k [02/12 23:14:16]
Tensorboard not available: not logging progress [02/12 23:14:16]
------------LLFF HOLD------------- [02/12 23:14:17]

Reading camera 1/301
Reading camera 2/301
Reading camera 3/301
Reading camera 4/301
Reading camera 5/301
Reading camera 6/301
Reading camera 7/301
Reading camera 8/301
Reading camera 9/301
Reading camera 10/301
Reading camera 11/301
Reading camera 12/301
Reading camera 13/301
Reading camera 14/301
Reading camera 15/301
Reading camera 16/301
Reading camera 17/301
Reading camera 18/301
Reading camera 19/301
Reading camera 20/301
Reading camera 21/301
Reading camera 22/301
Reading camera 23/301
Reading camera 24/301
Reading camera 25/301
Reading camera 26/301
Reading camera 27/301
Reading camera 28/301
Reading camera 29/301
Reading camera 30/301
Reading camera 31/301
Reading camera 32/301
Reading camera 33/301
Reading camera 34/301
Reading camera 35/301
Reading camera 36/301
Reading camera 37/301
Reading camera 38/301
Reading camera 39/301
Reading camera 40/301
Reading camera 41/301
Reading camera 42/301
Reading camera 43/301
Reading camera 44/301
Reading camera 45/301
Reading camera 46/301
Reading camera 47/301
Reading camera 48/301
Reading camera 49/301
Reading camera 50/301
Reading camera 51/301
Reading camera 52/301
Reading camera 53/301
Reading camera 54/301
Reading camera 55/301
Reading camera 56/301
Reading camera 57/301
Reading camera 58/301
Reading camera 59/301
Reading camera 60/301
Reading camera 61/301
Reading camera 62/301
Reading camera 63/301
Reading camera 64/301
Reading camera 65/301
Reading camera 66/301
Reading camera 67/301
Reading camera 68/301
Reading camera 69/301
Reading camera 70/301
Reading camera 71/301
Reading camera 72/301
Reading camera 73/301
Reading camera 74/301
Reading camera 75/301
Reading camera 76/301
Reading camera 77/301
Reading camera 78/301
Reading camera 79/301
Reading camera 80/301
Reading camera 81/301
Reading camera 82/301
Reading camera 83/301
Reading camera 84/301
Reading camera 85/301
Reading camera 86/301
Reading camera 87/301
Reading camera 88/301
Reading camera 89/301
Reading camera 90/301
Reading camera 91/301
Reading camera 92/301
Reading camera 93/301
Reading camera 94/301
Reading camera 95/301
Reading camera 96/301
Reading camera 97/301
Reading camera 98/301
Reading camera 99/301
Reading camera 100/301
Reading camera 101/301
Reading camera 102/301
Reading camera 103/301
Reading camera 104/301
Reading camera 105/301
Reading camera 106/301
Reading camera 107/301
Reading camera 108/301
Reading camera 109/301
Reading camera 110/301
Reading camera 111/301
Reading camera 112/301
Reading camera 113/301
Reading camera 114/301
Reading camera 115/301
Reading camera 116/301
Reading camera 117/301
Reading camera 118/301
Reading camera 119/301
Reading camera 120/301
Reading camera 121/301
Reading camera 122/301
Reading camera 123/301
Reading camera 124/301
Reading camera 125/301
Reading camera 126/301
Reading camera 127/301
Reading camera 128/301
Reading camera 129/301
Reading camera 130/301
Reading camera 131/301
Reading camera 132/301
Reading camera 133/301
Reading camera 134/301
Reading camera 135/301
Reading camera 136/301
Reading camera 137/301
Reading camera 138/301
Reading camera 139/301
Reading camera 140/301
Reading camera 141/301
Reading camera 142/301
Reading camera 143/301
Reading camera 144/301
Reading camera 145/301
Reading camera 146/301
Reading camera 147/301
Reading camera 148/301
Reading camera 149/301
Reading camera 150/301
Reading camera 151/301
Reading camera 152/301
Reading camera 153/301
Reading camera 154/301
Reading camera 155/301
Reading camera 156/301
Reading camera 157/301
Reading camera 158/301
Reading camera 159/301
Reading camera 160/301
Reading camera 161/301
Reading camera 162/301
Reading camera 163/301
Reading camera 164/301
Reading camera 165/301
Reading camera 166/301
Reading camera 167/301
Reading camera 168/301
Reading camera 169/301
Reading camera 170/301
Reading camera 171/301
Reading camera 172/301
Reading camera 173/301
Reading camera 174/301
Reading camera 175/301
Reading camera 176/301
Reading camera 177/301
Reading camera 178/301
Reading camera 179/301
Reading camera 180/301
Reading camera 181/301
Reading camera 182/301
Reading camera 183/301
Reading camera 184/301
Reading camera 185/301
Reading camera 186/301
Reading camera 187/301
Reading camera 188/301
Reading camera 189/301
Reading camera 190/301
Reading camera 191/301
Reading camera 192/301
Reading camera 193/301
Reading camera 194/301
Reading camera 195/301
Reading camera 196/301
Reading camera 197/301
Reading camera 198/301
Reading camera 199/301
Reading camera 200/301
Reading camera 201/301
Reading camera 202/301
Reading camera 203/301
Reading camera 204/301
Reading camera 205/301
Reading camera 206/301
Reading camera 207/301
Reading camera 208/301
Reading camera 209/301
Reading camera 210/301
Reading camera 211/301
Reading camera 212/301
Reading camera 213/301
Reading camera 214/301
Reading camera 215/301
Reading camera 216/301
Reading camera 217/301
Reading camera 218/301
Reading camera 219/301
Reading camera 220/301
Reading camera 221/301
Reading camera 222/301
Reading camera 223/301
Reading camera 224/301
Reading camera 225/301
Reading camera 226/301
Reading camera 227/301
Reading camera 228/301
Reading camera 229/301
Reading camera 230/301
Reading camera 231/301
Reading camera 232/301
Reading camera 233/301
Reading camera 234/301
Reading camera 235/301
Reading camera 236/301
Reading camera 237/301
Reading camera 238/301
Reading camera 239/301
Reading camera 240/301
Reading camera 241/301
Reading camera 242/301
Reading camera 243/301
Reading camera 244/301
Reading camera 245/301
Reading camera 246/301
Reading camera 247/301
Reading camera 248/301
Reading camera 249/301
Reading camera 250/301
Reading camera 251/301
Reading camera 252/301
Reading camera 253/301
Reading camera 254/301
Reading camera 255/301
Reading camera 256/301
Reading camera 257/301
Reading camera 258/301
Reading camera 259/301
Reading camera 260/301
Reading camera 261/301
Reading camera 262/301
Reading camera 263/301
Reading camera 264/301
Reading camera 265/301
Reading camera 266/301
Reading camera 267/301
Reading camera 268/301
Reading camera 269/301
Reading camera 270/301
Reading camera 271/301
Reading camera 272/301
Reading camera 273/301
Reading camera 274/301
Reading camera 275/301
Reading camera 276/301
Reading camera 277/301
Reading camera 278/301
Reading camera 279/301
Reading camera 280/301
Reading camera 281/301
Reading camera 282/301
Reading camera 283/301
Reading camera 284/301
Reading camera 285/301
Reading camera 286/301
Reading camera 287/301
Reading camera 288/301
Reading camera 289/301
Reading camera 290/301
Reading camera 291/301
Reading camera 292/301
Reading camera 293/301
Reading camera 294/301
Reading camera 295/301
Reading camera 296/301
Reading camera 297/301
Reading camera 298/301
Reading camera 299/301
Reading camera 300/301
Reading camera 301/301 [02/12 23:14:17]
Loading Training Cameras [02/12 23:14:17]
Loading Test Cameras [02/12 23:14:42]
Number of points at initialisation :  182686 [02/12 23:14:46]

Training progress:   0%|          | 0/2000 [00:00<?, ?it/s]/ext3/conda/envs/3dgs/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/ext3/conda/envs/3dgs/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)

Training progress:   0%|          | 0/2000 [00:10<?, ?it/s, Loss=0.1518292, Gaussian number=182686, print grad=6.169323751237243e-05, Depth Loss=0.0000000]
Training progress:   0%|          | 10/2000 [00:10<34:33,  1.04s/it, Loss=0.1518292, Gaussian number=182686, print grad=6.169323751237243e-05, Depth Loss=0.0000000]
Training progress:   0%|          | 10/2000 [00:14<34:33,  1.04s/it, Loss=0.1470603, Gaussian number=182686, print grad=0.00016373078688047826, Depth Loss=0.0000000]
Training progress:   1%|          | 20/2000 [00:14<21:15,  1.55it/s, Loss=0.1470603, Gaussian number=182686, print grad=0.00016373078688047826, Depth Loss=0.0000000]
Training progress:   1%|          | 20/2000 [00:17<21:15,  1.55it/s, Loss=0.1459849, Gaussian number=182686, print grad=0.00025976134929805994, Depth Loss=0.0000000]
Training progress:   2%|▏         | 30/2000 [00:17<16:59,  1.93it/s, Loss=0.1459849, Gaussian number=182686, print grad=0.00025976134929805994, Depth Loss=0.0000000]
Training progress:   2%|▏         | 30/2000 [00:21<16:59,  1.93it/s, Loss=0.1573306, Gaussian number=182686, print grad=0.0003625855897553265, Depth Loss=0.0000000] 
Training progress:   2%|▏         | 40/2000 [00:21<14:56,  2.19it/s, Loss=0.1573306, Gaussian number=182686, print grad=0.0003625855897553265, Depth Loss=0.0000000]
Training progress:   2%|▏         | 40/2000 [00:25<14:56,  2.19it/s, Loss=0.1199011, Gaussian number=182686, print grad=0.00044177164090797305, Depth Loss=0.0000000]
Training progress:   2%|▎         | 50/2000 [00:25<13:47,  2.36it/s, Loss=0.1199011, Gaussian number=182686, print grad=0.00044177164090797305, Depth Loss=0.0000000]
Training progress:   2%|▎         | 50/2000 [00:28<13:47,  2.36it/s, Loss=0.1376885, Gaussian number=182686, print grad=0.0005654665292240679, Depth Loss=0.0000000] 
Training progress:   3%|▎         | 60/2000 [00:28<13:03,  2.48it/s, Loss=0.1376885, Gaussian number=182686, print grad=0.0005654665292240679, Depth Loss=0.0000000]
Training progress:   3%|▎         | 60/2000 [00:32<13:03,  2.48it/s, Loss=0.1240633, Gaussian number=182686, print grad=0.0007253865478560328, Depth Loss=0.0000000]
Training progress:   4%|▎         | 70/2000 [00:32<12:34,  2.56it/s, Loss=0.1240633, Gaussian number=182686, print grad=0.0007253865478560328, Depth Loss=0.0000000]
Training progress:   4%|▎         | 70/2000 [00:35<12:34,  2.56it/s, Loss=0.1436866, Gaussian number=182686, print grad=0.0008413204923272133, Depth Loss=0.0000000]
Training progress:   4%|▍         | 80/2000 [00:35<12:14,  2.61it/s, Loss=0.1436866, Gaussian number=182686, print grad=0.0008413204923272133, Depth Loss=0.0000000]
Training progress:   4%|▍         | 80/2000 [00:39<12:14,  2.61it/s, Loss=0.1235569, Gaussian number=182686, print grad=0.0009616636671125889, Depth Loss=0.0000000]
Training progress:   4%|▍         | 90/2000 [00:39<12:01,  2.65it/s, Loss=0.1235569, Gaussian number=182686, print grad=0.0009616636671125889, Depth Loss=0.0000000]
Training progress:   4%|▍         | 90/2000 [00:43<12:01,  2.65it/s, Loss=0.1234736, Gaussian number=182686, print grad=0.00110745953861624, Depth Loss=0.0000000]  
Training progress:   5%|▌         | 100/2000 [00:43<11:50,  2.67it/s, Loss=0.1234736, Gaussian number=182686, print grad=0.00110745953861624, Depth Loss=0.0000000]
Training progress:   5%|▌         | 100/2000 [01:50<11:50,  2.67it/s, Loss=0.1442696, Gaussian number=182686, print grad=0.0012687456328421831, Depth Loss=0.0000000]
Training progress:   6%|▌         | 110/2000 [01:50<1:12:58,  2.32s/it, Loss=0.1442696, Gaussian number=182686, print grad=0.0012687456328421831, Depth Loss=0.0000000]
Training progress:   6%|▌         | 110/2000 [01:54<1:12:58,  2.32s/it, Loss=0.1196996, Gaussian number=182686, print grad=0.0014249533414840698, Depth Loss=0.0000000]
Training progress:   6%|▌         | 120/2000 [01:54<53:58,  1.72s/it, Loss=0.1196996, Gaussian number=182686, print grad=0.0014249533414840698, Depth Loss=0.0000000]  
Training progress:   6%|▌         | 120/2000 [01:57<53:58,  1.72s/it, Loss=0.1397343, Gaussian number=182686, print grad=0.001625304576009512, Depth Loss=0.0000000] 
Training progress:   6%|▋         | 130/2000 [01:57<40:51,  1.31s/it, Loss=0.1397343, Gaussian number=182686, print grad=0.001625304576009512, Depth Loss=0.0000000]
Training progress:   6%|▋         | 130/2000 [02:01<40:51,  1.31s/it, Loss=0.1268329, Gaussian number=182686, print grad=0.001829432905651629, Depth Loss=0.0000000]
Training progress:   7%|▋         | 140/2000 [02:01<31:46,  1.03s/it, Loss=0.1268329, Gaussian number=182686, print grad=0.001829432905651629, Depth Loss=0.0000000]
Training progress:   7%|▋         | 140/2000 [02:05<31:46,  1.03s/it, Loss=0.1099266, Gaussian number=182686, print grad=0.002008466050028801, Depth Loss=0.0000000]
Training progress:   8%|▊         | 150/2000 [02:05<25:27,  1.21it/s, Loss=0.1099266, Gaussian number=182686, print grad=0.002008466050028801, Depth Loss=0.0000000]
Training progress:   8%|▊         | 150/2000 [02:08<25:27,  1.21it/s, Loss=0.1174121, Gaussian number=182686, print grad=0.0022472890559583902, Depth Loss=0.0000000]
Training progress:   8%|▊         | 160/2000 [02:08<21:02,  1.46it/s, Loss=0.1174121, Gaussian number=182686, print grad=0.0022472890559583902, Depth Loss=0.0000000]
Training progress:   8%|▊         | 160/2000 [02:12<21:02,  1.46it/s, Loss=0.1160792, Gaussian number=182686, print grad=0.0024191932752728462, Depth Loss=0.0000000]
Training progress:   8%|▊         | 170/2000 [02:12<17:58,  1.70it/s, Loss=0.1160792, Gaussian number=182686, print grad=0.0024191932752728462, Depth Loss=0.0000000]
Training progress:   8%|▊         | 170/2000 [02:15<17:58,  1.70it/s, Loss=0.1021355, Gaussian number=182686, print grad=0.0026332258712500334, Depth Loss=0.0000000]
Training progress:   9%|▉         | 180/2000 [02:15<15:49,  1.92it/s, Loss=0.1021355, Gaussian number=182686, print grad=0.0026332258712500334, Depth Loss=0.0000000]
Training progress:   9%|▉         | 180/2000 [02:19<15:49,  1.92it/s, Loss=0.1286055, Gaussian number=182686, print grad=0.002810596488416195, Depth Loss=0.0000000] 
Training progress:  10%|▉         | 190/2000 [02:19<14:17,  2.11it/s, Loss=0.1286055, Gaussian number=182686, print grad=0.002810596488416195, Depth Loss=0.0000000]
Training progress:  10%|▉         | 190/2000 [02:23<14:17,  2.11it/s, Loss=0.1156168, Gaussian number=182686, print grad=0.0030341539531946182, Depth Loss=0.0000000]
Training progress:  10%|█         | 200/2000 [02:23<13:12,  2.27it/s, Loss=0.1156168, Gaussian number=182686, print grad=0.0030341539531946182, Depth Loss=0.0000000]
Training progress:  10%|█         | 200/2000 [03:29<13:12,  2.27it/s, Loss=0.1282712, Gaussian number=182686, print grad=0.0032726991921663284, Depth Loss=0.0000000]
Training progress:  10%|█         | 210/2000 [03:29<1:08:32,  2.30s/it, Loss=0.1282712, Gaussian number=182686, print grad=0.0032726991921663284, Depth Loss=0.0000000]
Training progress:  10%|█         | 210/2000 [03:33<1:08:32,  2.30s/it, Loss=0.1071646, Gaussian number=182686, print grad=0.003482509171590209, Depth Loss=0.0000000] 
Training progress:  11%|█         | 220/2000 [03:33<50:54,  1.72s/it, Loss=0.1071646, Gaussian number=182686, print grad=0.003482509171590209, Depth Loss=0.0000000]  
Training progress:  11%|█         | 220/2000 [03:36<50:54,  1.72s/it, Loss=0.1185485, Gaussian number=182686, print grad=0.003695218125358224, Depth Loss=0.0000000]
Training progress:  12%|█▏        | 230/2000 [03:36<38:37,  1.31s/it, Loss=0.1185485, Gaussian number=182686, print grad=0.003695218125358224, Depth Loss=0.0000000]
Training progress:  12%|█▏        | 230/2000 [03:40<38:37,  1.31s/it, Loss=0.1425734, Gaussian number=182686, print grad=0.003902314929291606, Depth Loss=0.0000000]
Training progress:  12%|█▏        | 240/2000 [03:40<30:03,  1.02s/it, Loss=0.1425734, Gaussian number=182686, print grad=0.003902314929291606, Depth Loss=0.0000000]
Training progress:  12%|█▏        | 240/2000 [03:43<30:03,  1.02s/it, Loss=0.1094515, Gaussian number=182686, print grad=0.004141352139413357, Depth Loss=0.0000000]
Training progress:  12%|█▎        | 250/2000 [03:43<24:04,  1.21it/s, Loss=0.1094515, Gaussian number=182686, print grad=0.004141352139413357, Depth Loss=0.0000000]
Training progress:  12%|█▎        | 250/2000 [03:47<24:04,  1.21it/s, Loss=0.1234031, Gaussian number=182686, print grad=0.0043618083000183105, Depth Loss=0.0000000]
Training progress:  13%|█▎        | 260/2000 [03:47<19:53,  1.46it/s, Loss=0.1234031, Gaussian number=182686, print grad=0.0043618083000183105, Depth Loss=0.0000000]
Training progress:  13%|█▎        | 260/2000 [03:51<19:53,  1.46it/s, Loss=0.0909304, Gaussian number=182686, print grad=0.004592130426317453, Depth Loss=0.0000000] 
Training progress:  14%|█▎        | 270/2000 [03:51<16:57,  1.70it/s, Loss=0.0909304, Gaussian number=182686, print grad=0.004592130426317453, Depth Loss=0.0000000]
Training progress:  14%|█▎        | 270/2000 [03:54<16:57,  1.70it/s, Loss=0.1173386, Gaussian number=182686, print grad=0.0048771873116493225, Depth Loss=0.0000000]
Training progress:  14%|█▍        | 280/2000 [03:54<14:54,  1.92it/s, Loss=0.1173386, Gaussian number=182686, print grad=0.0048771873116493225, Depth Loss=0.0000000]
Training progress:  14%|█▍        | 280/2000 [03:58<14:54,  1.92it/s, Loss=0.1143840, Gaussian number=182686, print grad=0.005127888172864914, Depth Loss=0.0000000] 
Training progress:  14%|█▍        | 290/2000 [03:58<13:27,  2.12it/s, Loss=0.1143840, Gaussian number=182686, print grad=0.005127888172864914, Depth Loss=0.0000000]
Training progress:  14%|█▍        | 290/2000 [04:01<13:27,  2.12it/s, Loss=0.1063474, Gaussian number=182686, print grad=0.0053775678388774395, Depth Loss=0.0000000]
Training progress:  15%|█▌        | 300/2000 [04:01<12:26,  2.28it/s, Loss=0.1063474, Gaussian number=182686, print grad=0.0053775678388774395, Depth Loss=0.0000000]
Training progress:  15%|█▌        | 300/2000 [05:08<12:26,  2.28it/s, Loss=0.0907999, Gaussian number=182686, print grad=0.0056606195867061615, Depth Loss=0.0000000]
Training progress:  16%|█▌        | 310/2000 [05:08<1:04:44,  2.30s/it, Loss=0.0907999, Gaussian number=182686, print grad=0.0056606195867061615, Depth Loss=0.0000000]
Training progress:  16%|█▌        | 310/2000 [05:11<1:04:44,  2.30s/it, Loss=0.0942875, Gaussian number=182686, print grad=0.005847478285431862, Depth Loss=0.0000000] 
Training progress:  16%|█▌        | 320/2000 [05:11<48:04,  1.72s/it, Loss=0.0942875, Gaussian number=182686, print grad=0.005847478285431862, Depth Loss=0.0000000]  
Training progress:  16%|█▌        | 320/2000 [05:15<48:04,  1.72s/it, Loss=0.1223307, Gaussian number=182686, print grad=0.006089377216994762, Depth Loss=0.0000000]
Training progress:  16%|█▋        | 330/2000 [05:15<36:26,  1.31s/it, Loss=0.1223307, Gaussian number=182686, print grad=0.006089377216994762, Depth Loss=0.0000000]
Training progress:  16%|█▋        | 330/2000 [05:19<36:26,  1.31s/it, Loss=0.0920846, Gaussian number=182686, print grad=0.006355473306030035, Depth Loss=0.0000000]
Training progress:  17%|█▋        | 340/2000 [05:19<28:21,  1.02s/it, Loss=0.0920846, Gaussian number=182686, print grad=0.006355473306030035, Depth Loss=0.0000000]
Training progress:  17%|█▋        | 340/2000 [05:22<28:21,  1.02s/it, Loss=0.0951178, Gaussian number=182686, print grad=0.006613904610276222, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 350/2000 [05:22<22:41,  1.21it/s, Loss=0.0951178, Gaussian number=182686, print grad=0.006613904610276222, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 350/2000 [05:26<22:41,  1.21it/s, Loss=0.0902121, Gaussian number=182686, print grad=0.00692540081217885, Depth Loss=0.0000000] 
Training progress:  18%|█▊        | 360/2000 [05:26<18:44,  1.46it/s, Loss=0.0902121, Gaussian number=182686, print grad=0.00692540081217885, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 360/2000 [05:29<18:44,  1.46it/s, Loss=0.0923748, Gaussian number=182686, print grad=0.007202646695077419, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 370/2000 [05:29<15:58,  1.70it/s, Loss=0.0923748, Gaussian number=182686, print grad=0.007202646695077419, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 370/2000 [05:33<15:58,  1.70it/s, Loss=0.1180319, Gaussian number=182686, print grad=0.00742213474586606, Depth Loss=0.0000000] 
Training progress:  19%|█▉        | 380/2000 [05:33<14:01,  1.93it/s, Loss=0.1180319, Gaussian number=182686, print grad=0.00742213474586606, Depth Loss=0.0000000]
Training progress:  19%|█▉        | 380/2000 [05:37<14:01,  1.93it/s, Loss=0.1081738, Gaussian number=182686, print grad=0.007692106533795595, Depth Loss=0.0000000]
Training progress:  20%|█▉        | 390/2000 [05:37<12:38,  2.12it/s, Loss=0.1081738, Gaussian number=182686, print grad=0.007692106533795595, Depth Loss=0.0000000]
Training progress:  20%|█▉        | 390/2000 [05:40<12:38,  2.12it/s, Loss=0.1271389, Gaussian number=182686, print grad=0.007939794100821018, Depth Loss=0.0000000]
Training progress:  20%|██        | 400/2000 [05:40<11:39,  2.29it/s, Loss=0.1271389, Gaussian number=182686, print grad=0.007939794100821018, Depth Loss=0.0000000]
Training progress:  20%|██        | 400/2000 [05:44<11:39,  2.29it/s, Loss=0.1085848, Gaussian number=182686, print grad=0.008253967389464378, Depth Loss=0.0000000]
Training progress:  20%|██        | 410/2000 [05:44<10:58,  2.42it/s, Loss=0.1085848, Gaussian number=182686, print grad=0.008253967389464378, Depth Loss=0.0000000]
Training progress:  20%|██        | 410/2000 [05:47<10:58,  2.42it/s, Loss=0.0977853, Gaussian number=182686, print grad=0.008547504432499409, Depth Loss=0.0000000]
Training progress:  21%|██        | 420/2000 [05:47<10:28,  2.52it/s, Loss=0.0977853, Gaussian number=182686, print grad=0.008547504432499409, Depth Loss=0.0000000]
Training progress:  21%|██        | 420/2000 [05:51<10:28,  2.52it/s, Loss=0.1205579, Gaussian number=182686, print grad=0.008851018734276295, Depth Loss=0.0000000]
Training progress:  22%|██▏       | 430/2000 [05:51<10:06,  2.59it/s, Loss=0.1205579, Gaussian number=182686, print grad=0.008851018734276295, Depth Loss=0.0000000]
Training progress:  22%|██▏       | 430/2000 [05:55<10:06,  2.59it/s, Loss=0.0959601, Gaussian number=182686, print grad=0.009135369211435318, Depth Loss=0.0000000]
Training progress:  22%|██▏       | 440/2000 [05:55<09:49,  2.64it/s, Loss=0.0959601, Gaussian number=182686, print grad=0.009135369211435318, Depth Loss=0.0000000]
Training progress:  22%|██▏       | 440/2000 [05:58<09:49,  2.64it/s, Loss=0.1065827, Gaussian number=182686, print grad=0.00943850353360176, Depth Loss=0.0000000] 
Training progress:  22%|██▎       | 450/2000 [05:58<09:37,  2.69it/s, Loss=0.1065827, Gaussian number=182686, print grad=0.00943850353360176, Depth Loss=0.0000000]
Training progress:  22%|██▎       | 450/2000 [06:02<09:37,  2.69it/s, Loss=0.1079893, Gaussian number=182686, print grad=0.00972813367843628, Depth Loss=0.0000000]
Training progress:  23%|██▎       | 460/2000 [06:02<09:27,  2.72it/s, Loss=0.1079893, Gaussian number=182686, print grad=0.00972813367843628, Depth Loss=0.0000000]
Training progress:  23%|██▎       | 460/2000 [06:05<09:27,  2.72it/s, Loss=0.1297389, Gaussian number=182686, print grad=0.009998091496527195, Depth Loss=0.0000000]
Training progress:  24%|██▎       | 470/2000 [06:05<09:18,  2.74it/s, Loss=0.1297389, Gaussian number=182686, print grad=0.009998091496527195, Depth Loss=0.0000000]
Training progress:  24%|██▎       | 470/2000 [06:09<09:18,  2.74it/s, Loss=0.0884942, Gaussian number=182686, print grad=0.010304347611963749, Depth Loss=0.0000000]
Training progress:  24%|██▍       | 480/2000 [06:09<09:12,  2.75it/s, Loss=0.0884942, Gaussian number=182686, print grad=0.010304347611963749, Depth Loss=0.0000000]
Training progress:  24%|██▍       | 480/2000 [06:12<09:12,  2.75it/s, Loss=0.0935892, Gaussian number=182686, print grad=0.010587838478386402, Depth Loss=0.0000000]
Training progress:  24%|██▍       | 490/2000 [06:12<09:06,  2.76it/s, Loss=0.0935892, Gaussian number=182686, print grad=0.010587838478386402, Depth Loss=0.0000000]
Training progress:  24%|██▍       | 490/2000 [06:16<09:06,  2.76it/s, Loss=0.0768629, Gaussian number=182686, print grad=0.010874242521822453, Depth Loss=0.0000000]
Training progress:  25%|██▌       | 500/2000 [06:16<09:00,  2.77it/s, Loss=0.0768629, Gaussian number=182686, print grad=0.010874242521822453, Depth Loss=0.0000000]
Training progress:  25%|██▌       | 500/2000 [07:22<09:00,  2.77it/s, Loss=0.0885906, Gaussian number=182686, print grad=0.011169233359396458, Depth Loss=0.0000000]
Training progress:  26%|██▌       | 510/2000 [07:22<55:39,  2.24s/it, Loss=0.0885906, Gaussian number=182686, print grad=0.011169233359396458, Depth Loss=0.0000000]
Training progress:  26%|██▌       | 510/2000 [07:26<55:39,  2.24s/it, Loss=0.0908196, Gaussian number=182686, print grad=0.011480171233415604, Depth Loss=0.0000000]
Training progress:  26%|██▌       | 520/2000 [07:26<41:20,  1.68s/it, Loss=0.0908196, Gaussian number=182686, print grad=0.011480171233415604, Depth Loss=0.0000000]
Training progress:  26%|██▌       | 520/2000 [07:30<41:20,  1.68s/it, Loss=0.0743798, Gaussian number=182686, print grad=0.011739463545382023, Depth Loss=0.0000000]
Training progress:  26%|██▋       | 530/2000 [07:30<31:21,  1.28s/it, Loss=0.0743798, Gaussian number=182686, print grad=0.011739463545382023, Depth Loss=0.0000000]
Training progress:  26%|██▋       | 530/2000 [07:33<31:21,  1.28s/it, Loss=0.0995504, Gaussian number=182686, print grad=0.01203293725848198, Depth Loss=0.0000000] 
Training progress:  27%|██▋       | 540/2000 [07:33<24:24,  1.00s/it, Loss=0.0995504, Gaussian number=182686, print grad=0.01203293725848198, Depth Loss=0.0000000]
Training progress:  27%|██▋       | 540/2000 [07:37<24:24,  1.00s/it, Loss=0.0952749, Gaussian number=182686, print grad=0.012348625808954239, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 550/2000 [07:37<19:33,  1.24it/s, Loss=0.0952749, Gaussian number=182686, print grad=0.012348625808954239, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 550/2000 [07:40<19:33,  1.24it/s, Loss=0.0776006, Gaussian number=182686, print grad=0.012650598771870136, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 560/2000 [07:40<16:09,  1.48it/s, Loss=0.0776006, Gaussian number=182686, print grad=0.012650598771870136, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 560/2000 [07:44<16:09,  1.48it/s, Loss=0.0993525, Gaussian number=182686, print grad=0.01299477368593216, Depth Loss=0.0000000] 
Training progress:  28%|██▊       | 570/2000 [07:44<13:47,  1.73it/s, Loss=0.0993525, Gaussian number=182686, print grad=0.01299477368593216, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 570/2000 [07:47<13:47,  1.73it/s, Loss=0.0859822, Gaussian number=182686, print grad=0.013295424170792103, Depth Loss=0.0000000]
Training progress:  29%|██▉       | 580/2000 [07:47<12:07,  1.95it/s, Loss=0.0859822, Gaussian number=182686, print grad=0.013295424170792103, Depth Loss=0.0000000]
Training progress:  29%|██▉       | 580/2000 [07:51<12:07,  1.95it/s, Loss=0.0974257, Gaussian number=182686, print grad=0.013612105511128902, Depth Loss=0.0000000]
Training progress:  30%|██▉       | 590/2000 [07:51<10:57,  2.15it/s, Loss=0.0974257, Gaussian number=182686, print grad=0.013612105511128902, Depth Loss=0.0000000]
Training progress:  30%|██▉       | 590/2000 [07:55<10:57,  2.15it/s, Loss=0.0996848, Gaussian number=182686, print grad=0.013904578052461147, Depth Loss=0.0000000]
Training progress:  30%|███       | 600/2000 [07:55<10:07,  2.30it/s, Loss=0.0996848, Gaussian number=182686, print grad=0.013904578052461147, Depth Loss=0.0000000]
Training progress:  30%|███       | 600/2000 [07:59<10:07,  2.30it/s, Loss=0.0873372, Gaussian number=184669, print grad=0.0002997391566168517, Depth Loss=0.0000000]
Training progress:  30%|███       | 610/2000 [07:59<09:53,  2.34it/s, Loss=0.0873372, Gaussian number=184669, print grad=0.0002997391566168517, Depth Loss=0.0000000]
Training progress:  30%|███       | 610/2000 [08:02<09:53,  2.34it/s, Loss=0.1121469, Gaussian number=184669, print grad=0.000647944223601371, Depth Loss=0.0000000] 
Training progress:  31%|███       | 620/2000 [08:02<09:20,  2.46it/s, Loss=0.1121469, Gaussian number=184669, print grad=0.000647944223601371, Depth Loss=0.0000000]
Training progress:  31%|███       | 620/2000 [08:06<09:20,  2.46it/s, Loss=0.0818800, Gaussian number=184669, print grad=0.0009298642980866134, Depth Loss=0.0000000]
Training progress:  32%|███▏      | 630/2000 [08:06<08:55,  2.56it/s, Loss=0.0818800, Gaussian number=184669, print grad=0.0009298642980866134, Depth Loss=0.0000000]
Training progress:  32%|███▏      | 630/2000 [08:09<08:55,  2.56it/s, Loss=0.0877253, Gaussian number=184669, print grad=0.0013061939971521497, Depth Loss=0.0000000]
Training progress:  32%|███▏      | 640/2000 [08:09<08:37,  2.63it/s, Loss=0.0877253, Gaussian number=184669, print grad=0.0013061939971521497, Depth Loss=0.0000000]
Training progress:  32%|███▏      | 640/2000 [08:13<08:37,  2.63it/s, Loss=0.0991691, Gaussian number=184669, print grad=0.0015797694213688374, Depth Loss=0.0000000]
Training progress:  32%|███▎      | 650/2000 [08:13<08:23,  2.68it/s, Loss=0.0991691, Gaussian number=184669, print grad=0.0015797694213688374, Depth Loss=0.0000000]
Training progress:  32%|███▎      | 650/2000 [08:16<08:23,  2.68it/s, Loss=0.1031532, Gaussian number=184669, print grad=0.0019213632913306355, Depth Loss=0.0000000]
Training progress:  33%|███▎      | 660/2000 [08:16<08:12,  2.72it/s, Loss=0.1031532, Gaussian number=184669, print grad=0.0019213632913306355, Depth Loss=0.0000000]
Training progress:  33%|███▎      | 660/2000 [08:20<08:12,  2.72it/s, Loss=0.0887704, Gaussian number=184669, print grad=0.0022320381831377745, Depth Loss=0.0000000]
Training progress:  34%|███▎      | 670/2000 [08:20<08:04,  2.75it/s, Loss=0.0887704, Gaussian number=184669, print grad=0.0022320381831377745, Depth Loss=0.0000000]
Training progress:  34%|███▎      | 670/2000 [08:24<08:04,  2.75it/s, Loss=0.0845042, Gaussian number=184669, print grad=0.0025878013111650944, Depth Loss=0.0000000]
Training progress:  34%|███▍      | 680/2000 [08:24<07:57,  2.76it/s, Loss=0.0845042, Gaussian number=184669, print grad=0.0025878013111650944, Depth Loss=0.0000000]
Training progress:  34%|███▍      | 680/2000 [08:27<07:57,  2.76it/s, Loss=0.0989463, Gaussian number=184669, print grad=0.0028955067973583937, Depth Loss=0.0000000]
Training progress:  34%|███▍      | 690/2000 [08:27<07:51,  2.78it/s, Loss=0.0989463, Gaussian number=184669, print grad=0.0028955067973583937, Depth Loss=0.0000000]
Training progress:  34%|███▍      | 690/2000 [08:31<07:51,  2.78it/s, Loss=0.0997724, Gaussian number=184669, print grad=0.003192203352227807, Depth Loss=0.0000000] 
Training progress:  35%|███▌      | 700/2000 [08:31<07:45,  2.79it/s, Loss=0.0997724, Gaussian number=184669, print grad=0.003192203352227807, Depth Loss=0.0000000]
Training progress:  35%|███▌      | 700/2000 [08:34<07:45,  2.79it/s, Loss=0.0894032, Gaussian number=191858, print grad=0.00028689534519799054, Depth Loss=0.0000000]
Training progress:  36%|███▌      | 710/2000 [08:34<07:40,  2.80it/s, Loss=0.0894032, Gaussian number=191858, print grad=0.00028689534519799054, Depth Loss=0.0000000]
Training progress:  36%|███▌      | 710/2000 [08:38<07:40,  2.80it/s, Loss=0.0817068, Gaussian number=191858, print grad=0.0006282432586885989, Depth Loss=0.0000000] 
Training progress:  36%|███▌      | 720/2000 [08:38<07:35,  2.81it/s, Loss=0.0817068, Gaussian number=191858, print grad=0.0006282432586885989, Depth Loss=0.0000000]
Training progress:  36%|███▌      | 720/2000 [08:41<07:35,  2.81it/s, Loss=0.1011008, Gaussian number=191858, print grad=0.0009274375042878091, Depth Loss=0.0000000]
Training progress:  36%|███▋      | 730/2000 [08:41<07:31,  2.81it/s, Loss=0.1011008, Gaussian number=191858, print grad=0.0009274375042878091, Depth Loss=0.0000000]
Training progress:  36%|███▋      | 730/2000 [08:45<07:31,  2.81it/s, Loss=0.1256943, Gaussian number=191858, print grad=0.0013039467157796025, Depth Loss=0.0000000]
Training progress:  37%|███▋      | 740/2000 [08:45<07:27,  2.82it/s, Loss=0.1256943, Gaussian number=191858, print grad=0.0013039467157796025, Depth Loss=0.0000000]
Training progress:  37%|███▋      | 740/2000 [08:48<07:27,  2.82it/s, Loss=0.0893560, Gaussian number=191858, print grad=0.0016510102432221174, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 750/2000 [08:48<07:23,  2.82it/s, Loss=0.0893560, Gaussian number=191858, print grad=0.0016510102432221174, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 750/2000 [08:52<07:23,  2.82it/s, Loss=0.0835372, Gaussian number=191858, print grad=0.0019750145729631186, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 760/2000 [08:52<07:19,  2.82it/s, Loss=0.0835372, Gaussian number=191858, print grad=0.0019750145729631186, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 760/2000 [08:55<07:19,  2.82it/s, Loss=0.0785150, Gaussian number=191858, print grad=0.00231136754155159, Depth Loss=0.0000000]  
Training progress:  38%|███▊      | 770/2000 [08:55<07:15,  2.82it/s, Loss=0.0785150, Gaussian number=191858, print grad=0.00231136754155159, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 770/2000 [08:59<07:15,  2.82it/s, Loss=0.1001871, Gaussian number=191858, print grad=0.002619897248223424, Depth Loss=0.0000000]
Training progress:  39%|███▉      | 780/2000 [08:59<07:12,  2.82it/s, Loss=0.1001871, Gaussian number=191858, print grad=0.002619897248223424, Depth Loss=0.0000000]
Training progress:  39%|███▉      | 780/2000 [09:03<07:12,  2.82it/s, Loss=0.1145002, Gaussian number=191858, print grad=0.002941524377092719, Depth Loss=0.0000000]
Training progress:  40%|███▉      | 790/2000 [09:03<07:08,  2.82it/s, Loss=0.1145002, Gaussian number=191858, print grad=0.002941524377092719, Depth Loss=0.0000000]
Training progress:  40%|███▉      | 790/2000 [09:06<07:08,  2.82it/s, Loss=0.0983747, Gaussian number=191858, print grad=0.0032979408279061317, Depth Loss=0.0000000]
Training progress:  40%|████      | 800/2000 [09:06<07:04,  2.82it/s, Loss=0.0983747, Gaussian number=191858, print grad=0.0032979408279061317, Depth Loss=0.0000000]
Training progress:  40%|████      | 800/2000 [09:10<07:04,  2.82it/s, Loss=0.1023358, Gaussian number=199830, print grad=0.0003225966065656394, Depth Loss=0.0000000]
Training progress:  40%|████      | 810/2000 [09:10<07:02,  2.82it/s, Loss=0.1023358, Gaussian number=199830, print grad=0.0003225966065656394, Depth Loss=0.0000000]
Training progress:  40%|████      | 810/2000 [09:13<07:02,  2.82it/s, Loss=0.0959088, Gaussian number=199830, print grad=0.0006477703573182225, Depth Loss=0.0000000]
Training progress:  41%|████      | 820/2000 [09:13<06:58,  2.82it/s, Loss=0.0959088, Gaussian number=199830, print grad=0.0006477703573182225, Depth Loss=0.0000000]
Training progress:  41%|████      | 820/2000 [09:17<06:58,  2.82it/s, Loss=0.0800920, Gaussian number=199830, print grad=0.0010566236451268196, Depth Loss=0.0000000]
Training progress:  42%|████▏     | 830/2000 [09:17<06:55,  2.82it/s, Loss=0.0800920, Gaussian number=199830, print grad=0.0010566236451268196, Depth Loss=0.0000000]
Training progress:  42%|████▏     | 830/2000 [09:20<06:55,  2.82it/s, Loss=0.0822231, Gaussian number=199830, print grad=0.001402942929416895, Depth Loss=0.0000000] 
Training progress:  42%|████▏     | 840/2000 [09:20<06:51,  2.82it/s, Loss=0.0822231, Gaussian number=199830, print grad=0.001402942929416895, Depth Loss=0.0000000]
Training progress:  42%|████▏     | 840/2000 [09:24<06:51,  2.82it/s, Loss=0.0908234, Gaussian number=199830, print grad=0.0017640519654378295, Depth Loss=0.0000000]
Training progress:  42%|████▎     | 850/2000 [09:24<06:48,  2.82it/s, Loss=0.0908234, Gaussian number=199830, print grad=0.0017640519654378295, Depth Loss=0.0000000]
Training progress:  42%|████▎     | 850/2000 [09:27<06:48,  2.82it/s, Loss=0.0852132, Gaussian number=199830, print grad=0.002093015005812049, Depth Loss=0.0000000] 
Training progress:  43%|████▎     | 860/2000 [09:27<06:44,  2.82it/s, Loss=0.0852132, Gaussian number=199830, print grad=0.002093015005812049, Depth Loss=0.0000000]
Training progress:  43%|████▎     | 860/2000 [09:31<06:44,  2.82it/s, Loss=0.1009888, Gaussian number=199830, print grad=0.0024204920046031475, Depth Loss=0.0000000]
Training progress:  44%|████▎     | 870/2000 [09:31<06:41,  2.82it/s, Loss=0.1009888, Gaussian number=199830, print grad=0.0024204920046031475, Depth Loss=0.0000000]
Training progress:  44%|████▎     | 870/2000 [09:34<06:41,  2.82it/s, Loss=0.0965312, Gaussian number=199830, print grad=0.0027382399421185255, Depth Loss=0.0000000]
Training progress:  44%|████▍     | 880/2000 [09:34<06:37,  2.82it/s, Loss=0.0965312, Gaussian number=199830, print grad=0.0027382399421185255, Depth Loss=0.0000000]
Training progress:  44%|████▍     | 880/2000 [09:38<06:37,  2.82it/s, Loss=0.0751550, Gaussian number=199830, print grad=0.003085073782131076, Depth Loss=0.0000000] 
Training progress:  44%|████▍     | 890/2000 [09:38<06:34,  2.82it/s, Loss=0.0751550, Gaussian number=199830, print grad=0.003085073782131076, Depth Loss=0.0000000]
Training progress:  44%|████▍     | 890/2000 [09:42<06:34,  2.82it/s, Loss=0.0943582, Gaussian number=199830, print grad=0.00340393278747797, Depth Loss=0.0000000] 
Training progress:  45%|████▌     | 900/2000 [09:42<06:30,  2.82it/s, Loss=0.0943582, Gaussian number=199830, print grad=0.00340393278747797, Depth Loss=0.0000000]
Training progress:  45%|████▌     | 900/2000 [09:45<06:30,  2.82it/s, Loss=0.0795920, Gaussian number=208687, print grad=0.00030410243198275566, Depth Loss=0.0000000]
Training progress:  46%|████▌     | 910/2000 [09:45<06:26,  2.82it/s, Loss=0.0795920, Gaussian number=208687, print grad=0.00030410243198275566, Depth Loss=0.0000000]
Training progress:  46%|████▌     | 910/2000 [09:49<06:26,  2.82it/s, Loss=0.0928411, Gaussian number=208687, print grad=0.0005869133747182786, Depth Loss=0.0000000] 
Training progress:  46%|████▌     | 920/2000 [09:49<06:22,  2.82it/s, Loss=0.0928411, Gaussian number=208687, print grad=0.0005869133747182786, Depth Loss=0.0000000]
Training progress:  46%|████▌     | 920/2000 [09:52<06:22,  2.82it/s, Loss=0.0988740, Gaussian number=208687, print grad=0.0009727442520670593, Depth Loss=0.0000000]
Training progress:  46%|████▋     | 930/2000 [09:52<06:18,  2.83it/s, Loss=0.0988740, Gaussian number=208687, print grad=0.0009727442520670593, Depth Loss=0.0000000]
Training progress:  46%|████▋     | 930/2000 [09:56<06:18,  2.83it/s, Loss=0.0883830, Gaussian number=208687, print grad=0.001287051010876894, Depth Loss=0.0000000] 
Training progress:  47%|████▋     | 940/2000 [09:56<06:15,  2.83it/s, Loss=0.0883830, Gaussian number=208687, print grad=0.001287051010876894, Depth Loss=0.0000000]
Training progress:  47%|████▋     | 940/2000 [09:59<06:15,  2.83it/s, Loss=0.0830091, Gaussian number=208687, print grad=0.0016390264499932528, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 950/2000 [09:59<06:11,  2.83it/s, Loss=0.0830091, Gaussian number=208687, print grad=0.0016390264499932528, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 950/2000 [10:03<06:11,  2.83it/s, Loss=0.0853240, Gaussian number=208687, print grad=0.0019600975792855024, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 960/2000 [10:03<06:07,  2.83it/s, Loss=0.0853240, Gaussian number=208687, print grad=0.0019600975792855024, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 960/2000 [10:06<06:07,  2.83it/s, Loss=0.1058504, Gaussian number=208687, print grad=0.0023098986130207777, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 970/2000 [10:06<06:04,  2.83it/s, Loss=0.1058504, Gaussian number=208687, print grad=0.0023098986130207777, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 970/2000 [10:10<06:04,  2.83it/s, Loss=0.0725010, Gaussian number=208687, print grad=0.002637138357385993, Depth Loss=0.0000000] 
Training progress:  49%|████▉     | 980/2000 [10:10<06:00,  2.83it/s, Loss=0.0725010, Gaussian number=208687, print grad=0.002637138357385993, Depth Loss=0.0000000]
Training progress:  49%|████▉     | 980/2000 [10:13<06:00,  2.83it/s, Loss=0.0736803, Gaussian number=208687, print grad=0.0029237777926027775, Depth Loss=0.0000000]
Training progress:  50%|████▉     | 990/2000 [10:13<05:57,  2.83it/s, Loss=0.0736803, Gaussian number=208687, print grad=0.0029237777926027775, Depth Loss=0.0000000]
Training progress:  50%|████▉     | 990/2000 [10:17<05:57,  2.83it/s, Loss=0.0946280, Gaussian number=208687, print grad=0.003197884652763605, Depth Loss=0.0000000] 
Training progress:  50%|█████     | 1000/2000 [10:17<05:53,  2.83it/s, Loss=0.0946280, Gaussian number=208687, print grad=0.003197884652763605, Depth Loss=0.0000000]
Training progress:  50%|█████     | 1000/2000 [11:23<05:53,  2.83it/s, Loss=0.0904677, Gaussian number=217282, print grad=0.0002806902921292931, Depth Loss=0.0000000]
Training progress:  50%|█████     | 1010/2000 [11:23<36:54,  2.24s/it, Loss=0.0904677, Gaussian number=217282, print grad=0.0002806902921292931, Depth Loss=0.0000000]
Training progress:  50%|█████     | 1010/2000 [11:27<36:54,  2.24s/it, Loss=0.1109179, Gaussian number=217282, print grad=0.0006659060600213706, Depth Loss=0.0000000]
Training progress:  51%|█████     | 1020/2000 [11:27<27:17,  1.67s/it, Loss=0.1109179, Gaussian number=217282, print grad=0.0006659060600213706, Depth Loss=0.0000000]
Training progress:  51%|█████     | 1020/2000 [11:30<27:17,  1.67s/it, Loss=0.0931029, Gaussian number=217282, print grad=0.0010049480479210615, Depth Loss=0.0000000]
Training progress:  52%|█████▏    | 1030/2000 [11:30<20:37,  1.28s/it, Loss=0.0931029, Gaussian number=217282, print grad=0.0010049480479210615, Depth Loss=0.0000000]
Training progress:  52%|█████▏    | 1030/2000 [11:34<20:37,  1.28s/it, Loss=0.0942575, Gaussian number=217282, print grad=0.0013768206117674708, Depth Loss=0.0000000]
Training progress:  52%|█████▏    | 1040/2000 [11:34<15:57,  1.00it/s, Loss=0.0942575, Gaussian number=217282, print grad=0.0013768206117674708, Depth Loss=0.0000000]
Training progress:  52%|█████▏    | 1040/2000 [11:37<15:57,  1.00it/s, Loss=0.0857308, Gaussian number=217282, print grad=0.0016627220902591944, Depth Loss=0.0000000]
Training progress:  52%|█████▎    | 1050/2000 [11:37<12:43,  1.24it/s, Loss=0.0857308, Gaussian number=217282, print grad=0.0016627220902591944, Depth Loss=0.0000000]
Training progress:  52%|█████▎    | 1050/2000 [11:41<12:43,  1.24it/s, Loss=0.0842375, Gaussian number=217282, print grad=0.0019804462790489197, Depth Loss=0.0000000]
Training progress:  53%|█████▎    | 1060/2000 [11:41<10:27,  1.50it/s, Loss=0.0842375, Gaussian number=217282, print grad=0.0019804462790489197, Depth Loss=0.0000000]
Training progress:  53%|█████▎    | 1060/2000 [11:44<10:27,  1.50it/s, Loss=0.0700046, Gaussian number=217282, print grad=0.0023437850177288055, Depth Loss=0.0000000]
Training progress:  54%|█████▎    | 1070/2000 [11:44<08:52,  1.75it/s, Loss=0.0700046, Gaussian number=217282, print grad=0.0023437850177288055, Depth Loss=0.0000000]
Training progress:  54%|█████▎    | 1070/2000 [11:48<08:52,  1.75it/s, Loss=0.0727250, Gaussian number=217282, print grad=0.002643219195306301, Depth Loss=0.0000000] 
Training progress:  54%|█████▍    | 1080/2000 [11:48<07:46,  1.97it/s, Loss=0.0727250, Gaussian number=217282, print grad=0.002643219195306301, Depth Loss=0.0000000]
Training progress:  54%|█████▍    | 1080/2000 [11:51<07:46,  1.97it/s, Loss=0.0914682, Gaussian number=217282, print grad=0.0029799400363117456, Depth Loss=0.0000000]
Training progress:  55%|█████▍    | 1090/2000 [11:51<06:58,  2.17it/s, Loss=0.0914682, Gaussian number=217282, print grad=0.0029799400363117456, Depth Loss=0.0000000]
Training progress:  55%|█████▍    | 1090/2000 [11:55<06:58,  2.17it/s, Loss=0.0899073, Gaussian number=217282, print grad=0.0033064456656575203, Depth Loss=0.0000000]
Training progress:  55%|█████▌    | 1100/2000 [11:55<06:24,  2.34it/s, Loss=0.0899073, Gaussian number=217282, print grad=0.0033064456656575203, Depth Loss=0.0000000]
Training progress:  55%|█████▌    | 1100/2000 [11:58<06:24,  2.34it/s, Loss=0.0995889, Gaussian number=226640, print grad=0.00028151695732958615, Depth Loss=0.0000000]
Training progress:  56%|█████▌    | 1110/2000 [11:58<06:00,  2.47it/s, Loss=0.0995889, Gaussian number=226640, print grad=0.00028151695732958615, Depth Loss=0.0000000]
Training progress:  56%|█████▌    | 1110/2000 [12:02<06:00,  2.47it/s, Loss=0.0948175, Gaussian number=226640, print grad=0.0006270139710977674, Depth Loss=0.0000000] 
Training progress:  56%|█████▌    | 1120/2000 [12:02<05:42,  2.57it/s, Loss=0.0948175, Gaussian number=226640, print grad=0.0006270139710977674, Depth Loss=0.0000000]
Training progress:  56%|█████▌    | 1120/2000 [12:05<05:42,  2.57it/s, Loss=0.0752189, Gaussian number=226640, print grad=0.0009927708888426423, Depth Loss=0.0000000]
Training progress:  56%|█████▋    | 1130/2000 [12:05<05:29,  2.64it/s, Loss=0.0752189, Gaussian number=226640, print grad=0.0009927708888426423, Depth Loss=0.0000000]
Training progress:  56%|█████▋    | 1130/2000 [12:09<05:29,  2.64it/s, Loss=0.0900867, Gaussian number=226640, print grad=0.0013343840837478638, Depth Loss=0.0000000]
Training progress:  57%|█████▋    | 1140/2000 [12:09<05:19,  2.70it/s, Loss=0.0900867, Gaussian number=226640, print grad=0.0013343840837478638, Depth Loss=0.0000000]
Training progress:  57%|█████▋    | 1140/2000 [12:13<05:19,  2.70it/s, Loss=0.0668351, Gaussian number=226640, print grad=0.0016865527722984552, Depth Loss=0.0000000]
Training progress:  57%|█████▊    | 1150/2000 [12:13<05:11,  2.73it/s, Loss=0.0668351, Gaussian number=226640, print grad=0.0016865527722984552, Depth Loss=0.0000000]
Training progress:  57%|█████▊    | 1150/2000 [12:16<05:11,  2.73it/s, Loss=0.0707330, Gaussian number=226640, print grad=0.001969141885638237, Depth Loss=0.0000000] 
Training progress:  58%|█████▊    | 1160/2000 [12:16<05:04,  2.76it/s, Loss=0.0707330, Gaussian number=226640, print grad=0.001969141885638237, Depth Loss=0.0000000]
Training progress:  58%|█████▊    | 1160/2000 [12:20<05:04,  2.76it/s, Loss=0.0855711, Gaussian number=226640, print grad=0.0022951080463826656, Depth Loss=0.0000000]
Training progress:  58%|█████▊    | 1170/2000 [12:20<04:58,  2.78it/s, Loss=0.0855711, Gaussian number=226640, print grad=0.0022951080463826656, Depth Loss=0.0000000]
Training progress:  58%|█████▊    | 1170/2000 [12:23<04:58,  2.78it/s, Loss=0.0864798, Gaussian number=226640, print grad=0.0026314635761082172, Depth Loss=0.0000000]
Training progress:  59%|█████▉    | 1180/2000 [12:23<04:53,  2.80it/s, Loss=0.0864798, Gaussian number=226640, print grad=0.0026314635761082172, Depth Loss=0.0000000]
Training progress:  59%|█████▉    | 1180/2000 [12:27<04:53,  2.80it/s, Loss=0.0859178, Gaussian number=226640, print grad=0.00297318072989583, Depth Loss=0.0000000]  
Training progress:  60%|█████▉    | 1190/2000 [12:27<04:48,  2.81it/s, Loss=0.0859178, Gaussian number=226640, print grad=0.00297318072989583, Depth Loss=0.0000000]
Training progress:  60%|█████▉    | 1190/2000 [12:30<04:48,  2.81it/s, Loss=0.0954407, Gaussian number=226640, print grad=0.0032519353553652763, Depth Loss=0.0000000]
Training progress:  60%|██████    | 1200/2000 [12:30<04:44,  2.82it/s, Loss=0.0954407, Gaussian number=226640, print grad=0.0032519353553652763, Depth Loss=0.0000000]
Training progress:  60%|██████    | 1200/2000 [12:34<04:44,  2.82it/s, Loss=0.0770112, Gaussian number=236372, print grad=0.0003125198418274522, Depth Loss=0.0000000]
Training progress:  60%|██████    | 1210/2000 [12:34<04:40,  2.82it/s, Loss=0.0770112, Gaussian number=236372, print grad=0.0003125198418274522, Depth Loss=0.0000000]
Training progress:  60%|██████    | 1210/2000 [12:37<04:40,  2.82it/s, Loss=0.0693572, Gaussian number=236372, print grad=0.0006816773093305528, Depth Loss=0.0000000]
Training progress:  61%|██████    | 1220/2000 [12:37<04:36,  2.82it/s, Loss=0.0693572, Gaussian number=236372, print grad=0.0006816773093305528, Depth Loss=0.0000000]
Training progress:  61%|██████    | 1220/2000 [12:41<04:36,  2.82it/s, Loss=0.0716837, Gaussian number=236372, print grad=0.0010037118336185813, Depth Loss=0.0000000]
Training progress:  62%|██████▏   | 1230/2000 [12:41<04:33,  2.82it/s, Loss=0.0716837, Gaussian number=236372, print grad=0.0010037118336185813, Depth Loss=0.0000000]
Training progress:  62%|██████▏   | 1230/2000 [12:44<04:33,  2.82it/s, Loss=0.0687324, Gaussian number=236372, print grad=0.0013578864745795727, Depth Loss=0.0000000]
Training progress:  62%|██████▏   | 1240/2000 [12:44<04:29,  2.82it/s, Loss=0.0687324, Gaussian number=236372, print grad=0.0013578864745795727, Depth Loss=0.0000000]
Training progress:  62%|██████▏   | 1240/2000 [12:48<04:29,  2.82it/s, Loss=0.0692675, Gaussian number=236372, print grad=0.0016466102097183466, Depth Loss=0.0000000]
Training progress:  62%|██████▎   | 1250/2000 [12:48<04:25,  2.82it/s, Loss=0.0692675, Gaussian number=236372, print grad=0.0016466102097183466, Depth Loss=0.0000000]
Training progress:  62%|██████▎   | 1250/2000 [12:51<04:25,  2.82it/s, Loss=0.0717759, Gaussian number=236372, print grad=0.001919132424518466, Depth Loss=0.0000000] 
Training progress:  63%|██████▎   | 1260/2000 [12:51<04:22,  2.82it/s, Loss=0.0717759, Gaussian number=236372, print grad=0.001919132424518466, Depth Loss=0.0000000]
Training progress:  63%|██████▎   | 1260/2000 [12:55<04:22,  2.82it/s, Loss=0.0848861, Gaussian number=236372, print grad=0.0022489989642053843, Depth Loss=0.0000000]
Training progress:  64%|██████▎   | 1270/2000 [12:55<04:18,  2.82it/s, Loss=0.0848861, Gaussian number=236372, print grad=0.0022489989642053843, Depth Loss=0.0000000]
Training progress:  64%|██████▎   | 1270/2000 [12:59<04:18,  2.82it/s, Loss=0.0868073, Gaussian number=236372, print grad=0.0025340223219245672, Depth Loss=0.0000000]
Training progress:  64%|██████▍   | 1280/2000 [12:59<04:15,  2.82it/s, Loss=0.0868073, Gaussian number=236372, print grad=0.0025340223219245672, Depth Loss=0.0000000]
Training progress:  64%|██████▍   | 1280/2000 [13:02<04:15,  2.82it/s, Loss=0.0668658, Gaussian number=236372, print grad=0.0028707371093332767, Depth Loss=0.0000000]
Training progress:  64%|██████▍   | 1290/2000 [13:02<04:11,  2.82it/s, Loss=0.0668658, Gaussian number=236372, print grad=0.0028707371093332767, Depth Loss=0.0000000]
Training progress:  64%|██████▍   | 1290/2000 [13:06<04:11,  2.82it/s, Loss=0.1017309, Gaussian number=236372, print grad=0.003167178947478533, Depth Loss=0.0000000] 
Training progress:  65%|██████▌   | 1300/2000 [13:06<04:08,  2.82it/s, Loss=0.1017309, Gaussian number=236372, print grad=0.003167178947478533, Depth Loss=0.0000000]
Training progress:  65%|██████▌   | 1300/2000 [13:09<04:08,  2.82it/s, Loss=0.0968028, Gaussian number=246572, print grad=0.0003360763657838106, Depth Loss=0.0000000]
Training progress:  66%|██████▌   | 1310/2000 [13:09<04:04,  2.82it/s, Loss=0.0968028, Gaussian number=246572, print grad=0.0003360763657838106, Depth Loss=0.0000000]
Training progress:  66%|██████▌   | 1310/2000 [13:13<04:04,  2.82it/s, Loss=0.0989127, Gaussian number=246572, print grad=0.0006552283884957433, Depth Loss=0.0000000]
Training progress:  66%|██████▌   | 1320/2000 [13:13<04:00,  2.83it/s, Loss=0.0989127, Gaussian number=246572, print grad=0.0006552283884957433, Depth Loss=0.0000000]
Training progress:  66%|██████▌   | 1320/2000 [13:16<04:00,  2.83it/s, Loss=0.0786887, Gaussian number=246572, print grad=0.0009958934970200062, Depth Loss=0.0000000]
Training progress:  66%|██████▋   | 1330/2000 [13:16<03:56,  2.83it/s, Loss=0.0786887, Gaussian number=246572, print grad=0.0009958934970200062, Depth Loss=0.0000000]
Training progress:  66%|██████▋   | 1330/2000 [13:20<03:56,  2.83it/s, Loss=0.0824035, Gaussian number=246572, print grad=0.0013231459306553006, Depth Loss=0.0000000]
Training progress:  67%|██████▋   | 1340/2000 [13:20<03:53,  2.83it/s, Loss=0.0824035, Gaussian number=246572, print grad=0.0013231459306553006, Depth Loss=0.0000000]
Training progress:  67%|██████▋   | 1340/2000 [13:23<03:53,  2.83it/s, Loss=0.1071316, Gaussian number=246572, print grad=0.0015916352858766913, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1350/2000 [13:23<03:49,  2.83it/s, Loss=0.1071316, Gaussian number=246572, print grad=0.0015916352858766913, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1350/2000 [13:27<03:49,  2.83it/s, Loss=0.0643739, Gaussian number=246572, print grad=0.0018803091952577233, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1360/2000 [13:27<03:45,  2.83it/s, Loss=0.0643739, Gaussian number=246572, print grad=0.0018803091952577233, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1360/2000 [13:30<03:45,  2.83it/s, Loss=0.1174827, Gaussian number=246572, print grad=0.002225188072770834, Depth Loss=0.0000000] 
Training progress:  68%|██████▊   | 1370/2000 [13:30<03:42,  2.83it/s, Loss=0.1174827, Gaussian number=246572, print grad=0.002225188072770834, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1370/2000 [13:34<03:42,  2.83it/s, Loss=0.0785117, Gaussian number=246572, print grad=0.002510473597794771, Depth Loss=0.0000000]
Training progress:  69%|██████▉   | 1380/2000 [13:34<03:38,  2.83it/s, Loss=0.0785117, Gaussian number=246572, print grad=0.002510473597794771, Depth Loss=0.0000000]
Training progress:  69%|██████▉   | 1380/2000 [13:37<03:38,  2.83it/s, Loss=0.0725796, Gaussian number=246572, print grad=0.002802319824695587, Depth Loss=0.0000000]
Training progress:  70%|██████▉   | 1390/2000 [13:37<03:35,  2.83it/s, Loss=0.0725796, Gaussian number=246572, print grad=0.002802319824695587, Depth Loss=0.0000000]
Training progress:  70%|██████▉   | 1390/2000 [13:41<03:35,  2.83it/s, Loss=0.0799326, Gaussian number=246572, print grad=0.003101619891822338, Depth Loss=0.0000000]
Training progress:  70%|███████   | 1400/2000 [13:41<03:31,  2.83it/s, Loss=0.0799326, Gaussian number=246572, print grad=0.003101619891822338, Depth Loss=0.0000000]
Training progress:  70%|███████   | 1400/2000 [13:44<03:31,  2.83it/s, Loss=0.0931365, Gaussian number=256642, print grad=0.0003355593653395772, Depth Loss=0.0000000]
Training progress:  70%|███████   | 1410/2000 [13:44<03:28,  2.83it/s, Loss=0.0931365, Gaussian number=256642, print grad=0.0003355593653395772, Depth Loss=0.0000000]
Training progress:  70%|███████   | 1410/2000 [13:48<03:28,  2.83it/s, Loss=0.0803639, Gaussian number=256642, print grad=0.0006620262865908444, Depth Loss=0.0000000]
Training progress:  71%|███████   | 1420/2000 [13:48<03:25,  2.83it/s, Loss=0.0803639, Gaussian number=256642, print grad=0.0006620262865908444, Depth Loss=0.0000000]
Training progress:  71%|███████   | 1420/2000 [13:52<03:25,  2.83it/s, Loss=0.0800595, Gaussian number=256642, print grad=0.00101820332929492, Depth Loss=0.0000000]  
Training progress:  72%|███████▏  | 1430/2000 [13:52<03:21,  2.82it/s, Loss=0.0800595, Gaussian number=256642, print grad=0.00101820332929492, Depth Loss=0.0000000]
Training progress:  72%|███████▏  | 1430/2000 [13:55<03:21,  2.82it/s, Loss=0.0765930, Gaussian number=256642, print grad=0.0013002135092392564, Depth Loss=0.0000000]
Training progress:  72%|███████▏  | 1440/2000 [13:55<03:18,  2.82it/s, Loss=0.0765930, Gaussian number=256642, print grad=0.0013002135092392564, Depth Loss=0.0000000]
Training progress:  72%|███████▏  | 1440/2000 [13:59<03:18,  2.82it/s, Loss=0.0663109, Gaussian number=256642, print grad=0.0015889330534264445, Depth Loss=0.0000000]
Training progress:  72%|███████▎  | 1450/2000 [13:59<03:14,  2.82it/s, Loss=0.0663109, Gaussian number=256642, print grad=0.0015889330534264445, Depth Loss=0.0000000]
Training progress:  72%|███████▎  | 1450/2000 [14:02<03:14,  2.82it/s, Loss=0.0603027, Gaussian number=256642, print grad=0.0018889517523348331, Depth Loss=0.0000000]
Training progress:  73%|███████▎  | 1460/2000 [14:02<03:11,  2.82it/s, Loss=0.0603027, Gaussian number=256642, print grad=0.0018889517523348331, Depth Loss=0.0000000]
Training progress:  73%|███████▎  | 1460/2000 [14:06<03:11,  2.82it/s, Loss=0.0833663, Gaussian number=256642, print grad=0.002200793009251356, Depth Loss=0.0000000] 
Training progress:  74%|███████▎  | 1470/2000 [14:06<03:07,  2.82it/s, Loss=0.0833663, Gaussian number=256642, print grad=0.002200793009251356, Depth Loss=0.0000000]
Training progress:  74%|███████▎  | 1470/2000 [14:09<03:07,  2.82it/s, Loss=0.0843072, Gaussian number=256642, print grad=0.002525465330109, Depth Loss=0.0000000]   
Training progress:  74%|███████▍  | 1480/2000 [14:09<03:04,  2.82it/s, Loss=0.0843072, Gaussian number=256642, print grad=0.002525465330109, Depth Loss=0.0000000]
Training progress:  74%|███████▍  | 1480/2000 [14:13<03:04,  2.82it/s, Loss=0.0870574, Gaussian number=256642, print grad=0.0028369382489472628, Depth Loss=0.0000000]
Training progress:  74%|███████▍  | 1490/2000 [14:13<03:00,  2.82it/s, Loss=0.0870574, Gaussian number=256642, print grad=0.0028369382489472628, Depth Loss=0.0000000]
Training progress:  74%|███████▍  | 1490/2000 [14:16<03:00,  2.82it/s, Loss=0.0836266, Gaussian number=256642, print grad=0.003151063807308674, Depth Loss=0.0000000] 
Training progress:  75%|███████▌  | 1500/2000 [14:16<02:57,  2.82it/s, Loss=0.0836266, Gaussian number=256642, print grad=0.003151063807308674, Depth Loss=0.0000000]
Training progress:  75%|███████▌  | 1500/2000 [15:22<02:57,  2.82it/s, Loss=0.0972943, Gaussian number=266814, print grad=0.00029523303965106606, Depth Loss=0.0000000]
Training progress:  76%|███████▌  | 1510/2000 [15:22<18:10,  2.22s/it, Loss=0.0972943, Gaussian number=266814, print grad=0.00029523303965106606, Depth Loss=0.0000000]
Training progress:  76%|███████▌  | 1510/2000 [15:26<18:10,  2.22s/it, Loss=0.0883368, Gaussian number=266814, print grad=0.0005885875434614718, Depth Loss=0.0000000] 
Training progress:  76%|███████▌  | 1520/2000 [15:26<13:18,  1.66s/it, Loss=0.0883368, Gaussian number=266814, print grad=0.0005885875434614718, Depth Loss=0.0000000]
Training progress:  76%|███████▌  | 1520/2000 [15:29<13:18,  1.66s/it, Loss=0.0523697, Gaussian number=266814, print grad=0.0009392118081450462, Depth Loss=0.0000000]
Training progress:  76%|███████▋  | 1530/2000 [15:29<09:56,  1.27s/it, Loss=0.0523697, Gaussian number=266814, print grad=0.0009392118081450462, Depth Loss=0.0000000]
Training progress:  76%|███████▋  | 1530/2000 [15:33<09:56,  1.27s/it, Loss=0.0701451, Gaussian number=266814, print grad=0.0012584020150825381, Depth Loss=0.0000000]
Training progress:  77%|███████▋  | 1540/2000 [15:33<07:37,  1.01it/s, Loss=0.0701451, Gaussian number=266814, print grad=0.0012584020150825381, Depth Loss=0.0000000]
Training progress:  77%|███████▋  | 1540/2000 [15:36<07:37,  1.01it/s, Loss=0.0798913, Gaussian number=266814, print grad=0.0015802591806277633, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1550/2000 [15:36<06:00,  1.25it/s, Loss=0.0798913, Gaussian number=266814, print grad=0.0015802591806277633, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1550/2000 [15:40<06:00,  1.25it/s, Loss=0.0831610, Gaussian number=266814, print grad=0.0019250598270446062, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1560/2000 [15:40<04:53,  1.50it/s, Loss=0.0831610, Gaussian number=266814, print grad=0.0019250598270446062, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1560/2000 [15:43<04:53,  1.50it/s, Loss=0.0720004, Gaussian number=266814, print grad=0.002251132857054472, Depth Loss=0.0000000] 
Training progress:  78%|███████▊  | 1570/2000 [15:43<04:06,  1.75it/s, Loss=0.0720004, Gaussian number=266814, print grad=0.002251132857054472, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1570/2000 [15:47<04:06,  1.75it/s, Loss=0.0539940, Gaussian number=266814, print grad=0.0025069816038012505, Depth Loss=0.0000000]
Training progress:  79%|███████▉  | 1580/2000 [15:47<03:32,  1.97it/s, Loss=0.0539940, Gaussian number=266814, print grad=0.0025069816038012505, Depth Loss=0.0000000]
Training progress:  79%|███████▉  | 1580/2000 [15:50<03:32,  1.97it/s, Loss=0.0765571, Gaussian number=266814, print grad=0.0027948874048888683, Depth Loss=0.0000000]
Training progress:  80%|███████▉  | 1590/2000 [15:50<03:08,  2.17it/s, Loss=0.0765571, Gaussian number=266814, print grad=0.0027948874048888683, Depth Loss=0.0000000]
Training progress:  80%|███████▉  | 1590/2000 [15:54<03:08,  2.17it/s, Loss=0.0701960, Gaussian number=266814, print grad=0.0031168153509497643, Depth Loss=0.0000000]
Training progress:  80%|████████  | 1600/2000 [15:54<02:51,  2.34it/s, Loss=0.0701960, Gaussian number=266814, print grad=0.0031168153509497643, Depth Loss=0.0000000]
Training progress:  80%|████████  | 1600/2000 [15:58<02:51,  2.34it/s, Loss=0.0840686, Gaussian number=277073, print grad=0.0003122789494227618, Depth Loss=0.0000000]
Training progress:  80%|████████  | 1610/2000 [15:58<02:38,  2.47it/s, Loss=0.0840686, Gaussian number=277073, print grad=0.0003122789494227618, Depth Loss=0.0000000]
Training progress:  80%|████████  | 1610/2000 [16:01<02:38,  2.47it/s, Loss=0.0836100, Gaussian number=277073, print grad=0.000679326883982867, Depth Loss=0.0000000] 
Training progress:  81%|████████  | 1620/2000 [16:01<02:28,  2.57it/s, Loss=0.0836100, Gaussian number=277073, print grad=0.000679326883982867, Depth Loss=0.0000000]
Training progress:  81%|████████  | 1620/2000 [16:05<02:28,  2.57it/s, Loss=0.0723688, Gaussian number=277073, print grad=0.0009884624741971493, Depth Loss=0.0000000]
Training progress:  82%|████████▏ | 1630/2000 [16:05<02:19,  2.64it/s, Loss=0.0723688, Gaussian number=277073, print grad=0.0009884624741971493, Depth Loss=0.0000000]
Training progress:  82%|████████▏ | 1630/2000 [16:08<02:19,  2.64it/s, Loss=0.0573167, Gaussian number=277073, print grad=0.0012893046950921416, Depth Loss=0.0000000]
Training progress:  82%|████████▏ | 1640/2000 [16:08<02:13,  2.70it/s, Loss=0.0573167, Gaussian number=277073, print grad=0.0012893046950921416, Depth Loss=0.0000000]
Training progress:  82%|████████▏ | 1640/2000 [16:12<02:13,  2.70it/s, Loss=0.0710070, Gaussian number=277073, print grad=0.001588646206073463, Depth Loss=0.0000000] 
Training progress:  82%|████████▎ | 1650/2000 [16:12<02:07,  2.74it/s, Loss=0.0710070, Gaussian number=277073, print grad=0.001588646206073463, Depth Loss=0.0000000]
Training progress:  82%|████████▎ | 1650/2000 [16:15<02:07,  2.74it/s, Loss=0.0693169, Gaussian number=277073, print grad=0.001866340870037675, Depth Loss=0.0000000]
Training progress:  83%|████████▎ | 1660/2000 [16:15<02:02,  2.77it/s, Loss=0.0693169, Gaussian number=277073, print grad=0.001866340870037675, Depth Loss=0.0000000]
Training progress:  83%|████████▎ | 1660/2000 [16:19<02:02,  2.77it/s, Loss=0.0661044, Gaussian number=277073, print grad=0.0021542725153267384, Depth Loss=0.0000000]
Training progress:  84%|████████▎ | 1670/2000 [16:19<01:58,  2.79it/s, Loss=0.0661044, Gaussian number=277073, print grad=0.0021542725153267384, Depth Loss=0.0000000]
Training progress:  84%|████████▎ | 1670/2000 [16:22<01:58,  2.79it/s, Loss=0.0622865, Gaussian number=277073, print grad=0.0024412961211055517, Depth Loss=0.0000000]
Training progress:  84%|████████▍ | 1680/2000 [16:22<01:53,  2.81it/s, Loss=0.0622865, Gaussian number=277073, print grad=0.0024412961211055517, Depth Loss=0.0000000]
Training progress:  84%|████████▍ | 1680/2000 [16:26<01:53,  2.81it/s, Loss=0.0709737, Gaussian number=277073, print grad=0.0027461585123091936, Depth Loss=0.0000000]
Training progress:  84%|████████▍ | 1690/2000 [16:26<01:50,  2.82it/s, Loss=0.0709737, Gaussian number=277073, print grad=0.0027461585123091936, Depth Loss=0.0000000]
Training progress:  84%|████████▍ | 1690/2000 [16:29<01:50,  2.82it/s, Loss=0.0769599, Gaussian number=277073, print grad=0.0030227582901716232, Depth Loss=0.0000000]
Training progress:  85%|████████▌ | 1700/2000 [16:29<01:46,  2.82it/s, Loss=0.0769599, Gaussian number=277073, print grad=0.0030227582901716232, Depth Loss=0.0000000]
Training progress:  85%|████████▌ | 1700/2000 [16:33<01:46,  2.82it/s, Loss=0.0827902, Gaussian number=286848, print grad=0.00032943044789135456, Depth Loss=0.0000000]
Training progress:  86%|████████▌ | 1710/2000 [16:33<01:42,  2.84it/s, Loss=0.0827902, Gaussian number=286848, print grad=0.00032943044789135456, Depth Loss=0.0000000]
Training progress:  86%|████████▌ | 1710/2000 [16:36<01:42,  2.84it/s, Loss=0.0882627, Gaussian number=286848, print grad=0.0006029905052855611, Depth Loss=0.0000000] 
Training progress:  86%|████████▌ | 1720/2000 [16:36<01:38,  2.85it/s, Loss=0.0882627, Gaussian number=286848, print grad=0.0006029905052855611, Depth Loss=0.0000000]
Training progress:  86%|████████▌ | 1720/2000 [16:40<01:38,  2.85it/s, Loss=0.0800758, Gaussian number=286848, print grad=0.0008975956006906927, Depth Loss=0.0000000]
Training progress:  86%|████████▋ | 1730/2000 [16:40<01:34,  2.85it/s, Loss=0.0800758, Gaussian number=286848, print grad=0.0008975956006906927, Depth Loss=0.0000000]
Training progress:  86%|████████▋ | 1730/2000 [16:43<01:34,  2.85it/s, Loss=0.0991708, Gaussian number=286848, print grad=0.0012156536104157567, Depth Loss=0.0000000]
Training progress:  87%|████████▋ | 1740/2000 [16:43<01:31,  2.86it/s, Loss=0.0991708, Gaussian number=286848, print grad=0.0012156536104157567, Depth Loss=0.0000000]
Training progress:  87%|████████▋ | 1740/2000 [16:47<01:31,  2.86it/s, Loss=0.0922004, Gaussian number=286848, print grad=0.0015298931393772364, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1750/2000 [16:47<01:27,  2.86it/s, Loss=0.0922004, Gaussian number=286848, print grad=0.0015298931393772364, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1750/2000 [16:50<01:27,  2.86it/s, Loss=0.0768736, Gaussian number=286848, print grad=0.0018178130267187953, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1760/2000 [16:50<01:23,  2.86it/s, Loss=0.0768736, Gaussian number=286848, print grad=0.0018178130267187953, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1760/2000 [16:54<01:23,  2.86it/s, Loss=0.0628016, Gaussian number=286848, print grad=0.002088660839945078, Depth Loss=0.0000000] 
Training progress:  88%|████████▊ | 1770/2000 [16:54<01:20,  2.86it/s, Loss=0.0628016, Gaussian number=286848, print grad=0.002088660839945078, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1770/2000 [16:57<01:20,  2.86it/s, Loss=0.0726366, Gaussian number=286848, print grad=0.002361938124522567, Depth Loss=0.0000000]
Training progress:  89%|████████▉ | 1780/2000 [16:57<01:16,  2.87it/s, Loss=0.0726366, Gaussian number=286848, print grad=0.002361938124522567, Depth Loss=0.0000000]
Training progress:  89%|████████▉ | 1780/2000 [17:01<01:16,  2.87it/s, Loss=0.0679809, Gaussian number=286848, print grad=0.0025968176778405905, Depth Loss=0.0000000]
Training progress:  90%|████████▉ | 1790/2000 [17:01<01:13,  2.87it/s, Loss=0.0679809, Gaussian number=286848, print grad=0.0025968176778405905, Depth Loss=0.0000000]
Training progress:  90%|████████▉ | 1790/2000 [17:04<01:13,  2.87it/s, Loss=0.0699026, Gaussian number=286848, print grad=0.0029014365281909704, Depth Loss=0.0000000]
Training progress:  90%|█████████ | 1800/2000 [17:04<01:09,  2.87it/s, Loss=0.0699026, Gaussian number=286848, print grad=0.0029014365281909704, Depth Loss=0.0000000]
Training progress:  90%|█████████ | 1800/2000 [17:08<01:09,  2.87it/s, Loss=0.0782819, Gaussian number=297176, print grad=0.00029041164088994265, Depth Loss=0.0000000]
Training progress:  90%|█████████ | 1810/2000 [17:08<01:06,  2.86it/s, Loss=0.0782819, Gaussian number=297176, print grad=0.00029041164088994265, Depth Loss=0.0000000]
Training progress:  90%|█████████ | 1810/2000 [17:11<01:06,  2.86it/s, Loss=0.0704836, Gaussian number=297176, print grad=0.0006274821935221553, Depth Loss=0.0000000] 
Training progress:  91%|█████████ | 1820/2000 [17:11<01:03,  2.85it/s, Loss=0.0704836, Gaussian number=297176, print grad=0.0006274821935221553, Depth Loss=0.0000000]
Training progress:  91%|█████████ | 1820/2000 [17:15<01:03,  2.85it/s, Loss=0.0598122, Gaussian number=297176, print grad=0.0008643787587061524, Depth Loss=0.0000000]
Training progress:  92%|█████████▏| 1830/2000 [17:15<00:59,  2.85it/s, Loss=0.0598122, Gaussian number=297176, print grad=0.0008643787587061524, Depth Loss=0.0000000]
Training progress:  92%|█████████▏| 1830/2000 [17:18<00:59,  2.85it/s, Loss=0.0634351, Gaussian number=297176, print grad=0.0011759103508666158, Depth Loss=0.0000000]
Training progress:  92%|█████████▏| 1840/2000 [17:18<00:56,  2.85it/s, Loss=0.0634351, Gaussian number=297176, print grad=0.0011759103508666158, Depth Loss=0.0000000]
Training progress:  92%|█████████▏| 1840/2000 [17:22<00:56,  2.85it/s, Loss=0.0683644, Gaussian number=297176, print grad=0.0014598958659917116, Depth Loss=0.0000000]
Training progress:  92%|█████████▎| 1850/2000 [17:22<00:52,  2.84it/s, Loss=0.0683644, Gaussian number=297176, print grad=0.0014598958659917116, Depth Loss=0.0000000]
Training progress:  92%|█████████▎| 1850/2000 [17:25<00:52,  2.84it/s, Loss=0.0715463, Gaussian number=297176, print grad=0.001714165206067264, Depth Loss=0.0000000] 
Training progress:  93%|█████████▎| 1860/2000 [17:25<00:49,  2.84it/s, Loss=0.0715463, Gaussian number=297176, print grad=0.001714165206067264, Depth Loss=0.0000000]
Training progress:  93%|█████████▎| 1860/2000 [17:29<00:49,  2.84it/s, Loss=0.0814931, Gaussian number=297176, print grad=0.0020402909722179174, Depth Loss=0.0000000]
Training progress:  94%|█████████▎| 1870/2000 [17:29<00:45,  2.85it/s, Loss=0.0814931, Gaussian number=297176, print grad=0.0020402909722179174, Depth Loss=0.0000000]
Training progress:  94%|█████████▎| 1870/2000 [17:32<00:45,  2.85it/s, Loss=0.0618036, Gaussian number=297176, print grad=0.0023299148306250572, Depth Loss=0.0000000]
Training progress:  94%|█████████▍| 1880/2000 [17:32<00:42,  2.85it/s, Loss=0.0618036, Gaussian number=297176, print grad=0.0023299148306250572, Depth Loss=0.0000000]
Training progress:  94%|█████████▍| 1880/2000 [17:36<00:42,  2.85it/s, Loss=0.0698573, Gaussian number=297176, print grad=0.002617592690512538, Depth Loss=0.0000000] 
Training progress:  94%|█████████▍| 1890/2000 [17:36<00:38,  2.84it/s, Loss=0.0698573, Gaussian number=297176, print grad=0.002617592690512538, Depth Loss=0.0000000]
Training progress:  94%|█████████▍| 1890/2000 [17:39<00:38,  2.84it/s, Loss=0.0831951, Gaussian number=297176, print grad=0.0029080314561724663, Depth Loss=0.0000000]
Training progress:  95%|█████████▌| 1900/2000 [17:39<00:35,  2.84it/s, Loss=0.0831951, Gaussian number=297176, print grad=0.0029080314561724663, Depth Loss=0.0000000]
Training progress:  95%|█████████▌| 1900/2000 [17:43<00:35,  2.84it/s, Loss=0.0777290, Gaussian number=308122, print grad=0.00024322989338543266, Depth Loss=0.0000000]
Training progress:  96%|█████████▌| 1910/2000 [17:43<00:31,  2.85it/s, Loss=0.0777290, Gaussian number=308122, print grad=0.00024322989338543266, Depth Loss=0.0000000]
Training progress:  96%|█████████▌| 1910/2000 [17:46<00:31,  2.85it/s, Loss=0.0708840, Gaussian number=308122, print grad=0.0005355154280550778, Depth Loss=0.0000000] 
Training progress:  96%|█████████▌| 1920/2000 [17:46<00:28,  2.85it/s, Loss=0.0708840, Gaussian number=308122, print grad=0.0005355154280550778, Depth Loss=0.0000000]
Training progress:  96%|█████████▌| 1920/2000 [17:50<00:28,  2.85it/s, Loss=0.0569531, Gaussian number=308122, print grad=0.0008346524555236101, Depth Loss=0.0000000]
Training progress:  96%|█████████▋| 1930/2000 [17:50<00:24,  2.85it/s, Loss=0.0569531, Gaussian number=308122, print grad=0.0008346524555236101, Depth Loss=0.0000000]
Training progress:  96%|█████████▋| 1930/2000 [17:53<00:24,  2.85it/s, Loss=0.0762137, Gaussian number=308122, print grad=0.0011141427094116807, Depth Loss=0.0000000]
Training progress:  97%|█████████▋| 1940/2000 [17:53<00:21,  2.85it/s, Loss=0.0762137, Gaussian number=308122, print grad=0.0011141427094116807, Depth Loss=0.0000000]
Training progress:  97%|█████████▋| 1940/2000 [17:57<00:21,  2.85it/s, Loss=0.0624392, Gaussian number=308122, print grad=0.0013861180050298572, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1950/2000 [17:57<00:17,  2.85it/s, Loss=0.0624392, Gaussian number=308122, print grad=0.0013861180050298572, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1950/2000 [18:00<00:17,  2.85it/s, Loss=0.0932620, Gaussian number=308122, print grad=0.0016463936772197485, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1960/2000 [18:00<00:14,  2.85it/s, Loss=0.0932620, Gaussian number=308122, print grad=0.0016463936772197485, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1960/2000 [18:04<00:14,  2.85it/s, Loss=0.0793748, Gaussian number=308122, print grad=0.0019184006378054619, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1970/2000 [18:04<00:10,  2.85it/s, Loss=0.0793748, Gaussian number=308122, print grad=0.0019184006378054619, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1970/2000 [18:07<00:10,  2.85it/s, Loss=0.0674725, Gaussian number=308122, print grad=0.0022090624552220106, Depth Loss=0.0000000]
Training progress:  99%|█████████▉| 1980/2000 [18:07<00:07,  2.85it/s, Loss=0.0674725, Gaussian number=308122, print grad=0.0022090624552220106, Depth Loss=0.0000000]
Training progress:  99%|█████████▉| 1980/2000 [18:11<00:07,  2.85it/s, Loss=0.0665760, Gaussian number=308122, print grad=0.0025041468907147646, Depth Loss=0.0000000]
Training progress: 100%|█████████▉| 1990/2000 [18:11<00:03,  2.85it/s, Loss=0.0665760, Gaussian number=308122, print grad=0.0025041468907147646, Depth Loss=0.0000000]
Training progress: 100%|█████████▉| 1990/2000 [18:14<00:03,  2.85it/s, Loss=0.0535479, Gaussian number=308122, print grad=0.002822035923600197, Depth Loss=0.0000000] 
Training progress: 100%|██████████| 2000/2000 [18:14<00:00,  2.85it/s, Loss=0.0535479, Gaussian number=308122, print grad=0.002822035923600197, Depth Loss=0.0000000]
Training progress: 100%|██████████| 2000/2000 [18:14<00:00,  1.83it/s, Loss=0.0535479, Gaussian number=308122, print grad=0.002822035923600197, Depth Loss=0.0000000]
Iteration 100 [02/12 23:15:30]

[ITER 100] Evaluating test: WD 0.131919, PSNR 12.8696,lpips 0.586418,ssim 0.453444 [02/12 23:16:26]

[ITER 100] Evaluating train: WD 0.134607, PSNR 13.2670,lpips 0.589654,ssim 0.472939 [02/12 23:16:34]
Gaussian number:182686,print gradients:1.5943669495754875e-05 [02/12 23:16:34]
Iteration 200 [02/12 23:17:10]

[ITER 200] Evaluating test: WD 0.118836, PSNR 14.1802,lpips 0.536027,ssim 0.488086 [02/12 23:18:05]

[ITER 200] Evaluating train: WD 0.119179, PSNR 14.6043,lpips 0.532213,ssim 0.505808 [02/12 23:18:13]
Gaussian number:182686,print gradients:2.1410733097582124e-05 [02/12 23:18:13]
Iteration 300 [02/12 23:18:48]

[ITER 300] Evaluating test: WD 0.109698, PSNR 14.9725,lpips 0.501239,ssim 0.510911 [02/12 23:19:44]

[ITER 300] Evaluating train: WD 0.109425, PSNR 15.5235,lpips 0.489722,ssim 0.529016 [02/12 23:19:52]
Gaussian number:182686,print gradients:2.5280316549469717e-05 [02/12 23:19:52]
Iteration 400 [02/12 23:20:27]
Iteration 500 [02/12 23:21:03]

[ITER 500] Evaluating test: WD 0.099118, PSNR 15.9516,lpips 0.461903,ssim 0.538164 [02/12 23:21:59]

[ITER 500] Evaluating train: WD 0.103976, PSNR 16.1961,lpips 0.461303,ssim 0.548645 [02/12 23:22:06]
Gaussian number:182686,print gradients:3.086755896219984e-05 [02/12 23:22:06]
Iteration 600 [02/12 23:22:42]
Iteration 700 [02/12 23:23:18]
Iteration 800 [02/12 23:23:53]
Iteration 900 [02/12 23:24:29]
Iteration 1000 [02/12 23:25:04]

[ITER 1000] Evaluating test: WD 0.086947, PSNR 16.9452,lpips 0.408999,ssim 0.570125 [02/12 23:26:00]

[ITER 1000] Evaluating train: WD 0.093457, PSNR 17.2358,lpips 0.414971,ssim 0.573230 [02/12 23:26:07]
Gaussian number:208687,print gradients:4.919680213788524e-05 [02/12 23:26:07]
Iteration 1100 [02/12 23:26:42]
Iteration 1200 [02/12 23:27:17]
Iteration 1300 [02/12 23:27:53]
Iteration 1400 [02/12 23:28:28]
Iteration 1500 [02/12 23:29:03]

[ITER 1500] Evaluating test: WD 0.077889, PSNR 17.4251,lpips 0.373304,ssim 0.590224 [02/12 23:29:59]

[ITER 1500] Evaluating train: WD 0.082893, PSNR 17.7696,lpips 0.375338,ssim 0.591851 [02/12 23:30:06]
Gaussian number:256642,print gradients:4.9277343350695446e-05 [02/12 23:30:06]
Iteration 1600 [02/12 23:30:41]
Iteration 1700 [02/12 23:31:16]
Iteration 1800 [02/12 23:31:51]
Iteration 1900 [02/12 23:32:26]
Iteration 2000 [02/12 23:33:01]

[ITER 2000] Evaluating test: WD 0.072086, PSNR 17.8349,lpips 0.350355,ssim 0.603932 [02/12 23:33:57]

[ITER 2000] Evaluating train: WD 0.079998, PSNR 18.3191,lpips 0.358628,ssim 0.604029 [02/12 23:34:04]
Gaussian number:308122,print gradients:nan [02/12 23:34:05]

[ITER 2000] Saving Gaussians [02/12 23:34:05]

Training complete. [02/12 23:34:07]
