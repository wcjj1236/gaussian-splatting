Optimizing /home/cw4287/gaussian-model/train1
Output folder: /home/cw4287/gaussian-model/train1 [14/11 19:32:13]
Tensorboard not available: not logging progress [14/11 19:32:13]
------------LLFF HOLD------------- [14/11 19:32:15]

Reading camera 1/301
Reading camera 2/301
Reading camera 3/301
Reading camera 4/301
Reading camera 5/301
Reading camera 6/301
Reading camera 7/301
Reading camera 8/301
Reading camera 9/301
Reading camera 10/301
Reading camera 11/301
Reading camera 12/301
Reading camera 13/301
Reading camera 14/301
Reading camera 15/301
Reading camera 16/301
Reading camera 17/301
Reading camera 18/301
Reading camera 19/301
Reading camera 20/301
Reading camera 21/301
Reading camera 22/301
Reading camera 23/301
Reading camera 24/301
Reading camera 25/301
Reading camera 26/301
Reading camera 27/301
Reading camera 28/301
Reading camera 29/301
Reading camera 30/301
Reading camera 31/301
Reading camera 32/301
Reading camera 33/301
Reading camera 34/301
Reading camera 35/301
Reading camera 36/301
Reading camera 37/301
Reading camera 38/301
Reading camera 39/301
Reading camera 40/301
Reading camera 41/301
Reading camera 42/301
Reading camera 43/301
Reading camera 44/301
Reading camera 45/301
Reading camera 46/301
Reading camera 47/301
Reading camera 48/301
Reading camera 49/301
Reading camera 50/301
Reading camera 51/301
Reading camera 52/301
Reading camera 53/301
Reading camera 54/301
Reading camera 55/301
Reading camera 56/301
Reading camera 57/301
Reading camera 58/301
Reading camera 59/301
Reading camera 60/301
Reading camera 61/301
Reading camera 62/301
Reading camera 63/301
Reading camera 64/301
Reading camera 65/301
Reading camera 66/301
Reading camera 67/301
Reading camera 68/301
Reading camera 69/301
Reading camera 70/301
Reading camera 71/301
Reading camera 72/301
Reading camera 73/301
Reading camera 74/301
Reading camera 75/301
Reading camera 76/301
Reading camera 77/301
Reading camera 78/301
Reading camera 79/301
Reading camera 80/301
Reading camera 81/301
Reading camera 82/301
Reading camera 83/301
Reading camera 84/301
Reading camera 85/301
Reading camera 86/301
Reading camera 87/301
Reading camera 88/301
Reading camera 89/301
Reading camera 90/301
Reading camera 91/301
Reading camera 92/301
Reading camera 93/301
Reading camera 94/301
Reading camera 95/301
Reading camera 96/301
Reading camera 97/301
Reading camera 98/301
Reading camera 99/301
Reading camera 100/301
Reading camera 101/301
Reading camera 102/301
Reading camera 103/301
Reading camera 104/301
Reading camera 105/301
Reading camera 106/301
Reading camera 107/301
Reading camera 108/301
Reading camera 109/301
Reading camera 110/301
Reading camera 111/301
Reading camera 112/301
Reading camera 113/301
Reading camera 114/301
Reading camera 115/301
Reading camera 116/301
Reading camera 117/301
Reading camera 118/301
Reading camera 119/301
Reading camera 120/301
Reading camera 121/301
Reading camera 122/301
Reading camera 123/301
Reading camera 124/301
Reading camera 125/301
Reading camera 126/301
Reading camera 127/301
Reading camera 128/301
Reading camera 129/301
Reading camera 130/301
Reading camera 131/301
Reading camera 132/301
Reading camera 133/301
Reading camera 134/301
Reading camera 135/301
Reading camera 136/301
Reading camera 137/301
Reading camera 138/301
Reading camera 139/301
Reading camera 140/301
Reading camera 141/301
Reading camera 142/301
Reading camera 143/301
Reading camera 144/301
Reading camera 145/301
Reading camera 146/301
Reading camera 147/301
Reading camera 148/301
Reading camera 149/301
Reading camera 150/301
Reading camera 151/301
Reading camera 152/301
Reading camera 153/301
Reading camera 154/301
Reading camera 155/301
Reading camera 156/301
Reading camera 157/301
Reading camera 158/301
Reading camera 159/301
Reading camera 160/301
Reading camera 161/301
Reading camera 162/301
Reading camera 163/301
Reading camera 164/301
Reading camera 165/301
Reading camera 166/301
Reading camera 167/301
Reading camera 168/301
Reading camera 169/301
Reading camera 170/301
Reading camera 171/301
Reading camera 172/301
Reading camera 173/301
Reading camera 174/301
Reading camera 175/301
Reading camera 176/301
Reading camera 177/301
Reading camera 178/301
Reading camera 179/301
Reading camera 180/301
Reading camera 181/301
Reading camera 182/301
Reading camera 183/301
Reading camera 184/301
Reading camera 185/301
Reading camera 186/301
Reading camera 187/301
Reading camera 188/301
Reading camera 189/301
Reading camera 190/301
Reading camera 191/301
Reading camera 192/301
Reading camera 193/301
Reading camera 194/301
Reading camera 195/301
Reading camera 196/301
Reading camera 197/301
Reading camera 198/301
Reading camera 199/301
Reading camera 200/301
Reading camera 201/301
Reading camera 202/301
Reading camera 203/301
Reading camera 204/301
Reading camera 205/301
Reading camera 206/301
Reading camera 207/301
Reading camera 208/301
Reading camera 209/301
Reading camera 210/301
Reading camera 211/301
Reading camera 212/301
Reading camera 213/301
Reading camera 214/301
Reading camera 215/301
Reading camera 216/301
Reading camera 217/301
Reading camera 218/301
Reading camera 219/301
Reading camera 220/301
Reading camera 221/301
Reading camera 222/301
Reading camera 223/301
Reading camera 224/301
Reading camera 225/301
Reading camera 226/301
Reading camera 227/301
Reading camera 228/301
Reading camera 229/301
Reading camera 230/301
Reading camera 231/301
Reading camera 232/301
Reading camera 233/301
Reading camera 234/301
Reading camera 235/301
Reading camera 236/301
Reading camera 237/301
Reading camera 238/301
Reading camera 239/301
Reading camera 240/301
Reading camera 241/301
Reading camera 242/301
Reading camera 243/301
Reading camera 244/301
Reading camera 245/301
Reading camera 246/301
Reading camera 247/301
Reading camera 248/301
Reading camera 249/301
Reading camera 250/301
Reading camera 251/301
Reading camera 252/301
Reading camera 253/301
Reading camera 254/301
Reading camera 255/301
Reading camera 256/301
Reading camera 257/301
Reading camera 258/301
Reading camera 259/301
Reading camera 260/301
Reading camera 261/301
Reading camera 262/301
Reading camera 263/301
Reading camera 264/301
Reading camera 265/301
Reading camera 266/301
Reading camera 267/301
Reading camera 268/301
Reading camera 269/301
Reading camera 270/301
Reading camera 271/301
Reading camera 272/301
Reading camera 273/301
Reading camera 274/301
Reading camera 275/301
Reading camera 276/301
Reading camera 277/301
Reading camera 278/301
Reading camera 279/301
Reading camera 280/301
Reading camera 281/301
Reading camera 282/301
Reading camera 283/301
Reading camera 284/301
Reading camera 285/301
Reading camera 286/301
Reading camera 287/301
Reading camera 288/301
Reading camera 289/301
Reading camera 290/301
Reading camera 291/301
Reading camera 292/301
Reading camera 293/301
Reading camera 294/301
Reading camera 295/301
Reading camera 296/301
Reading camera 297/301
Reading camera 298/301
Reading camera 299/301
Reading camera 300/301
Reading camera 301/301 [14/11 19:32:15]
Loading Training Cameras [14/11 19:32:15]
Loading Test Cameras [14/11 19:32:43]
Number of points at initialisation :  182686 [14/11 19:32:48]

Training progress:   0%|          | 0/2000 [00:00<?, ?it/s]/ext3/conda/envs/3dgs/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/ext3/conda/envs/3dgs/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
/ext3/conda/envs/3dgs/lib/python3.12/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at /opt/conda/conda-bld/pytorch_1712609048481/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)
  return F.conv2d(input, weight, bias, self.stride,

Training progress:   0%|          | 0/2000 [00:05<?, ?it/s, Loss=0.2378358, Gaussian number=182686, print grad=0.00011358172923792154, Depth Loss=0.0000000]
Training progress:   0%|          | 10/2000 [00:05<19:45,  1.68it/s, Loss=0.2378358, Gaussian number=182686, print grad=0.00011358172923792154, Depth Loss=0.0000000]
Training progress:   0%|          | 10/2000 [00:08<19:45,  1.68it/s, Loss=0.2231459, Gaussian number=182686, print grad=0.00029385884408839047, Depth Loss=0.0000000]
Training progress:   1%|          | 20/2000 [00:08<12:22,  2.67it/s, Loss=0.2231459, Gaussian number=182686, print grad=0.00029385884408839047, Depth Loss=0.0000000]
Training progress:   1%|          | 20/2000 [00:10<12:22,  2.67it/s, Loss=0.2217218, Gaussian number=182686, print grad=0.0004623789864126593, Depth Loss=0.0000000] 
Training progress:   2%|▏         | 30/2000 [00:10<10:06,  3.25it/s, Loss=0.2217218, Gaussian number=182686, print grad=0.0004623789864126593, Depth Loss=0.0000000]
Training progress:   2%|▏         | 30/2000 [00:12<10:06,  3.25it/s, Loss=0.2394869, Gaussian number=182686, print grad=0.0006385028827935457, Depth Loss=0.0000000]
Training progress:   2%|▏         | 40/2000 [00:12<08:53,  3.67it/s, Loss=0.2394869, Gaussian number=182686, print grad=0.0006385028827935457, Depth Loss=0.0000000]
Training progress:   2%|▏         | 40/2000 [00:14<08:53,  3.67it/s, Loss=0.1833401, Gaussian number=182686, print grad=0.0007810805691406131, Depth Loss=0.0000000]
Training progress:   2%|▎         | 50/2000 [00:14<08:10,  3.98it/s, Loss=0.1833401, Gaussian number=182686, print grad=0.0007810805691406131, Depth Loss=0.0000000]
Training progress:   2%|▎         | 50/2000 [00:16<08:10,  3.98it/s, Loss=0.2039178, Gaussian number=182686, print grad=0.0009884757455438375, Depth Loss=0.0000000]
Training progress:   3%|▎         | 60/2000 [00:16<07:42,  4.19it/s, Loss=0.2039178, Gaussian number=182686, print grad=0.0009884757455438375, Depth Loss=0.0000000]
Training progress:   3%|▎         | 60/2000 [00:19<07:42,  4.19it/s, Loss=0.1828673, Gaussian number=182686, print grad=0.0012497534044086933, Depth Loss=0.0000000]
Training progress:   4%|▎         | 70/2000 [00:19<07:24,  4.35it/s, Loss=0.1828673, Gaussian number=182686, print grad=0.0012497534044086933, Depth Loss=0.0000000]
Training progress:   4%|▎         | 70/2000 [00:21<07:24,  4.35it/s, Loss=0.2234870, Gaussian number=182686, print grad=0.00145534158218652, Depth Loss=0.0000000]  
Training progress:   4%|▍         | 80/2000 [00:21<07:11,  4.45it/s, Loss=0.2234870, Gaussian number=182686, print grad=0.00145534158218652, Depth Loss=0.0000000]
Training progress:   4%|▍         | 80/2000 [00:23<07:11,  4.45it/s, Loss=0.1884968, Gaussian number=182686, print grad=0.001667048898525536, Depth Loss=0.0000000]
Training progress:   4%|▍         | 90/2000 [00:23<07:02,  4.52it/s, Loss=0.1884968, Gaussian number=182686, print grad=0.001667048898525536, Depth Loss=0.0000000]
Training progress:   4%|▍         | 90/2000 [00:25<07:02,  4.52it/s, Loss=0.1845229, Gaussian number=182686, print grad=0.0019187688594684005, Depth Loss=0.0000000]
Training progress:   5%|▌         | 100/2000 [00:25<07:09,  4.42it/s, Loss=0.1845229, Gaussian number=182686, print grad=0.0019187688594684005, Depth Loss=0.0000000]
Training progress:   5%|▌         | 100/2000 [00:30<07:09,  4.42it/s, Loss=0.2133368, Gaussian number=182686, print grad=0.0021916329860687256, Depth Loss=0.0000000]
Training progress:   6%|▌         | 110/2000 [00:30<09:24,  3.35it/s, Loss=0.2133368, Gaussian number=182686, print grad=0.0021916329860687256, Depth Loss=0.0000000]
Training progress:   6%|▌         | 110/2000 [00:32<09:24,  3.35it/s, Loss=0.1783814, Gaussian number=182686, print grad=0.002449573716148734, Depth Loss=0.0000000] 
Training progress:   6%|▌         | 120/2000 [00:32<08:31,  3.68it/s, Loss=0.1783814, Gaussian number=182686, print grad=0.002449573716148734, Depth Loss=0.0000000]
Training progress:   6%|▌         | 120/2000 [00:34<08:31,  3.68it/s, Loss=0.2039848, Gaussian number=182686, print grad=0.0027738616336137056, Depth Loss=0.0000000]
Training progress:   6%|▋         | 130/2000 [00:34<07:53,  3.95it/s, Loss=0.2039848, Gaussian number=182686, print grad=0.0027738616336137056, Depth Loss=0.0000000]
Training progress:   6%|▋         | 130/2000 [00:36<07:53,  3.95it/s, Loss=0.1868406, Gaussian number=182686, print grad=0.003098498797044158, Depth Loss=0.0000000] 
Training progress:   7%|▋         | 140/2000 [00:36<07:27,  4.16it/s, Loss=0.1868406, Gaussian number=182686, print grad=0.003098498797044158, Depth Loss=0.0000000]
Training progress:   7%|▋         | 140/2000 [00:38<07:27,  4.16it/s, Loss=0.1652543, Gaussian number=182686, print grad=0.003391486592590809, Depth Loss=0.0000000]
Training progress:   8%|▊         | 150/2000 [00:38<07:08,  4.32it/s, Loss=0.1652543, Gaussian number=182686, print grad=0.003391486592590809, Depth Loss=0.0000000]
Training progress:   8%|▊         | 150/2000 [00:40<07:08,  4.32it/s, Loss=0.1739547, Gaussian number=182686, print grad=0.0037593061570078135, Depth Loss=0.0000000]
Training progress:   8%|▊         | 160/2000 [00:40<06:53,  4.45it/s, Loss=0.1739547, Gaussian number=182686, print grad=0.0037593061570078135, Depth Loss=0.0000000]
Training progress:   8%|▊         | 160/2000 [00:42<06:53,  4.45it/s, Loss=0.1726285, Gaussian number=182686, print grad=0.004050194751471281, Depth Loss=0.0000000] 
Training progress:   8%|▊         | 170/2000 [00:42<06:43,  4.53it/s, Loss=0.1726285, Gaussian number=182686, print grad=0.004050194751471281, Depth Loss=0.0000000]
Training progress:   8%|▊         | 170/2000 [00:45<06:43,  4.53it/s, Loss=0.1483686, Gaussian number=182686, print grad=0.004384081345051527, Depth Loss=0.0000000]
Training progress:   9%|▉         | 180/2000 [00:45<06:35,  4.60it/s, Loss=0.1483686, Gaussian number=182686, print grad=0.004384081345051527, Depth Loss=0.0000000]
Training progress:   9%|▉         | 180/2000 [00:47<06:35,  4.60it/s, Loss=0.1913613, Gaussian number=182686, print grad=0.004675532225519419, Depth Loss=0.0000000]
Training progress:  10%|▉         | 190/2000 [00:47<06:29,  4.65it/s, Loss=0.1913613, Gaussian number=182686, print grad=0.004675532225519419, Depth Loss=0.0000000]
Training progress:  10%|▉         | 190/2000 [00:49<06:29,  4.65it/s, Loss=0.1660588, Gaussian number=182686, print grad=0.0050337472930550575, Depth Loss=0.0000000]
Training progress:  10%|█         | 200/2000 [00:49<06:23,  4.69it/s, Loss=0.1660588, Gaussian number=182686, print grad=0.0050337472930550575, Depth Loss=0.0000000]
Training progress:  10%|█         | 200/2000 [00:53<06:23,  4.69it/s, Loss=0.1875835, Gaussian number=182686, print grad=0.0053985342383384705, Depth Loss=0.0000000]
Training progress:  10%|█         | 210/2000 [00:53<08:31,  3.50it/s, Loss=0.1875835, Gaussian number=182686, print grad=0.0053985342383384705, Depth Loss=0.0000000]
Training progress:  10%|█         | 210/2000 [00:55<08:31,  3.50it/s, Loss=0.1530146, Gaussian number=182686, print grad=0.005726915784180164, Depth Loss=0.0000000] 
Training progress:  11%|█         | 220/2000 [00:55<07:46,  3.82it/s, Loss=0.1530146, Gaussian number=182686, print grad=0.005726915784180164, Depth Loss=0.0000000]
Training progress:  11%|█         | 220/2000 [00:57<07:46,  3.82it/s, Loss=0.1713019, Gaussian number=182686, print grad=0.006071672309190035, Depth Loss=0.0000000]
Training progress:  12%|█▏        | 230/2000 [00:57<07:14,  4.08it/s, Loss=0.1713019, Gaussian number=182686, print grad=0.006071672309190035, Depth Loss=0.0000000]
Training progress:  12%|█▏        | 230/2000 [00:59<07:14,  4.08it/s, Loss=0.2101728, Gaussian number=182686, print grad=0.006394640076905489, Depth Loss=0.0000000]
Training progress:  12%|█▏        | 240/2000 [00:59<06:51,  4.27it/s, Loss=0.2101728, Gaussian number=182686, print grad=0.006394640076905489, Depth Loss=0.0000000]
Training progress:  12%|█▏        | 240/2000 [01:02<06:51,  4.27it/s, Loss=0.1621065, Gaussian number=182686, print grad=0.00675309868529439, Depth Loss=0.0000000] 
Training progress:  12%|█▎        | 250/2000 [01:02<06:37,  4.40it/s, Loss=0.1621065, Gaussian number=182686, print grad=0.00675309868529439, Depth Loss=0.0000000]
Training progress:  12%|█▎        | 250/2000 [01:04<06:37,  4.40it/s, Loss=0.1825445, Gaussian number=182686, print grad=0.007088749669492245, Depth Loss=0.0000000]
Training progress:  13%|█▎        | 260/2000 [01:04<06:25,  4.52it/s, Loss=0.1825445, Gaussian number=182686, print grad=0.007088749669492245, Depth Loss=0.0000000]
Training progress:  13%|█▎        | 260/2000 [01:06<06:25,  4.52it/s, Loss=0.1281011, Gaussian number=182686, print grad=0.007442194502800703, Depth Loss=0.0000000]
Training progress:  14%|█▎        | 270/2000 [01:06<06:16,  4.59it/s, Loss=0.1281011, Gaussian number=182686, print grad=0.007442194502800703, Depth Loss=0.0000000]
Training progress:  14%|█▎        | 270/2000 [01:08<06:16,  4.59it/s, Loss=0.1644002, Gaussian number=182686, print grad=0.00784561038017273, Depth Loss=0.0000000] 
Training progress:  14%|█▍        | 280/2000 [01:08<06:10,  4.65it/s, Loss=0.1644002, Gaussian number=182686, print grad=0.00784561038017273, Depth Loss=0.0000000]
Training progress:  14%|█▍        | 280/2000 [01:10<06:10,  4.65it/s, Loss=0.1678124, Gaussian number=182686, print grad=0.00822252407670021, Depth Loss=0.0000000]
Training progress:  14%|█▍        | 290/2000 [01:10<06:04,  4.70it/s, Loss=0.1678124, Gaussian number=182686, print grad=0.00822252407670021, Depth Loss=0.0000000]
Training progress:  14%|█▍        | 290/2000 [01:12<06:04,  4.70it/s, Loss=0.1567665, Gaussian number=182686, print grad=0.008611321449279785, Depth Loss=0.0000000]
Training progress:  15%|█▌        | 300/2000 [01:12<06:00,  4.71it/s, Loss=0.1567665, Gaussian number=182686, print grad=0.008611321449279785, Depth Loss=0.0000000]
Training progress:  15%|█▌        | 300/2000 [01:17<06:00,  4.71it/s, Loss=0.1304001, Gaussian number=182686, print grad=0.009019950404763222, Depth Loss=0.0000000]
Training progress:  16%|█▌        | 310/2000 [01:17<08:01,  3.51it/s, Loss=0.1304001, Gaussian number=182686, print grad=0.009019950404763222, Depth Loss=0.0000000]
Training progress:  16%|█▌        | 310/2000 [01:19<08:01,  3.51it/s, Loss=0.1358317, Gaussian number=182686, print grad=0.009311310946941376, Depth Loss=0.0000000]
Training progress:  16%|█▌        | 320/2000 [01:19<07:19,  3.82it/s, Loss=0.1358317, Gaussian number=182686, print grad=0.009311310946941376, Depth Loss=0.0000000]
Training progress:  16%|█▌        | 320/2000 [01:21<07:19,  3.82it/s, Loss=0.1792279, Gaussian number=182686, print grad=0.009660391137003899, Depth Loss=0.0000000]
Training progress:  16%|█▋        | 330/2000 [01:21<06:49,  4.08it/s, Loss=0.1792279, Gaussian number=182686, print grad=0.009660391137003899, Depth Loss=0.0000000]
Training progress:  16%|█▋        | 330/2000 [01:23<06:49,  4.08it/s, Loss=0.1300712, Gaussian number=182686, print grad=0.010059891268610954, Depth Loss=0.0000000]
Training progress:  17%|█▋        | 340/2000 [01:23<06:28,  4.27it/s, Loss=0.1300712, Gaussian number=182686, print grad=0.010059891268610954, Depth Loss=0.0000000]
Training progress:  17%|█▋        | 340/2000 [01:25<06:28,  4.27it/s, Loss=0.1385523, Gaussian number=182686, print grad=0.010433471761643887, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 350/2000 [01:25<06:13,  4.41it/s, Loss=0.1385523, Gaussian number=182686, print grad=0.010433471761643887, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 350/2000 [01:27<06:13,  4.41it/s, Loss=0.1318102, Gaussian number=182686, print grad=0.01087784394621849, Depth Loss=0.0000000] 
Training progress:  18%|█▊        | 360/2000 [01:27<06:01,  4.53it/s, Loss=0.1318102, Gaussian number=182686, print grad=0.01087784394621849, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 360/2000 [01:29<06:01,  4.53it/s, Loss=0.1284469, Gaussian number=182686, print grad=0.011270533315837383, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 370/2000 [01:29<05:53,  4.61it/s, Loss=0.1284469, Gaussian number=182686, print grad=0.011270533315837383, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 370/2000 [01:31<05:53,  4.61it/s, Loss=0.1732097, Gaussian number=182686, print grad=0.01160223875194788, Depth Loss=0.0000000] 
Training progress:  19%|█▉        | 380/2000 [01:31<05:48,  4.64it/s, Loss=0.1732097, Gaussian number=182686, print grad=0.01160223875194788, Depth Loss=0.0000000]
Training progress:  19%|█▉        | 380/2000 [01:33<05:48,  4.64it/s, Loss=0.1528958, Gaussian number=182686, print grad=0.01200864277780056, Depth Loss=0.0000000]
Training progress:  20%|█▉        | 390/2000 [01:33<05:41,  4.71it/s, Loss=0.1528958, Gaussian number=182686, print grad=0.01200864277780056, Depth Loss=0.0000000]
Training progress:  20%|█▉        | 390/2000 [01:35<05:41,  4.71it/s, Loss=0.1837217, Gaussian number=182686, print grad=0.012390290386974812, Depth Loss=0.0000000]
Training progress:  20%|██        | 400/2000 [01:35<05:36,  4.75it/s, Loss=0.1837217, Gaussian number=182686, print grad=0.012390290386974812, Depth Loss=0.0000000]
Training progress:  20%|██        | 400/2000 [01:40<05:36,  4.75it/s, Loss=0.1566314, Gaussian number=182686, print grad=0.012845556251704693, Depth Loss=0.0000000]
Training progress:  20%|██        | 410/2000 [01:40<07:30,  3.53it/s, Loss=0.1566314, Gaussian number=182686, print grad=0.012845556251704693, Depth Loss=0.0000000]
Training progress:  20%|██        | 410/2000 [01:42<07:30,  3.53it/s, Loss=0.1406629, Gaussian number=182686, print grad=0.013279358856379986, Depth Loss=0.0000000]
Training progress:  21%|██        | 420/2000 [01:42<06:51,  3.84it/s, Loss=0.1406629, Gaussian number=182686, print grad=0.013279358856379986, Depth Loss=0.0000000]
Training progress:  21%|██        | 420/2000 [01:44<06:51,  3.84it/s, Loss=0.1760510, Gaussian number=182686, print grad=0.013721486553549767, Depth Loss=0.0000000]
Training progress:  22%|██▏       | 430/2000 [01:44<06:23,  4.09it/s, Loss=0.1760510, Gaussian number=182686, print grad=0.013721486553549767, Depth Loss=0.0000000]
Training progress:  22%|██▏       | 430/2000 [01:46<06:23,  4.09it/s, Loss=0.1368958, Gaussian number=182686, print grad=0.014135317876935005, Depth Loss=0.0000000]
Training progress:  22%|██▏       | 440/2000 [01:46<06:03,  4.29it/s, Loss=0.1368958, Gaussian number=182686, print grad=0.014135317876935005, Depth Loss=0.0000000]
Training progress:  22%|██▏       | 440/2000 [01:48<06:03,  4.29it/s, Loss=0.1569661, Gaussian number=182686, print grad=0.014566387981176376, Depth Loss=0.0000000]
Training progress:  22%|██▎       | 450/2000 [01:48<05:46,  4.47it/s, Loss=0.1569661, Gaussian number=182686, print grad=0.014566387981176376, Depth Loss=0.0000000]
Training progress:  22%|██▎       | 450/2000 [01:50<05:46,  4.47it/s, Loss=0.1634800, Gaussian number=182686, print grad=0.01498507522046566, Depth Loss=0.0000000] 
Training progress:  23%|██▎       | 460/2000 [01:50<05:36,  4.58it/s, Loss=0.1634800, Gaussian number=182686, print grad=0.01498507522046566, Depth Loss=0.0000000]
Training progress:  23%|██▎       | 460/2000 [01:52<05:36,  4.58it/s, Loss=0.1937182, Gaussian number=182686, print grad=0.01538063958287239, Depth Loss=0.0000000]
Training progress:  24%|██▎       | 470/2000 [01:52<05:27,  4.68it/s, Loss=0.1937182, Gaussian number=182686, print grad=0.01538063958287239, Depth Loss=0.0000000]
Training progress:  24%|██▎       | 470/2000 [01:54<05:27,  4.68it/s, Loss=0.1252280, Gaussian number=182686, print grad=0.015832191333174706, Depth Loss=0.0000000]
Training progress:  24%|██▍       | 480/2000 [01:54<05:20,  4.75it/s, Loss=0.1252280, Gaussian number=182686, print grad=0.015832191333174706, Depth Loss=0.0000000]
Training progress:  24%|██▍       | 480/2000 [01:56<05:20,  4.75it/s, Loss=0.1388553, Gaussian number=182686, print grad=0.016244538128376007, Depth Loss=0.0000000]
Training progress:  24%|██▍       | 490/2000 [01:56<05:14,  4.80it/s, Loss=0.1388553, Gaussian number=182686, print grad=0.016244538128376007, Depth Loss=0.0000000]
Training progress:  24%|██▍       | 490/2000 [01:58<05:14,  4.80it/s, Loss=0.1094649, Gaussian number=182686, print grad=0.016667773947119713, Depth Loss=0.0000000]
Training progress:  25%|██▌       | 500/2000 [01:58<05:10,  4.83it/s, Loss=0.1094649, Gaussian number=182686, print grad=0.016667773947119713, Depth Loss=0.0000000]
Training progress:  25%|██▌       | 500/2000 [02:03<05:10,  4.83it/s, Loss=0.1296926, Gaussian number=182686, print grad=0.017090000212192535, Depth Loss=0.0000000]
Training progress:  26%|██▌       | 510/2000 [02:03<06:55,  3.58it/s, Loss=0.1296926, Gaussian number=182686, print grad=0.017090000212192535, Depth Loss=0.0000000]
Training progress:  26%|██▌       | 510/2000 [02:05<06:55,  3.58it/s, Loss=0.1321871, Gaussian number=182686, print grad=0.01753600873053074, Depth Loss=0.0000000] 
Training progress:  26%|██▌       | 520/2000 [02:05<06:21,  3.88it/s, Loss=0.1321871, Gaussian number=182686, print grad=0.01753600873053074, Depth Loss=0.0000000]
Training progress:  26%|██▌       | 520/2000 [02:07<06:21,  3.88it/s, Loss=0.1044986, Gaussian number=182686, print grad=0.01791941560804844, Depth Loss=0.0000000]
Training progress:  26%|██▋       | 530/2000 [02:07<05:55,  4.13it/s, Loss=0.1044986, Gaussian number=182686, print grad=0.01791941560804844, Depth Loss=0.0000000]
Training progress:  26%|██▋       | 530/2000 [02:09<05:55,  4.13it/s, Loss=0.1417679, Gaussian number=182686, print grad=0.018344998359680176, Depth Loss=0.0000000]
Training progress:  27%|██▋       | 540/2000 [02:09<05:38,  4.32it/s, Loss=0.1417679, Gaussian number=182686, print grad=0.018344998359680176, Depth Loss=0.0000000]
Training progress:  27%|██▋       | 540/2000 [02:11<05:38,  4.32it/s, Loss=0.1351563, Gaussian number=182686, print grad=0.01880183443427086, Depth Loss=0.0000000] 
Training progress:  28%|██▊       | 550/2000 [02:11<05:24,  4.47it/s, Loss=0.1351563, Gaussian number=182686, print grad=0.01880183443427086, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 550/2000 [02:13<05:24,  4.47it/s, Loss=0.1081492, Gaussian number=182686, print grad=0.019220657646656036, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 560/2000 [02:13<05:13,  4.59it/s, Loss=0.1081492, Gaussian number=182686, print grad=0.019220657646656036, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 560/2000 [02:15<05:13,  4.59it/s, Loss=0.1444152, Gaussian number=182686, print grad=0.019690904766321182, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 570/2000 [02:15<05:06,  4.67it/s, Loss=0.1444152, Gaussian number=182686, print grad=0.019690904766321182, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 570/2000 [02:17<05:06,  4.67it/s, Loss=0.1247119, Gaussian number=182686, print grad=0.020124666392803192, Depth Loss=0.0000000]
Training progress:  29%|██▉       | 580/2000 [02:17<05:00,  4.72it/s, Loss=0.1247119, Gaussian number=182686, print grad=0.020124666392803192, Depth Loss=0.0000000]
Training progress:  29%|██▉       | 580/2000 [02:19<05:00,  4.72it/s, Loss=0.1439596, Gaussian number=182686, print grad=0.02057616226375103, Depth Loss=0.0000000] 
Training progress:  30%|██▉       | 590/2000 [02:19<04:55,  4.77it/s, Loss=0.1439596, Gaussian number=182686, print grad=0.02057616226375103, Depth Loss=0.0000000]
Training progress:  30%|██▉       | 590/2000 [02:21<04:55,  4.77it/s, Loss=0.1439426, Gaussian number=182686, print grad=0.020993728190660477, Depth Loss=0.0000000]
Training progress:  30%|███       | 600/2000 [02:21<04:51,  4.80it/s, Loss=0.1439426, Gaussian number=182686, print grad=0.020993728190660477, Depth Loss=0.0000000]
Training progress:  30%|███       | 600/2000 [02:26<04:51,  4.80it/s, Loss=0.1272814, Gaussian number=187728, print grad=0.0004246774478815496, Depth Loss=0.0000000]
Training progress:  30%|███       | 610/2000 [02:26<06:34,  3.52it/s, Loss=0.1272814, Gaussian number=187728, print grad=0.0004246774478815496, Depth Loss=0.0000000]
Training progress:  30%|███       | 610/2000 [02:28<06:34,  3.52it/s, Loss=0.1724093, Gaussian number=187728, print grad=0.000928215857129544, Depth Loss=0.0000000] 
Training progress:  31%|███       | 620/2000 [02:28<05:59,  3.84it/s, Loss=0.1724093, Gaussian number=187728, print grad=0.000928215857129544, Depth Loss=0.0000000]
Training progress:  31%|███       | 620/2000 [02:30<05:59,  3.84it/s, Loss=0.1188040, Gaussian number=187728, print grad=0.0013521979562938213, Depth Loss=0.0000000]
Training progress:  32%|███▏      | 630/2000 [02:30<05:35,  4.09it/s, Loss=0.1188040, Gaussian number=187728, print grad=0.0013521979562938213, Depth Loss=0.0000000]
Training progress:  32%|███▏      | 630/2000 [02:32<05:35,  4.09it/s, Loss=0.1256857, Gaussian number=187728, print grad=0.0018681768560782075, Depth Loss=0.0000000]
Training progress:  32%|███▏      | 640/2000 [02:32<05:18,  4.28it/s, Loss=0.1256857, Gaussian number=187728, print grad=0.0018681768560782075, Depth Loss=0.0000000]
Training progress:  32%|███▏      | 640/2000 [02:34<05:18,  4.28it/s, Loss=0.1478475, Gaussian number=187728, print grad=0.0022733178921043873, Depth Loss=0.0000000]
Training progress:  32%|███▎      | 650/2000 [02:34<05:02,  4.46it/s, Loss=0.1478475, Gaussian number=187728, print grad=0.0022733178921043873, Depth Loss=0.0000000]
Training progress:  32%|███▎      | 650/2000 [02:36<05:02,  4.46it/s, Loss=0.1485812, Gaussian number=187728, print grad=0.0027563872281461954, Depth Loss=0.0000000]
Training progress:  33%|███▎      | 660/2000 [02:36<04:52,  4.58it/s, Loss=0.1485812, Gaussian number=187728, print grad=0.0027563872281461954, Depth Loss=0.0000000]
Training progress:  33%|███▎      | 660/2000 [02:38<04:52,  4.58it/s, Loss=0.1279686, Gaussian number=187728, print grad=0.0031930040568113327, Depth Loss=0.0000000]
Training progress:  34%|███▎      | 670/2000 [02:38<04:45,  4.66it/s, Loss=0.1279686, Gaussian number=187728, print grad=0.0031930040568113327, Depth Loss=0.0000000]
Training progress:  34%|███▎      | 670/2000 [02:40<04:45,  4.66it/s, Loss=0.1190512, Gaussian number=187728, print grad=0.003681441070511937, Depth Loss=0.0000000] 
Training progress:  34%|███▍      | 680/2000 [02:40<04:39,  4.73it/s, Loss=0.1190512, Gaussian number=187728, print grad=0.003681441070511937, Depth Loss=0.0000000]
Training progress:  34%|███▍      | 680/2000 [02:42<04:39,  4.73it/s, Loss=0.1413170, Gaussian number=187728, print grad=0.004116311203688383, Depth Loss=0.0000000]
Training progress:  34%|███▍      | 690/2000 [02:42<04:34,  4.76it/s, Loss=0.1413170, Gaussian number=187728, print grad=0.004116311203688383, Depth Loss=0.0000000]
Training progress:  34%|███▍      | 690/2000 [02:44<04:34,  4.76it/s, Loss=0.1414820, Gaussian number=187728, print grad=0.004550914280116558, Depth Loss=0.0000000]
Training progress:  35%|███▌      | 700/2000 [02:44<04:32,  4.78it/s, Loss=0.1414820, Gaussian number=187728, print grad=0.004550914280116558, Depth Loss=0.0000000]
Training progress:  35%|███▌      | 700/2000 [02:49<04:32,  4.78it/s, Loss=0.1362283, Gaussian number=200652, print grad=0.00042018157546408474, Depth Loss=0.0000000]
Training progress:  36%|███▌      | 710/2000 [02:49<06:03,  3.55it/s, Loss=0.1362283, Gaussian number=200652, print grad=0.00042018157546408474, Depth Loss=0.0000000]
Training progress:  36%|███▌      | 710/2000 [02:51<06:03,  3.55it/s, Loss=0.1189231, Gaussian number=200652, print grad=0.0008946540765464306, Depth Loss=0.0000000] 
Training progress:  36%|███▌      | 720/2000 [02:51<05:30,  3.88it/s, Loss=0.1189231, Gaussian number=200652, print grad=0.0008946540765464306, Depth Loss=0.0000000]
Training progress:  36%|███▌      | 720/2000 [02:53<05:30,  3.88it/s, Loss=0.1577089, Gaussian number=200652, print grad=0.0013218080857768655, Depth Loss=0.0000000]
Training progress:  36%|███▋      | 730/2000 [02:53<05:06,  4.15it/s, Loss=0.1577089, Gaussian number=200652, print grad=0.0013218080857768655, Depth Loss=0.0000000]
Training progress:  36%|███▋      | 730/2000 [02:55<05:06,  4.15it/s, Loss=0.1839707, Gaussian number=200652, print grad=0.0018369851168245077, Depth Loss=0.0000000]
Training progress:  37%|███▋      | 740/2000 [02:55<04:49,  4.35it/s, Loss=0.1839707, Gaussian number=200652, print grad=0.0018369851168245077, Depth Loss=0.0000000]
Training progress:  37%|███▋      | 740/2000 [02:57<04:49,  4.35it/s, Loss=0.1283551, Gaussian number=200652, print grad=0.002310345880687237, Depth Loss=0.0000000] 
Training progress:  38%|███▊      | 750/2000 [02:57<04:37,  4.50it/s, Loss=0.1283551, Gaussian number=200652, print grad=0.002310345880687237, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 750/2000 [02:59<04:37,  4.50it/s, Loss=0.1231994, Gaussian number=200652, print grad=0.0027540544979274273, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 760/2000 [02:59<04:28,  4.62it/s, Loss=0.1231994, Gaussian number=200652, print grad=0.0027540544979274273, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 760/2000 [03:01<04:28,  4.62it/s, Loss=0.1130493, Gaussian number=200652, print grad=0.003233780385926366, Depth Loss=0.0000000] 
Training progress:  38%|███▊      | 770/2000 [03:01<04:21,  4.71it/s, Loss=0.1130493, Gaussian number=200652, print grad=0.003233780385926366, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 770/2000 [03:03<04:21,  4.71it/s, Loss=0.1501777, Gaussian number=200652, print grad=0.0036605915520340204, Depth Loss=0.0000000]
Training progress:  39%|███▉      | 780/2000 [03:03<04:16,  4.76it/s, Loss=0.1501777, Gaussian number=200652, print grad=0.0036605915520340204, Depth Loss=0.0000000]
Training progress:  39%|███▉      | 780/2000 [03:05<04:16,  4.76it/s, Loss=0.1685439, Gaussian number=200652, print grad=0.0041022817604243755, Depth Loss=0.0000000]
Training progress:  40%|███▉      | 790/2000 [03:05<04:12,  4.79it/s, Loss=0.1685439, Gaussian number=200652, print grad=0.0041022817604243755, Depth Loss=0.0000000]
Training progress:  40%|███▉      | 790/2000 [03:07<04:12,  4.79it/s, Loss=0.1484043, Gaussian number=200652, print grad=0.004581913817673922, Depth Loss=0.0000000] 
Training progress:  40%|████      | 800/2000 [03:07<04:09,  4.81it/s, Loss=0.1484043, Gaussian number=200652, print grad=0.004581913817673922, Depth Loss=0.0000000]
Training progress:  40%|████      | 800/2000 [03:12<04:09,  4.81it/s, Loss=0.1505988, Gaussian number=214656, print grad=0.0004282458976376802, Depth Loss=0.0000000]
Training progress:  40%|████      | 810/2000 [03:12<05:36,  3.53it/s, Loss=0.1505988, Gaussian number=214656, print grad=0.0004282458976376802, Depth Loss=0.0000000]
Training progress:  40%|████      | 810/2000 [03:14<05:36,  3.53it/s, Loss=0.1435001, Gaussian number=214656, print grad=0.0008840732625685632, Depth Loss=0.0000000]
Training progress:  41%|████      | 820/2000 [03:14<05:06,  3.85it/s, Loss=0.1435001, Gaussian number=214656, print grad=0.0008840732625685632, Depth Loss=0.0000000]
Training progress:  41%|████      | 820/2000 [03:16<05:06,  3.85it/s, Loss=0.1162453, Gaussian number=214656, print grad=0.0014372195582836866, Depth Loss=0.0000000]
Training progress:  42%|████▏     | 830/2000 [03:16<04:44,  4.11it/s, Loss=0.1162453, Gaussian number=214656, print grad=0.0014372195582836866, Depth Loss=0.0000000]
Training progress:  42%|████▏     | 830/2000 [03:18<04:44,  4.11it/s, Loss=0.1246779, Gaussian number=214656, print grad=0.0019053459400311112, Depth Loss=0.0000000]
Training progress:  42%|████▏     | 840/2000 [03:18<04:29,  4.31it/s, Loss=0.1246779, Gaussian number=214656, print grad=0.0019053459400311112, Depth Loss=0.0000000]
Training progress:  42%|████▏     | 840/2000 [03:20<04:29,  4.31it/s, Loss=0.1251298, Gaussian number=214656, print grad=0.0023830689024180174, Depth Loss=0.0000000]
Training progress:  42%|████▎     | 850/2000 [03:20<04:17,  4.47it/s, Loss=0.1251298, Gaussian number=214656, print grad=0.0023830689024180174, Depth Loss=0.0000000]
Training progress:  42%|████▎     | 850/2000 [03:22<04:17,  4.47it/s, Loss=0.1240569, Gaussian number=214656, print grad=0.002818731591105461, Depth Loss=0.0000000] 
Training progress:  43%|████▎     | 860/2000 [03:22<04:08,  4.59it/s, Loss=0.1240569, Gaussian number=214656, print grad=0.002818731591105461, Depth Loss=0.0000000]
Training progress:  43%|████▎     | 860/2000 [03:24<04:08,  4.59it/s, Loss=0.1468591, Gaussian number=214656, print grad=0.0032628700137138367, Depth Loss=0.0000000]
Training progress:  44%|████▎     | 870/2000 [03:24<04:02,  4.66it/s, Loss=0.1468591, Gaussian number=214656, print grad=0.0032628700137138367, Depth Loss=0.0000000]
Training progress:  44%|████▎     | 870/2000 [03:26<04:02,  4.66it/s, Loss=0.1344384, Gaussian number=214656, print grad=0.0037024132907390594, Depth Loss=0.0000000]
Training progress:  44%|████▍     | 880/2000 [03:26<03:57,  4.71it/s, Loss=0.1344384, Gaussian number=214656, print grad=0.0037024132907390594, Depth Loss=0.0000000]
Training progress:  44%|████▍     | 880/2000 [03:28<03:57,  4.71it/s, Loss=0.1071206, Gaussian number=214656, print grad=0.004154681693762541, Depth Loss=0.0000000] 
Training progress:  44%|████▍     | 890/2000 [03:28<03:53,  4.75it/s, Loss=0.1071206, Gaussian number=214656, print grad=0.004154681693762541, Depth Loss=0.0000000]
Training progress:  44%|████▍     | 890/2000 [03:30<03:53,  4.75it/s, Loss=0.1404580, Gaussian number=214656, print grad=0.004596906714141369, Depth Loss=0.0000000]
Training progress:  45%|████▌     | 900/2000 [03:30<03:47,  4.84it/s, Loss=0.1404580, Gaussian number=214656, print grad=0.004596906714141369, Depth Loss=0.0000000]
Training progress:  45%|████▌     | 900/2000 [03:35<03:47,  4.84it/s, Loss=0.1224070, Gaussian number=229894, print grad=0.00040964732761494815, Depth Loss=0.0000000]
Training progress:  46%|████▌     | 910/2000 [03:35<05:04,  3.57it/s, Loss=0.1224070, Gaussian number=229894, print grad=0.00040964732761494815, Depth Loss=0.0000000]
Training progress:  46%|████▌     | 910/2000 [03:37<05:04,  3.57it/s, Loss=0.1341481, Gaussian number=229894, print grad=0.0008100815466605127, Depth Loss=0.0000000] 
Training progress:  46%|████▌     | 920/2000 [03:37<04:38,  3.88it/s, Loss=0.1341481, Gaussian number=229894, print grad=0.0008100815466605127, Depth Loss=0.0000000]
Training progress:  46%|████▌     | 920/2000 [03:39<04:38,  3.88it/s, Loss=0.1420210, Gaussian number=229894, print grad=0.0013209643075242639, Depth Loss=0.0000000]
Training progress:  46%|████▋     | 930/2000 [03:39<04:19,  4.12it/s, Loss=0.1420210, Gaussian number=229894, print grad=0.0013209643075242639, Depth Loss=0.0000000]
Training progress:  46%|████▋     | 930/2000 [03:41<04:19,  4.12it/s, Loss=0.1252118, Gaussian number=229894, print grad=0.00173859519418329, Depth Loss=0.0000000]  
Training progress:  47%|████▋     | 940/2000 [03:41<04:05,  4.32it/s, Loss=0.1252118, Gaussian number=229894, print grad=0.00173859519418329, Depth Loss=0.0000000]
Training progress:  47%|████▋     | 940/2000 [03:43<04:05,  4.32it/s, Loss=0.1232393, Gaussian number=229894, print grad=0.0021842289716005325, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 950/2000 [03:43<03:54,  4.47it/s, Loss=0.1232393, Gaussian number=229894, print grad=0.0021842289716005325, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 950/2000 [03:45<03:54,  4.47it/s, Loss=0.1251575, Gaussian number=229894, print grad=0.0026013264432549477, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 960/2000 [03:45<03:46,  4.58it/s, Loss=0.1251575, Gaussian number=229894, print grad=0.0026013264432549477, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 960/2000 [03:47<03:46,  4.58it/s, Loss=0.1592833, Gaussian number=229894, print grad=0.0030746236443519592, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 970/2000 [03:47<03:40,  4.66it/s, Loss=0.1592833, Gaussian number=229894, print grad=0.0030746236443519592, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 970/2000 [03:49<03:40,  4.66it/s, Loss=0.1020427, Gaussian number=229894, print grad=0.003514285897836089, Depth Loss=0.0000000] 
Training progress:  49%|████▉     | 980/2000 [03:49<03:36,  4.71it/s, Loss=0.1020427, Gaussian number=229894, print grad=0.003514285897836089, Depth Loss=0.0000000]
Training progress:  49%|████▉     | 980/2000 [03:51<03:36,  4.71it/s, Loss=0.1064876, Gaussian number=229894, print grad=0.0039007924497127533, Depth Loss=0.0000000]
Training progress:  50%|████▉     | 990/2000 [03:51<03:39,  4.59it/s, Loss=0.1064876, Gaussian number=229894, print grad=0.0039007924497127533, Depth Loss=0.0000000]
Training progress:  50%|████▉     | 990/2000 [03:53<03:39,  4.59it/s, Loss=0.1404519, Gaussian number=229894, print grad=0.004269381053745747, Depth Loss=0.0000000] 
Training progress:  50%|█████     | 1000/2000 [03:53<03:33,  4.69it/s, Loss=0.1404519, Gaussian number=229894, print grad=0.004269381053745747, Depth Loss=0.0000000]
Training progress:  50%|█████     | 1000/2000 [03:58<03:33,  4.69it/s, Loss=0.1407330, Gaussian number=245205, print grad=0.00037944462383165956, Depth Loss=0.0000000]
Training progress:  50%|█████     | 1010/2000 [03:58<04:41,  3.52it/s, Loss=0.1407330, Gaussian number=245205, print grad=0.00037944462383165956, Depth Loss=0.0000000]
Training progress:  50%|█████     | 1010/2000 [04:00<04:41,  3.52it/s, Loss=0.1713387, Gaussian number=245205, print grad=0.0008905723807401955, Depth Loss=0.0000000] 
Training progress:  51%|█████     | 1020/2000 [04:00<04:14,  3.85it/s, Loss=0.1713387, Gaussian number=245205, print grad=0.0008905723807401955, Depth Loss=0.0000000]
Training progress:  51%|█████     | 1020/2000 [04:02<04:14,  3.85it/s, Loss=0.1345478, Gaussian number=245205, print grad=0.0013370747910812497, Depth Loss=0.0000000]
Training progress:  52%|█████▏    | 1030/2000 [04:02<03:55,  4.13it/s, Loss=0.1345478, Gaussian number=245205, print grad=0.0013370747910812497, Depth Loss=0.0000000]
Training progress:  52%|█████▏    | 1030/2000 [04:04<03:55,  4.13it/s, Loss=0.1394888, Gaussian number=245205, print grad=0.0018160557374358177, Depth Loss=0.0000000]
Training progress:  52%|█████▏    | 1040/2000 [04:04<03:42,  4.32it/s, Loss=0.1394888, Gaussian number=245205, print grad=0.0018160557374358177, Depth Loss=0.0000000]
Training progress:  52%|█████▏    | 1040/2000 [04:06<03:42,  4.32it/s, Loss=0.1255118, Gaussian number=245205, print grad=0.0021951354574412107, Depth Loss=0.0000000]
Training progress:  52%|█████▎    | 1050/2000 [04:06<03:33,  4.46it/s, Loss=0.1255118, Gaussian number=245205, print grad=0.0021951354574412107, Depth Loss=0.0000000]
Training progress:  52%|█████▎    | 1050/2000 [04:08<03:33,  4.46it/s, Loss=0.1193031, Gaussian number=245205, print grad=0.002611257368698716, Depth Loss=0.0000000] 
Training progress:  53%|█████▎    | 1060/2000 [04:08<03:25,  4.57it/s, Loss=0.1193031, Gaussian number=245205, print grad=0.002611257368698716, Depth Loss=0.0000000]
Training progress:  53%|█████▎    | 1060/2000 [04:10<03:25,  4.57it/s, Loss=0.0998648, Gaussian number=245205, print grad=0.0030727647244930267, Depth Loss=0.0000000]
Training progress:  54%|█████▎    | 1070/2000 [04:10<03:19,  4.66it/s, Loss=0.0998648, Gaussian number=245205, print grad=0.0030727647244930267, Depth Loss=0.0000000]
Training progress:  54%|█████▎    | 1070/2000 [04:12<03:19,  4.66it/s, Loss=0.1026929, Gaussian number=245205, print grad=0.003470480674877763, Depth Loss=0.0000000] 
Training progress:  54%|█████▍    | 1080/2000 [04:12<03:14,  4.74it/s, Loss=0.1026929, Gaussian number=245205, print grad=0.003470480674877763, Depth Loss=0.0000000]
Training progress:  54%|█████▍    | 1080/2000 [04:14<03:14,  4.74it/s, Loss=0.1341534, Gaussian number=245205, print grad=0.0038915907498449087, Depth Loss=0.0000000]
Training progress:  55%|█████▍    | 1090/2000 [04:14<03:07,  4.84it/s, Loss=0.1341534, Gaussian number=245205, print grad=0.0038915907498449087, Depth Loss=0.0000000]
Training progress:  55%|█████▍    | 1090/2000 [04:16<03:07,  4.84it/s, Loss=0.1292046, Gaussian number=245205, print grad=0.004298647399991751, Depth Loss=0.0000000] 
Training progress:  55%|█████▌    | 1100/2000 [04:16<03:05,  4.85it/s, Loss=0.1292046, Gaussian number=245205, print grad=0.004298647399991751, Depth Loss=0.0000000]
Training progress:  55%|█████▌    | 1100/2000 [04:18<03:05,  4.85it/s, Loss=0.1493195, Gaussian number=261563, print grad=0.0003717179934028536, Depth Loss=0.0000000]
Training progress:  56%|█████▌    | 1110/2000 [04:18<03:03,  4.84it/s, Loss=0.1493195, Gaussian number=261563, print grad=0.0003717179934028536, Depth Loss=0.0000000]
Training progress:  56%|█████▌    | 1110/2000 [04:20<03:03,  4.84it/s, Loss=0.1388699, Gaussian number=261563, print grad=0.0008258409216068685, Depth Loss=0.0000000]
Training progress:  56%|█████▌    | 1120/2000 [04:20<03:02,  4.83it/s, Loss=0.1388699, Gaussian number=261563, print grad=0.0008258409216068685, Depth Loss=0.0000000]
Training progress:  56%|█████▌    | 1120/2000 [04:22<03:02,  4.83it/s, Loss=0.1066910, Gaussian number=261563, print grad=0.001293705659918487, Depth Loss=0.0000000] 
Training progress:  56%|█████▋    | 1130/2000 [04:22<02:59,  4.85it/s, Loss=0.1066910, Gaussian number=261563, print grad=0.001293705659918487, Depth Loss=0.0000000]
Training progress:  56%|█████▋    | 1130/2000 [04:24<02:59,  4.85it/s, Loss=0.1309540, Gaussian number=261563, print grad=0.00173593417275697, Depth Loss=0.0000000] 
Training progress:  57%|█████▋    | 1140/2000 [04:24<02:55,  4.89it/s, Loss=0.1309540, Gaussian number=261563, print grad=0.00173593417275697, Depth Loss=0.0000000]
Training progress:  57%|█████▋    | 1140/2000 [04:27<02:55,  4.89it/s, Loss=0.0927866, Gaussian number=261563, print grad=0.0021640928462147713, Depth Loss=0.0000000]
Training progress:  57%|█████▊    | 1150/2000 [04:27<02:53,  4.89it/s, Loss=0.0927866, Gaussian number=261563, print grad=0.0021640928462147713, Depth Loss=0.0000000]
Training progress:  57%|█████▊    | 1150/2000 [04:29<02:53,  4.89it/s, Loss=0.1003150, Gaussian number=261563, print grad=0.002532079117372632, Depth Loss=0.0000000] 
Training progress:  58%|█████▊    | 1160/2000 [04:29<02:52,  4.88it/s, Loss=0.1003150, Gaussian number=261563, print grad=0.002532079117372632, Depth Loss=0.0000000]
Training progress:  58%|█████▊    | 1160/2000 [04:31<02:52,  4.88it/s, Loss=0.1214256, Gaussian number=261563, print grad=0.002939777448773384, Depth Loss=0.0000000]
Training progress:  58%|█████▊    | 1170/2000 [04:31<02:50,  4.87it/s, Loss=0.1214256, Gaussian number=261563, print grad=0.002939777448773384, Depth Loss=0.0000000]
Training progress:  58%|█████▊    | 1170/2000 [04:33<02:50,  4.87it/s, Loss=0.1311331, Gaussian number=261563, print grad=0.003349690232425928, Depth Loss=0.0000000]
Training progress:  59%|█████▉    | 1180/2000 [04:33<02:49,  4.84it/s, Loss=0.1311331, Gaussian number=261563, print grad=0.003349690232425928, Depth Loss=0.0000000]
Training progress:  59%|█████▉    | 1180/2000 [04:35<02:49,  4.84it/s, Loss=0.1191590, Gaussian number=261563, print grad=0.0037791456561535597, Depth Loss=0.0000000]
Training progress:  60%|█████▉    | 1190/2000 [04:35<02:47,  4.84it/s, Loss=0.1191590, Gaussian number=261563, print grad=0.0037791456561535597, Depth Loss=0.0000000]
Training progress:  60%|█████▉    | 1190/2000 [04:37<02:47,  4.84it/s, Loss=0.1371179, Gaussian number=261563, print grad=0.004130578134208918, Depth Loss=0.0000000] 
Training progress:  60%|██████    | 1200/2000 [04:37<02:44,  4.86it/s, Loss=0.1371179, Gaussian number=261563, print grad=0.004130578134208918, Depth Loss=0.0000000]
Training progress:  60%|██████    | 1200/2000 [04:39<02:44,  4.86it/s, Loss=0.1092914, Gaussian number=278595, print grad=0.0003900726151186973, Depth Loss=0.0000000]
Training progress:  60%|██████    | 1210/2000 [04:39<02:42,  4.87it/s, Loss=0.1092914, Gaussian number=278595, print grad=0.0003900726151186973, Depth Loss=0.0000000]
Training progress:  60%|██████    | 1210/2000 [04:41<02:42,  4.87it/s, Loss=0.0987063, Gaussian number=278595, print grad=0.0008579852874390781, Depth Loss=0.0000000]
Training progress:  61%|██████    | 1220/2000 [04:41<02:39,  4.89it/s, Loss=0.0987063, Gaussian number=278595, print grad=0.0008579852874390781, Depth Loss=0.0000000]
Training progress:  61%|██████    | 1220/2000 [04:43<02:39,  4.89it/s, Loss=0.0998625, Gaussian number=278595, print grad=0.0012554096756502986, Depth Loss=0.0000000]
Training progress:  62%|██████▏   | 1230/2000 [04:43<02:37,  4.90it/s, Loss=0.0998625, Gaussian number=278595, print grad=0.0012554096756502986, Depth Loss=0.0000000]
Training progress:  62%|██████▏   | 1230/2000 [04:45<02:37,  4.90it/s, Loss=0.0981325, Gaussian number=278595, print grad=0.0016843924531713128, Depth Loss=0.0000000]
Training progress:  62%|██████▏   | 1240/2000 [04:45<02:35,  4.88it/s, Loss=0.0981325, Gaussian number=278595, print grad=0.0016843924531713128, Depth Loss=0.0000000]
Training progress:  62%|██████▏   | 1240/2000 [04:47<02:35,  4.88it/s, Loss=0.0971554, Gaussian number=278595, print grad=0.0020506642758846283, Depth Loss=0.0000000]
Training progress:  62%|██████▎   | 1250/2000 [04:47<02:33,  4.88it/s, Loss=0.0971554, Gaussian number=278595, print grad=0.0020506642758846283, Depth Loss=0.0000000]
Training progress:  62%|██████▎   | 1250/2000 [04:49<02:33,  4.88it/s, Loss=0.0997072, Gaussian number=278595, print grad=0.0023962934501469135, Depth Loss=0.0000000]
Training progress:  63%|██████▎   | 1260/2000 [04:49<02:31,  4.88it/s, Loss=0.0997072, Gaussian number=278595, print grad=0.0023962934501469135, Depth Loss=0.0000000]
Training progress:  63%|██████▎   | 1260/2000 [04:51<02:31,  4.88it/s, Loss=0.1242225, Gaussian number=278595, print grad=0.0027979183942079544, Depth Loss=0.0000000]
Training progress:  64%|██████▎   | 1270/2000 [04:51<02:29,  4.89it/s, Loss=0.1242225, Gaussian number=278595, print grad=0.0027979183942079544, Depth Loss=0.0000000]
Training progress:  64%|██████▎   | 1270/2000 [04:53<02:29,  4.89it/s, Loss=0.1211501, Gaussian number=278595, print grad=0.003160768887028098, Depth Loss=0.0000000] 
Training progress:  64%|██████▍   | 1280/2000 [04:53<02:27,  4.89it/s, Loss=0.1211501, Gaussian number=278595, print grad=0.003160768887028098, Depth Loss=0.0000000]
Training progress:  64%|██████▍   | 1280/2000 [04:55<02:27,  4.89it/s, Loss=0.0945632, Gaussian number=278595, print grad=0.003575766459107399, Depth Loss=0.0000000]
Training progress:  64%|██████▍   | 1290/2000 [04:55<02:24,  4.91it/s, Loss=0.0945632, Gaussian number=278595, print grad=0.003575766459107399, Depth Loss=0.0000000]
Training progress:  64%|██████▍   | 1290/2000 [04:57<02:24,  4.91it/s, Loss=0.1457746, Gaussian number=278595, print grad=0.003941076807677746, Depth Loss=0.0000000]
Training progress:  65%|██████▌   | 1300/2000 [04:57<02:22,  4.91it/s, Loss=0.1457746, Gaussian number=278595, print grad=0.003941076807677746, Depth Loss=0.0000000]
Training progress:  65%|██████▌   | 1300/2000 [04:59<02:22,  4.91it/s, Loss=0.1409950, Gaussian number=296306, print grad=0.0004080489161424339, Depth Loss=0.0000000]
Training progress:  66%|██████▌   | 1310/2000 [04:59<02:20,  4.90it/s, Loss=0.1409950, Gaussian number=296306, print grad=0.0004080489161424339, Depth Loss=0.0000000]
Training progress:  66%|██████▌   | 1310/2000 [05:01<02:20,  4.90it/s, Loss=0.1443208, Gaussian number=296306, print grad=0.0007983095711097121, Depth Loss=0.0000000]
Training progress:  66%|██████▌   | 1320/2000 [05:01<02:19,  4.89it/s, Loss=0.1443208, Gaussian number=296306, print grad=0.0007983095711097121, Depth Loss=0.0000000]
Training progress:  66%|██████▌   | 1320/2000 [05:03<02:19,  4.89it/s, Loss=0.1147760, Gaussian number=296306, print grad=0.0012116357684135437, Depth Loss=0.0000000]
Training progress:  66%|██████▋   | 1330/2000 [05:03<02:16,  4.89it/s, Loss=0.1147760, Gaussian number=296306, print grad=0.0012116357684135437, Depth Loss=0.0000000]
Training progress:  66%|██████▋   | 1330/2000 [05:05<02:16,  4.89it/s, Loss=0.1154308, Gaussian number=296306, print grad=0.0016189732123166323, Depth Loss=0.0000000]
Training progress:  67%|██████▋   | 1340/2000 [05:05<02:15,  4.88it/s, Loss=0.1154308, Gaussian number=296306, print grad=0.0016189732123166323, Depth Loss=0.0000000]
Training progress:  67%|██████▋   | 1340/2000 [05:08<02:15,  4.88it/s, Loss=0.1531178, Gaussian number=296306, print grad=0.0019622594118118286, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1350/2000 [05:08<02:13,  4.88it/s, Loss=0.1531178, Gaussian number=296306, print grad=0.0019622594118118286, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1350/2000 [05:10<02:13,  4.88it/s, Loss=0.0932481, Gaussian number=296306, print grad=0.0023206358309835196, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1360/2000 [05:10<02:10,  4.89it/s, Loss=0.0932481, Gaussian number=296306, print grad=0.0023206358309835196, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1360/2000 [05:12<02:10,  4.89it/s, Loss=0.1736956, Gaussian number=296306, print grad=0.00272064795717597, Depth Loss=0.0000000]  
Training progress:  68%|██████▊   | 1370/2000 [05:12<02:10,  4.82it/s, Loss=0.1736956, Gaussian number=296306, print grad=0.00272064795717597, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1370/2000 [05:14<02:10,  4.82it/s, Loss=0.1118555, Gaussian number=296306, print grad=0.0030709204729646444, Depth Loss=0.0000000]
Training progress:  69%|██████▉   | 1380/2000 [05:14<02:09,  4.78it/s, Loss=0.1118555, Gaussian number=296306, print grad=0.0030709204729646444, Depth Loss=0.0000000]
Training progress:  69%|██████▉   | 1380/2000 [05:16<02:09,  4.78it/s, Loss=0.1000175, Gaussian number=296306, print grad=0.0034226546995341778, Depth Loss=0.0000000]
Training progress:  70%|██████▉   | 1390/2000 [05:16<02:08,  4.76it/s, Loss=0.1000175, Gaussian number=296306, print grad=0.0034226546995341778, Depth Loss=0.0000000]
Training progress:  70%|██████▉   | 1390/2000 [05:18<02:08,  4.76it/s, Loss=0.1125741, Gaussian number=296306, print grad=0.0037863755133002996, Depth Loss=0.0000000]
Training progress:  70%|███████   | 1400/2000 [05:18<02:05,  4.77it/s, Loss=0.1125741, Gaussian number=296306, print grad=0.0037863755133002996, Depth Loss=0.0000000]
Training progress:  70%|███████   | 1400/2000 [05:20<02:05,  4.77it/s, Loss=0.1360815, Gaussian number=313586, print grad=0.00040023965993896127, Depth Loss=0.0000000]
Training progress:  70%|███████   | 1410/2000 [05:20<02:01,  4.86it/s, Loss=0.1360815, Gaussian number=313586, print grad=0.00040023965993896127, Depth Loss=0.0000000]
Training progress:  70%|███████   | 1410/2000 [05:22<02:01,  4.86it/s, Loss=0.1139952, Gaussian number=313586, print grad=0.0008107144967652857, Depth Loss=0.0000000] 
Training progress:  71%|███████   | 1420/2000 [05:22<01:59,  4.86it/s, Loss=0.1139952, Gaussian number=313586, print grad=0.0008107144967652857, Depth Loss=0.0000000]
Training progress:  71%|███████   | 1420/2000 [05:24<01:59,  4.86it/s, Loss=0.1168632, Gaussian number=313586, print grad=0.001233662129379809, Depth Loss=0.0000000] 
Training progress:  72%|███████▏  | 1430/2000 [05:24<01:57,  4.87it/s, Loss=0.1168632, Gaussian number=313586, print grad=0.001233662129379809, Depth Loss=0.0000000]
Training progress:  72%|███████▏  | 1430/2000 [05:26<01:57,  4.87it/s, Loss=0.1068434, Gaussian number=313586, print grad=0.0015770131722092628, Depth Loss=0.0000000]
Training progress:  72%|███████▏  | 1440/2000 [05:26<01:55,  4.87it/s, Loss=0.1068434, Gaussian number=313586, print grad=0.0015770131722092628, Depth Loss=0.0000000]
Training progress:  72%|███████▏  | 1440/2000 [05:28<01:55,  4.87it/s, Loss=0.0953255, Gaussian number=313586, print grad=0.0019248139578849077, Depth Loss=0.0000000]
Training progress:  72%|███████▎  | 1450/2000 [05:28<01:52,  4.87it/s, Loss=0.0953255, Gaussian number=313586, print grad=0.0019248139578849077, Depth Loss=0.0000000]
Training progress:  72%|███████▎  | 1450/2000 [05:30<01:52,  4.87it/s, Loss=0.0863221, Gaussian number=313586, print grad=0.002279803156852722, Depth Loss=0.0000000] 
Training progress:  73%|███████▎  | 1460/2000 [05:30<01:51,  4.85it/s, Loss=0.0863221, Gaussian number=313586, print grad=0.002279803156852722, Depth Loss=0.0000000]
Training progress:  73%|███████▎  | 1460/2000 [05:32<01:51,  4.85it/s, Loss=0.1164882, Gaussian number=313586, print grad=0.002645813161507249, Depth Loss=0.0000000]
Training progress:  74%|███████▎  | 1470/2000 [05:32<01:49,  4.82it/s, Loss=0.1164882, Gaussian number=313586, print grad=0.002645813161507249, Depth Loss=0.0000000]
Training progress:  74%|███████▎  | 1470/2000 [05:34<01:49,  4.82it/s, Loss=0.1184548, Gaussian number=313586, print grad=0.0030392154585570097, Depth Loss=0.0000000]
Training progress:  74%|███████▍  | 1480/2000 [05:34<01:47,  4.83it/s, Loss=0.1184548, Gaussian number=313586, print grad=0.0030392154585570097, Depth Loss=0.0000000]
Training progress:  74%|███████▍  | 1480/2000 [05:36<01:47,  4.83it/s, Loss=0.1238744, Gaussian number=313586, print grad=0.0034239389933645725, Depth Loss=0.0000000]
Training progress:  74%|███████▍  | 1490/2000 [05:36<01:45,  4.85it/s, Loss=0.1238744, Gaussian number=313586, print grad=0.0034239389933645725, Depth Loss=0.0000000]
Training progress:  74%|███████▍  | 1490/2000 [05:39<01:45,  4.85it/s, Loss=0.1178917, Gaussian number=313586, print grad=0.003797969315201044, Depth Loss=0.0000000] 
Training progress:  75%|███████▌  | 1500/2000 [05:39<01:42,  4.87it/s, Loss=0.1178917, Gaussian number=313586, print grad=0.003797969315201044, Depth Loss=0.0000000]
Training progress:  75%|███████▌  | 1500/2000 [05:43<01:42,  4.87it/s, Loss=0.1354741, Gaussian number=331041, print grad=0.00034794231760315597, Depth Loss=0.0000000]
Training progress:  76%|███████▌  | 1510/2000 [05:43<02:16,  3.58it/s, Loss=0.1354741, Gaussian number=331041, print grad=0.00034794231760315597, Depth Loss=0.0000000]
Training progress:  76%|███████▌  | 1510/2000 [05:45<02:16,  3.58it/s, Loss=0.1269860, Gaussian number=331041, print grad=0.0007081006187945604, Depth Loss=0.0000000] 
Training progress:  76%|███████▌  | 1520/2000 [05:45<02:03,  3.89it/s, Loss=0.1269860, Gaussian number=331041, print grad=0.0007081006187945604, Depth Loss=0.0000000]
Training progress:  76%|███████▌  | 1520/2000 [05:47<02:03,  3.89it/s, Loss=0.0717104, Gaussian number=331041, print grad=0.0011117563117295504, Depth Loss=0.0000000]
Training progress:  76%|███████▋  | 1530/2000 [05:47<01:54,  4.10it/s, Loss=0.0717104, Gaussian number=331041, print grad=0.0011117563117295504, Depth Loss=0.0000000]
Training progress:  76%|███████▋  | 1530/2000 [05:49<01:54,  4.10it/s, Loss=0.0979206, Gaussian number=331041, print grad=0.0014758615288883448, Depth Loss=0.0000000]
Training progress:  77%|███████▋  | 1540/2000 [05:49<01:47,  4.29it/s, Loss=0.0979206, Gaussian number=331041, print grad=0.0014758615288883448, Depth Loss=0.0000000]
Training progress:  77%|███████▋  | 1540/2000 [05:51<01:47,  4.29it/s, Loss=0.1127875, Gaussian number=331041, print grad=0.0018657257314771414, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1550/2000 [05:51<01:41,  4.45it/s, Loss=0.1127875, Gaussian number=331041, print grad=0.0018657257314771414, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1550/2000 [05:53<01:41,  4.45it/s, Loss=0.1149426, Gaussian number=331041, print grad=0.0022675623185932636, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1560/2000 [05:53<01:35,  4.59it/s, Loss=0.1149426, Gaussian number=331041, print grad=0.0022675623185932636, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1560/2000 [05:55<01:35,  4.59it/s, Loss=0.0991475, Gaussian number=331041, print grad=0.0026383704971522093, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1570/2000 [05:55<01:32,  4.67it/s, Loss=0.0991475, Gaussian number=331041, print grad=0.0026383704971522093, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1570/2000 [05:57<01:32,  4.67it/s, Loss=0.0742399, Gaussian number=331041, print grad=0.002938448451459408, Depth Loss=0.0000000] 
Training progress:  79%|███████▉  | 1580/2000 [05:57<01:28,  4.73it/s, Loss=0.0742399, Gaussian number=331041, print grad=0.002938448451459408, Depth Loss=0.0000000]
Training progress:  79%|███████▉  | 1580/2000 [06:00<01:28,  4.73it/s, Loss=0.1044733, Gaussian number=331041, print grad=0.00328086712397635, Depth Loss=0.0000000] 
Training progress:  80%|███████▉  | 1590/2000 [06:00<01:25,  4.77it/s, Loss=0.1044733, Gaussian number=331041, print grad=0.00328086712397635, Depth Loss=0.0000000]
Training progress:  80%|███████▉  | 1590/2000 [06:02<01:25,  4.77it/s, Loss=0.0991397, Gaussian number=331041, print grad=0.003659247187897563, Depth Loss=0.0000000]
Training progress:  80%|████████  | 1600/2000 [06:02<01:23,  4.81it/s, Loss=0.0991397, Gaussian number=331041, print grad=0.003659247187897563, Depth Loss=0.0000000]
Training progress:  80%|████████  | 1600/2000 [06:04<01:23,  4.81it/s, Loss=0.1187967, Gaussian number=348442, print grad=0.00036731557338498533, Depth Loss=0.0000000]
Training progress:  80%|████████  | 1610/2000 [06:04<01:20,  4.83it/s, Loss=0.1187967, Gaussian number=348442, print grad=0.00036731557338498533, Depth Loss=0.0000000]
Training progress:  80%|████████  | 1610/2000 [06:06<01:20,  4.83it/s, Loss=0.1164575, Gaussian number=348442, print grad=0.00078777497401461, Depth Loss=0.0000000]   
Training progress:  81%|████████  | 1620/2000 [06:06<01:18,  4.84it/s, Loss=0.1164575, Gaussian number=348442, print grad=0.00078777497401461, Depth Loss=0.0000000]
Training progress:  81%|████████  | 1620/2000 [06:08<01:18,  4.84it/s, Loss=0.0996840, Gaussian number=348442, print grad=0.0011453768238425255, Depth Loss=0.0000000]
Training progress:  82%|████████▏ | 1630/2000 [06:08<01:16,  4.85it/s, Loss=0.0996840, Gaussian number=348442, print grad=0.0011453768238425255, Depth Loss=0.0000000]
Training progress:  82%|████████▏ | 1630/2000 [06:10<01:16,  4.85it/s, Loss=0.0784120, Gaussian number=348442, print grad=0.0014954641228541732, Depth Loss=0.0000000]
Training progress:  82%|████████▏ | 1640/2000 [06:10<01:14,  4.85it/s, Loss=0.0784120, Gaussian number=348442, print grad=0.0014954641228541732, Depth Loss=0.0000000]
Training progress:  82%|████████▏ | 1640/2000 [06:12<01:14,  4.85it/s, Loss=0.0999494, Gaussian number=348442, print grad=0.0018336910288780928, Depth Loss=0.0000000]
Training progress:  82%|████████▎ | 1650/2000 [06:12<01:12,  4.84it/s, Loss=0.0999494, Gaussian number=348442, print grad=0.0018336910288780928, Depth Loss=0.0000000]
Training progress:  82%|████████▎ | 1650/2000 [06:14<01:12,  4.84it/s, Loss=0.0988563, Gaussian number=348442, print grad=0.0021679243072867393, Depth Loss=0.0000000]
Training progress:  83%|████████▎ | 1660/2000 [06:14<01:10,  4.84it/s, Loss=0.0988563, Gaussian number=348442, print grad=0.0021679243072867393, Depth Loss=0.0000000]
Training progress:  83%|████████▎ | 1660/2000 [06:16<01:10,  4.84it/s, Loss=0.0911719, Gaussian number=348442, print grad=0.0025010353419929743, Depth Loss=0.0000000]
Training progress:  84%|████████▎ | 1670/2000 [06:16<01:08,  4.84it/s, Loss=0.0911719, Gaussian number=348442, print grad=0.0025010353419929743, Depth Loss=0.0000000]
Training progress:  84%|████████▎ | 1670/2000 [06:18<01:08,  4.84it/s, Loss=0.0854860, Gaussian number=348442, print grad=0.002844978356733918, Depth Loss=0.0000000] 
Training progress:  84%|████████▍ | 1680/2000 [06:18<01:06,  4.84it/s, Loss=0.0854860, Gaussian number=348442, print grad=0.002844978356733918, Depth Loss=0.0000000]
Training progress:  84%|████████▍ | 1680/2000 [06:20<01:06,  4.84it/s, Loss=0.0996215, Gaussian number=348442, print grad=0.0031932080164551735, Depth Loss=0.0000000]
Training progress:  84%|████████▍ | 1690/2000 [06:20<01:04,  4.84it/s, Loss=0.0996215, Gaussian number=348442, print grad=0.0031932080164551735, Depth Loss=0.0000000]
Training progress:  84%|████████▍ | 1690/2000 [06:22<01:04,  4.84it/s, Loss=0.1085768, Gaussian number=348442, print grad=0.0035145811270922422, Depth Loss=0.0000000]
Training progress:  85%|████████▌ | 1700/2000 [06:22<01:02,  4.84it/s, Loss=0.1085768, Gaussian number=348442, print grad=0.0035145811270922422, Depth Loss=0.0000000]
Training progress:  85%|████████▌ | 1700/2000 [06:24<01:02,  4.84it/s, Loss=0.1146401, Gaussian number=365163, print grad=0.00037095433799549937, Depth Loss=0.0000000]
Training progress:  86%|████████▌ | 1710/2000 [06:24<00:59,  4.84it/s, Loss=0.1146401, Gaussian number=365163, print grad=0.00037095433799549937, Depth Loss=0.0000000]
Training progress:  86%|████████▌ | 1710/2000 [06:26<00:59,  4.84it/s, Loss=0.1278875, Gaussian number=365163, print grad=0.0006946290377527475, Depth Loss=0.0000000] 
Training progress:  86%|████████▌ | 1720/2000 [06:26<00:57,  4.87it/s, Loss=0.1278875, Gaussian number=365163, print grad=0.0006946290377527475, Depth Loss=0.0000000]
Training progress:  86%|████████▌ | 1720/2000 [06:28<00:57,  4.87it/s, Loss=0.1118842, Gaussian number=365163, print grad=0.0010342345340177417, Depth Loss=0.0000000]
Training progress:  86%|████████▋ | 1730/2000 [06:28<00:55,  4.86it/s, Loss=0.1118842, Gaussian number=365163, print grad=0.0010342345340177417, Depth Loss=0.0000000]
Training progress:  86%|████████▋ | 1730/2000 [06:30<00:55,  4.86it/s, Loss=0.1438956, Gaussian number=365163, print grad=0.0014117705868557096, Depth Loss=0.0000000]
Training progress:  87%|████████▋ | 1740/2000 [06:30<00:53,  4.84it/s, Loss=0.1438956, Gaussian number=365163, print grad=0.0014117705868557096, Depth Loss=0.0000000]
Training progress:  87%|████████▋ | 1740/2000 [06:33<00:53,  4.84it/s, Loss=0.1322718, Gaussian number=365163, print grad=0.0017741417977958918, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1750/2000 [06:33<00:51,  4.84it/s, Loss=0.1322718, Gaussian number=365163, print grad=0.0017741417977958918, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1750/2000 [06:35<00:51,  4.84it/s, Loss=0.1075025, Gaussian number=365163, print grad=0.002100159414112568, Depth Loss=0.0000000] 
Training progress:  88%|████████▊ | 1760/2000 [06:35<00:49,  4.84it/s, Loss=0.1075025, Gaussian number=365163, print grad=0.002100159414112568, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1760/2000 [06:37<00:49,  4.84it/s, Loss=0.0867530, Gaussian number=365163, print grad=0.0024143902119249105, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1770/2000 [06:37<00:47,  4.85it/s, Loss=0.0867530, Gaussian number=365163, print grad=0.0024143902119249105, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1770/2000 [06:39<00:47,  4.85it/s, Loss=0.0999768, Gaussian number=365163, print grad=0.00273111741989851, Depth Loss=0.0000000]  
Training progress:  89%|████████▉ | 1780/2000 [06:39<00:45,  4.85it/s, Loss=0.0999768, Gaussian number=365163, print grad=0.00273111741989851, Depth Loss=0.0000000]
Training progress:  89%|████████▉ | 1780/2000 [06:41<00:45,  4.85it/s, Loss=0.0955350, Gaussian number=365163, print grad=0.003002193057909608, Depth Loss=0.0000000]
Training progress:  90%|████████▉ | 1790/2000 [06:41<00:43,  4.86it/s, Loss=0.0955350, Gaussian number=365163, print grad=0.003002193057909608, Depth Loss=0.0000000]
Training progress:  90%|████████▉ | 1790/2000 [06:43<00:43,  4.86it/s, Loss=0.0952371, Gaussian number=365163, print grad=0.0033555980771780014, Depth Loss=0.0000000]
Training progress:  90%|█████████ | 1800/2000 [06:43<00:41,  4.87it/s, Loss=0.0952371, Gaussian number=365163, print grad=0.0033555980771780014, Depth Loss=0.0000000]
Training progress:  90%|█████████ | 1800/2000 [06:45<00:41,  4.87it/s, Loss=0.1113613, Gaussian number=382638, print grad=0.0003441416483838111, Depth Loss=0.0000000]
Training progress:  90%|█████████ | 1810/2000 [06:45<00:39,  4.86it/s, Loss=0.1113613, Gaussian number=382638, print grad=0.0003441416483838111, Depth Loss=0.0000000]
Training progress:  90%|█████████ | 1810/2000 [06:47<00:39,  4.86it/s, Loss=0.0964289, Gaussian number=382638, print grad=0.0007269317866303027, Depth Loss=0.0000000]
Training progress:  91%|█████████ | 1820/2000 [06:47<00:37,  4.83it/s, Loss=0.0964289, Gaussian number=382638, print grad=0.0007269317866303027, Depth Loss=0.0000000]
Training progress:  91%|█████████ | 1820/2000 [06:49<00:37,  4.83it/s, Loss=0.0851965, Gaussian number=382638, print grad=0.0010032879654318094, Depth Loss=0.0000000]
Training progress:  92%|█████████▏| 1830/2000 [06:49<00:35,  4.84it/s, Loss=0.0851965, Gaussian number=382638, print grad=0.0010032879654318094, Depth Loss=0.0000000]
Training progress:  92%|█████████▏| 1830/2000 [06:51<00:35,  4.84it/s, Loss=0.0859421, Gaussian number=382638, print grad=0.0013481751084327698, Depth Loss=0.0000000]
Training progress:  92%|█████████▏| 1840/2000 [06:51<00:33,  4.84it/s, Loss=0.0859421, Gaussian number=382638, print grad=0.0013481751084327698, Depth Loss=0.0000000]
Training progress:  92%|█████████▏| 1840/2000 [06:53<00:33,  4.84it/s, Loss=0.0926600, Gaussian number=382638, print grad=0.001672891085036099, Depth Loss=0.0000000] 
Training progress:  92%|█████████▎| 1850/2000 [06:53<00:30,  4.84it/s, Loss=0.0926600, Gaussian number=382638, print grad=0.001672891085036099, Depth Loss=0.0000000]
Training progress:  92%|█████████▎| 1850/2000 [06:55<00:30,  4.84it/s, Loss=0.1022182, Gaussian number=382638, print grad=0.001957475673407316, Depth Loss=0.0000000]
Training progress:  93%|█████████▎| 1860/2000 [06:55<00:28,  4.87it/s, Loss=0.1022182, Gaussian number=382638, print grad=0.001957475673407316, Depth Loss=0.0000000]
Training progress:  93%|█████████▎| 1860/2000 [06:57<00:28,  4.87it/s, Loss=0.1134048, Gaussian number=382638, print grad=0.0023222123272717, Depth Loss=0.0000000]  
Training progress:  94%|█████████▎| 1870/2000 [06:57<00:26,  4.96it/s, Loss=0.1134048, Gaussian number=382638, print grad=0.0023222123272717, Depth Loss=0.0000000]
Training progress:  94%|█████████▎| 1870/2000 [06:59<00:26,  4.96it/s, Loss=0.0838614, Gaussian number=382638, print grad=0.002645439701154828, Depth Loss=0.0000000]
Training progress:  94%|█████████▍| 1880/2000 [06:59<00:24,  4.85it/s, Loss=0.0838614, Gaussian number=382638, print grad=0.002645439701154828, Depth Loss=0.0000000]
Training progress:  94%|█████████▍| 1880/2000 [07:01<00:24,  4.85it/s, Loss=0.0978668, Gaussian number=382638, print grad=0.002967502921819687, Depth Loss=0.0000000]
Training progress:  94%|█████████▍| 1890/2000 [07:01<00:22,  4.95it/s, Loss=0.0978668, Gaussian number=382638, print grad=0.002967502921819687, Depth Loss=0.0000000]
Training progress:  94%|█████████▍| 1890/2000 [07:03<00:22,  4.95it/s, Loss=0.1190035, Gaussian number=382638, print grad=0.003300762502476573, Depth Loss=0.0000000]
Training progress:  95%|█████████▌| 1900/2000 [07:03<00:19,  5.03it/s, Loss=0.1190035, Gaussian number=382638, print grad=0.003300762502476573, Depth Loss=0.0000000]
Training progress:  95%|█████████▌| 1900/2000 [07:05<00:19,  5.03it/s, Loss=0.1070953, Gaussian number=400735, print grad=0.0002856568025890738, Depth Loss=0.0000000]
Training progress:  96%|█████████▌| 1910/2000 [07:05<00:17,  5.07it/s, Loss=0.1070953, Gaussian number=400735, print grad=0.0002856568025890738, Depth Loss=0.0000000]
Training progress:  96%|█████████▌| 1910/2000 [07:07<00:17,  5.07it/s, Loss=0.0993834, Gaussian number=400735, print grad=0.0006156949675641954, Depth Loss=0.0000000]
Training progress:  96%|█████████▌| 1920/2000 [07:07<00:15,  5.01it/s, Loss=0.0993834, Gaussian number=400735, print grad=0.0006156949675641954, Depth Loss=0.0000000]
Training progress:  96%|█████████▌| 1920/2000 [07:09<00:15,  5.01it/s, Loss=0.0800745, Gaussian number=400735, print grad=0.0009579684701748192, Depth Loss=0.0000000]
Training progress:  96%|█████████▋| 1930/2000 [07:09<00:14,  4.95it/s, Loss=0.0800745, Gaussian number=400735, print grad=0.0009579684701748192, Depth Loss=0.0000000]
Training progress:  96%|█████████▋| 1930/2000 [07:11<00:14,  4.95it/s, Loss=0.1100388, Gaussian number=400735, print grad=0.0012721663806587458, Depth Loss=0.0000000]
Training progress:  97%|█████████▋| 1940/2000 [07:11<00:12,  4.92it/s, Loss=0.1100388, Gaussian number=400735, print grad=0.0012721663806587458, Depth Loss=0.0000000]
Training progress:  97%|█████████▋| 1940/2000 [07:13<00:12,  4.92it/s, Loss=0.0846733, Gaussian number=400735, print grad=0.001575132948346436, Depth Loss=0.0000000] 
Training progress:  98%|█████████▊| 1950/2000 [07:13<00:10,  4.89it/s, Loss=0.0846733, Gaussian number=400735, print grad=0.001575132948346436, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1950/2000 [07:15<00:10,  4.89it/s, Loss=0.1327715, Gaussian number=400735, print grad=0.0018606564262881875, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1960/2000 [07:15<00:08,  4.88it/s, Loss=0.1327715, Gaussian number=400735, print grad=0.0018606564262881875, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1960/2000 [07:17<00:08,  4.88it/s, Loss=0.1128054, Gaussian number=400735, print grad=0.002167921047657728, Depth Loss=0.0000000] 
Training progress:  98%|█████████▊| 1970/2000 [07:17<00:06,  4.86it/s, Loss=0.1128054, Gaussian number=400735, print grad=0.002167921047657728, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1970/2000 [07:20<00:06,  4.86it/s, Loss=0.0919485, Gaussian number=400735, print grad=0.00249089440330863, Depth Loss=0.0000000] 
Training progress:  99%|█████████▉| 1980/2000 [07:20<00:04,  4.85it/s, Loss=0.0919485, Gaussian number=400735, print grad=0.00249089440330863, Depth Loss=0.0000000]
Training progress:  99%|█████████▉| 1980/2000 [07:22<00:04,  4.85it/s, Loss=0.0910408, Gaussian number=400735, print grad=0.002829080680385232, Depth Loss=0.0000000]
Training progress: 100%|█████████▉| 1990/2000 [07:22<00:02,  4.84it/s, Loss=0.0910408, Gaussian number=400735, print grad=0.002829080680385232, Depth Loss=0.0000000]
Training progress: 100%|█████████▉| 1990/2000 [07:24<00:02,  4.84it/s, Loss=0.0715081, Gaussian number=400735, print grad=0.0031713058706372976, Depth Loss=0.0000000]
Training progress: 100%|██████████| 2000/2000 [07:24<00:00,  4.85it/s, Loss=0.0715081, Gaussian number=400735, print grad=0.0031713058706372976, Depth Loss=0.0000000]
Training progress: 100%|██████████| 2000/2000 [07:24<00:00,  4.50it/s, Loss=0.0715081, Gaussian number=400735, print grad=0.0031713058706372976, Depth Loss=0.0000000]
Iteration 100 [14/11 19:33:13]

[ITER 100] Evaluating test: WD 0.197875, PSNR 12.9382 [14/11 19:33:16]

[ITER 100] Evaluating train: WD 0.206072, PSNR 13.2933 [14/11 19:33:16]
Gaussian number:182686,print gradients:2.8100894269300625e-05 [14/11 19:33:16]
Iteration 200 [14/11 19:33:37]

[ITER 200] Evaluating test: WD 0.175293, PSNR 14.2261 [14/11 19:33:39]

[ITER 200] Evaluating train: WD 0.178010, PSNR 14.3943 [14/11 19:33:39]
Gaussian number:182686,print gradients:3.6251953133614734e-05 [14/11 19:33:40]
Iteration 300 [14/11 19:34:00]

[ITER 300] Evaluating test: WD 0.160148, PSNR 14.9446 [14/11 19:34:03]

[ITER 300] Evaluating train: WD 0.162162, PSNR 15.2067 [14/11 19:34:03]
Gaussian number:182686,print gradients:4.131381865590811e-05 [14/11 19:34:03]
Iteration 400 [14/11 19:34:23]

[ITER 400] Evaluating test: WD 0.153544, PSNR 15.3871 [14/11 19:34:26]

[ITER 400] Evaluating train: WD 0.156050, PSNR 15.7836 [14/11 19:34:26]
Gaussian number:182686,print gradients:4.458387411432341e-05 [14/11 19:34:26]
Iteration 500 [14/11 19:34:46]

[ITER 500] Evaluating test: WD 0.144252, PSNR 15.8293 [14/11 19:34:49]

[ITER 500] Evaluating train: WD 0.155479, PSNR 15.8650 [14/11 19:34:49]
Gaussian number:182686,print gradients:4.82388750242535e-05 [14/11 19:34:49]
Iteration 600 [14/11 19:35:09]

[ITER 600] Evaluating test: WD 0.138331, PSNR 16.0733 [14/11 19:35:12]

[ITER 600] Evaluating train: WD 0.146393, PSNR 16.0856 [14/11 19:35:12]
Gaussian number:182686,print gradients:5.0803006161004305e-05 [14/11 19:35:12]
Iteration 700 [14/11 19:35:32]

[ITER 700] Evaluating test: WD 0.136879, PSNR 16.2101 [14/11 19:35:35]

[ITER 700] Evaluating train: WD 0.144307, PSNR 15.9344 [14/11 19:35:35]
Gaussian number:187728,print gradients:6.958456651773304e-05 [14/11 19:35:35]
Iteration 800 [14/11 19:35:55]

[ITER 800] Evaluating test: WD 0.129343, PSNR 16.5263 [14/11 19:35:58]

[ITER 800] Evaluating train: WD 0.134837, PSNR 16.8879 [14/11 19:35:58]
Gaussian number:200652,print gradients:6.877103442093357e-05 [14/11 19:35:58]
Iteration 900 [14/11 19:36:18]

[ITER 900] Evaluating test: WD 0.127229, PSNR 16.6692 [14/11 19:36:21]

[ITER 900] Evaluating train: WD 0.138222, PSNR 16.8097 [14/11 19:36:21]
Gaussian number:214656,print gradients:7.051225838949904e-05 [14/11 19:36:21]
Iteration 1000 [14/11 19:36:42]

[ITER 1000] Evaluating test: WD 0.125180, PSNR 16.7972 [14/11 19:36:44]

[ITER 1000] Evaluating train: WD 0.137047, PSNR 16.7785 [14/11 19:36:44]
Gaussian number:229894,print gradients:6.778062379453331e-05 [14/11 19:36:44]
Iteration 1100 [14/11 19:37:04]
Iteration 1200 [14/11 19:37:25]
Iteration 1300 [14/11 19:37:45]
Iteration 1400 [14/11 19:38:06]
Iteration 1500 [14/11 19:38:27]

[ITER 1500] Evaluating test: WD 0.109979, PSNR 17.3417 [14/11 19:38:29]

[ITER 1500] Evaluating train: WD 0.118636, PSNR 17.6239 [14/11 19:38:29]
Gaussian number:313586,print gradients:nan [14/11 19:38:29]
Iteration 1600 [14/11 19:38:50]
Iteration 1700 [14/11 19:39:10]
Iteration 1800 [14/11 19:39:31]
Iteration 1900 [14/11 19:39:51]
Iteration 2000 [14/11 19:40:12]

[ITER 2000] Evaluating test: WD 0.101083, PSNR 17.8159 [14/11 19:40:14]

[ITER 2000] Evaluating train: WD 0.113356, PSNR 18.1475 [14/11 19:40:15]
Gaussian number:400735,print gradients:nan [14/11 19:40:15]

[ITER 2000] Saving Gaussians [14/11 19:40:15]

Training complete. [14/11 19:40:19]
