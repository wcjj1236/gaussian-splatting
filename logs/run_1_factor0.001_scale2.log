Optimizing /home/cw4287/gaussian-model/train1
Output folder: /home/cw4287/gaussian-model/train1 [15/11 00:10:11]
Tensorboard not available: not logging progress [15/11 00:10:11]
------------LLFF HOLD------------- [15/11 00:10:12]

Reading camera 1/301
Reading camera 2/301
Reading camera 3/301
Reading camera 4/301
Reading camera 5/301
Reading camera 6/301
Reading camera 7/301
Reading camera 8/301
Reading camera 9/301
Reading camera 10/301
Reading camera 11/301
Reading camera 12/301
Reading camera 13/301
Reading camera 14/301
Reading camera 15/301
Reading camera 16/301
Reading camera 17/301
Reading camera 18/301
Reading camera 19/301
Reading camera 20/301
Reading camera 21/301
Reading camera 22/301
Reading camera 23/301
Reading camera 24/301
Reading camera 25/301
Reading camera 26/301
Reading camera 27/301
Reading camera 28/301
Reading camera 29/301
Reading camera 30/301
Reading camera 31/301
Reading camera 32/301
Reading camera 33/301
Reading camera 34/301
Reading camera 35/301
Reading camera 36/301
Reading camera 37/301
Reading camera 38/301
Reading camera 39/301
Reading camera 40/301
Reading camera 41/301
Reading camera 42/301
Reading camera 43/301
Reading camera 44/301
Reading camera 45/301
Reading camera 46/301
Reading camera 47/301
Reading camera 48/301
Reading camera 49/301
Reading camera 50/301
Reading camera 51/301
Reading camera 52/301
Reading camera 53/301
Reading camera 54/301
Reading camera 55/301
Reading camera 56/301
Reading camera 57/301
Reading camera 58/301
Reading camera 59/301
Reading camera 60/301
Reading camera 61/301
Reading camera 62/301
Reading camera 63/301
Reading camera 64/301
Reading camera 65/301
Reading camera 66/301
Reading camera 67/301
Reading camera 68/301
Reading camera 69/301
Reading camera 70/301
Reading camera 71/301
Reading camera 72/301
Reading camera 73/301
Reading camera 74/301
Reading camera 75/301
Reading camera 76/301
Reading camera 77/301
Reading camera 78/301
Reading camera 79/301
Reading camera 80/301
Reading camera 81/301
Reading camera 82/301
Reading camera 83/301
Reading camera 84/301
Reading camera 85/301
Reading camera 86/301
Reading camera 87/301
Reading camera 88/301
Reading camera 89/301
Reading camera 90/301
Reading camera 91/301
Reading camera 92/301
Reading camera 93/301
Reading camera 94/301
Reading camera 95/301
Reading camera 96/301
Reading camera 97/301
Reading camera 98/301
Reading camera 99/301
Reading camera 100/301
Reading camera 101/301
Reading camera 102/301
Reading camera 103/301
Reading camera 104/301
Reading camera 105/301
Reading camera 106/301
Reading camera 107/301
Reading camera 108/301
Reading camera 109/301
Reading camera 110/301
Reading camera 111/301
Reading camera 112/301
Reading camera 113/301
Reading camera 114/301
Reading camera 115/301
Reading camera 116/301
Reading camera 117/301
Reading camera 118/301
Reading camera 119/301
Reading camera 120/301
Reading camera 121/301
Reading camera 122/301
Reading camera 123/301
Reading camera 124/301
Reading camera 125/301
Reading camera 126/301
Reading camera 127/301
Reading camera 128/301
Reading camera 129/301
Reading camera 130/301
Reading camera 131/301
Reading camera 132/301
Reading camera 133/301
Reading camera 134/301
Reading camera 135/301
Reading camera 136/301
Reading camera 137/301
Reading camera 138/301
Reading camera 139/301
Reading camera 140/301
Reading camera 141/301
Reading camera 142/301
Reading camera 143/301
Reading camera 144/301
Reading camera 145/301
Reading camera 146/301
Reading camera 147/301
Reading camera 148/301
Reading camera 149/301
Reading camera 150/301
Reading camera 151/301
Reading camera 152/301
Reading camera 153/301
Reading camera 154/301
Reading camera 155/301
Reading camera 156/301
Reading camera 157/301
Reading camera 158/301
Reading camera 159/301
Reading camera 160/301
Reading camera 161/301
Reading camera 162/301
Reading camera 163/301
Reading camera 164/301
Reading camera 165/301
Reading camera 166/301
Reading camera 167/301
Reading camera 168/301
Reading camera 169/301
Reading camera 170/301
Reading camera 171/301
Reading camera 172/301
Reading camera 173/301
Reading camera 174/301
Reading camera 175/301
Reading camera 176/301
Reading camera 177/301
Reading camera 178/301
Reading camera 179/301
Reading camera 180/301
Reading camera 181/301
Reading camera 182/301
Reading camera 183/301
Reading camera 184/301
Reading camera 185/301
Reading camera 186/301
Reading camera 187/301
Reading camera 188/301
Reading camera 189/301
Reading camera 190/301
Reading camera 191/301
Reading camera 192/301
Reading camera 193/301
Reading camera 194/301
Reading camera 195/301
Reading camera 196/301
Reading camera 197/301
Reading camera 198/301
Reading camera 199/301
Reading camera 200/301
Reading camera 201/301
Reading camera 202/301
Reading camera 203/301
Reading camera 204/301
Reading camera 205/301
Reading camera 206/301
Reading camera 207/301
Reading camera 208/301
Reading camera 209/301
Reading camera 210/301
Reading camera 211/301
Reading camera 212/301
Reading camera 213/301
Reading camera 214/301
Reading camera 215/301
Reading camera 216/301
Reading camera 217/301
Reading camera 218/301
Reading camera 219/301
Reading camera 220/301
Reading camera 221/301
Reading camera 222/301
Reading camera 223/301
Reading camera 224/301
Reading camera 225/301
Reading camera 226/301
Reading camera 227/301
Reading camera 228/301
Reading camera 229/301
Reading camera 230/301
Reading camera 231/301
Reading camera 232/301
Reading camera 233/301
Reading camera 234/301
Reading camera 235/301
Reading camera 236/301
Reading camera 237/301
Reading camera 238/301
Reading camera 239/301
Reading camera 240/301
Reading camera 241/301
Reading camera 242/301
Reading camera 243/301
Reading camera 244/301
Reading camera 245/301
Reading camera 246/301
Reading camera 247/301
Reading camera 248/301
Reading camera 249/301
Reading camera 250/301
Reading camera 251/301
Reading camera 252/301
Reading camera 253/301
Reading camera 254/301
Reading camera 255/301
Reading camera 256/301
Reading camera 257/301
Reading camera 258/301
Reading camera 259/301
Reading camera 260/301
Reading camera 261/301
Reading camera 262/301
Reading camera 263/301
Reading camera 264/301
Reading camera 265/301
Reading camera 266/301
Reading camera 267/301
Reading camera 268/301
Reading camera 269/301
Reading camera 270/301
Reading camera 271/301
Reading camera 272/301
Reading camera 273/301
Reading camera 274/301
Reading camera 275/301
Reading camera 276/301
Reading camera 277/301
Reading camera 278/301
Reading camera 279/301
Reading camera 280/301
Reading camera 281/301
Reading camera 282/301
Reading camera 283/301
Reading camera 284/301
Reading camera 285/301
Reading camera 286/301
Reading camera 287/301
Reading camera 288/301
Reading camera 289/301
Reading camera 290/301
Reading camera 291/301
Reading camera 292/301
Reading camera 293/301
Reading camera 294/301
Reading camera 295/301
Reading camera 296/301
Reading camera 297/301
Reading camera 298/301
Reading camera 299/301
Reading camera 300/301
Reading camera 301/301 [15/11 00:10:12]
Loading Training Cameras [15/11 00:10:12]
Loading Test Cameras [15/11 00:10:24]
Number of points at initialisation :  182686 [15/11 00:10:26]

Training progress:   0%|          | 0/2000 [00:00<?, ?it/s]/ext3/conda/envs/3dgs/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/ext3/conda/envs/3dgs/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)

Training progress:   0%|          | 0/2000 [00:05<?, ?it/s, Loss=0.0151829, Gaussian number=182686, print grad=6.168858817545697e-06, Depth Loss=0.0000000]
Training progress:   0%|          | 10/2000 [00:05<18:04,  1.84it/s, Loss=0.0151829, Gaussian number=182686, print grad=6.168858817545697e-06, Depth Loss=0.0000000]
Training progress:   0%|          | 10/2000 [00:09<18:04,  1.84it/s, Loss=0.0147060, Gaussian number=182686, print grad=1.6373283870052546e-05, Depth Loss=0.0000000]
Training progress:   1%|          | 20/2000 [00:09<14:31,  2.27it/s, Loss=0.0147060, Gaussian number=182686, print grad=1.6373283870052546e-05, Depth Loss=0.0000000]
Training progress:   1%|          | 20/2000 [00:12<14:31,  2.27it/s, Loss=0.0145987, Gaussian number=182686, print grad=2.5977027689805254e-05, Depth Loss=0.0000000]
Training progress:   2%|▏         | 30/2000 [00:12<13:22,  2.45it/s, Loss=0.0145987, Gaussian number=182686, print grad=2.5977027689805254e-05, Depth Loss=0.0000000]
Training progress:   2%|▏         | 30/2000 [00:16<13:22,  2.45it/s, Loss=0.0157336, Gaussian number=182686, print grad=3.6261972127249464e-05, Depth Loss=0.0000000]
Training progress:   2%|▏         | 40/2000 [00:16<12:47,  2.55it/s, Loss=0.0157336, Gaussian number=182686, print grad=3.6261972127249464e-05, Depth Loss=0.0000000]
Training progress:   2%|▏         | 40/2000 [00:20<12:47,  2.55it/s, Loss=0.0119899, Gaussian number=182686, print grad=4.4182364945299923e-05, Depth Loss=0.0000000]
Training progress:   2%|▎         | 50/2000 [00:20<12:26,  2.61it/s, Loss=0.0119899, Gaussian number=182686, print grad=4.4182364945299923e-05, Depth Loss=0.0000000]
Training progress:   2%|▎         | 50/2000 [00:23<12:26,  2.61it/s, Loss=0.0137702, Gaussian number=182686, print grad=5.654714914271608e-05, Depth Loss=0.0000000] 
Training progress:   3%|▎         | 60/2000 [00:23<12:10,  2.65it/s, Loss=0.0137702, Gaussian number=182686, print grad=5.654714914271608e-05, Depth Loss=0.0000000]
Training progress:   3%|▎         | 60/2000 [00:27<12:10,  2.65it/s, Loss=0.0124068, Gaussian number=182686, print grad=7.252945215441287e-05, Depth Loss=0.0000000]
Training progress:   4%|▎         | 70/2000 [00:27<12:02,  2.67it/s, Loss=0.0124068, Gaussian number=182686, print grad=7.252945215441287e-05, Depth Loss=0.0000000]
Training progress:   4%|▎         | 70/2000 [00:31<12:02,  2.67it/s, Loss=0.0143665, Gaussian number=182686, print grad=8.412954048253596e-05, Depth Loss=0.0000000]
Training progress:   4%|▍         | 80/2000 [00:31<11:54,  2.69it/s, Loss=0.0143665, Gaussian number=182686, print grad=8.412954048253596e-05, Depth Loss=0.0000000]
Training progress:   4%|▍         | 80/2000 [00:34<11:54,  2.69it/s, Loss=0.0123571, Gaussian number=182686, print grad=9.615781891625375e-05, Depth Loss=0.0000000]
Training progress:   4%|▍         | 90/2000 [00:34<11:47,  2.70it/s, Loss=0.0123571, Gaussian number=182686, print grad=9.615781891625375e-05, Depth Loss=0.0000000]
Training progress:   4%|▍         | 90/2000 [00:38<11:47,  2.70it/s, Loss=0.0123492, Gaussian number=182686, print grad=0.00011074960639234632, Depth Loss=0.0000000]
Training progress:   5%|▌         | 100/2000 [00:38<11:42,  2.70it/s, Loss=0.0123492, Gaussian number=182686, print grad=0.00011074960639234632, Depth Loss=0.0000000]
Training progress:   5%|▌         | 100/2000 [00:47<11:42,  2.70it/s, Loss=0.0144323, Gaussian number=182686, print grad=0.00012687039270531386, Depth Loss=0.0000000]
Training progress:   6%|▌         | 110/2000 [00:47<17:11,  1.83it/s, Loss=0.0144323, Gaussian number=182686, print grad=0.00012687039270531386, Depth Loss=0.0000000]
Training progress:   6%|▌         | 110/2000 [00:51<17:11,  1.83it/s, Loss=0.0119663, Gaussian number=182686, print grad=0.00014250044478103518, Depth Loss=0.0000000]
Training progress:   6%|▌         | 120/2000 [00:51<15:23,  2.04it/s, Loss=0.0119663, Gaussian number=182686, print grad=0.00014250044478103518, Depth Loss=0.0000000]
Training progress:   6%|▌         | 120/2000 [00:55<15:23,  2.04it/s, Loss=0.0139744, Gaussian number=182686, print grad=0.00016255889204330742, Depth Loss=0.0000000]
Training progress:   6%|▋         | 130/2000 [00:55<14:08,  2.20it/s, Loss=0.0139744, Gaussian number=182686, print grad=0.00016255889204330742, Depth Loss=0.0000000]
Training progress:   6%|▋         | 130/2000 [00:58<14:08,  2.20it/s, Loss=0.0126893, Gaussian number=182686, print grad=0.00018291773449163884, Depth Loss=0.0000000]
Training progress:   7%|▋         | 140/2000 [00:58<13:15,  2.34it/s, Loss=0.0126893, Gaussian number=182686, print grad=0.00018291773449163884, Depth Loss=0.0000000]
Training progress:   7%|▋         | 140/2000 [01:02<13:15,  2.34it/s, Loss=0.0109924, Gaussian number=182686, print grad=0.00020081627008039504, Depth Loss=0.0000000]
Training progress:   8%|▊         | 150/2000 [01:02<12:35,  2.45it/s, Loss=0.0109924, Gaussian number=182686, print grad=0.00020081627008039504, Depth Loss=0.0000000]
Training progress:   8%|▊         | 150/2000 [01:06<12:35,  2.45it/s, Loss=0.0117401, Gaussian number=182686, print grad=0.00022471195552498102, Depth Loss=0.0000000]
Training progress:   8%|▊         | 160/2000 [01:06<12:06,  2.53it/s, Loss=0.0117401, Gaussian number=182686, print grad=0.00022471195552498102, Depth Loss=0.0000000]
Training progress:   8%|▊         | 160/2000 [01:09<12:06,  2.53it/s, Loss=0.0116009, Gaussian number=182686, print grad=0.0002419488300802186, Depth Loss=0.0000000] 
Training progress:   8%|▊         | 170/2000 [01:09<11:46,  2.59it/s, Loss=0.0116009, Gaussian number=182686, print grad=0.0002419488300802186, Depth Loss=0.0000000]
Training progress:   8%|▊         | 170/2000 [01:13<11:46,  2.59it/s, Loss=0.0102117, Gaussian number=182686, print grad=0.0002633347758091986, Depth Loss=0.0000000]
Training progress:   9%|▉         | 180/2000 [01:13<11:32,  2.63it/s, Loss=0.0102117, Gaussian number=182686, print grad=0.0002633347758091986, Depth Loss=0.0000000]
Training progress:   9%|▉         | 180/2000 [01:17<11:32,  2.63it/s, Loss=0.0128731, Gaussian number=182686, print grad=0.0002810063597280532, Depth Loss=0.0000000]
Training progress:  10%|▉         | 190/2000 [01:17<11:20,  2.66it/s, Loss=0.0128731, Gaussian number=182686, print grad=0.0002810063597280532, Depth Loss=0.0000000]
Training progress:  10%|▉         | 190/2000 [01:20<11:20,  2.66it/s, Loss=0.0115774, Gaussian number=182686, print grad=0.00030332611640915275, Depth Loss=0.0000000]
Training progress:  10%|█         | 200/2000 [01:20<11:10,  2.69it/s, Loss=0.0115774, Gaussian number=182686, print grad=0.00030332611640915275, Depth Loss=0.0000000]
Training progress:  10%|█         | 200/2000 [01:30<11:10,  2.69it/s, Loss=0.0128369, Gaussian number=182686, print grad=0.00032708761864341795, Depth Loss=0.0000000]
Training progress:  10%|█         | 210/2000 [01:30<16:03,  1.86it/s, Loss=0.0128369, Gaussian number=182686, print grad=0.00032708761864341795, Depth Loss=0.0000000]
Training progress:  10%|█         | 210/2000 [01:33<16:03,  1.86it/s, Loss=0.0107120, Gaussian number=182686, print grad=0.0003480276500340551, Depth Loss=0.0000000] 
Training progress:  11%|█         | 220/2000 [01:33<14:24,  2.06it/s, Loss=0.0107120, Gaussian number=182686, print grad=0.0003480276500340551, Depth Loss=0.0000000]
Training progress:  11%|█         | 220/2000 [01:37<14:24,  2.06it/s, Loss=0.0118529, Gaussian number=182686, print grad=0.0003692235331982374, Depth Loss=0.0000000]
Training progress:  12%|█▏        | 230/2000 [01:37<13:15,  2.23it/s, Loss=0.0118529, Gaussian number=182686, print grad=0.0003692235331982374, Depth Loss=0.0000000]
Training progress:  12%|█▏        | 230/2000 [01:41<13:15,  2.23it/s, Loss=0.0142378, Gaussian number=182686, print grad=0.00038995640352368355, Depth Loss=0.0000000]
Training progress:  12%|█▏        | 240/2000 [01:41<12:24,  2.36it/s, Loss=0.0142378, Gaussian number=182686, print grad=0.00038995640352368355, Depth Loss=0.0000000]
Training progress:  12%|█▏        | 240/2000 [01:44<12:24,  2.36it/s, Loss=0.0109562, Gaussian number=182686, print grad=0.0004138745425734669, Depth Loss=0.0000000] 
Training progress:  12%|█▎        | 250/2000 [01:44<11:47,  2.47it/s, Loss=0.0109562, Gaussian number=182686, print grad=0.0004138745425734669, Depth Loss=0.0000000]
Training progress:  12%|█▎        | 250/2000 [01:48<11:47,  2.47it/s, Loss=0.0123339, Gaussian number=182686, print grad=0.000435977999586612, Depth Loss=0.0000000] 
Training progress:  13%|█▎        | 260/2000 [01:48<11:21,  2.55it/s, Loss=0.0123339, Gaussian number=182686, print grad=0.000435977999586612, Depth Loss=0.0000000]
Training progress:  13%|█▎        | 260/2000 [01:51<11:21,  2.55it/s, Loss=0.0091129, Gaussian number=182686, print grad=0.00045898399548605084, Depth Loss=0.0000000]
Training progress:  14%|█▎        | 270/2000 [01:51<11:02,  2.61it/s, Loss=0.0091129, Gaussian number=182686, print grad=0.00045898399548605084, Depth Loss=0.0000000]
Training progress:  14%|█▎        | 270/2000 [01:55<11:02,  2.61it/s, Loss=0.0117456, Gaussian number=182686, print grad=0.00048742469516582787, Depth Loss=0.0000000]
Training progress:  14%|█▍        | 280/2000 [01:55<10:48,  2.65it/s, Loss=0.0117456, Gaussian number=182686, print grad=0.00048742469516582787, Depth Loss=0.0000000]
Training progress:  14%|█▍        | 280/2000 [01:59<10:48,  2.65it/s, Loss=0.0114300, Gaussian number=182686, print grad=0.0005125610041432083, Depth Loss=0.0000000] 
Training progress:  14%|█▍        | 290/2000 [01:59<10:39,  2.67it/s, Loss=0.0114300, Gaussian number=182686, print grad=0.0005125610041432083, Depth Loss=0.0000000]
Training progress:  14%|█▍        | 290/2000 [02:02<10:39,  2.67it/s, Loss=0.0106561, Gaussian number=182686, print grad=0.0005376928602345288, Depth Loss=0.0000000]
Training progress:  15%|█▌        | 300/2000 [02:02<10:30,  2.70it/s, Loss=0.0106561, Gaussian number=182686, print grad=0.0005376928602345288, Depth Loss=0.0000000]
Training progress:  15%|█▌        | 300/2000 [02:12<10:30,  2.70it/s, Loss=0.0090877, Gaussian number=182686, print grad=0.0005659314338117838, Depth Loss=0.0000000]
Training progress:  16%|█▌        | 310/2000 [02:12<15:07,  1.86it/s, Loss=0.0090877, Gaussian number=182686, print grad=0.0005659314338117838, Depth Loss=0.0000000]
Training progress:  16%|█▌        | 310/2000 [02:15<15:07,  1.86it/s, Loss=0.0094393, Gaussian number=182686, print grad=0.0005845587584190071, Depth Loss=0.0000000]
Training progress:  16%|█▌        | 320/2000 [02:15<13:34,  2.06it/s, Loss=0.0094393, Gaussian number=182686, print grad=0.0005845587584190071, Depth Loss=0.0000000]
Training progress:  16%|█▌        | 320/2000 [02:19<13:34,  2.06it/s, Loss=0.0122336, Gaussian number=182686, print grad=0.0006087846704758704, Depth Loss=0.0000000]
Training progress:  16%|█▋        | 330/2000 [02:19<12:28,  2.23it/s, Loss=0.0122336, Gaussian number=182686, print grad=0.0006087846704758704, Depth Loss=0.0000000]
Training progress:  16%|█▋        | 330/2000 [02:22<12:28,  2.23it/s, Loss=0.0092027, Gaussian number=182686, print grad=0.0006353825447149575, Depth Loss=0.0000000]
Training progress:  17%|█▋        | 340/2000 [02:22<11:40,  2.37it/s, Loss=0.0092027, Gaussian number=182686, print grad=0.0006353825447149575, Depth Loss=0.0000000]
Training progress:  17%|█▋        | 340/2000 [02:26<11:40,  2.37it/s, Loss=0.0095096, Gaussian number=182686, print grad=0.0006612539291381836, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 350/2000 [02:26<11:06,  2.47it/s, Loss=0.0095096, Gaussian number=182686, print grad=0.0006612539291381836, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 350/2000 [02:30<11:06,  2.47it/s, Loss=0.0090508, Gaussian number=182686, print grad=0.0006924400222487748, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 360/2000 [02:30<10:42,  2.55it/s, Loss=0.0090508, Gaussian number=182686, print grad=0.0006924400222487748, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 360/2000 [02:33<10:42,  2.55it/s, Loss=0.0092298, Gaussian number=182686, print grad=0.0007202386623248458, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 370/2000 [02:33<10:23,  2.61it/s, Loss=0.0092298, Gaussian number=182686, print grad=0.0007202386623248458, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 370/2000 [02:37<10:23,  2.61it/s, Loss=0.0117610, Gaussian number=182686, print grad=0.0007421522750519216, Depth Loss=0.0000000]
Training progress:  19%|█▉        | 380/2000 [02:37<10:08,  2.66it/s, Loss=0.0117610, Gaussian number=182686, print grad=0.0007421522750519216, Depth Loss=0.0000000]
Training progress:  19%|█▉        | 380/2000 [02:41<10:08,  2.66it/s, Loss=0.0108287, Gaussian number=182686, print grad=0.0007693058578297496, Depth Loss=0.0000000]
Training progress:  20%|█▉        | 390/2000 [02:41<09:57,  2.70it/s, Loss=0.0108287, Gaussian number=182686, print grad=0.0007693058578297496, Depth Loss=0.0000000]
Training progress:  20%|█▉        | 390/2000 [02:44<09:57,  2.70it/s, Loss=0.0127439, Gaussian number=182686, print grad=0.0007941417279653251, Depth Loss=0.0000000]
Training progress:  20%|██        | 400/2000 [02:44<09:48,  2.72it/s, Loss=0.0127439, Gaussian number=182686, print grad=0.0007941417279653251, Depth Loss=0.0000000]
Training progress:  20%|██        | 400/2000 [02:53<09:48,  2.72it/s, Loss=0.0108496, Gaussian number=182686, print grad=0.0008256086730398238, Depth Loss=0.0000000]
Training progress:  20%|██        | 410/2000 [02:53<14:10,  1.87it/s, Loss=0.0108496, Gaussian number=182686, print grad=0.0008256086730398238, Depth Loss=0.0000000]
Training progress:  20%|██        | 410/2000 [02:57<14:10,  1.87it/s, Loss=0.0097535, Gaussian number=182686, print grad=0.000854943529702723, Depth Loss=0.0000000] 
Training progress:  21%|██        | 420/2000 [02:57<12:41,  2.07it/s, Loss=0.0097535, Gaussian number=182686, print grad=0.000854943529702723, Depth Loss=0.0000000]
Training progress:  21%|██        | 420/2000 [03:01<12:41,  2.07it/s, Loss=0.0120613, Gaussian number=182686, print grad=0.0008853731560520828, Depth Loss=0.0000000]
Training progress:  22%|██▏       | 430/2000 [03:01<11:39,  2.24it/s, Loss=0.0120613, Gaussian number=182686, print grad=0.0008853731560520828, Depth Loss=0.0000000]
Training progress:  22%|██▏       | 430/2000 [03:04<11:39,  2.24it/s, Loss=0.0096201, Gaussian number=182686, print grad=0.0009139018948189914, Depth Loss=0.0000000]
Training progress:  22%|██▏       | 440/2000 [03:04<10:58,  2.37it/s, Loss=0.0096201, Gaussian number=182686, print grad=0.0009139018948189914, Depth Loss=0.0000000]
Training progress:  22%|██▏       | 440/2000 [03:08<10:58,  2.37it/s, Loss=0.0106468, Gaussian number=182686, print grad=0.0009442743030376732, Depth Loss=0.0000000]
Training progress:  22%|██▎       | 450/2000 [03:08<10:27,  2.47it/s, Loss=0.0106468, Gaussian number=182686, print grad=0.0009442743030376732, Depth Loss=0.0000000]
Training progress:  22%|██▎       | 450/2000 [03:11<10:27,  2.47it/s, Loss=0.0107816, Gaussian number=182686, print grad=0.000973268412053585, Depth Loss=0.0000000] 
Training progress:  23%|██▎       | 460/2000 [03:11<10:03,  2.55it/s, Loss=0.0107816, Gaussian number=182686, print grad=0.000973268412053585, Depth Loss=0.0000000]
Training progress:  23%|██▎       | 460/2000 [03:15<10:03,  2.55it/s, Loss=0.0129481, Gaussian number=182686, print grad=0.0010001719929277897, Depth Loss=0.0000000]
Training progress:  24%|██▎       | 470/2000 [03:15<09:45,  2.62it/s, Loss=0.0129481, Gaussian number=182686, print grad=0.0010001719929277897, Depth Loss=0.0000000]
Training progress:  24%|██▎       | 470/2000 [03:19<09:45,  2.62it/s, Loss=0.0088524, Gaussian number=182686, print grad=0.001030813786201179, Depth Loss=0.0000000] 
Training progress:  24%|██▍       | 480/2000 [03:19<09:30,  2.66it/s, Loss=0.0088524, Gaussian number=182686, print grad=0.001030813786201179, Depth Loss=0.0000000]
Training progress:  24%|██▍       | 480/2000 [03:22<09:30,  2.66it/s, Loss=0.0093850, Gaussian number=182686, print grad=0.001059174071997404, Depth Loss=0.0000000]
Training progress:  24%|██▍       | 490/2000 [03:22<09:20,  2.70it/s, Loss=0.0093850, Gaussian number=182686, print grad=0.001059174071997404, Depth Loss=0.0000000]
Training progress:  24%|██▍       | 490/2000 [03:26<09:20,  2.70it/s, Loss=0.0076814, Gaussian number=182686, print grad=0.0010879128240048885, Depth Loss=0.0000000]
Training progress:  25%|██▌       | 500/2000 [03:26<09:11,  2.72it/s, Loss=0.0076814, Gaussian number=182686, print grad=0.0010879128240048885, Depth Loss=0.0000000]
Training progress:  25%|██▌       | 500/2000 [03:35<09:11,  2.72it/s, Loss=0.0088818, Gaussian number=182686, print grad=0.0011174235260114074, Depth Loss=0.0000000]
Training progress:  26%|██▌       | 510/2000 [03:35<13:15,  1.87it/s, Loss=0.0088818, Gaussian number=182686, print grad=0.0011174235260114074, Depth Loss=0.0000000]
Training progress:  26%|██▌       | 510/2000 [03:39<13:15,  1.87it/s, Loss=0.0090905, Gaussian number=182686, print grad=0.0011487174779176712, Depth Loss=0.0000000]
Training progress:  26%|██▌       | 520/2000 [03:39<11:52,  2.08it/s, Loss=0.0090905, Gaussian number=182686, print grad=0.0011487174779176712, Depth Loss=0.0000000]
Training progress:  26%|██▌       | 520/2000 [03:42<11:52,  2.08it/s, Loss=0.0074106, Gaussian number=182686, print grad=0.0011748215183615685, Depth Loss=0.0000000]
Training progress:  26%|██▋       | 530/2000 [03:42<10:53,  2.25it/s, Loss=0.0074106, Gaussian number=182686, print grad=0.0011748215183615685, Depth Loss=0.0000000]
Training progress:  26%|██▋       | 530/2000 [03:46<10:53,  2.25it/s, Loss=0.0099577, Gaussian number=182686, print grad=0.0012042414164170623, Depth Loss=0.0000000]
Training progress:  27%|██▋       | 540/2000 [03:46<10:11,  2.39it/s, Loss=0.0099577, Gaussian number=182686, print grad=0.0012042414164170623, Depth Loss=0.0000000]
Training progress:  27%|██▋       | 540/2000 [03:49<10:11,  2.39it/s, Loss=0.0094924, Gaussian number=182686, print grad=0.0012361779808998108, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 550/2000 [03:49<09:41,  2.49it/s, Loss=0.0094924, Gaussian number=182686, print grad=0.0012361779808998108, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 550/2000 [03:53<09:41,  2.49it/s, Loss=0.0077351, Gaussian number=182686, print grad=0.001266532577574253, Depth Loss=0.0000000] 
Training progress:  28%|██▊       | 560/2000 [03:53<09:19,  2.58it/s, Loss=0.0077351, Gaussian number=182686, print grad=0.001266532577574253, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 560/2000 [03:57<09:19,  2.58it/s, Loss=0.0100019, Gaussian number=182686, print grad=0.001300892559811473, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 570/2000 [03:57<09:03,  2.63it/s, Loss=0.0100019, Gaussian number=182686, print grad=0.001300892559811473, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 570/2000 [04:00<09:03,  2.63it/s, Loss=0.0085638, Gaussian number=182686, print grad=0.0013308661291375756, Depth Loss=0.0000000]
Training progress:  29%|██▉       | 580/2000 [04:00<08:51,  2.67it/s, Loss=0.0085638, Gaussian number=182686, print grad=0.0013308661291375756, Depth Loss=0.0000000]
Training progress:  29%|██▉       | 580/2000 [04:04<08:51,  2.67it/s, Loss=0.0096765, Gaussian number=182686, print grad=0.0013623976847156882, Depth Loss=0.0000000]
Training progress:  30%|██▉       | 590/2000 [04:04<08:41,  2.70it/s, Loss=0.0096765, Gaussian number=182686, print grad=0.0013623976847156882, Depth Loss=0.0000000]
Training progress:  30%|██▉       | 590/2000 [04:07<08:41,  2.70it/s, Loss=0.0099224, Gaussian number=182686, print grad=0.0013915237504988909, Depth Loss=0.0000000]
Training progress:  30%|███       | 600/2000 [04:07<08:33,  2.73it/s, Loss=0.0099224, Gaussian number=182686, print grad=0.0013915237504988909, Depth Loss=0.0000000]
Training progress:  30%|███       | 600/2000 [04:17<08:33,  2.73it/s, Loss=0.0084047, Gaussian number=182649, print grad=2.9001386792515405e-05, Depth Loss=0.0000000]
Training progress:  30%|███       | 610/2000 [04:17<12:47,  1.81it/s, Loss=0.0084047, Gaussian number=182649, print grad=2.9001386792515405e-05, Depth Loss=0.0000000]
Training progress:  30%|███       | 610/2000 [04:21<12:47,  1.81it/s, Loss=0.0108257, Gaussian number=182649, print grad=6.192787259351462e-05, Depth Loss=0.0000000] 
Training progress:  31%|███       | 620/2000 [04:21<11:20,  2.03it/s, Loss=0.0108257, Gaussian number=182649, print grad=6.192787259351462e-05, Depth Loss=0.0000000]
Training progress:  31%|███       | 620/2000 [04:24<11:20,  2.03it/s, Loss=0.0079414, Gaussian number=182649, print grad=8.925361908040941e-05, Depth Loss=0.0000000]
Training progress:  32%|███▏      | 630/2000 [04:24<10:19,  2.21it/s, Loss=0.0079414, Gaussian number=182649, print grad=8.925361908040941e-05, Depth Loss=0.0000000]
Training progress:  32%|███▏      | 630/2000 [04:28<10:19,  2.21it/s, Loss=0.0085666, Gaussian number=182649, print grad=0.00012597833119798452, Depth Loss=0.0000000]
Training progress:  32%|███▏      | 640/2000 [04:28<09:36,  2.36it/s, Loss=0.0085666, Gaussian number=182649, print grad=0.00012597833119798452, Depth Loss=0.0000000]
Training progress:  32%|███▏      | 640/2000 [04:32<09:36,  2.36it/s, Loss=0.0097631, Gaussian number=182649, print grad=0.00015320915554184467, Depth Loss=0.0000000]
Training progress:  32%|███▎      | 650/2000 [04:32<09:05,  2.48it/s, Loss=0.0097631, Gaussian number=182649, print grad=0.00015320915554184467, Depth Loss=0.0000000]
Training progress:  32%|███▎      | 650/2000 [04:35<09:05,  2.48it/s, Loss=0.0103352, Gaussian number=182649, print grad=0.0001868629187811166, Depth Loss=0.0000000] 
Training progress:  33%|███▎      | 660/2000 [04:35<08:44,  2.56it/s, Loss=0.0103352, Gaussian number=182649, print grad=0.0001868629187811166, Depth Loss=0.0000000]
Training progress:  33%|███▎      | 660/2000 [04:39<08:44,  2.56it/s, Loss=0.0087979, Gaussian number=182649, print grad=0.00021777897200081497, Depth Loss=0.0000000]
Training progress:  34%|███▎      | 670/2000 [04:39<08:26,  2.62it/s, Loss=0.0087979, Gaussian number=182649, print grad=0.00021777897200081497, Depth Loss=0.0000000]
Training progress:  34%|███▎      | 670/2000 [04:42<08:26,  2.62it/s, Loss=0.0083799, Gaussian number=182649, print grad=0.00025305990129709244, Depth Loss=0.0000000]
Training progress:  34%|███▍      | 680/2000 [04:42<08:13,  2.68it/s, Loss=0.0083799, Gaussian number=182649, print grad=0.00025305990129709244, Depth Loss=0.0000000]
Training progress:  34%|███▍      | 680/2000 [04:46<08:13,  2.68it/s, Loss=0.0098701, Gaussian number=182649, print grad=0.00028377227135933936, Depth Loss=0.0000000]
Training progress:  34%|███▍      | 690/2000 [04:46<08:02,  2.72it/s, Loss=0.0098701, Gaussian number=182649, print grad=0.00028377227135933936, Depth Loss=0.0000000]
Training progress:  34%|███▍      | 690/2000 [04:49<08:02,  2.72it/s, Loss=0.0099279, Gaussian number=182649, print grad=0.0003131440607830882, Depth Loss=0.0000000] 
Training progress:  35%|███▌      | 700/2000 [04:49<07:53,  2.74it/s, Loss=0.0099279, Gaussian number=182649, print grad=0.0003131440607830882, Depth Loss=0.0000000]
Training progress:  35%|███▌      | 700/2000 [04:59<07:53,  2.74it/s, Loss=0.0083699, Gaussian number=182697, print grad=2.6833027732209302e-05, Depth Loss=0.0000000]
Training progress:  36%|███▌      | 710/2000 [04:59<11:24,  1.88it/s, Loss=0.0083699, Gaussian number=182697, print grad=2.6833027732209302e-05, Depth Loss=0.0000000]
Training progress:  36%|███▌      | 710/2000 [05:02<11:24,  1.88it/s, Loss=0.0078146, Gaussian number=182697, print grad=5.8513596741249785e-05, Depth Loss=0.0000000]
Training progress:  36%|███▌      | 720/2000 [05:02<10:11,  2.09it/s, Loss=0.0078146, Gaussian number=182697, print grad=5.8513596741249785e-05, Depth Loss=0.0000000]
Training progress:  36%|███▌      | 720/2000 [05:06<10:11,  2.09it/s, Loss=0.0099518, Gaussian number=182697, print grad=8.735686424188316e-05, Depth Loss=0.0000000] 
Training progress:  36%|███▋      | 730/2000 [05:06<09:21,  2.26it/s, Loss=0.0099518, Gaussian number=182697, print grad=8.735686424188316e-05, Depth Loss=0.0000000]
Training progress:  36%|███▋      | 730/2000 [05:09<09:21,  2.26it/s, Loss=0.0122669, Gaussian number=182697, print grad=0.00012306230200920254, Depth Loss=0.0000000]
Training progress:  37%|███▋      | 740/2000 [05:09<08:44,  2.40it/s, Loss=0.0122669, Gaussian number=182697, print grad=0.00012306230200920254, Depth Loss=0.0000000]
Training progress:  37%|███▋      | 740/2000 [05:13<08:44,  2.40it/s, Loss=0.0088672, Gaussian number=182697, print grad=0.0001569682644912973, Depth Loss=0.0000000] 
Training progress:  38%|███▊      | 750/2000 [05:13<08:17,  2.51it/s, Loss=0.0088672, Gaussian number=182697, print grad=0.0001569682644912973, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 750/2000 [05:16<08:17,  2.51it/s, Loss=0.0082232, Gaussian number=182697, print grad=0.00018920900765806437, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 760/2000 [05:16<07:57,  2.60it/s, Loss=0.0082232, Gaussian number=182697, print grad=0.00018920900765806437, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 760/2000 [05:20<07:57,  2.60it/s, Loss=0.0077858, Gaussian number=182697, print grad=0.00022241767146624625, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 770/2000 [05:20<07:42,  2.66it/s, Loss=0.0077858, Gaussian number=182697, print grad=0.00022241767146624625, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 770/2000 [05:24<07:42,  2.66it/s, Loss=0.0098390, Gaussian number=182697, print grad=0.0002530566125642508, Depth Loss=0.0000000] 
Training progress:  39%|███▉      | 780/2000 [05:24<07:31,  2.70it/s, Loss=0.0098390, Gaussian number=182697, print grad=0.0002530566125642508, Depth Loss=0.0000000]
Training progress:  39%|███▉      | 780/2000 [05:27<07:31,  2.70it/s, Loss=0.0114632, Gaussian number=182697, print grad=0.0002848660515155643, Depth Loss=0.0000000]
Training progress:  40%|███▉      | 790/2000 [05:27<07:22,  2.73it/s, Loss=0.0114632, Gaussian number=182697, print grad=0.0002848660515155643, Depth Loss=0.0000000]
Training progress:  40%|███▉      | 790/2000 [05:31<07:22,  2.73it/s, Loss=0.0097670, Gaussian number=182697, print grad=0.0003200933279003948, Depth Loss=0.0000000]
Training progress:  40%|████      | 800/2000 [05:31<07:15,  2.76it/s, Loss=0.0097670, Gaussian number=182697, print grad=0.0003200933279003948, Depth Loss=0.0000000]
Training progress:  40%|████      | 800/2000 [05:40<07:15,  2.76it/s, Loss=0.0096041, Gaussian number=182749, print grad=3.0090643122093752e-05, Depth Loss=0.0000000]
Training progress:  40%|████      | 810/2000 [05:40<10:30,  1.89it/s, Loss=0.0096041, Gaussian number=182749, print grad=3.0090643122093752e-05, Depth Loss=0.0000000]
Training progress:  40%|████      | 810/2000 [05:43<10:30,  1.89it/s, Loss=0.0093749, Gaussian number=182749, print grad=6.080922685214318e-05, Depth Loss=0.0000000] 
Training progress:  41%|████      | 820/2000 [05:43<09:23,  2.09it/s, Loss=0.0093749, Gaussian number=182749, print grad=6.080922685214318e-05, Depth Loss=0.0000000]
Training progress:  41%|████      | 820/2000 [05:47<09:23,  2.09it/s, Loss=0.0075341, Gaussian number=182749, print grad=9.946530917659402e-05, Depth Loss=0.0000000]
Training progress:  42%|████▏     | 830/2000 [05:47<08:35,  2.27it/s, Loss=0.0075341, Gaussian number=182749, print grad=9.946530917659402e-05, Depth Loss=0.0000000]
Training progress:  42%|████▏     | 830/2000 [05:50<08:35,  2.27it/s, Loss=0.0079193, Gaussian number=182749, print grad=0.0001328782964264974, Depth Loss=0.0000000]
Training progress:  42%|████▏     | 840/2000 [05:50<08:01,  2.41it/s, Loss=0.0079193, Gaussian number=182749, print grad=0.0001328782964264974, Depth Loss=0.0000000]
Training progress:  42%|████▏     | 840/2000 [05:54<08:01,  2.41it/s, Loss=0.0089036, Gaussian number=182749, print grad=0.00016883696662262082, Depth Loss=0.0000000]
Training progress:  42%|████▎     | 850/2000 [05:54<07:36,  2.52it/s, Loss=0.0089036, Gaussian number=182749, print grad=0.00016883696662262082, Depth Loss=0.0000000]
Training progress:  42%|████▎     | 850/2000 [05:58<07:36,  2.52it/s, Loss=0.0082755, Gaussian number=182749, print grad=0.00020153146761003882, Depth Loss=0.0000000]
Training progress:  43%|████▎     | 860/2000 [05:58<07:17,  2.60it/s, Loss=0.0082755, Gaussian number=182749, print grad=0.00020153146761003882, Depth Loss=0.0000000]
Training progress:  43%|████▎     | 860/2000 [06:01<07:17,  2.60it/s, Loss=0.0100169, Gaussian number=182749, print grad=0.0002347772679058835, Depth Loss=0.0000000] 
Training progress:  44%|████▎     | 870/2000 [06:01<07:03,  2.67it/s, Loss=0.0100169, Gaussian number=182749, print grad=0.0002347772679058835, Depth Loss=0.0000000]
Training progress:  44%|████▎     | 870/2000 [06:05<07:03,  2.67it/s, Loss=0.0095495, Gaussian number=182749, print grad=0.0002668382367119193, Depth Loss=0.0000000]
Training progress:  44%|████▍     | 880/2000 [06:05<06:52,  2.71it/s, Loss=0.0095495, Gaussian number=182749, print grad=0.0002668382367119193, Depth Loss=0.0000000]
Training progress:  44%|████▍     | 880/2000 [06:08<06:52,  2.71it/s, Loss=0.0075181, Gaussian number=182749, print grad=0.0003018155402969569, Depth Loss=0.0000000]
Training progress:  44%|████▍     | 890/2000 [06:08<06:43,  2.75it/s, Loss=0.0075181, Gaussian number=182749, print grad=0.0003018155402969569, Depth Loss=0.0000000]
Training progress:  44%|████▍     | 890/2000 [06:12<06:43,  2.75it/s, Loss=0.0093848, Gaussian number=182749, print grad=0.0003340888360980898, Depth Loss=0.0000000]
Training progress:  45%|████▌     | 900/2000 [06:12<06:36,  2.77it/s, Loss=0.0093848, Gaussian number=182749, print grad=0.0003340888360980898, Depth Loss=0.0000000]
Training progress:  45%|████▌     | 900/2000 [06:21<06:36,  2.77it/s, Loss=0.0072768, Gaussian number=182803, print grad=2.965591374959331e-05, Depth Loss=0.0000000]
Training progress:  46%|████▌     | 910/2000 [06:21<09:34,  1.90it/s, Loss=0.0072768, Gaussian number=182803, print grad=2.965591374959331e-05, Depth Loss=0.0000000]
Training progress:  46%|████▌     | 910/2000 [06:24<09:34,  1.90it/s, Loss=0.0089934, Gaussian number=182803, print grad=5.641406460199505e-05, Depth Loss=0.0000000]
Training progress:  46%|████▌     | 920/2000 [06:24<08:33,  2.10it/s, Loss=0.0089934, Gaussian number=182803, print grad=5.641406460199505e-05, Depth Loss=0.0000000]
Training progress:  46%|████▌     | 920/2000 [06:28<08:33,  2.10it/s, Loss=0.0093825, Gaussian number=182803, print grad=9.347886953037232e-05, Depth Loss=0.0000000]
Training progress:  46%|████▋     | 930/2000 [06:28<07:49,  2.28it/s, Loss=0.0093825, Gaussian number=182803, print grad=9.347886953037232e-05, Depth Loss=0.0000000]
Training progress:  46%|████▋     | 930/2000 [06:31<07:49,  2.28it/s, Loss=0.0086289, Gaussian number=182803, print grad=0.0001250257046194747, Depth Loss=0.0000000]
Training progress:  47%|████▋     | 940/2000 [06:31<07:18,  2.42it/s, Loss=0.0086289, Gaussian number=182803, print grad=0.0001250257046194747, Depth Loss=0.0000000]
Training progress:  47%|████▋     | 940/2000 [06:35<07:18,  2.42it/s, Loss=0.0079722, Gaussian number=182803, print grad=0.00015967903891578317, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 950/2000 [06:35<06:55,  2.53it/s, Loss=0.0079722, Gaussian number=182803, print grad=0.00015967903891578317, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 950/2000 [06:39<06:55,  2.53it/s, Loss=0.0083696, Gaussian number=182803, print grad=0.000192196064745076, Depth Loss=0.0000000]  
Training progress:  48%|████▊     | 960/2000 [06:39<06:38,  2.61it/s, Loss=0.0083696, Gaussian number=182803, print grad=0.000192196064745076, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 960/2000 [06:42<06:38,  2.61it/s, Loss=0.0103871, Gaussian number=182803, print grad=0.0002273471764056012, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 970/2000 [06:42<06:25,  2.67it/s, Loss=0.0103871, Gaussian number=182803, print grad=0.0002273471764056012, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 970/2000 [06:46<06:25,  2.67it/s, Loss=0.0072155, Gaussian number=182803, print grad=0.00026102704578079283, Depth Loss=0.0000000]
Training progress:  49%|████▉     | 980/2000 [06:46<06:15,  2.72it/s, Loss=0.0072155, Gaussian number=182803, print grad=0.00026102704578079283, Depth Loss=0.0000000]
Training progress:  49%|████▉     | 980/2000 [06:49<06:15,  2.72it/s, Loss=0.0072455, Gaussian number=182803, print grad=0.00029060663655400276, Depth Loss=0.0000000]
Training progress:  50%|████▉     | 990/2000 [06:49<06:07,  2.75it/s, Loss=0.0072455, Gaussian number=182803, print grad=0.00029060663655400276, Depth Loss=0.0000000]
Training progress:  50%|████▉     | 990/2000 [06:53<06:07,  2.75it/s, Loss=0.0096676, Gaussian number=182803, print grad=0.0003189006238244474, Depth Loss=0.0000000] 
Training progress:  50%|█████     | 1000/2000 [06:53<06:00,  2.77it/s, Loss=0.0096676, Gaussian number=182803, print grad=0.0003189006238244474, Depth Loss=0.0000000]
Training progress:  50%|█████     | 1000/2000 [07:02<06:00,  2.77it/s, Loss=0.0084861, Gaussian number=182861, print grad=2.7522799427970313e-05, Depth Loss=0.0000000]
Training progress:  50%|█████     | 1010/2000 [07:02<08:42,  1.89it/s, Loss=0.0084861, Gaussian number=182861, print grad=2.7522799427970313e-05, Depth Loss=0.0000000]
Training progress:  50%|█████     | 1010/2000 [07:05<08:42,  1.89it/s, Loss=0.0105166, Gaussian number=182861, print grad=6.585806841030717e-05, Depth Loss=0.0000000] 
Training progress:  51%|█████     | 1020/2000 [07:05<07:46,  2.10it/s, Loss=0.0105166, Gaussian number=182861, print grad=6.585806841030717e-05, Depth Loss=0.0000000]
Training progress:  51%|█████     | 1020/2000 [07:09<07:46,  2.10it/s, Loss=0.0088238, Gaussian number=182861, print grad=0.00010079552157549188, Depth Loss=0.0000000]
Training progress:  52%|█████▏    | 1030/2000 [07:09<07:06,  2.27it/s, Loss=0.0088238, Gaussian number=182861, print grad=0.00010079552157549188, Depth Loss=0.0000000]
Training progress:  52%|█████▏    | 1030/2000 [07:13<07:06,  2.27it/s, Loss=0.0092149, Gaussian number=182861, print grad=0.00013806829520035535, Depth Loss=0.0000000]
Training progress:  52%|█████▏    | 1040/2000 [07:13<06:37,  2.42it/s, Loss=0.0092149, Gaussian number=182861, print grad=0.00013806829520035535, Depth Loss=0.0000000]
Training progress:  52%|█████▏    | 1040/2000 [07:16<06:37,  2.42it/s, Loss=0.0084445, Gaussian number=182861, print grad=0.0001674122759141028, Depth Loss=0.0000000] 
Training progress:  52%|█████▎    | 1050/2000 [07:16<06:16,  2.53it/s, Loss=0.0084445, Gaussian number=182861, print grad=0.0001674122759141028, Depth Loss=0.0000000]
Training progress:  52%|█████▎    | 1050/2000 [07:20<06:16,  2.53it/s, Loss=0.0083224, Gaussian number=182861, print grad=0.00020009360741823912, Depth Loss=0.0000000]
Training progress:  53%|█████▎    | 1060/2000 [07:20<06:00,  2.61it/s, Loss=0.0083224, Gaussian number=182861, print grad=0.00020009360741823912, Depth Loss=0.0000000]
Training progress:  53%|█████▎    | 1060/2000 [07:23<06:00,  2.61it/s, Loss=0.0068753, Gaussian number=182861, print grad=0.00023783771030139178, Depth Loss=0.0000000]
Training progress:  54%|█████▎    | 1070/2000 [07:23<05:48,  2.67it/s, Loss=0.0068753, Gaussian number=182861, print grad=0.00023783771030139178, Depth Loss=0.0000000]
Training progress:  54%|█████▎    | 1070/2000 [07:27<05:48,  2.67it/s, Loss=0.0073073, Gaussian number=182861, print grad=0.00026971352053806186, Depth Loss=0.0000000]
Training progress:  54%|█████▍    | 1080/2000 [07:27<05:38,  2.71it/s, Loss=0.0073073, Gaussian number=182861, print grad=0.00026971352053806186, Depth Loss=0.0000000]
Training progress:  54%|█████▍    | 1080/2000 [07:30<05:38,  2.71it/s, Loss=0.0089991, Gaussian number=182861, print grad=0.000305473426124081, Depth Loss=0.0000000]  
Training progress:  55%|█████▍    | 1090/2000 [07:30<05:31,  2.75it/s, Loss=0.0089991, Gaussian number=182861, print grad=0.000305473426124081, Depth Loss=0.0000000]
Training progress:  55%|█████▍    | 1090/2000 [07:34<05:31,  2.75it/s, Loss=0.0089197, Gaussian number=182861, print grad=0.00033997511491179466, Depth Loss=0.0000000]
Training progress:  55%|█████▌    | 1100/2000 [07:34<05:25,  2.77it/s, Loss=0.0089197, Gaussian number=182861, print grad=0.00033997511491179466, Depth Loss=0.0000000]
Training progress:  55%|█████▌    | 1100/2000 [07:37<05:25,  2.77it/s, Loss=0.0093714, Gaussian number=182917, print grad=2.9082017135806382e-05, Depth Loss=0.0000000]
Training progress:  56%|█████▌    | 1110/2000 [07:37<05:19,  2.78it/s, Loss=0.0093714, Gaussian number=182917, print grad=2.9082017135806382e-05, Depth Loss=0.0000000]
Training progress:  56%|█████▌    | 1110/2000 [07:41<05:19,  2.78it/s, Loss=0.0088267, Gaussian number=182917, print grad=6.452073284890503e-05, Depth Loss=0.0000000] 
Training progress:  56%|█████▌    | 1120/2000 [07:41<05:15,  2.79it/s, Loss=0.0088267, Gaussian number=182917, print grad=6.452073284890503e-05, Depth Loss=0.0000000]
Training progress:  56%|█████▌    | 1120/2000 [07:44<05:15,  2.79it/s, Loss=0.0071863, Gaussian number=182917, print grad=0.00010223727440461516, Depth Loss=0.0000000]
Training progress:  56%|█████▋    | 1130/2000 [07:44<05:10,  2.80it/s, Loss=0.0071863, Gaussian number=182917, print grad=0.00010223727440461516, Depth Loss=0.0000000]
Training progress:  56%|█████▋    | 1130/2000 [07:48<05:10,  2.80it/s, Loss=0.0087078, Gaussian number=182917, print grad=0.00013809086522087455, Depth Loss=0.0000000]
Training progress:  57%|█████▋    | 1140/2000 [07:48<05:06,  2.81it/s, Loss=0.0087078, Gaussian number=182917, print grad=0.00013809086522087455, Depth Loss=0.0000000]
Training progress:  57%|█████▋    | 1140/2000 [07:52<05:06,  2.81it/s, Loss=0.0065383, Gaussian number=182917, print grad=0.00017472528270445764, Depth Loss=0.0000000]
Training progress:  57%|█████▊    | 1150/2000 [07:52<05:02,  2.81it/s, Loss=0.0065383, Gaussian number=182917, print grad=0.00017472528270445764, Depth Loss=0.0000000]
Training progress:  57%|█████▊    | 1150/2000 [07:55<05:02,  2.81it/s, Loss=0.0069893, Gaussian number=182917, print grad=0.0002047469315584749, Depth Loss=0.0000000] 
Training progress:  58%|█████▊    | 1160/2000 [07:55<04:58,  2.81it/s, Loss=0.0069893, Gaussian number=182917, print grad=0.0002047469315584749, Depth Loss=0.0000000]
Training progress:  58%|█████▊    | 1160/2000 [07:59<04:58,  2.81it/s, Loss=0.0084984, Gaussian number=182917, print grad=0.0002394910407019779, Depth Loss=0.0000000]
Training progress:  58%|█████▊    | 1170/2000 [07:59<04:54,  2.82it/s, Loss=0.0084984, Gaussian number=182917, print grad=0.0002394910407019779, Depth Loss=0.0000000]
Training progress:  58%|█████▊    | 1170/2000 [08:02<04:54,  2.82it/s, Loss=0.0086547, Gaussian number=182917, print grad=0.0002757831825874746, Depth Loss=0.0000000]
Training progress:  59%|█████▉    | 1180/2000 [08:02<04:51,  2.82it/s, Loss=0.0086547, Gaussian number=182917, print grad=0.0002757831825874746, Depth Loss=0.0000000]
Training progress:  59%|█████▉    | 1180/2000 [08:06<04:51,  2.82it/s, Loss=0.0084603, Gaussian number=182917, print grad=0.0003123768838122487, Depth Loss=0.0000000]
Training progress:  60%|█████▉    | 1190/2000 [08:06<04:47,  2.82it/s, Loss=0.0084603, Gaussian number=182917, print grad=0.0003123768838122487, Depth Loss=0.0000000]
Training progress:  60%|█████▉    | 1190/2000 [08:09<04:47,  2.82it/s, Loss=0.0094161, Gaussian number=182917, print grad=0.00034207748831249774, Depth Loss=0.0000000]
Training progress:  60%|██████    | 1200/2000 [08:09<04:43,  2.82it/s, Loss=0.0094161, Gaussian number=182917, print grad=0.00034207748831249774, Depth Loss=0.0000000]
Training progress:  60%|██████    | 1200/2000 [08:13<04:43,  2.82it/s, Loss=0.0074739, Gaussian number=182976, print grad=3.290763561381027e-05, Depth Loss=0.0000000] 
Training progress:  60%|██████    | 1210/2000 [08:13<04:40,  2.82it/s, Loss=0.0074739, Gaussian number=182976, print grad=3.290763561381027e-05, Depth Loss=0.0000000]
Training progress:  60%|██████    | 1210/2000 [08:16<04:40,  2.82it/s, Loss=0.0064455, Gaussian number=182976, print grad=7.1003581979312e-05, Depth Loss=0.0000000]  
Training progress:  61%|██████    | 1220/2000 [08:16<04:36,  2.82it/s, Loss=0.0064455, Gaussian number=182976, print grad=7.1003581979312e-05, Depth Loss=0.0000000]
Training progress:  61%|██████    | 1220/2000 [08:20<04:36,  2.82it/s, Loss=0.0069631, Gaussian number=182976, print grad=0.00010458450560690835, Depth Loss=0.0000000]
Training progress:  62%|██████▏   | 1230/2000 [08:20<04:32,  2.82it/s, Loss=0.0069631, Gaussian number=182976, print grad=0.00010458450560690835, Depth Loss=0.0000000]
Training progress:  62%|██████▏   | 1230/2000 [08:23<04:32,  2.82it/s, Loss=0.0067157, Gaussian number=182976, print grad=0.0001424233487341553, Depth Loss=0.0000000] 
Training progress:  62%|██████▏   | 1240/2000 [08:23<04:28,  2.83it/s, Loss=0.0067157, Gaussian number=182976, print grad=0.0001424233487341553, Depth Loss=0.0000000]
Training progress:  62%|██████▏   | 1240/2000 [08:27<04:28,  2.83it/s, Loss=0.0068156, Gaussian number=182976, print grad=0.00017343569197691977, Depth Loss=0.0000000]
Training progress:  62%|██████▎   | 1250/2000 [08:27<04:25,  2.83it/s, Loss=0.0068156, Gaussian number=182976, print grad=0.00017343569197691977, Depth Loss=0.0000000]
Training progress:  62%|██████▎   | 1250/2000 [08:30<04:25,  2.83it/s, Loss=0.0070948, Gaussian number=182976, print grad=0.00020375561143737286, Depth Loss=0.0000000]
Training progress:  63%|██████▎   | 1260/2000 [08:30<04:21,  2.83it/s, Loss=0.0070948, Gaussian number=182976, print grad=0.00020375561143737286, Depth Loss=0.0000000]
Training progress:  63%|██████▎   | 1260/2000 [08:34<04:21,  2.83it/s, Loss=0.0083993, Gaussian number=182976, print grad=0.00024001493875402957, Depth Loss=0.0000000]
Training progress:  64%|██████▎   | 1270/2000 [08:34<04:18,  2.83it/s, Loss=0.0083993, Gaussian number=182976, print grad=0.00024001493875402957, Depth Loss=0.0000000]
Training progress:  64%|██████▎   | 1270/2000 [08:38<04:18,  2.83it/s, Loss=0.0087300, Gaussian number=182976, print grad=0.00027167031657882035, Depth Loss=0.0000000]
Training progress:  64%|██████▍   | 1280/2000 [08:38<04:14,  2.83it/s, Loss=0.0087300, Gaussian number=182976, print grad=0.00027167031657882035, Depth Loss=0.0000000]
Training progress:  64%|██████▍   | 1280/2000 [08:41<04:14,  2.83it/s, Loss=0.0068375, Gaussian number=182976, print grad=0.0003089509264100343, Depth Loss=0.0000000] 
Training progress:  64%|██████▍   | 1290/2000 [08:41<04:11,  2.83it/s, Loss=0.0068375, Gaussian number=182976, print grad=0.0003089509264100343, Depth Loss=0.0000000]
Training progress:  64%|██████▍   | 1290/2000 [08:45<04:11,  2.83it/s, Loss=0.0102003, Gaussian number=182976, print grad=0.0003418301057536155, Depth Loss=0.0000000]
Training progress:  65%|██████▌   | 1300/2000 [08:45<04:07,  2.83it/s, Loss=0.0102003, Gaussian number=182976, print grad=0.0003418301057536155, Depth Loss=0.0000000]
Training progress:  65%|██████▌   | 1300/2000 [08:48<04:07,  2.83it/s, Loss=0.0093153, Gaussian number=183023, print grad=3.529907553456724e-05, Depth Loss=0.0000000]
Training progress:  66%|██████▌   | 1310/2000 [08:48<04:04,  2.82it/s, Loss=0.0093153, Gaussian number=183023, print grad=3.529907553456724e-05, Depth Loss=0.0000000]
Training progress:  66%|██████▌   | 1310/2000 [08:52<04:04,  2.82it/s, Loss=0.0092844, Gaussian number=183023, print grad=6.855663377791643e-05, Depth Loss=0.0000000]
Training progress:  66%|██████▌   | 1320/2000 [08:52<04:01,  2.82it/s, Loss=0.0092844, Gaussian number=183023, print grad=6.855663377791643e-05, Depth Loss=0.0000000]
Training progress:  66%|██████▌   | 1320/2000 [08:55<04:01,  2.82it/s, Loss=0.0072218, Gaussian number=183023, print grad=0.00010442372877150774, Depth Loss=0.0000000]
Training progress:  66%|██████▋   | 1330/2000 [08:55<03:57,  2.82it/s, Loss=0.0072218, Gaussian number=183023, print grad=0.00010442372877150774, Depth Loss=0.0000000]
Training progress:  66%|██████▋   | 1330/2000 [08:59<03:57,  2.82it/s, Loss=0.0080446, Gaussian number=183023, print grad=0.0001402756170136854, Depth Loss=0.0000000] 
Training progress:  67%|██████▋   | 1340/2000 [08:59<03:54,  2.82it/s, Loss=0.0080446, Gaussian number=183023, print grad=0.0001402756170136854, Depth Loss=0.0000000]
Training progress:  67%|██████▋   | 1340/2000 [09:02<03:54,  2.82it/s, Loss=0.0105323, Gaussian number=183023, print grad=0.00016996920749079436, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1350/2000 [09:02<03:50,  2.82it/s, Loss=0.0105323, Gaussian number=183023, print grad=0.00016996920749079436, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1350/2000 [09:06<03:50,  2.82it/s, Loss=0.0064956, Gaussian number=183023, print grad=0.00020236203272361308, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1360/2000 [09:06<03:47,  2.82it/s, Loss=0.0064956, Gaussian number=183023, print grad=0.00020236203272361308, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1360/2000 [09:09<03:47,  2.82it/s, Loss=0.0115016, Gaussian number=183023, print grad=0.00024123323964886367, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1370/2000 [09:09<03:43,  2.82it/s, Loss=0.0115016, Gaussian number=183023, print grad=0.00024123323964886367, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1370/2000 [09:13<03:43,  2.82it/s, Loss=0.0077926, Gaussian number=183023, print grad=0.0002740290074143559, Depth Loss=0.0000000] 
Training progress:  69%|██████▉   | 1380/2000 [09:13<03:40,  2.82it/s, Loss=0.0077926, Gaussian number=183023, print grad=0.0002740290074143559, Depth Loss=0.0000000]
Training progress:  69%|██████▉   | 1380/2000 [09:17<03:40,  2.82it/s, Loss=0.0073457, Gaussian number=183023, print grad=0.00030693417647853494, Depth Loss=0.0000000]
Training progress:  70%|██████▉   | 1390/2000 [09:17<03:36,  2.82it/s, Loss=0.0073457, Gaussian number=183023, print grad=0.00030693417647853494, Depth Loss=0.0000000]
Training progress:  70%|██████▉   | 1390/2000 [09:20<03:36,  2.82it/s, Loss=0.0080238, Gaussian number=183023, print grad=0.0003417077532503754, Depth Loss=0.0000000] 
Training progress:  70%|███████   | 1400/2000 [09:20<03:33,  2.82it/s, Loss=0.0080238, Gaussian number=183023, print grad=0.0003417077532503754, Depth Loss=0.0000000]
Training progress:  70%|███████   | 1400/2000 [09:24<03:33,  2.82it/s, Loss=0.0087661, Gaussian number=183093, print grad=3.650307553471066e-05, Depth Loss=0.0000000]
Training progress:  70%|███████   | 1410/2000 [09:24<03:29,  2.81it/s, Loss=0.0087661, Gaussian number=183093, print grad=3.650307553471066e-05, Depth Loss=0.0000000]
Training progress:  70%|███████   | 1410/2000 [09:27<03:29,  2.81it/s, Loss=0.0077934, Gaussian number=183093, print grad=7.181432738434523e-05, Depth Loss=0.0000000]
Training progress:  71%|███████   | 1420/2000 [09:27<03:26,  2.81it/s, Loss=0.0077934, Gaussian number=183093, print grad=7.181432738434523e-05, Depth Loss=0.0000000]
Training progress:  71%|███████   | 1420/2000 [09:31<03:26,  2.81it/s, Loss=0.0076097, Gaussian number=183093, print grad=0.00011186234769411385, Depth Loss=0.0000000]
Training progress:  72%|███████▏  | 1430/2000 [09:31<03:22,  2.81it/s, Loss=0.0076097, Gaussian number=183093, print grad=0.00011186234769411385, Depth Loss=0.0000000]
Training progress:  72%|███████▏  | 1430/2000 [09:34<03:22,  2.81it/s, Loss=0.0075941, Gaussian number=183093, print grad=0.00014370855933520943, Depth Loss=0.0000000]
Training progress:  72%|███████▏  | 1440/2000 [09:34<03:19,  2.81it/s, Loss=0.0075941, Gaussian number=183093, print grad=0.00014370855933520943, Depth Loss=0.0000000]
Training progress:  72%|███████▏  | 1440/2000 [09:38<03:19,  2.81it/s, Loss=0.0066125, Gaussian number=183093, print grad=0.0001764767657732591, Depth Loss=0.0000000] 
Training progress:  72%|███████▎  | 1450/2000 [09:38<03:15,  2.81it/s, Loss=0.0066125, Gaussian number=183093, print grad=0.0001764767657732591, Depth Loss=0.0000000]
Training progress:  72%|███████▎  | 1450/2000 [09:41<03:15,  2.81it/s, Loss=0.0061173, Gaussian number=183093, print grad=0.00021128292428329587, Depth Loss=0.0000000]
Training progress:  73%|███████▎  | 1460/2000 [09:41<03:11,  2.81it/s, Loss=0.0061173, Gaussian number=183093, print grad=0.00021128292428329587, Depth Loss=0.0000000]
Training progress:  73%|███████▎  | 1460/2000 [09:45<03:11,  2.81it/s, Loss=0.0082539, Gaussian number=183093, print grad=0.00024673156440258026, Depth Loss=0.0000000]
Training progress:  74%|███████▎  | 1470/2000 [09:45<03:08,  2.81it/s, Loss=0.0082539, Gaussian number=183093, print grad=0.00024673156440258026, Depth Loss=0.0000000]
Training progress:  74%|███████▎  | 1470/2000 [09:49<03:08,  2.81it/s, Loss=0.0082173, Gaussian number=183093, print grad=0.00028373152599669993, Depth Loss=0.0000000]
Training progress:  74%|███████▍  | 1480/2000 [09:49<03:04,  2.81it/s, Loss=0.0082173, Gaussian number=183093, print grad=0.00028373152599669993, Depth Loss=0.0000000]
Training progress:  74%|███████▍  | 1480/2000 [09:52<03:04,  2.81it/s, Loss=0.0087223, Gaussian number=183093, print grad=0.0003201976069249213, Depth Loss=0.0000000] 
Training progress:  74%|███████▍  | 1490/2000 [09:52<03:01,  2.81it/s, Loss=0.0087223, Gaussian number=183093, print grad=0.0003201976069249213, Depth Loss=0.0000000]
Training progress:  74%|███████▍  | 1490/2000 [09:56<03:01,  2.81it/s, Loss=0.0082803, Gaussian number=183093, print grad=0.0003565252118278295, Depth Loss=0.0000000]
Training progress:  75%|███████▌  | 1500/2000 [09:56<02:57,  2.81it/s, Loss=0.0082803, Gaussian number=183093, print grad=0.0003565252118278295, Depth Loss=0.0000000]
Training progress:  75%|███████▌  | 1500/2000 [10:05<02:57,  2.81it/s, Loss=0.0093300, Gaussian number=183146, print grad=3.2079671655083075e-05, Depth Loss=0.0000000]
Training progress:  76%|███████▌  | 1510/2000 [10:05<04:16,  1.91it/s, Loss=0.0093300, Gaussian number=183146, print grad=3.2079671655083075e-05, Depth Loss=0.0000000]
Training progress:  76%|███████▌  | 1510/2000 [10:08<04:16,  1.91it/s, Loss=0.0080607, Gaussian number=183146, print grad=6.453530659200624e-05, Depth Loss=0.0000000] 
Training progress:  76%|███████▌  | 1520/2000 [10:08<03:47,  2.11it/s, Loss=0.0080607, Gaussian number=183146, print grad=6.453530659200624e-05, Depth Loss=0.0000000]
Training progress:  76%|███████▌  | 1520/2000 [10:12<03:47,  2.11it/s, Loss=0.0051867, Gaussian number=183146, print grad=0.00010429234680486843, Depth Loss=0.0000000]
Training progress:  76%|███████▋  | 1530/2000 [10:12<03:25,  2.28it/s, Loss=0.0051867, Gaussian number=183146, print grad=0.00010429234680486843, Depth Loss=0.0000000]
Training progress:  76%|███████▋  | 1530/2000 [10:16<03:25,  2.28it/s, Loss=0.0069206, Gaussian number=183146, print grad=0.0001408796670148149, Depth Loss=0.0000000] 
Training progress:  77%|███████▋  | 1540/2000 [10:16<03:10,  2.42it/s, Loss=0.0069206, Gaussian number=183146, print grad=0.0001408796670148149, Depth Loss=0.0000000]
Training progress:  77%|███████▋  | 1540/2000 [10:19<03:10,  2.42it/s, Loss=0.0077319, Gaussian number=183146, print grad=0.0001775481941876933, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1550/2000 [10:19<02:58,  2.53it/s, Loss=0.0077319, Gaussian number=183146, print grad=0.0001775481941876933, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1550/2000 [10:23<02:58,  2.53it/s, Loss=0.0082070, Gaussian number=183146, print grad=0.00021750712767243385, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1560/2000 [10:23<02:48,  2.61it/s, Loss=0.0082070, Gaussian number=183146, print grad=0.00021750712767243385, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1560/2000 [10:26<02:48,  2.61it/s, Loss=0.0071956, Gaussian number=183146, print grad=0.0002565520699135959, Depth Loss=0.0000000] 
Training progress:  78%|███████▊  | 1570/2000 [10:26<02:41,  2.66it/s, Loss=0.0071956, Gaussian number=183146, print grad=0.0002565520699135959, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1570/2000 [10:30<02:41,  2.66it/s, Loss=0.0054477, Gaussian number=183146, print grad=0.00028709860634990036, Depth Loss=0.0000000]
Training progress:  79%|███████▉  | 1580/2000 [10:30<02:35,  2.70it/s, Loss=0.0054477, Gaussian number=183146, print grad=0.00028709860634990036, Depth Loss=0.0000000]
Training progress:  79%|███████▉  | 1580/2000 [10:33<02:35,  2.70it/s, Loss=0.0077928, Gaussian number=183146, print grad=0.00032077019568532705, Depth Loss=0.0000000]
Training progress:  80%|███████▉  | 1590/2000 [10:33<02:29,  2.74it/s, Loss=0.0077928, Gaussian number=183146, print grad=0.00032077019568532705, Depth Loss=0.0000000]
Training progress:  80%|███████▉  | 1590/2000 [10:37<02:29,  2.74it/s, Loss=0.0071683, Gaussian number=183146, print grad=0.00035892738378606737, Depth Loss=0.0000000]
Training progress:  80%|████████  | 1600/2000 [10:37<02:24,  2.76it/s, Loss=0.0071683, Gaussian number=183146, print grad=0.00035892738378606737, Depth Loss=0.0000000]
Training progress:  80%|████████  | 1600/2000 [10:40<02:24,  2.76it/s, Loss=0.0078110, Gaussian number=183206, print grad=3.61029633495491e-05, Depth Loss=0.0000000]  
Training progress:  80%|████████  | 1610/2000 [10:40<02:20,  2.78it/s, Loss=0.0078110, Gaussian number=183206, print grad=3.61029633495491e-05, Depth Loss=0.0000000]
Training progress:  80%|████████  | 1610/2000 [10:44<02:20,  2.78it/s, Loss=0.0080209, Gaussian number=183206, print grad=7.771565287839621e-05, Depth Loss=0.0000000]
Training progress:  81%|████████  | 1620/2000 [10:44<02:16,  2.79it/s, Loss=0.0080209, Gaussian number=183206, print grad=7.771565287839621e-05, Depth Loss=0.0000000]
Training progress:  81%|████████  | 1620/2000 [10:47<02:16,  2.79it/s, Loss=0.0071402, Gaussian number=183206, print grad=0.00011377968621673062, Depth Loss=0.0000000]
Training progress:  82%|████████▏ | 1630/2000 [10:47<02:12,  2.80it/s, Loss=0.0071402, Gaussian number=183206, print grad=0.00011377968621673062, Depth Loss=0.0000000]
Training progress:  82%|████████▏ | 1630/2000 [10:51<02:12,  2.80it/s, Loss=0.0055078, Gaussian number=183206, print grad=0.00015009130584076047, Depth Loss=0.0000000]
Training progress:  82%|████████▏ | 1640/2000 [10:51<02:08,  2.81it/s, Loss=0.0055078, Gaussian number=183206, print grad=0.00015009130584076047, Depth Loss=0.0000000]
Training progress:  82%|████████▏ | 1640/2000 [10:55<02:08,  2.81it/s, Loss=0.0071118, Gaussian number=183206, print grad=0.0001857298775576055, Depth Loss=0.0000000] 
Training progress:  82%|████████▎ | 1650/2000 [10:55<02:04,  2.81it/s, Loss=0.0071118, Gaussian number=183206, print grad=0.0001857298775576055, Depth Loss=0.0000000]
Training progress:  82%|████████▎ | 1650/2000 [10:58<02:04,  2.81it/s, Loss=0.0069473, Gaussian number=183206, print grad=0.00021956232376396656, Depth Loss=0.0000000]
Training progress:  83%|████████▎ | 1660/2000 [10:58<02:00,  2.82it/s, Loss=0.0069473, Gaussian number=183206, print grad=0.00021956232376396656, Depth Loss=0.0000000]
Training progress:  83%|████████▎ | 1660/2000 [11:02<02:00,  2.82it/s, Loss=0.0067189, Gaussian number=183206, print grad=0.0002545398019719869, Depth Loss=0.0000000] 
Training progress:  84%|████████▎ | 1670/2000 [11:02<01:57,  2.82it/s, Loss=0.0067189, Gaussian number=183206, print grad=0.0002545398019719869, Depth Loss=0.0000000]
Training progress:  84%|████████▎ | 1670/2000 [11:05<01:57,  2.82it/s, Loss=0.0062240, Gaussian number=183206, print grad=0.0002900008112192154, Depth Loss=0.0000000]
Training progress:  84%|████████▍ | 1680/2000 [11:05<01:53,  2.82it/s, Loss=0.0062240, Gaussian number=183206, print grad=0.0002900008112192154, Depth Loss=0.0000000]
Training progress:  84%|████████▍ | 1680/2000 [11:09<01:53,  2.82it/s, Loss=0.0072333, Gaussian number=183206, print grad=0.00032771736732684076, Depth Loss=0.0000000]
Training progress:  84%|████████▍ | 1690/2000 [11:09<01:49,  2.82it/s, Loss=0.0072333, Gaussian number=183206, print grad=0.00032771736732684076, Depth Loss=0.0000000]
Training progress:  84%|████████▍ | 1690/2000 [11:12<01:49,  2.82it/s, Loss=0.0078423, Gaussian number=183206, print grad=0.00036164504126645625, Depth Loss=0.0000000]
Training progress:  85%|████████▌ | 1700/2000 [11:12<01:46,  2.82it/s, Loss=0.0078423, Gaussian number=183206, print grad=0.00036164504126645625, Depth Loss=0.0000000]
Training progress:  85%|████████▌ | 1700/2000 [11:16<01:46,  2.82it/s, Loss=0.0079138, Gaussian number=183297, print grad=3.8370613765437156e-05, Depth Loss=0.0000000]
Training progress:  86%|████████▌ | 1710/2000 [11:16<01:42,  2.82it/s, Loss=0.0079138, Gaussian number=183297, print grad=3.8370613765437156e-05, Depth Loss=0.0000000]
Training progress:  86%|████████▌ | 1710/2000 [11:19<01:42,  2.82it/s, Loss=0.0080530, Gaussian number=183297, print grad=7.032302528386936e-05, Depth Loss=0.0000000] 
Training progress:  86%|████████▌ | 1720/2000 [11:19<01:39,  2.82it/s, Loss=0.0080530, Gaussian number=183297, print grad=7.032302528386936e-05, Depth Loss=0.0000000]
Training progress:  86%|████████▌ | 1720/2000 [11:23<01:39,  2.82it/s, Loss=0.0076939, Gaussian number=183297, print grad=0.00010599575034575537, Depth Loss=0.0000000]
Training progress:  86%|████████▋ | 1730/2000 [11:23<01:35,  2.82it/s, Loss=0.0076939, Gaussian number=183297, print grad=0.00010599575034575537, Depth Loss=0.0000000]
Training progress:  86%|████████▋ | 1730/2000 [11:26<01:35,  2.82it/s, Loss=0.0093400, Gaussian number=183297, print grad=0.00014468103472609073, Depth Loss=0.0000000]
Training progress:  87%|████████▋ | 1740/2000 [11:26<01:32,  2.82it/s, Loss=0.0093400, Gaussian number=183297, print grad=0.00014468103472609073, Depth Loss=0.0000000]
Training progress:  87%|████████▋ | 1740/2000 [11:30<01:32,  2.82it/s, Loss=0.0090149, Gaussian number=183297, print grad=0.00018326110148336738, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1750/2000 [11:30<01:28,  2.81it/s, Loss=0.0090149, Gaussian number=183297, print grad=0.00018326110148336738, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1750/2000 [11:34<01:28,  2.81it/s, Loss=0.0077648, Gaussian number=183297, print grad=0.0002199041482526809, Depth Loss=0.0000000] 
Training progress:  88%|████████▊ | 1760/2000 [11:34<01:25,  2.81it/s, Loss=0.0077648, Gaussian number=183297, print grad=0.0002199041482526809, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1760/2000 [11:37<01:25,  2.81it/s, Loss=0.0063014, Gaussian number=183297, print grad=0.00025353027740493417, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1770/2000 [11:37<01:21,  2.82it/s, Loss=0.0063014, Gaussian number=183297, print grad=0.00025353027740493417, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1770/2000 [11:41<01:21,  2.82it/s, Loss=0.0073604, Gaussian number=183297, print grad=0.00028777922852896154, Depth Loss=0.0000000]
Training progress:  89%|████████▉ | 1780/2000 [11:41<01:17,  2.82it/s, Loss=0.0073604, Gaussian number=183297, print grad=0.00028777922852896154, Depth Loss=0.0000000]
Training progress:  89%|████████▉ | 1780/2000 [11:44<01:17,  2.82it/s, Loss=0.0069288, Gaussian number=183297, print grad=0.00031761827995069325, Depth Loss=0.0000000]
Training progress:  90%|████████▉ | 1790/2000 [11:44<01:14,  2.82it/s, Loss=0.0069288, Gaussian number=183297, print grad=0.00031761827995069325, Depth Loss=0.0000000]
Training progress:  90%|████████▉ | 1790/2000 [11:48<01:14,  2.82it/s, Loss=0.0070722, Gaussian number=183297, print grad=0.00035631979699246585, Depth Loss=0.0000000]
Training progress:  90%|█████████ | 1800/2000 [11:48<01:10,  2.83it/s, Loss=0.0070722, Gaussian number=183297, print grad=0.00035631979699246585, Depth Loss=0.0000000]
Training progress:  90%|█████████ | 1800/2000 [11:51<01:10,  2.83it/s, Loss=0.0073599, Gaussian number=183365, print grad=3.477449354249984e-05, Depth Loss=0.0000000] 
Training progress:  90%|█████████ | 1810/2000 [11:51<01:07,  2.82it/s, Loss=0.0073599, Gaussian number=183365, print grad=3.477449354249984e-05, Depth Loss=0.0000000]
Training progress:  90%|█████████ | 1810/2000 [11:55<01:07,  2.82it/s, Loss=0.0067789, Gaussian number=183365, print grad=7.562932296423241e-05, Depth Loss=0.0000000]
Training progress:  91%|█████████ | 1820/2000 [11:55<01:03,  2.82it/s, Loss=0.0067789, Gaussian number=183365, print grad=7.562932296423241e-05, Depth Loss=0.0000000]
Training progress:  91%|█████████ | 1820/2000 [11:58<01:03,  2.82it/s, Loss=0.0056460, Gaussian number=183365, print grad=0.00010537834896240383, Depth Loss=0.0000000]
Training progress:  92%|█████████▏| 1830/2000 [11:58<01:00,  2.82it/s, Loss=0.0056460, Gaussian number=183365, print grad=0.00010537834896240383, Depth Loss=0.0000000]
Training progress:  92%|█████████▏| 1830/2000 [12:02<01:00,  2.82it/s, Loss=0.0063990, Gaussian number=183365, print grad=0.00014499678218271583, Depth Loss=0.0000000]
Training progress:  92%|█████████▏| 1840/2000 [12:02<00:56,  2.82it/s, Loss=0.0063990, Gaussian number=183365, print grad=0.00014499678218271583, Depth Loss=0.0000000]
Training progress:  92%|█████████▏| 1840/2000 [12:06<00:56,  2.82it/s, Loss=0.0069171, Gaussian number=183365, print grad=0.00018098484724760056, Depth Loss=0.0000000]
Training progress:  92%|█████████▎| 1850/2000 [12:06<00:53,  2.82it/s, Loss=0.0069171, Gaussian number=183365, print grad=0.00018098484724760056, Depth Loss=0.0000000]
Training progress:  92%|█████████▎| 1850/2000 [12:09<00:53,  2.82it/s, Loss=0.0071211, Gaussian number=183365, print grad=0.00021304283291101456, Depth Loss=0.0000000]
Training progress:  93%|█████████▎| 1860/2000 [12:09<00:49,  2.82it/s, Loss=0.0071211, Gaussian number=183365, print grad=0.00021304283291101456, Depth Loss=0.0000000]
Training progress:  93%|█████████▎| 1860/2000 [12:13<00:49,  2.82it/s, Loss=0.0080167, Gaussian number=183365, print grad=0.00025499207549728453, Depth Loss=0.0000000]
Training progress:  94%|█████████▎| 1870/2000 [12:13<00:46,  2.82it/s, Loss=0.0080167, Gaussian number=183365, print grad=0.00025499207549728453, Depth Loss=0.0000000]
Training progress:  94%|█████████▎| 1870/2000 [12:16<00:46,  2.82it/s, Loss=0.0063789, Gaussian number=183365, print grad=0.0002923085994552821, Depth Loss=0.0000000] 
Training progress:  94%|█████████▍| 1880/2000 [12:16<00:42,  2.82it/s, Loss=0.0063789, Gaussian number=183365, print grad=0.0002923085994552821, Depth Loss=0.0000000]
Training progress:  94%|█████████▍| 1880/2000 [12:20<00:42,  2.82it/s, Loss=0.0070770, Gaussian number=183365, print grad=0.0003296193608548492, Depth Loss=0.0000000]
Training progress:  94%|█████████▍| 1890/2000 [12:20<00:38,  2.82it/s, Loss=0.0070770, Gaussian number=183365, print grad=0.0003296193608548492, Depth Loss=0.0000000]
Training progress:  94%|█████████▍| 1890/2000 [12:23<00:38,  2.82it/s, Loss=0.0081399, Gaussian number=183365, print grad=0.00036654213909059763, Depth Loss=0.0000000]
Training progress:  95%|█████████▌| 1900/2000 [12:23<00:35,  2.82it/s, Loss=0.0081399, Gaussian number=183365, print grad=0.00036654213909059763, Depth Loss=0.0000000]
Training progress:  95%|█████████▌| 1900/2000 [12:27<00:35,  2.82it/s, Loss=0.0076701, Gaussian number=183457, print grad=3.0396899092011154e-05, Depth Loss=0.0000000]
Training progress:  96%|█████████▌| 1910/2000 [12:27<00:31,  2.82it/s, Loss=0.0076701, Gaussian number=183457, print grad=3.0396899092011154e-05, Depth Loss=0.0000000]
Training progress:  96%|█████████▌| 1910/2000 [12:30<00:31,  2.82it/s, Loss=0.0061032, Gaussian number=183457, print grad=6.65709376335144e-05, Depth Loss=0.0000000]  
Training progress:  96%|█████████▌| 1920/2000 [12:30<00:28,  2.82it/s, Loss=0.0061032, Gaussian number=183457, print grad=6.65709376335144e-05, Depth Loss=0.0000000]
Training progress:  96%|█████████▌| 1920/2000 [12:34<00:28,  2.82it/s, Loss=0.0055345, Gaussian number=183457, print grad=0.00010373177065048367, Depth Loss=0.0000000]
Training progress:  96%|█████████▋| 1930/2000 [12:34<00:24,  2.82it/s, Loss=0.0055345, Gaussian number=183457, print grad=0.00010373177065048367, Depth Loss=0.0000000]
Training progress:  96%|█████████▋| 1930/2000 [12:37<00:24,  2.82it/s, Loss=0.0076214, Gaussian number=183457, print grad=0.0001399847969878465, Depth Loss=0.0000000] 
Training progress:  97%|█████████▋| 1940/2000 [12:37<00:21,  2.82it/s, Loss=0.0076214, Gaussian number=183457, print grad=0.0001399847969878465, Depth Loss=0.0000000]
Training progress:  97%|█████████▋| 1940/2000 [12:41<00:21,  2.82it/s, Loss=0.0061496, Gaussian number=183457, print grad=0.00017558503895998, Depth Loss=0.0000000]  
Training progress:  98%|█████████▊| 1950/2000 [12:41<00:17,  2.82it/s, Loss=0.0061496, Gaussian number=183457, print grad=0.00017558503895998, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1950/2000 [12:44<00:17,  2.82it/s, Loss=0.0092501, Gaussian number=183457, print grad=0.0002101998688885942, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1960/2000 [12:44<00:14,  2.82it/s, Loss=0.0092501, Gaussian number=183457, print grad=0.0002101998688885942, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1960/2000 [12:48<00:14,  2.82it/s, Loss=0.0077177, Gaussian number=183457, print grad=0.00024574616691097617, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1970/2000 [12:48<00:10,  2.83it/s, Loss=0.0077177, Gaussian number=183457, print grad=0.00024574616691097617, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1970/2000 [12:52<00:10,  2.83it/s, Loss=0.0066327, Gaussian number=183457, print grad=0.00028360390570014715, Depth Loss=0.0000000]
Training progress:  99%|█████████▉| 1980/2000 [12:52<00:07,  2.83it/s, Loss=0.0066327, Gaussian number=183457, print grad=0.00028360390570014715, Depth Loss=0.0000000]
Training progress:  99%|█████████▉| 1980/2000 [12:55<00:07,  2.83it/s, Loss=0.0066253, Gaussian number=183457, print grad=0.0003223620296921581, Depth Loss=0.0000000] 
Training progress: 100%|█████████▉| 1990/2000 [12:55<00:03,  2.83it/s, Loss=0.0066253, Gaussian number=183457, print grad=0.0003223620296921581, Depth Loss=0.0000000]
Training progress: 100%|█████████▉| 1990/2000 [12:59<00:03,  2.83it/s, Loss=0.0056607, Gaussian number=183457, print grad=0.0003637400222942233, Depth Loss=0.0000000]
Training progress: 100%|██████████| 2000/2000 [12:59<00:00,  2.83it/s, Loss=0.0056607, Gaussian number=183457, print grad=0.0003637400222942233, Depth Loss=0.0000000]
Training progress: 100%|██████████| 2000/2000 [12:59<00:00,  2.57it/s, Loss=0.0056607, Gaussian number=183457, print grad=0.0003637400222942233, Depth Loss=0.0000000]
Iteration 100 [15/11 00:11:04]

[ITER 100] Evaluating test: WD 0.013193, PSNR 12.8686 [15/11 00:11:10]

[ITER 100] Evaluating train: WD 0.013456, PSNR 13.2664 [15/11 00:11:10]
Gaussian number:182686,print gradients:1.5944915503496304e-06 [15/11 00:11:10]
Iteration 200 [15/11 00:11:46]

[ITER 200] Evaluating test: WD 0.011878, PSNR 14.1784 [15/11 00:11:52]

[ITER 200] Evaluating train: WD 0.011904, PSNR 14.6025 [15/11 00:11:52]
Gaussian number:182686,print gradients:2.1403782284323825e-06 [15/11 00:11:52]
Iteration 300 [15/11 00:12:28]

[ITER 300] Evaluating test: WD 0.010959, PSNR 14.9725 [15/11 00:12:34]

[ITER 300] Evaluating train: WD 0.010950, PSNR 15.5137 [15/11 00:12:34]
Gaussian number:182686,print gradients:2.527356173231965e-06 [15/11 00:12:34]
Iteration 400 [15/11 00:13:10]

[ITER 400] Evaluating test: WD 0.010499, PSNR 15.4946 [15/11 00:13:15]

[ITER 400] Evaluating train: WD 0.010455, PSNR 16.1895 [15/11 00:13:16]
Gaussian number:182686,print gradients:2.801447863021167e-06 [15/11 00:13:16]
Iteration 500 [15/11 00:13:52]

[ITER 500] Evaluating test: WD 0.009924, PSNR 15.9457 [15/11 00:13:57]

[ITER 500] Evaluating train: WD 0.010408, PSNR 16.2036 [15/11 00:13:58]
Gaussian number:182686,print gradients:3.0883343242749106e-06 [15/11 00:13:58]
Iteration 600 [15/11 00:14:33]

[ITER 600] Evaluating test: WD 0.009538, PSNR 16.2303 [15/11 00:14:39]

[ITER 600] Evaluating train: WD 0.009769, PSNR 16.5205 [15/11 00:14:39]
Gaussian number:182686,print gradients:3.305341124359984e-06 [15/11 00:14:39]
Iteration 700 [15/11 00:15:15]

[ITER 700] Evaluating test: WD 0.009361, PSNR 16.3888 [15/11 00:15:21]

[ITER 700] Evaluating train: WD 0.009514, PSNR 16.7176 [15/11 00:15:21]
Gaussian number:182649,print gradients:4.685555268224562e-06 [15/11 00:15:21]
Iteration 800 [15/11 00:15:57]

[ITER 800] Evaluating test: WD 0.008911, PSNR 16.6067 [15/11 00:16:02]

[ITER 800] Evaluating train: WD 0.009103, PSNR 16.9770 [15/11 00:16:03]
Gaussian number:182697,print gradients:4.665165761252865e-06 [15/11 00:16:03]
Iteration 900 [15/11 00:16:38]

[ITER 900] Evaluating test: WD 0.008806, PSNR 16.7235 [15/11 00:16:43]

[ITER 900] Evaluating train: WD 0.009217, PSNR 17.0599 [15/11 00:16:44]
Gaussian number:182749,print gradients:4.902799446426798e-06 [15/11 00:16:44]
Iteration 1000 [15/11 00:17:19]

[ITER 1000] Evaluating test: WD 0.008709, PSNR 16.8458 [15/11 00:17:24]

[ITER 1000] Evaluating train: WD 0.009225, PSNR 17.0803 [15/11 00:17:25]
Gaussian number:182803,print gradients:4.8235751819447614e-06 [15/11 00:17:25]
Iteration 1100 [15/11 00:18:00]
Iteration 1200 [15/11 00:18:35]
Iteration 1300 [15/11 00:19:11]
Iteration 1400 [15/11 00:19:46]
Iteration 1500 [15/11 00:20:22]

[ITER 1500] Evaluating test: WD 0.007851, PSNR 17.3748 [15/11 00:20:27]

[ITER 1500] Evaluating train: WD 0.008204, PSNR 17.6206 [15/11 00:20:28]
Gaussian number:183093,print gradients:5.3354183364717755e-06 [15/11 00:20:28]
Iteration 1600 [15/11 00:21:03]
Iteration 1700 [15/11 00:21:38]
Iteration 1800 [15/11 00:22:14]
Iteration 1900 [15/11 00:22:49]
Iteration 2000 [15/11 00:23:25]

[ITER 2000] Evaluating test: WD 0.007259, PSNR 17.7753 [15/11 00:23:30]

[ITER 2000] Evaluating train: WD 0.007960, PSNR 17.9998 [15/11 00:23:31]
Gaussian number:183457,print gradients:5.516004875971703e-06 [15/11 00:23:31]

[ITER 2000] Saving Gaussians [15/11 00:23:31]

Training complete. [15/11 00:23:32]
