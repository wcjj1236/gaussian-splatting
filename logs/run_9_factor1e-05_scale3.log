Optimizing /home/cw4287/gaussian-model/train1
Output folder: /home/cw4287/gaussian-model/train1 [15/11 01:20:58]
Tensorboard not available: not logging progress [15/11 01:20:58]
------------LLFF HOLD------------- [15/11 01:20:59]

Reading camera 1/301
Reading camera 2/301
Reading camera 3/301
Reading camera 4/301
Reading camera 5/301
Reading camera 6/301
Reading camera 7/301
Reading camera 8/301
Reading camera 9/301
Reading camera 10/301
Reading camera 11/301
Reading camera 12/301
Reading camera 13/301
Reading camera 14/301
Reading camera 15/301
Reading camera 16/301
Reading camera 17/301
Reading camera 18/301
Reading camera 19/301
Reading camera 20/301
Reading camera 21/301
Reading camera 22/301
Reading camera 23/301
Reading camera 24/301
Reading camera 25/301
Reading camera 26/301
Reading camera 27/301
Reading camera 28/301
Reading camera 29/301
Reading camera 30/301
Reading camera 31/301
Reading camera 32/301
Reading camera 33/301
Reading camera 34/301
Reading camera 35/301
Reading camera 36/301
Reading camera 37/301
Reading camera 38/301
Reading camera 39/301
Reading camera 40/301
Reading camera 41/301
Reading camera 42/301
Reading camera 43/301
Reading camera 44/301
Reading camera 45/301
Reading camera 46/301
Reading camera 47/301
Reading camera 48/301
Reading camera 49/301
Reading camera 50/301
Reading camera 51/301
Reading camera 52/301
Reading camera 53/301
Reading camera 54/301
Reading camera 55/301
Reading camera 56/301
Reading camera 57/301
Reading camera 58/301
Reading camera 59/301
Reading camera 60/301
Reading camera 61/301
Reading camera 62/301
Reading camera 63/301
Reading camera 64/301
Reading camera 65/301
Reading camera 66/301
Reading camera 67/301
Reading camera 68/301
Reading camera 69/301
Reading camera 70/301
Reading camera 71/301
Reading camera 72/301
Reading camera 73/301
Reading camera 74/301
Reading camera 75/301
Reading camera 76/301
Reading camera 77/301
Reading camera 78/301
Reading camera 79/301
Reading camera 80/301
Reading camera 81/301
Reading camera 82/301
Reading camera 83/301
Reading camera 84/301
Reading camera 85/301
Reading camera 86/301
Reading camera 87/301
Reading camera 88/301
Reading camera 89/301
Reading camera 90/301
Reading camera 91/301
Reading camera 92/301
Reading camera 93/301
Reading camera 94/301
Reading camera 95/301
Reading camera 96/301
Reading camera 97/301
Reading camera 98/301
Reading camera 99/301
Reading camera 100/301
Reading camera 101/301
Reading camera 102/301
Reading camera 103/301
Reading camera 104/301
Reading camera 105/301
Reading camera 106/301
Reading camera 107/301
Reading camera 108/301
Reading camera 109/301
Reading camera 110/301
Reading camera 111/301
Reading camera 112/301
Reading camera 113/301
Reading camera 114/301
Reading camera 115/301
Reading camera 116/301
Reading camera 117/301
Reading camera 118/301
Reading camera 119/301
Reading camera 120/301
Reading camera 121/301
Reading camera 122/301
Reading camera 123/301
Reading camera 124/301
Reading camera 125/301
Reading camera 126/301
Reading camera 127/301
Reading camera 128/301
Reading camera 129/301
Reading camera 130/301
Reading camera 131/301
Reading camera 132/301
Reading camera 133/301
Reading camera 134/301
Reading camera 135/301
Reading camera 136/301
Reading camera 137/301
Reading camera 138/301
Reading camera 139/301
Reading camera 140/301
Reading camera 141/301
Reading camera 142/301
Reading camera 143/301
Reading camera 144/301
Reading camera 145/301
Reading camera 146/301
Reading camera 147/301
Reading camera 148/301
Reading camera 149/301
Reading camera 150/301
Reading camera 151/301
Reading camera 152/301
Reading camera 153/301
Reading camera 154/301
Reading camera 155/301
Reading camera 156/301
Reading camera 157/301
Reading camera 158/301
Reading camera 159/301
Reading camera 160/301
Reading camera 161/301
Reading camera 162/301
Reading camera 163/301
Reading camera 164/301
Reading camera 165/301
Reading camera 166/301
Reading camera 167/301
Reading camera 168/301
Reading camera 169/301
Reading camera 170/301
Reading camera 171/301
Reading camera 172/301
Reading camera 173/301
Reading camera 174/301
Reading camera 175/301
Reading camera 176/301
Reading camera 177/301
Reading camera 178/301
Reading camera 179/301
Reading camera 180/301
Reading camera 181/301
Reading camera 182/301
Reading camera 183/301
Reading camera 184/301
Reading camera 185/301
Reading camera 186/301
Reading camera 187/301
Reading camera 188/301
Reading camera 189/301
Reading camera 190/301
Reading camera 191/301
Reading camera 192/301
Reading camera 193/301
Reading camera 194/301
Reading camera 195/301
Reading camera 196/301
Reading camera 197/301
Reading camera 198/301
Reading camera 199/301
Reading camera 200/301
Reading camera 201/301
Reading camera 202/301
Reading camera 203/301
Reading camera 204/301
Reading camera 205/301
Reading camera 206/301
Reading camera 207/301
Reading camera 208/301
Reading camera 209/301
Reading camera 210/301
Reading camera 211/301
Reading camera 212/301
Reading camera 213/301
Reading camera 214/301
Reading camera 215/301
Reading camera 216/301
Reading camera 217/301
Reading camera 218/301
Reading camera 219/301
Reading camera 220/301
Reading camera 221/301
Reading camera 222/301
Reading camera 223/301
Reading camera 224/301
Reading camera 225/301
Reading camera 226/301
Reading camera 227/301
Reading camera 228/301
Reading camera 229/301
Reading camera 230/301
Reading camera 231/301
Reading camera 232/301
Reading camera 233/301
Reading camera 234/301
Reading camera 235/301
Reading camera 236/301
Reading camera 237/301
Reading camera 238/301
Reading camera 239/301
Reading camera 240/301
Reading camera 241/301
Reading camera 242/301
Reading camera 243/301
Reading camera 244/301
Reading camera 245/301
Reading camera 246/301
Reading camera 247/301
Reading camera 248/301
Reading camera 249/301
Reading camera 250/301
Reading camera 251/301
Reading camera 252/301
Reading camera 253/301
Reading camera 254/301
Reading camera 255/301
Reading camera 256/301
Reading camera 257/301
Reading camera 258/301
Reading camera 259/301
Reading camera 260/301
Reading camera 261/301
Reading camera 262/301
Reading camera 263/301
Reading camera 264/301
Reading camera 265/301
Reading camera 266/301
Reading camera 267/301
Reading camera 268/301
Reading camera 269/301
Reading camera 270/301
Reading camera 271/301
Reading camera 272/301
Reading camera 273/301
Reading camera 274/301
Reading camera 275/301
Reading camera 276/301
Reading camera 277/301
Reading camera 278/301
Reading camera 279/301
Reading camera 280/301
Reading camera 281/301
Reading camera 282/301
Reading camera 283/301
Reading camera 284/301
Reading camera 285/301
Reading camera 286/301
Reading camera 287/301
Reading camera 288/301
Reading camera 289/301
Reading camera 290/301
Reading camera 291/301
Reading camera 292/301
Reading camera 293/301
Reading camera 294/301
Reading camera 295/301
Reading camera 296/301
Reading camera 297/301
Reading camera 298/301
Reading camera 299/301
Reading camera 300/301
Reading camera 301/301 [15/11 01:20:59]
Loading Training Cameras [15/11 01:20:59]
Loading Test Cameras [15/11 01:21:11]
Number of points at initialisation :  182686 [15/11 01:21:12]

Training progress:   0%|          | 0/2000 [00:00<?, ?it/s]/ext3/conda/envs/3dgs/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/ext3/conda/envs/3dgs/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)

Training progress:   0%|          | 0/2000 [00:05<?, ?it/s, Loss=0.0002378, Gaussian number=182686, print grad=1.1353569107086514e-07, Depth Loss=0.0000000]
Training progress:   0%|          | 10/2000 [00:05<19:24,  1.71it/s, Loss=0.0002378, Gaussian number=182686, print grad=1.1353569107086514e-07, Depth Loss=0.0000000]
Training progress:   0%|          | 10/2000 [00:09<19:24,  1.71it/s, Loss=0.0002231, Gaussian number=182686, print grad=2.9375877375059645e-07, Depth Loss=0.0000000]
Training progress:   1%|          | 20/2000 [00:09<15:50,  2.08it/s, Loss=0.0002231, Gaussian number=182686, print grad=2.9375877375059645e-07, Depth Loss=0.0000000]
Training progress:   1%|          | 20/2000 [00:13<15:50,  2.08it/s, Loss=0.0002217, Gaussian number=182686, print grad=4.6223794925026596e-07, Depth Loss=0.0000000]
Training progress:   2%|▏         | 30/2000 [00:13<14:40,  2.24it/s, Loss=0.0002217, Gaussian number=182686, print grad=4.6223794925026596e-07, Depth Loss=0.0000000]
Training progress:   2%|▏         | 30/2000 [00:18<14:40,  2.24it/s, Loss=0.0002395, Gaussian number=182686, print grad=6.381691264323308e-07, Depth Loss=0.0000000] 
Training progress:   2%|▏         | 40/2000 [00:18<14:05,  2.32it/s, Loss=0.0002395, Gaussian number=182686, print grad=6.381691264323308e-07, Depth Loss=0.0000000]
Training progress:   2%|▏         | 40/2000 [00:22<14:05,  2.32it/s, Loss=0.0001834, Gaussian number=182686, print grad=7.809522912793909e-07, Depth Loss=0.0000000]
Training progress:   2%|▎         | 50/2000 [00:22<13:43,  2.37it/s, Loss=0.0001834, Gaussian number=182686, print grad=7.809522912793909e-07, Depth Loss=0.0000000]
Training progress:   2%|▎         | 50/2000 [00:26<13:43,  2.37it/s, Loss=0.0002039, Gaussian number=182686, print grad=9.88180886452028e-07, Depth Loss=0.0000000] 
Training progress:   3%|▎         | 60/2000 [00:26<13:28,  2.40it/s, Loss=0.0002039, Gaussian number=182686, print grad=9.88180886452028e-07, Depth Loss=0.0000000]
Training progress:   3%|▎         | 60/2000 [00:30<13:28,  2.40it/s, Loss=0.0001829, Gaussian number=182686, print grad=1.2492748737713555e-06, Depth Loss=0.0000000]
Training progress:   4%|▎         | 70/2000 [00:30<13:17,  2.42it/s, Loss=0.0001829, Gaussian number=182686, print grad=1.2492748737713555e-06, Depth Loss=0.0000000]
Training progress:   4%|▎         | 70/2000 [00:34<13:17,  2.42it/s, Loss=0.0002235, Gaussian number=182686, print grad=1.4547446198776015e-06, Depth Loss=0.0000000]
Training progress:   4%|▍         | 80/2000 [00:34<13:09,  2.43it/s, Loss=0.0002235, Gaussian number=182686, print grad=1.4547446198776015e-06, Depth Loss=0.0000000]
Training progress:   4%|▍         | 80/2000 [00:38<13:09,  2.43it/s, Loss=0.0001886, Gaussian number=182686, print grad=1.6661269910400733e-06, Depth Loss=0.0000000]
Training progress:   4%|▍         | 90/2000 [00:38<13:03,  2.44it/s, Loss=0.0001886, Gaussian number=182686, print grad=1.6661269910400733e-06, Depth Loss=0.0000000]
Training progress:   4%|▍         | 90/2000 [00:42<13:03,  2.44it/s, Loss=0.0001845, Gaussian number=182686, print grad=1.917799863804248e-06, Depth Loss=0.0000000] 
Training progress:   5%|▌         | 100/2000 [00:42<13:01,  2.43it/s, Loss=0.0001845, Gaussian number=182686, print grad=1.917799863804248e-06, Depth Loss=0.0000000]
Training progress:   5%|▌         | 100/2000 [00:52<13:01,  2.43it/s, Loss=0.0002132, Gaussian number=182686, print grad=2.190903842347325e-06, Depth Loss=0.0000000]
Training progress:   6%|▌         | 110/2000 [00:52<18:45,  1.68it/s, Loss=0.0002132, Gaussian number=182686, print grad=2.190903842347325e-06, Depth Loss=0.0000000]
Training progress:   6%|▌         | 110/2000 [00:56<18:45,  1.68it/s, Loss=0.0001783, Gaussian number=182686, print grad=2.4498476705048233e-06, Depth Loss=0.0000000]
Training progress:   6%|▌         | 120/2000 [00:56<16:50,  1.86it/s, Loss=0.0001783, Gaussian number=182686, print grad=2.4498476705048233e-06, Depth Loss=0.0000000]
Training progress:   6%|▌         | 120/2000 [01:00<16:50,  1.86it/s, Loss=0.0002040, Gaussian number=182686, print grad=2.773744881778839e-06, Depth Loss=0.0000000] 
Training progress:   6%|▋         | 130/2000 [01:00<15:30,  2.01it/s, Loss=0.0002040, Gaussian number=182686, print grad=2.773744881778839e-06, Depth Loss=0.0000000]
Training progress:   6%|▋         | 130/2000 [01:04<15:30,  2.01it/s, Loss=0.0001867, Gaussian number=182686, print grad=3.098879005847266e-06, Depth Loss=0.0000000]
Training progress:   7%|▋         | 140/2000 [01:04<14:34,  2.13it/s, Loss=0.0001867, Gaussian number=182686, print grad=3.098879005847266e-06, Depth Loss=0.0000000]
Training progress:   7%|▋         | 140/2000 [01:08<14:34,  2.13it/s, Loss=0.0001650, Gaussian number=182686, print grad=3.392035523575032e-06, Depth Loss=0.0000000]
Training progress:   8%|▊         | 150/2000 [01:08<13:53,  2.22it/s, Loss=0.0001650, Gaussian number=182686, print grad=3.392035523575032e-06, Depth Loss=0.0000000]
Training progress:   8%|▊         | 150/2000 [01:12<13:53,  2.22it/s, Loss=0.0001740, Gaussian number=182686, print grad=3.758879756787792e-06, Depth Loss=0.0000000]
Training progress:   8%|▊         | 160/2000 [01:12<13:22,  2.29it/s, Loss=0.0001740, Gaussian number=182686, print grad=3.758879756787792e-06, Depth Loss=0.0000000]
Training progress:   8%|▊         | 160/2000 [01:16<13:22,  2.29it/s, Loss=0.0001727, Gaussian number=182686, print grad=4.050639745400986e-06, Depth Loss=0.0000000]
Training progress:   8%|▊         | 170/2000 [01:16<13:00,  2.35it/s, Loss=0.0001727, Gaussian number=182686, print grad=4.050639745400986e-06, Depth Loss=0.0000000]
Training progress:   8%|▊         | 170/2000 [01:20<13:00,  2.35it/s, Loss=0.0001482, Gaussian number=182686, print grad=4.385013198771048e-06, Depth Loss=0.0000000]
Training progress:   9%|▉         | 180/2000 [01:20<12:43,  2.38it/s, Loss=0.0001482, Gaussian number=182686, print grad=4.385013198771048e-06, Depth Loss=0.0000000]
Training progress:   9%|▉         | 180/2000 [01:25<12:43,  2.38it/s, Loss=0.0001913, Gaussian number=182686, print grad=4.6749373723287135e-06, Depth Loss=0.0000000]
Training progress:  10%|▉         | 190/2000 [01:25<12:30,  2.41it/s, Loss=0.0001913, Gaussian number=182686, print grad=4.6749373723287135e-06, Depth Loss=0.0000000]
Training progress:  10%|▉         | 190/2000 [01:29<12:30,  2.41it/s, Loss=0.0001661, Gaussian number=182686, print grad=5.034973128204001e-06, Depth Loss=0.0000000] 
Training progress:  10%|█         | 200/2000 [01:29<12:19,  2.43it/s, Loss=0.0001661, Gaussian number=182686, print grad=5.034973128204001e-06, Depth Loss=0.0000000]
Training progress:  10%|█         | 200/2000 [01:39<12:19,  2.43it/s, Loss=0.0001883, Gaussian number=182686, print grad=5.400920599640813e-06, Depth Loss=0.0000000]
Training progress:  10%|█         | 210/2000 [01:39<17:36,  1.69it/s, Loss=0.0001883, Gaussian number=182686, print grad=5.400920599640813e-06, Depth Loss=0.0000000]
Training progress:  10%|█         | 210/2000 [01:43<17:36,  1.69it/s, Loss=0.0001530, Gaussian number=182686, print grad=5.7310035117552616e-06, Depth Loss=0.0000000]
Training progress:  11%|█         | 220/2000 [01:43<15:51,  1.87it/s, Loss=0.0001530, Gaussian number=182686, print grad=5.7310035117552616e-06, Depth Loss=0.0000000]
Training progress:  11%|█         | 220/2000 [01:47<15:51,  1.87it/s, Loss=0.0001713, Gaussian number=182686, print grad=6.074994871596573e-06, Depth Loss=0.0000000] 
Training progress:  12%|█▏        | 230/2000 [01:47<14:36,  2.02it/s, Loss=0.0001713, Gaussian number=182686, print grad=6.074994871596573e-06, Depth Loss=0.0000000]
Training progress:  12%|█▏        | 230/2000 [01:51<14:36,  2.02it/s, Loss=0.0002106, Gaussian number=182686, print grad=6.400079200830078e-06, Depth Loss=0.0000000]
Training progress:  12%|█▏        | 240/2000 [01:51<13:42,  2.14it/s, Loss=0.0002106, Gaussian number=182686, print grad=6.400079200830078e-06, Depth Loss=0.0000000]
Training progress:  12%|█▏        | 240/2000 [01:55<13:42,  2.14it/s, Loss=0.0001621, Gaussian number=182686, print grad=6.760477845091373e-06, Depth Loss=0.0000000]
Training progress:  12%|█▎        | 250/2000 [01:55<13:03,  2.23it/s, Loss=0.0001621, Gaussian number=182686, print grad=6.760477845091373e-06, Depth Loss=0.0000000]
Training progress:  12%|█▎        | 250/2000 [01:59<13:03,  2.23it/s, Loss=0.0001821, Gaussian number=182686, print grad=7.096627996361349e-06, Depth Loss=0.0000000]
Training progress:  13%|█▎        | 260/2000 [01:59<12:35,  2.30it/s, Loss=0.0001821, Gaussian number=182686, print grad=7.096627996361349e-06, Depth Loss=0.0000000]
Training progress:  13%|█▎        | 260/2000 [02:03<12:35,  2.30it/s, Loss=0.0001280, Gaussian number=182686, print grad=7.449859367625322e-06, Depth Loss=0.0000000]
Training progress:  14%|█▎        | 270/2000 [02:03<12:14,  2.36it/s, Loss=0.0001280, Gaussian number=182686, print grad=7.449859367625322e-06, Depth Loss=0.0000000]
Training progress:  14%|█▎        | 270/2000 [02:07<12:14,  2.36it/s, Loss=0.0001642, Gaussian number=182686, print grad=7.85473548603477e-06, Depth Loss=0.0000000] 
Training progress:  14%|█▍        | 280/2000 [02:07<11:57,  2.40it/s, Loss=0.0001642, Gaussian number=182686, print grad=7.85473548603477e-06, Depth Loss=0.0000000]
Training progress:  14%|█▍        | 280/2000 [02:11<11:57,  2.40it/s, Loss=0.0001677, Gaussian number=182686, print grad=8.233227163145784e-06, Depth Loss=0.0000000]
Training progress:  14%|█▍        | 290/2000 [02:11<11:45,  2.42it/s, Loss=0.0001677, Gaussian number=182686, print grad=8.233227163145784e-06, Depth Loss=0.0000000]
Training progress:  14%|█▍        | 290/2000 [02:15<11:45,  2.42it/s, Loss=0.0001568, Gaussian number=182686, print grad=8.62251272337744e-06, Depth Loss=0.0000000] 
Training progress:  15%|█▌        | 300/2000 [02:15<11:36,  2.44it/s, Loss=0.0001568, Gaussian number=182686, print grad=8.62251272337744e-06, Depth Loss=0.0000000]
Training progress:  15%|█▌        | 300/2000 [02:25<11:36,  2.44it/s, Loss=0.0001304, Gaussian number=182686, print grad=9.029561624629423e-06, Depth Loss=0.0000000]
Training progress:  16%|█▌        | 310/2000 [02:25<16:34,  1.70it/s, Loss=0.0001304, Gaussian number=182686, print grad=9.029561624629423e-06, Depth Loss=0.0000000]
Training progress:  16%|█▌        | 310/2000 [02:29<16:34,  1.70it/s, Loss=0.0001361, Gaussian number=182686, print grad=9.321289326180704e-06, Depth Loss=0.0000000]
Training progress:  16%|█▌        | 320/2000 [02:29<14:54,  1.88it/s, Loss=0.0001361, Gaussian number=182686, print grad=9.321289326180704e-06, Depth Loss=0.0000000]
Training progress:  16%|█▌        | 320/2000 [02:33<14:54,  1.88it/s, Loss=0.0001795, Gaussian number=182686, print grad=9.6713520179037e-06, Depth Loss=0.0000000]  
Training progress:  16%|█▋        | 330/2000 [02:33<13:45,  2.02it/s, Loss=0.0001795, Gaussian number=182686, print grad=9.6713520179037e-06, Depth Loss=0.0000000]
Training progress:  16%|█▋        | 330/2000 [02:37<13:45,  2.02it/s, Loss=0.0001300, Gaussian number=182686, print grad=1.0071910764963832e-05, Depth Loss=0.0000000]
Training progress:  17%|█▋        | 340/2000 [02:37<12:54,  2.14it/s, Loss=0.0001300, Gaussian number=182686, print grad=1.0071910764963832e-05, Depth Loss=0.0000000]
Training progress:  17%|█▋        | 340/2000 [02:41<12:54,  2.14it/s, Loss=0.0001381, Gaussian number=182686, print grad=1.0444247891427949e-05, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 350/2000 [02:41<12:17,  2.24it/s, Loss=0.0001381, Gaussian number=182686, print grad=1.0444247891427949e-05, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 350/2000 [02:45<12:17,  2.24it/s, Loss=0.0001320, Gaussian number=182686, print grad=1.0887865755648818e-05, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 360/2000 [02:45<11:49,  2.31it/s, Loss=0.0001320, Gaussian number=182686, print grad=1.0887865755648818e-05, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 360/2000 [02:49<11:49,  2.31it/s, Loss=0.0001285, Gaussian number=182686, print grad=1.1279749742243439e-05, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 370/2000 [02:49<11:29,  2.37it/s, Loss=0.0001285, Gaussian number=182686, print grad=1.1279749742243439e-05, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 370/2000 [02:53<11:29,  2.37it/s, Loss=0.0001731, Gaussian number=182686, print grad=1.1611359695962165e-05, Depth Loss=0.0000000]
Training progress:  19%|█▉        | 380/2000 [02:53<11:12,  2.41it/s, Loss=0.0001731, Gaussian number=182686, print grad=1.1611359695962165e-05, Depth Loss=0.0000000]
Training progress:  19%|█▉        | 380/2000 [02:57<11:12,  2.41it/s, Loss=0.0001533, Gaussian number=182686, print grad=1.20196154966834e-05, Depth Loss=0.0000000]  
Training progress:  20%|█▉        | 390/2000 [02:57<11:01,  2.43it/s, Loss=0.0001533, Gaussian number=182686, print grad=1.20196154966834e-05, Depth Loss=0.0000000]
Training progress:  20%|█▉        | 390/2000 [03:01<11:01,  2.43it/s, Loss=0.0001837, Gaussian number=182686, print grad=1.2401532330841292e-05, Depth Loss=0.0000000]
Training progress:  20%|██        | 400/2000 [03:01<10:51,  2.45it/s, Loss=0.0001837, Gaussian number=182686, print grad=1.2401532330841292e-05, Depth Loss=0.0000000]
Training progress:  20%|██        | 400/2000 [03:11<10:51,  2.45it/s, Loss=0.0001568, Gaussian number=182686, print grad=1.2856948160333559e-05, Depth Loss=0.0000000]
Training progress:  20%|██        | 410/2000 [03:11<15:33,  1.70it/s, Loss=0.0001568, Gaussian number=182686, print grad=1.2856948160333559e-05, Depth Loss=0.0000000]
Training progress:  20%|██        | 410/2000 [03:15<15:33,  1.70it/s, Loss=0.0001400, Gaussian number=182686, print grad=1.328637245023856e-05, Depth Loss=0.0000000] 
Training progress:  21%|██        | 420/2000 [03:15<14:01,  1.88it/s, Loss=0.0001400, Gaussian number=182686, print grad=1.328637245023856e-05, Depth Loss=0.0000000]
Training progress:  21%|██        | 420/2000 [03:19<14:01,  1.88it/s, Loss=0.0001752, Gaussian number=182686, print grad=1.3728888916375581e-05, Depth Loss=0.0000000]
Training progress:  22%|██▏       | 430/2000 [03:19<12:53,  2.03it/s, Loss=0.0001752, Gaussian number=182686, print grad=1.3728888916375581e-05, Depth Loss=0.0000000]
Training progress:  22%|██▏       | 430/2000 [03:23<12:53,  2.03it/s, Loss=0.0001365, Gaussian number=182686, print grad=1.414291273249546e-05, Depth Loss=0.0000000] 
Training progress:  22%|██▏       | 440/2000 [03:23<12:05,  2.15it/s, Loss=0.0001365, Gaussian number=182686, print grad=1.414291273249546e-05, Depth Loss=0.0000000]
Training progress:  22%|██▏       | 440/2000 [03:27<12:05,  2.15it/s, Loss=0.0001570, Gaussian number=182686, print grad=1.4571680367225781e-05, Depth Loss=0.0000000]
Training progress:  22%|██▎       | 450/2000 [03:27<11:30,  2.25it/s, Loss=0.0001570, Gaussian number=182686, print grad=1.4571680367225781e-05, Depth Loss=0.0000000]
Training progress:  22%|██▎       | 450/2000 [03:31<11:30,  2.25it/s, Loss=0.0001630, Gaussian number=182686, print grad=1.498892015661113e-05, Depth Loss=0.0000000] 
Training progress:  23%|██▎       | 460/2000 [03:31<11:05,  2.31it/s, Loss=0.0001630, Gaussian number=182686, print grad=1.498892015661113e-05, Depth Loss=0.0000000]
Training progress:  23%|██▎       | 460/2000 [03:35<11:05,  2.31it/s, Loss=0.0001934, Gaussian number=182686, print grad=1.5384535799967125e-05, Depth Loss=0.0000000]
Training progress:  24%|██▎       | 470/2000 [03:35<10:46,  2.37it/s, Loss=0.0001934, Gaussian number=182686, print grad=1.5384535799967125e-05, Depth Loss=0.0000000]
Training progress:  24%|██▎       | 470/2000 [03:39<10:46,  2.37it/s, Loss=0.0001251, Gaussian number=182686, print grad=1.583812445460353e-05, Depth Loss=0.0000000] 
Training progress:  24%|██▍       | 480/2000 [03:39<10:31,  2.41it/s, Loss=0.0001251, Gaussian number=182686, print grad=1.583812445460353e-05, Depth Loss=0.0000000]
Training progress:  24%|██▍       | 480/2000 [03:43<10:31,  2.41it/s, Loss=0.0001388, Gaussian number=182686, print grad=1.6248657630058005e-05, Depth Loss=0.0000000]
Training progress:  24%|██▍       | 490/2000 [03:43<10:21,  2.43it/s, Loss=0.0001388, Gaussian number=182686, print grad=1.6248657630058005e-05, Depth Loss=0.0000000]
Training progress:  24%|██▍       | 490/2000 [03:47<10:21,  2.43it/s, Loss=0.0001093, Gaussian number=182686, print grad=1.6669479009578936e-05, Depth Loss=0.0000000]
Training progress:  25%|██▌       | 500/2000 [03:47<10:10,  2.46it/s, Loss=0.0001093, Gaussian number=182686, print grad=1.6669479009578936e-05, Depth Loss=0.0000000]
Training progress:  25%|██▌       | 500/2000 [03:57<10:10,  2.46it/s, Loss=0.0001294, Gaussian number=182686, print grad=1.7094716895371675e-05, Depth Loss=0.0000000]
Training progress:  26%|██▌       | 510/2000 [03:57<14:33,  1.71it/s, Loss=0.0001294, Gaussian number=182686, print grad=1.7094716895371675e-05, Depth Loss=0.0000000]
Training progress:  26%|██▌       | 510/2000 [04:01<14:33,  1.71it/s, Loss=0.0001322, Gaussian number=182686, print grad=1.7540776752866805e-05, Depth Loss=0.0000000]
Training progress:  26%|██▌       | 520/2000 [04:01<13:04,  1.89it/s, Loss=0.0001322, Gaussian number=182686, print grad=1.7540776752866805e-05, Depth Loss=0.0000000]
Training progress:  26%|██▌       | 520/2000 [04:05<13:04,  1.89it/s, Loss=0.0001048, Gaussian number=182686, print grad=1.7927670342032798e-05, Depth Loss=0.0000000]
Training progress:  26%|██▋       | 530/2000 [04:05<12:00,  2.04it/s, Loss=0.0001048, Gaussian number=182686, print grad=1.7927670342032798e-05, Depth Loss=0.0000000]
Training progress:  26%|██▋       | 530/2000 [04:09<12:00,  2.04it/s, Loss=0.0001414, Gaussian number=182686, print grad=1.8354328858549707e-05, Depth Loss=0.0000000]
Training progress:  27%|██▋       | 540/2000 [04:09<11:15,  2.16it/s, Loss=0.0001414, Gaussian number=182686, print grad=1.8354328858549707e-05, Depth Loss=0.0000000]
Training progress:  27%|██▋       | 540/2000 [04:13<11:15,  2.16it/s, Loss=0.0001350, Gaussian number=182686, print grad=1.880760828498751e-05, Depth Loss=0.0000000] 
Training progress:  28%|██▊       | 550/2000 [04:13<10:42,  2.26it/s, Loss=0.0001350, Gaussian number=182686, print grad=1.880760828498751e-05, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 550/2000 [04:17<10:42,  2.26it/s, Loss=0.0001081, Gaussian number=182686, print grad=1.9227667507948354e-05, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 560/2000 [04:17<10:19,  2.33it/s, Loss=0.0001081, Gaussian number=182686, print grad=1.9227667507948354e-05, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 560/2000 [04:21<10:19,  2.33it/s, Loss=0.0001449, Gaussian number=182686, print grad=1.9699609765666537e-05, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 570/2000 [04:21<10:01,  2.38it/s, Loss=0.0001449, Gaussian number=182686, print grad=1.9699609765666537e-05, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 570/2000 [04:25<10:01,  2.38it/s, Loss=0.0001246, Gaussian number=182686, print grad=2.013443736359477e-05, Depth Loss=0.0000000] 
Training progress:  29%|██▉       | 580/2000 [04:25<09:47,  2.42it/s, Loss=0.0001246, Gaussian number=182686, print grad=2.013443736359477e-05, Depth Loss=0.0000000]
Training progress:  29%|██▉       | 580/2000 [04:29<09:47,  2.42it/s, Loss=0.0001434, Gaussian number=182686, print grad=2.0586870959959924e-05, Depth Loss=0.0000000]
Training progress:  30%|██▉       | 590/2000 [04:29<09:37,  2.44it/s, Loss=0.0001434, Gaussian number=182686, print grad=2.0586870959959924e-05, Depth Loss=0.0000000]
Training progress:  30%|██▉       | 590/2000 [04:33<09:37,  2.44it/s, Loss=0.0001441, Gaussian number=182686, print grad=2.1005620510550216e-05, Depth Loss=0.0000000]
Training progress:  30%|███       | 600/2000 [04:33<09:28,  2.46it/s, Loss=0.0001441, Gaussian number=182686, print grad=2.1005620510550216e-05, Depth Loss=0.0000000]
Training progress:  30%|███       | 600/2000 [04:43<09:28,  2.46it/s, Loss=0.0001184, Gaussian number=182665, print grad=3.9917148342283326e-07, Depth Loss=0.0000000]
Training progress:  30%|███       | 610/2000 [04:43<13:33,  1.71it/s, Loss=0.0001184, Gaussian number=182665, print grad=3.9917148342283326e-07, Depth Loss=0.0000000]
Training progress:  30%|███       | 610/2000 [04:47<13:33,  1.71it/s, Loss=0.0001583, Gaussian number=182665, print grad=8.654614589431731e-07, Depth Loss=0.0000000] 
Training progress:  31%|███       | 620/2000 [04:47<12:09,  1.89it/s, Loss=0.0001583, Gaussian number=182665, print grad=8.654614589431731e-07, Depth Loss=0.0000000]
Training progress:  31%|███       | 620/2000 [04:51<12:09,  1.89it/s, Loss=0.0001115, Gaussian number=182665, print grad=1.2773127764376113e-06, Depth Loss=0.0000000]
Training progress:  32%|███▏      | 630/2000 [04:51<11:11,  2.04it/s, Loss=0.0001115, Gaussian number=182665, print grad=1.2773127764376113e-06, Depth Loss=0.0000000]
Training progress:  32%|███▏      | 630/2000 [04:55<11:11,  2.04it/s, Loss=0.0001213, Gaussian number=182665, print grad=1.7797029840949108e-06, Depth Loss=0.0000000]
Training progress:  32%|███▏      | 640/2000 [04:55<10:28,  2.16it/s, Loss=0.0001213, Gaussian number=182665, print grad=1.7797029840949108e-06, Depth Loss=0.0000000]
Training progress:  32%|███▏      | 640/2000 [04:59<10:28,  2.16it/s, Loss=0.0001429, Gaussian number=182665, print grad=2.1753944565716665e-06, Depth Loss=0.0000000]
Training progress:  32%|███▎      | 650/2000 [04:59<09:57,  2.26it/s, Loss=0.0001429, Gaussian number=182665, print grad=2.1753944565716665e-06, Depth Loss=0.0000000]
Training progress:  32%|███▎      | 650/2000 [05:03<09:57,  2.26it/s, Loss=0.0001460, Gaussian number=182665, print grad=2.658511903064209e-06, Depth Loss=0.0000000] 
Training progress:  33%|███▎      | 660/2000 [05:03<09:34,  2.33it/s, Loss=0.0001460, Gaussian number=182665, print grad=2.658511903064209e-06, Depth Loss=0.0000000]
Training progress:  33%|███▎      | 660/2000 [05:07<09:34,  2.33it/s, Loss=0.0001256, Gaussian number=182665, print grad=3.0968903956818394e-06, Depth Loss=0.0000000]
Training progress:  34%|███▎      | 670/2000 [05:07<09:17,  2.39it/s, Loss=0.0001256, Gaussian number=182665, print grad=3.0968903956818394e-06, Depth Loss=0.0000000]
Training progress:  34%|███▎      | 670/2000 [05:11<09:17,  2.39it/s, Loss=0.0001182, Gaussian number=182665, print grad=3.5820601169689326e-06, Depth Loss=0.0000000]
Training progress:  34%|███▍      | 680/2000 [05:11<09:04,  2.43it/s, Loss=0.0001182, Gaussian number=182665, print grad=3.5820601169689326e-06, Depth Loss=0.0000000]
Training progress:  34%|███▍      | 680/2000 [05:15<09:04,  2.43it/s, Loss=0.0001402, Gaussian number=182665, print grad=4.026851456728764e-06, Depth Loss=0.0000000] 
Training progress:  34%|███▍      | 690/2000 [05:15<08:53,  2.45it/s, Loss=0.0001402, Gaussian number=182665, print grad=4.026851456728764e-06, Depth Loss=0.0000000]
Training progress:  34%|███▍      | 690/2000 [05:19<08:53,  2.45it/s, Loss=0.0001393, Gaussian number=182665, print grad=4.460709988052258e-06, Depth Loss=0.0000000]
Training progress:  35%|███▌      | 700/2000 [05:19<08:45,  2.47it/s, Loss=0.0001393, Gaussian number=182665, print grad=4.460709988052258e-06, Depth Loss=0.0000000]
Training progress:  35%|███▌      | 700/2000 [05:29<08:45,  2.47it/s, Loss=0.0001226, Gaussian number=182639, print grad=3.8643995026177436e-07, Depth Loss=0.0000000]
Training progress:  36%|███▌      | 710/2000 [05:29<12:34,  1.71it/s, Loss=0.0001226, Gaussian number=182639, print grad=3.8643995026177436e-07, Depth Loss=0.0000000]
Training progress:  36%|███▌      | 710/2000 [05:33<12:34,  1.71it/s, Loss=0.0001115, Gaussian number=182639, print grad=8.276785479210957e-07, Depth Loss=0.0000000] 
Training progress:  36%|███▌      | 720/2000 [05:33<11:17,  1.89it/s, Loss=0.0001115, Gaussian number=182639, print grad=8.276785479210957e-07, Depth Loss=0.0000000]
Training progress:  36%|███▌      | 720/2000 [05:37<11:17,  1.89it/s, Loss=0.0001472, Gaussian number=182639, print grad=1.2465643521863967e-06, Depth Loss=0.0000000]
Training progress:  36%|███▋      | 730/2000 [05:37<10:20,  2.05it/s, Loss=0.0001472, Gaussian number=182639, print grad=1.2465643521863967e-06, Depth Loss=0.0000000]
Training progress:  36%|███▋      | 730/2000 [05:41<10:20,  2.05it/s, Loss=0.0001742, Gaussian number=182639, print grad=1.746836801430618e-06, Depth Loss=0.0000000] 
Training progress:  37%|███▋      | 740/2000 [05:41<09:41,  2.17it/s, Loss=0.0001742, Gaussian number=182639, print grad=1.746836801430618e-06, Depth Loss=0.0000000]
Training progress:  37%|███▋      | 740/2000 [05:45<09:41,  2.17it/s, Loss=0.0001257, Gaussian number=182639, print grad=2.2152721612656023e-06, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 750/2000 [05:45<09:12,  2.26it/s, Loss=0.0001257, Gaussian number=182639, print grad=2.2152721612656023e-06, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 750/2000 [05:49<09:12,  2.26it/s, Loss=0.0001181, Gaussian number=182639, print grad=2.6584295937936986e-06, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 760/2000 [05:49<08:51,  2.33it/s, Loss=0.0001181, Gaussian number=182639, print grad=2.6584295937936986e-06, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 760/2000 [05:53<08:51,  2.33it/s, Loss=0.0001100, Gaussian number=182639, print grad=3.137534349662019e-06, Depth Loss=0.0000000] 
Training progress:  38%|███▊      | 770/2000 [05:53<08:35,  2.39it/s, Loss=0.0001100, Gaussian number=182639, print grad=3.137534349662019e-06, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 770/2000 [05:57<08:35,  2.39it/s, Loss=0.0001466, Gaussian number=182639, print grad=3.5736040899791988e-06, Depth Loss=0.0000000]
Training progress:  39%|███▉      | 780/2000 [05:57<08:23,  2.43it/s, Loss=0.0001466, Gaussian number=182639, print grad=3.5736040899791988e-06, Depth Loss=0.0000000]
Training progress:  39%|███▉      | 780/2000 [06:01<08:23,  2.43it/s, Loss=0.0001693, Gaussian number=182639, print grad=4.025534053653246e-06, Depth Loss=0.0000000] 
Training progress:  40%|███▉      | 790/2000 [06:01<08:13,  2.45it/s, Loss=0.0001693, Gaussian number=182639, print grad=4.025534053653246e-06, Depth Loss=0.0000000]
Training progress:  40%|███▉      | 790/2000 [06:05<08:13,  2.45it/s, Loss=0.0001444, Gaussian number=182639, print grad=4.505707693169825e-06, Depth Loss=0.0000000]
Training progress:  40%|████      | 800/2000 [06:05<08:05,  2.47it/s, Loss=0.0001444, Gaussian number=182639, print grad=4.505707693169825e-06, Depth Loss=0.0000000]
Training progress:  40%|████      | 800/2000 [06:15<08:05,  2.47it/s, Loss=0.0001343, Gaussian number=182614, print grad=4.0418481717097166e-07, Depth Loss=0.0000000]
Training progress:  40%|████      | 810/2000 [06:15<11:35,  1.71it/s, Loss=0.0001343, Gaussian number=182614, print grad=4.0418481717097166e-07, Depth Loss=0.0000000]
Training progress:  40%|████      | 810/2000 [06:19<11:35,  1.71it/s, Loss=0.0001340, Gaussian number=182614, print grad=8.396446560254844e-07, Depth Loss=0.0000000] 
Training progress:  41%|████      | 820/2000 [06:19<10:23,  1.89it/s, Loss=0.0001340, Gaussian number=182614, print grad=8.396446560254844e-07, Depth Loss=0.0000000]
Training progress:  41%|████      | 820/2000 [06:23<10:23,  1.89it/s, Loss=0.0001050, Gaussian number=182614, print grad=1.3717227602683124e-06, Depth Loss=0.0000000]
Training progress:  42%|████▏     | 830/2000 [06:23<09:32,  2.04it/s, Loss=0.0001050, Gaussian number=182614, print grad=1.3717227602683124e-06, Depth Loss=0.0000000]
Training progress:  42%|████▏     | 830/2000 [06:26<09:32,  2.04it/s, Loss=0.0001145, Gaussian number=182614, print grad=1.8343384908803273e-06, Depth Loss=0.0000000]
Training progress:  42%|████▏     | 840/2000 [06:26<08:54,  2.17it/s, Loss=0.0001145, Gaussian number=182614, print grad=1.8343384908803273e-06, Depth Loss=0.0000000]
Training progress:  42%|████▏     | 840/2000 [06:30<08:54,  2.17it/s, Loss=0.0001221, Gaussian number=182614, print grad=2.321843567187898e-06, Depth Loss=0.0000000] 
Training progress:  42%|████▎     | 850/2000 [06:30<08:27,  2.26it/s, Loss=0.0001221, Gaussian number=182614, print grad=2.321843567187898e-06, Depth Loss=0.0000000]
Training progress:  42%|████▎     | 850/2000 [06:34<08:27,  2.26it/s, Loss=0.0001211, Gaussian number=182614, print grad=2.7697910809365567e-06, Depth Loss=0.0000000]
Training progress:  43%|████▎     | 860/2000 [06:34<08:08,  2.33it/s, Loss=0.0001211, Gaussian number=182614, print grad=2.7697910809365567e-06, Depth Loss=0.0000000]
Training progress:  43%|████▎     | 860/2000 [06:38<08:08,  2.33it/s, Loss=0.0001432, Gaussian number=182614, print grad=3.2318755529558985e-06, Depth Loss=0.0000000]
Training progress:  44%|████▎     | 870/2000 [06:38<07:53,  2.39it/s, Loss=0.0001432, Gaussian number=182614, print grad=3.2318755529558985e-06, Depth Loss=0.0000000]
Training progress:  44%|████▎     | 870/2000 [06:42<07:53,  2.39it/s, Loss=0.0001330, Gaussian number=182614, print grad=3.6915039345331024e-06, Depth Loss=0.0000000]
Training progress:  44%|████▍     | 880/2000 [06:42<07:41,  2.43it/s, Loss=0.0001330, Gaussian number=182614, print grad=3.6915039345331024e-06, Depth Loss=0.0000000]
Training progress:  44%|████▍     | 880/2000 [06:46<07:41,  2.43it/s, Loss=0.0001069, Gaussian number=182614, print grad=4.158343017479638e-06, Depth Loss=0.0000000] 
Training progress:  44%|████▍     | 890/2000 [06:46<07:33,  2.45it/s, Loss=0.0001069, Gaussian number=182614, print grad=4.158343017479638e-06, Depth Loss=0.0000000]
Training progress:  44%|████▍     | 890/2000 [06:50<07:33,  2.45it/s, Loss=0.0001381, Gaussian number=182614, print grad=4.622253527486464e-06, Depth Loss=0.0000000]
Training progress:  45%|████▌     | 900/2000 [06:50<07:25,  2.47it/s, Loss=0.0001381, Gaussian number=182614, print grad=4.622253527486464e-06, Depth Loss=0.0000000]
Training progress:  45%|████▌     | 900/2000 [07:00<07:25,  2.47it/s, Loss=0.0001036, Gaussian number=182579, print grad=4.04488929461877e-07, Depth Loss=0.0000000] 
Training progress:  46%|████▌     | 910/2000 [07:00<10:38,  1.71it/s, Loss=0.0001036, Gaussian number=182579, print grad=4.04488929461877e-07, Depth Loss=0.0000000]
Training progress:  46%|████▌     | 910/2000 [07:04<10:38,  1.71it/s, Loss=0.0001261, Gaussian number=182579, print grad=8.012578973648488e-07, Depth Loss=0.0000000]
Training progress:  46%|████▌     | 920/2000 [07:04<09:31,  1.89it/s, Loss=0.0001261, Gaussian number=182579, print grad=8.012578973648488e-07, Depth Loss=0.0000000]
Training progress:  46%|████▌     | 920/2000 [07:08<09:31,  1.89it/s, Loss=0.0001326, Gaussian number=182579, print grad=1.2989312381250784e-06, Depth Loss=0.0000000]
Training progress:  46%|████▋     | 930/2000 [07:08<08:43,  2.04it/s, Loss=0.0001326, Gaussian number=182579, print grad=1.2989312381250784e-06, Depth Loss=0.0000000]
Training progress:  46%|████▋     | 930/2000 [07:12<08:43,  2.04it/s, Loss=0.0001213, Gaussian number=182579, print grad=1.7421565416952944e-06, Depth Loss=0.0000000]
Training progress:  47%|████▋     | 940/2000 [07:12<08:09,  2.17it/s, Loss=0.0001213, Gaussian number=182579, print grad=1.7421565416952944e-06, Depth Loss=0.0000000]
Training progress:  47%|████▋     | 940/2000 [07:16<08:09,  2.17it/s, Loss=0.0001152, Gaussian number=182579, print grad=2.213919287896715e-06, Depth Loss=0.0000000] 
Training progress:  48%|████▊     | 950/2000 [07:16<07:44,  2.26it/s, Loss=0.0001152, Gaussian number=182579, print grad=2.213919287896715e-06, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 950/2000 [07:20<07:44,  2.26it/s, Loss=0.0001215, Gaussian number=182579, print grad=2.659941628735396e-06, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 960/2000 [07:20<07:26,  2.33it/s, Loss=0.0001215, Gaussian number=182579, print grad=2.659941628735396e-06, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 960/2000 [07:24<07:26,  2.33it/s, Loss=0.0001548, Gaussian number=182579, print grad=3.157688752253307e-06, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 970/2000 [07:24<07:12,  2.38it/s, Loss=0.0001548, Gaussian number=182579, print grad=3.157688752253307e-06, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 970/2000 [07:28<07:12,  2.38it/s, Loss=0.0001035, Gaussian number=182579, print grad=3.6357548651722027e-06, Depth Loss=0.0000000]
Training progress:  49%|████▉     | 980/2000 [07:28<07:00,  2.42it/s, Loss=0.0001035, Gaussian number=182579, print grad=3.6357548651722027e-06, Depth Loss=0.0000000]
Training progress:  49%|████▉     | 980/2000 [07:32<07:00,  2.42it/s, Loss=0.0001046, Gaussian number=182579, print grad=4.052566055179341e-06, Depth Loss=0.0000000] 
Training progress:  50%|████▉     | 990/2000 [07:32<06:54,  2.44it/s, Loss=0.0001046, Gaussian number=182579, print grad=4.052566055179341e-06, Depth Loss=0.0000000]
Training progress:  50%|████▉     | 990/2000 [07:36<06:54,  2.44it/s, Loss=0.0001383, Gaussian number=182579, print grad=4.450586857274175e-06, Depth Loss=0.0000000]
Training progress:  50%|█████     | 1000/2000 [07:36<06:46,  2.46it/s, Loss=0.0001383, Gaussian number=182579, print grad=4.450586857274175e-06, Depth Loss=0.0000000]
Training progress:  50%|█████     | 1000/2000 [07:46<06:46,  2.46it/s, Loss=0.0001232, Gaussian number=182552, print grad=3.920474966889742e-07, Depth Loss=0.0000000]
Training progress:  50%|█████     | 1010/2000 [07:46<09:39,  1.71it/s, Loss=0.0001232, Gaussian number=182552, print grad=3.920474966889742e-07, Depth Loss=0.0000000]
Training progress:  50%|█████     | 1010/2000 [07:50<09:39,  1.71it/s, Loss=0.0001507, Gaussian number=182552, print grad=9.240673648491793e-07, Depth Loss=0.0000000]
Training progress:  51%|█████     | 1020/2000 [07:50<08:38,  1.89it/s, Loss=0.0001507, Gaussian number=182552, print grad=9.240673648491793e-07, Depth Loss=0.0000000]
Training progress:  51%|█████     | 1020/2000 [07:54<08:38,  1.89it/s, Loss=0.0001256, Gaussian number=182552, print grad=1.4130880572338356e-06, Depth Loss=0.0000000]
Training progress:  52%|█████▏    | 1030/2000 [07:54<07:55,  2.04it/s, Loss=0.0001256, Gaussian number=182552, print grad=1.4130880572338356e-06, Depth Loss=0.0000000]
Training progress:  52%|█████▏    | 1030/2000 [07:58<07:55,  2.04it/s, Loss=0.0001330, Gaussian number=182552, print grad=1.9343301573826466e-06, Depth Loss=0.0000000]
Training progress:  52%|█████▏    | 1040/2000 [07:58<07:23,  2.17it/s, Loss=0.0001330, Gaussian number=182552, print grad=1.9343301573826466e-06, Depth Loss=0.0000000]
Training progress:  52%|█████▏    | 1040/2000 [08:02<07:23,  2.17it/s, Loss=0.0001207, Gaussian number=182552, print grad=2.350739805478952e-06, Depth Loss=0.0000000] 
Training progress:  52%|█████▎    | 1050/2000 [08:02<06:59,  2.26it/s, Loss=0.0001207, Gaussian number=182552, print grad=2.350739805478952e-06, Depth Loss=0.0000000]
Training progress:  52%|█████▎    | 1050/2000 [08:06<06:59,  2.26it/s, Loss=0.0001165, Gaussian number=182552, print grad=2.8096528694732115e-06, Depth Loss=0.0000000]
Training progress:  53%|█████▎    | 1060/2000 [08:06<06:42,  2.34it/s, Loss=0.0001165, Gaussian number=182552, print grad=2.8096528694732115e-06, Depth Loss=0.0000000]
Training progress:  53%|█████▎    | 1060/2000 [08:10<06:42,  2.34it/s, Loss=0.0000968, Gaussian number=182552, print grad=3.3315466225758428e-06, Depth Loss=0.0000000]
Training progress:  54%|█████▎    | 1070/2000 [08:10<06:29,  2.39it/s, Loss=0.0000968, Gaussian number=182552, print grad=3.3315466225758428e-06, Depth Loss=0.0000000]
Training progress:  54%|█████▎    | 1070/2000 [08:14<06:29,  2.39it/s, Loss=0.0001037, Gaussian number=182552, print grad=3.7793315641465597e-06, Depth Loss=0.0000000]
Training progress:  54%|█████▍    | 1080/2000 [08:14<06:19,  2.42it/s, Loss=0.0001037, Gaussian number=182552, print grad=3.7793315641465597e-06, Depth Loss=0.0000000]
Training progress:  54%|█████▍    | 1080/2000 [08:18<06:19,  2.42it/s, Loss=0.0001310, Gaussian number=182552, print grad=4.263810296833981e-06, Depth Loss=0.0000000] 
Training progress:  55%|█████▍    | 1090/2000 [08:18<06:10,  2.45it/s, Loss=0.0001310, Gaussian number=182552, print grad=4.263810296833981e-06, Depth Loss=0.0000000]
Training progress:  55%|█████▍    | 1090/2000 [08:22<06:10,  2.45it/s, Loss=0.0001289, Gaussian number=182552, print grad=4.733926743938355e-06, Depth Loss=0.0000000]
Training progress:  55%|█████▌    | 1100/2000 [08:22<06:03,  2.47it/s, Loss=0.0001289, Gaussian number=182552, print grad=4.733926743938355e-06, Depth Loss=0.0000000]
Training progress:  55%|█████▌    | 1100/2000 [08:26<06:03,  2.47it/s, Loss=0.0001354, Gaussian number=182515, print grad=4.110149802727392e-07, Depth Loss=0.0000000]
Training progress:  56%|█████▌    | 1110/2000 [08:26<05:58,  2.49it/s, Loss=0.0001354, Gaussian number=182515, print grad=4.110149802727392e-07, Depth Loss=0.0000000]
Training progress:  56%|█████▌    | 1110/2000 [08:30<05:58,  2.49it/s, Loss=0.0001237, Gaussian number=182515, print grad=9.172676982416306e-07, Depth Loss=0.0000000]
Training progress:  56%|█████▌    | 1120/2000 [08:30<05:52,  2.50it/s, Loss=0.0001237, Gaussian number=182515, print grad=9.172676982416306e-07, Depth Loss=0.0000000]
Training progress:  56%|█████▌    | 1120/2000 [08:34<05:52,  2.50it/s, Loss=0.0000996, Gaussian number=182515, print grad=1.429974872735329e-06, Depth Loss=0.0000000]
Training progress:  56%|█████▋    | 1130/2000 [08:34<05:47,  2.50it/s, Loss=0.0000996, Gaussian number=182515, print grad=1.429974872735329e-06, Depth Loss=0.0000000]
Training progress:  56%|█████▋    | 1130/2000 [08:38<05:47,  2.50it/s, Loss=0.0001260, Gaussian number=182515, print grad=1.939787125593284e-06, Depth Loss=0.0000000]
Training progress:  57%|█████▋    | 1140/2000 [08:38<05:42,  2.51it/s, Loss=0.0001260, Gaussian number=182515, print grad=1.939787125593284e-06, Depth Loss=0.0000000]
Training progress:  57%|█████▋    | 1140/2000 [08:42<05:42,  2.51it/s, Loss=0.0000898, Gaussian number=182515, print grad=2.4289065549965017e-06, Depth Loss=0.0000000]
Training progress:  57%|█████▊    | 1150/2000 [08:42<05:38,  2.51it/s, Loss=0.0000898, Gaussian number=182515, print grad=2.4289065549965017e-06, Depth Loss=0.0000000]
Training progress:  57%|█████▊    | 1150/2000 [08:46<05:38,  2.51it/s, Loss=0.0000985, Gaussian number=182515, print grad=2.862893779820297e-06, Depth Loss=0.0000000] 
Training progress:  58%|█████▊    | 1160/2000 [08:46<05:35,  2.51it/s, Loss=0.0000985, Gaussian number=182515, print grad=2.862893779820297e-06, Depth Loss=0.0000000]
Training progress:  58%|█████▊    | 1160/2000 [08:50<05:35,  2.51it/s, Loss=0.0001224, Gaussian number=182515, print grad=3.3451217404945055e-06, Depth Loss=0.0000000]
Training progress:  58%|█████▊    | 1170/2000 [08:50<05:30,  2.51it/s, Loss=0.0001224, Gaussian number=182515, print grad=3.3451217404945055e-06, Depth Loss=0.0000000]
Training progress:  58%|█████▊    | 1170/2000 [08:54<05:30,  2.51it/s, Loss=0.0001253, Gaussian number=182515, print grad=3.831632511719363e-06, Depth Loss=0.0000000] 
Training progress:  59%|█████▉    | 1180/2000 [08:54<05:26,  2.51it/s, Loss=0.0001253, Gaussian number=182515, print grad=3.831632511719363e-06, Depth Loss=0.0000000]
Training progress:  59%|█████▉    | 1180/2000 [08:58<05:26,  2.51it/s, Loss=0.0001203, Gaussian number=182515, print grad=4.343915406934684e-06, Depth Loss=0.0000000]
Training progress:  60%|█████▉    | 1190/2000 [08:58<05:22,  2.51it/s, Loss=0.0001203, Gaussian number=182515, print grad=4.343915406934684e-06, Depth Loss=0.0000000]
Training progress:  60%|█████▉    | 1190/2000 [09:02<05:22,  2.51it/s, Loss=0.0001341, Gaussian number=182515, print grad=4.757920123665826e-06, Depth Loss=0.0000000]
Training progress:  60%|██████    | 1200/2000 [09:02<05:18,  2.51it/s, Loss=0.0001341, Gaussian number=182515, print grad=4.757920123665826e-06, Depth Loss=0.0000000]
Training progress:  60%|██████    | 1200/2000 [09:06<05:18,  2.51it/s, Loss=0.0001039, Gaussian number=182489, print grad=4.5662838488169655e-07, Depth Loss=0.0000000]
Training progress:  60%|██████    | 1210/2000 [09:06<05:14,  2.51it/s, Loss=0.0001039, Gaussian number=182489, print grad=4.5662838488169655e-07, Depth Loss=0.0000000]
Training progress:  60%|██████    | 1210/2000 [09:10<05:14,  2.51it/s, Loss=0.0000881, Gaussian number=182489, print grad=9.813970791583415e-07, Depth Loss=0.0000000] 
Training progress:  61%|██████    | 1220/2000 [09:10<05:10,  2.51it/s, Loss=0.0000881, Gaussian number=182489, print grad=9.813970791583415e-07, Depth Loss=0.0000000]
Training progress:  61%|██████    | 1220/2000 [09:14<05:10,  2.51it/s, Loss=0.0000955, Gaussian number=182489, print grad=1.4342235772346612e-06, Depth Loss=0.0000000]
Training progress:  62%|██████▏   | 1230/2000 [09:14<05:06,  2.52it/s, Loss=0.0000955, Gaussian number=182489, print grad=1.4342235772346612e-06, Depth Loss=0.0000000]
Training progress:  62%|██████▏   | 1230/2000 [09:18<05:06,  2.52it/s, Loss=0.0000937, Gaussian number=182489, print grad=1.9525530206010444e-06, Depth Loss=0.0000000]
Training progress:  62%|██████▏   | 1240/2000 [09:18<05:01,  2.52it/s, Loss=0.0000937, Gaussian number=182489, print grad=1.9525530206010444e-06, Depth Loss=0.0000000]
Training progress:  62%|██████▏   | 1240/2000 [09:22<05:01,  2.52it/s, Loss=0.0000946, Gaussian number=182489, print grad=2.3846314434194937e-06, Depth Loss=0.0000000]
Training progress:  62%|██████▎   | 1250/2000 [09:22<04:57,  2.52it/s, Loss=0.0000946, Gaussian number=182489, print grad=2.3846314434194937e-06, Depth Loss=0.0000000]
Training progress:  62%|██████▎   | 1250/2000 [09:26<04:57,  2.52it/s, Loss=0.0000992, Gaussian number=182489, print grad=2.8062281671736855e-06, Depth Loss=0.0000000]
Training progress:  63%|██████▎   | 1260/2000 [09:26<04:53,  2.52it/s, Loss=0.0000992, Gaussian number=182489, print grad=2.8062281671736855e-06, Depth Loss=0.0000000]
Training progress:  63%|██████▎   | 1260/2000 [09:29<04:53,  2.52it/s, Loss=0.0001205, Gaussian number=182489, print grad=3.310335159767419e-06, Depth Loss=0.0000000] 
Training progress:  64%|██████▎   | 1270/2000 [09:29<04:49,  2.52it/s, Loss=0.0001205, Gaussian number=182489, print grad=3.310335159767419e-06, Depth Loss=0.0000000]
Training progress:  64%|██████▎   | 1270/2000 [09:33<04:49,  2.52it/s, Loss=0.0001223, Gaussian number=182489, print grad=3.7605534544127295e-06, Depth Loss=0.0000000]
Training progress:  64%|██████▍   | 1280/2000 [09:33<04:45,  2.52it/s, Loss=0.0001223, Gaussian number=182489, print grad=3.7605534544127295e-06, Depth Loss=0.0000000]
Training progress:  64%|██████▍   | 1280/2000 [09:37<04:45,  2.52it/s, Loss=0.0000966, Gaussian number=182489, print grad=4.2762640077853575e-06, Depth Loss=0.0000000]
Training progress:  64%|██████▍   | 1290/2000 [09:37<04:41,  2.53it/s, Loss=0.0000966, Gaussian number=182489, print grad=4.2762640077853575e-06, Depth Loss=0.0000000]
Training progress:  64%|██████▍   | 1290/2000 [09:41<04:41,  2.53it/s, Loss=0.0001426, Gaussian number=182489, print grad=4.729106876766309e-06, Depth Loss=0.0000000] 
Training progress:  65%|██████▌   | 1300/2000 [09:41<04:37,  2.52it/s, Loss=0.0001426, Gaussian number=182489, print grad=4.729106876766309e-06, Depth Loss=0.0000000]
Training progress:  65%|██████▌   | 1300/2000 [09:45<04:37,  2.52it/s, Loss=0.0001319, Gaussian number=182447, print grad=4.782855853591172e-07, Depth Loss=0.0000000]
Training progress:  66%|██████▌   | 1310/2000 [09:45<04:33,  2.52it/s, Loss=0.0001319, Gaussian number=182447, print grad=4.782855853591172e-07, Depth Loss=0.0000000]
Training progress:  66%|██████▌   | 1310/2000 [09:49<04:33,  2.52it/s, Loss=0.0001282, Gaussian number=182447, print grad=9.306833703703887e-07, Depth Loss=0.0000000]
Training progress:  66%|██████▌   | 1320/2000 [09:49<04:29,  2.52it/s, Loss=0.0001282, Gaussian number=182447, print grad=9.306833703703887e-07, Depth Loss=0.0000000]
Training progress:  66%|██████▌   | 1320/2000 [09:53<04:29,  2.52it/s, Loss=0.0001024, Gaussian number=182447, print grad=1.413684913131874e-06, Depth Loss=0.0000000]
Training progress:  66%|██████▋   | 1330/2000 [09:53<04:25,  2.52it/s, Loss=0.0001024, Gaussian number=182447, print grad=1.413684913131874e-06, Depth Loss=0.0000000]
Training progress:  66%|██████▋   | 1330/2000 [09:57<04:25,  2.52it/s, Loss=0.0001117, Gaussian number=182447, print grad=1.922683395605418e-06, Depth Loss=0.0000000]
Training progress:  67%|██████▋   | 1340/2000 [09:57<04:22,  2.52it/s, Loss=0.0001117, Gaussian number=182447, print grad=1.922683395605418e-06, Depth Loss=0.0000000]
Training progress:  67%|██████▋   | 1340/2000 [10:01<04:22,  2.52it/s, Loss=0.0001503, Gaussian number=182447, print grad=2.3463176148652565e-06, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1350/2000 [10:01<04:18,  2.52it/s, Loss=0.0001503, Gaussian number=182447, print grad=2.3463176148652565e-06, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1350/2000 [10:05<04:18,  2.52it/s, Loss=0.0000921, Gaussian number=182447, print grad=2.7991918614134192e-06, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1360/2000 [10:05<04:14,  2.52it/s, Loss=0.0000921, Gaussian number=182447, print grad=2.7991918614134192e-06, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1360/2000 [10:09<04:14,  2.52it/s, Loss=0.0001664, Gaussian number=182447, print grad=3.311695991214947e-06, Depth Loss=0.0000000] 
Training progress:  68%|██████▊   | 1370/2000 [10:09<04:10,  2.52it/s, Loss=0.0001664, Gaussian number=182447, print grad=3.311695991214947e-06, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1370/2000 [10:13<04:10,  2.52it/s, Loss=0.0001098, Gaussian number=182447, print grad=3.7656218410120346e-06, Depth Loss=0.0000000]
Training progress:  69%|██████▉   | 1380/2000 [10:13<04:06,  2.51it/s, Loss=0.0001098, Gaussian number=182447, print grad=3.7656218410120346e-06, Depth Loss=0.0000000]
Training progress:  69%|██████▉   | 1380/2000 [10:17<04:06,  2.51it/s, Loss=0.0001010, Gaussian number=182447, print grad=4.211508894513827e-06, Depth Loss=0.0000000] 
Training progress:  70%|██████▉   | 1390/2000 [10:17<04:02,  2.52it/s, Loss=0.0001010, Gaussian number=182447, print grad=4.211508894513827e-06, Depth Loss=0.0000000]
Training progress:  70%|██████▉   | 1390/2000 [10:21<04:02,  2.52it/s, Loss=0.0001134, Gaussian number=182447, print grad=4.698184966400731e-06, Depth Loss=0.0000000]
Training progress:  70%|███████   | 1400/2000 [10:21<03:57,  2.52it/s, Loss=0.0001134, Gaussian number=182447, print grad=4.698184966400731e-06, Depth Loss=0.0000000]
Training progress:  70%|███████   | 1400/2000 [10:25<03:57,  2.52it/s, Loss=0.0001236, Gaussian number=182409, print grad=4.970733016307349e-07, Depth Loss=0.0000000]
Training progress:  70%|███████   | 1410/2000 [10:25<03:54,  2.52it/s, Loss=0.0001236, Gaussian number=182409, print grad=4.970733016307349e-07, Depth Loss=0.0000000]
Training progress:  70%|███████   | 1410/2000 [10:29<03:54,  2.52it/s, Loss=0.0001098, Gaussian number=182409, print grad=1.001637883746298e-06, Depth Loss=0.0000000]
Training progress:  71%|███████   | 1420/2000 [10:29<03:50,  2.52it/s, Loss=0.0001098, Gaussian number=182409, print grad=1.001637883746298e-06, Depth Loss=0.0000000]
Training progress:  71%|███████   | 1420/2000 [10:33<03:50,  2.52it/s, Loss=0.0001095, Gaussian number=182409, print grad=1.5475558257094235e-06, Depth Loss=0.0000000]
Training progress:  72%|███████▏  | 1430/2000 [10:33<03:46,  2.52it/s, Loss=0.0001095, Gaussian number=182409, print grad=1.5475558257094235e-06, Depth Loss=0.0000000]
Training progress:  72%|███████▏  | 1430/2000 [10:37<03:46,  2.52it/s, Loss=0.0001056, Gaussian number=182409, print grad=1.990428927456378e-06, Depth Loss=0.0000000] 
Training progress:  72%|███████▏  | 1440/2000 [10:37<03:41,  2.52it/s, Loss=0.0001056, Gaussian number=182409, print grad=1.990428927456378e-06, Depth Loss=0.0000000]
Training progress:  72%|███████▏  | 1440/2000 [10:41<03:41,  2.52it/s, Loss=0.0000939, Gaussian number=182409, print grad=2.4436585590592586e-06, Depth Loss=0.0000000]
Training progress:  72%|███████▎  | 1450/2000 [10:41<03:38,  2.52it/s, Loss=0.0000939, Gaussian number=182409, print grad=2.4436585590592586e-06, Depth Loss=0.0000000]
Training progress:  72%|███████▎  | 1450/2000 [10:45<03:38,  2.52it/s, Loss=0.0000863, Gaussian number=182409, print grad=2.922791509263334e-06, Depth Loss=0.0000000] 
Training progress:  73%|███████▎  | 1460/2000 [10:45<03:34,  2.52it/s, Loss=0.0000863, Gaussian number=182409, print grad=2.922791509263334e-06, Depth Loss=0.0000000]
Training progress:  73%|███████▎  | 1460/2000 [10:49<03:34,  2.52it/s, Loss=0.0001152, Gaussian number=182409, print grad=3.399894922040403e-06, Depth Loss=0.0000000]
Training progress:  74%|███████▎  | 1470/2000 [10:49<03:30,  2.52it/s, Loss=0.0001152, Gaussian number=182409, print grad=3.399894922040403e-06, Depth Loss=0.0000000]
Training progress:  74%|███████▎  | 1470/2000 [10:53<03:30,  2.52it/s, Loss=0.0001189, Gaussian number=182409, print grad=3.914706667274004e-06, Depth Loss=0.0000000]
Training progress:  74%|███████▍  | 1480/2000 [10:53<03:25,  2.53it/s, Loss=0.0001189, Gaussian number=182409, print grad=3.914706667274004e-06, Depth Loss=0.0000000]
Training progress:  74%|███████▍  | 1480/2000 [10:57<03:25,  2.53it/s, Loss=0.0001229, Gaussian number=182409, print grad=4.435665232449537e-06, Depth Loss=0.0000000]
Training progress:  74%|███████▍  | 1490/2000 [10:57<03:21,  2.53it/s, Loss=0.0001229, Gaussian number=182409, print grad=4.435665232449537e-06, Depth Loss=0.0000000]
Training progress:  74%|███████▍  | 1490/2000 [11:01<03:21,  2.53it/s, Loss=0.0001162, Gaussian number=182409, print grad=4.9328000386594795e-06, Depth Loss=0.0000000]
Training progress:  75%|███████▌  | 1500/2000 [11:01<03:17,  2.53it/s, Loss=0.0001162, Gaussian number=182409, print grad=4.9328000386594795e-06, Depth Loss=0.0000000]
Training progress:  75%|███████▌  | 1500/2000 [11:11<03:17,  2.53it/s, Loss=0.0001265, Gaussian number=182361, print grad=4.258731109985092e-07, Depth Loss=0.0000000] 
Training progress:  76%|███████▌  | 1510/2000 [11:11<04:42,  1.73it/s, Loss=0.0001265, Gaussian number=182361, print grad=4.258731109985092e-07, Depth Loss=0.0000000]
Training progress:  76%|███████▌  | 1510/2000 [11:15<04:42,  1.73it/s, Loss=0.0001115, Gaussian number=182361, print grad=8.803468745099963e-07, Depth Loss=0.0000000]
Training progress:  76%|███████▌  | 1520/2000 [11:15<04:11,  1.91it/s, Loss=0.0001115, Gaussian number=182361, print grad=8.803468745099963e-07, Depth Loss=0.0000000]
Training progress:  76%|███████▌  | 1520/2000 [11:19<04:11,  1.91it/s, Loss=0.0000716, Gaussian number=182361, print grad=1.4047452623344725e-06, Depth Loss=0.0000000]
Training progress:  76%|███████▋  | 1530/2000 [11:19<03:47,  2.06it/s, Loss=0.0000716, Gaussian number=182361, print grad=1.4047452623344725e-06, Depth Loss=0.0000000]
Training progress:  76%|███████▋  | 1530/2000 [11:23<03:47,  2.06it/s, Loss=0.0000973, Gaussian number=182361, print grad=1.890700104922871e-06, Depth Loss=0.0000000] 
Training progress:  77%|███████▋  | 1540/2000 [11:23<03:30,  2.18it/s, Loss=0.0000973, Gaussian number=182361, print grad=1.890700104922871e-06, Depth Loss=0.0000000]
Training progress:  77%|███████▋  | 1540/2000 [11:27<03:30,  2.18it/s, Loss=0.0001082, Gaussian number=182361, print grad=2.4091666546155466e-06, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1550/2000 [11:27<03:17,  2.27it/s, Loss=0.0001082, Gaussian number=182361, print grad=2.4091666546155466e-06, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1550/2000 [11:30<03:17,  2.27it/s, Loss=0.0001152, Gaussian number=182361, print grad=2.9583666218968574e-06, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1560/2000 [11:30<03:07,  2.34it/s, Loss=0.0001152, Gaussian number=182361, print grad=2.9583666218968574e-06, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1560/2000 [11:34<03:07,  2.34it/s, Loss=0.0000998, Gaussian number=182361, print grad=3.476237225186196e-06, Depth Loss=0.0000000] 
Training progress:  78%|███████▊  | 1570/2000 [11:34<02:59,  2.39it/s, Loss=0.0000998, Gaussian number=182361, print grad=3.476237225186196e-06, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1570/2000 [11:38<02:59,  2.39it/s, Loss=0.0000766, Gaussian number=182361, print grad=3.898222985299071e-06, Depth Loss=0.0000000]
Training progress:  79%|███████▉  | 1580/2000 [11:38<02:52,  2.43it/s, Loss=0.0000766, Gaussian number=182361, print grad=3.898222985299071e-06, Depth Loss=0.0000000]
Training progress:  79%|███████▉  | 1580/2000 [11:42<02:52,  2.43it/s, Loss=0.0001069, Gaussian number=182361, print grad=4.355386863608146e-06, Depth Loss=0.0000000]
Training progress:  80%|███████▉  | 1590/2000 [11:42<02:46,  2.46it/s, Loss=0.0001069, Gaussian number=182361, print grad=4.355386863608146e-06, Depth Loss=0.0000000]
Training progress:  80%|███████▉  | 1590/2000 [11:46<02:46,  2.46it/s, Loss=0.0001021, Gaussian number=182361, print grad=4.87942861582269e-06, Depth Loss=0.0000000] 
Training progress:  80%|████████  | 1600/2000 [11:46<02:41,  2.48it/s, Loss=0.0001021, Gaussian number=182361, print grad=4.87942861582269e-06, Depth Loss=0.0000000]
Training progress:  80%|████████  | 1600/2000 [11:50<02:41,  2.48it/s, Loss=0.0001062, Gaussian number=182322, print grad=4.880336632595572e-07, Depth Loss=0.0000000]
Training progress:  80%|████████  | 1610/2000 [11:50<02:36,  2.49it/s, Loss=0.0001062, Gaussian number=182322, print grad=4.880336632595572e-07, Depth Loss=0.0000000]
Training progress:  80%|████████  | 1610/2000 [11:54<02:36,  2.49it/s, Loss=0.0001099, Gaussian number=182322, print grad=1.0399913890069001e-06, Depth Loss=0.0000000]
Training progress:  81%|████████  | 1620/2000 [11:54<02:31,  2.50it/s, Loss=0.0001099, Gaussian number=182322, print grad=1.0399913890069001e-06, Depth Loss=0.0000000]
Training progress:  81%|████████  | 1620/2000 [11:58<02:31,  2.50it/s, Loss=0.0000979, Gaussian number=182322, print grad=1.5229486507450929e-06, Depth Loss=0.0000000]
Training progress:  82%|████████▏ | 1630/2000 [11:58<02:27,  2.51it/s, Loss=0.0000979, Gaussian number=182322, print grad=1.5229486507450929e-06, Depth Loss=0.0000000]
Training progress:  82%|████████▏ | 1630/2000 [12:02<02:27,  2.51it/s, Loss=0.0000751, Gaussian number=182322, print grad=2.01696957446984e-06, Depth Loss=0.0000000]  
Training progress:  82%|████████▏ | 1640/2000 [12:02<02:22,  2.52it/s, Loss=0.0000751, Gaussian number=182322, print grad=2.01696957446984e-06, Depth Loss=0.0000000]
Training progress:  82%|████████▏ | 1640/2000 [12:06<02:22,  2.52it/s, Loss=0.0000998, Gaussian number=182322, print grad=2.488054406057927e-06, Depth Loss=0.0000000]
Training progress:  82%|████████▎ | 1650/2000 [12:06<02:18,  2.52it/s, Loss=0.0000998, Gaussian number=182322, print grad=2.488054406057927e-06, Depth Loss=0.0000000]
Training progress:  82%|████████▎ | 1650/2000 [12:10<02:18,  2.52it/s, Loss=0.0000991, Gaussian number=182322, print grad=2.9574771360785235e-06, Depth Loss=0.0000000]
Training progress:  83%|████████▎ | 1660/2000 [12:10<02:14,  2.53it/s, Loss=0.0000991, Gaussian number=182322, print grad=2.9574771360785235e-06, Depth Loss=0.0000000]
Training progress:  83%|████████▎ | 1660/2000 [12:14<02:14,  2.53it/s, Loss=0.0000927, Gaussian number=182322, print grad=3.429730895732064e-06, Depth Loss=0.0000000] 
Training progress:  84%|████████▎ | 1670/2000 [12:14<02:10,  2.53it/s, Loss=0.0000927, Gaussian number=182322, print grad=3.429730895732064e-06, Depth Loss=0.0000000]
Training progress:  84%|████████▎ | 1670/2000 [12:18<02:10,  2.53it/s, Loss=0.0000862, Gaussian number=182322, print grad=3.942837793147191e-06, Depth Loss=0.0000000]
Training progress:  84%|████████▍ | 1680/2000 [12:18<02:06,  2.53it/s, Loss=0.0000862, Gaussian number=182322, print grad=3.942837793147191e-06, Depth Loss=0.0000000]
Training progress:  84%|████████▍ | 1680/2000 [12:22<02:06,  2.53it/s, Loss=0.0001006, Gaussian number=182322, print grad=4.455323505681008e-06, Depth Loss=0.0000000]
Training progress:  84%|████████▍ | 1690/2000 [12:22<02:02,  2.53it/s, Loss=0.0001006, Gaussian number=182322, print grad=4.455323505681008e-06, Depth Loss=0.0000000]
Training progress:  84%|████████▍ | 1690/2000 [12:26<02:02,  2.53it/s, Loss=0.0001087, Gaussian number=182322, print grad=4.919872026221128e-06, Depth Loss=0.0000000]
Training progress:  85%|████████▌ | 1700/2000 [12:26<01:58,  2.53it/s, Loss=0.0001087, Gaussian number=182322, print grad=4.919872026221128e-06, Depth Loss=0.0000000]
Training progress:  85%|████████▌ | 1700/2000 [12:30<01:58,  2.53it/s, Loss=0.0001079, Gaussian number=182276, print grad=5.102545515001111e-07, Depth Loss=0.0000000]
Training progress:  86%|████████▌ | 1710/2000 [12:30<01:54,  2.53it/s, Loss=0.0001079, Gaussian number=182276, print grad=5.102545515001111e-07, Depth Loss=0.0000000]
Training progress:  86%|████████▌ | 1710/2000 [12:34<01:54,  2.53it/s, Loss=0.0001118, Gaussian number=182276, print grad=9.519250170342275e-07, Depth Loss=0.0000000]
Training progress:  86%|████████▌ | 1720/2000 [12:34<01:50,  2.53it/s, Loss=0.0001118, Gaussian number=182276, print grad=9.519250170342275e-07, Depth Loss=0.0000000]
Training progress:  86%|████████▌ | 1720/2000 [12:38<01:50,  2.53it/s, Loss=0.0001057, Gaussian number=182276, print grad=1.4465823596765404e-06, Depth Loss=0.0000000]
Training progress:  86%|████████▋ | 1730/2000 [12:38<01:46,  2.53it/s, Loss=0.0001057, Gaussian number=182276, print grad=1.4465823596765404e-06, Depth Loss=0.0000000]
Training progress:  86%|████████▋ | 1730/2000 [12:42<01:46,  2.53it/s, Loss=0.0001270, Gaussian number=182276, print grad=1.996218543354189e-06, Depth Loss=0.0000000] 
Training progress:  87%|████████▋ | 1740/2000 [12:42<01:42,  2.53it/s, Loss=0.0001270, Gaussian number=182276, print grad=1.996218543354189e-06, Depth Loss=0.0000000]
Training progress:  87%|████████▋ | 1740/2000 [12:46<01:42,  2.53it/s, Loss=0.0001266, Gaussian number=182276, print grad=2.5321833163616247e-06, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1750/2000 [12:46<01:39,  2.52it/s, Loss=0.0001266, Gaussian number=182276, print grad=2.5321833163616247e-06, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1750/2000 [12:50<01:39,  2.52it/s, Loss=0.0001082, Gaussian number=182276, print grad=3.0371495540748583e-06, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1760/2000 [12:50<01:34,  2.53it/s, Loss=0.0001082, Gaussian number=182276, print grad=3.0371495540748583e-06, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1760/2000 [12:54<01:34,  2.53it/s, Loss=0.0000870, Gaussian number=182276, print grad=3.5056359592999797e-06, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1770/2000 [12:54<01:30,  2.53it/s, Loss=0.0000870, Gaussian number=182276, print grad=3.5056359592999797e-06, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1770/2000 [12:58<01:30,  2.53it/s, Loss=0.0001044, Gaussian number=182276, print grad=3.975143499701517e-06, Depth Loss=0.0000000] 
Training progress:  89%|████████▉ | 1780/2000 [12:58<01:27,  2.53it/s, Loss=0.0001044, Gaussian number=182276, print grad=3.975143499701517e-06, Depth Loss=0.0000000]
Training progress:  89%|████████▉ | 1780/2000 [13:01<01:27,  2.53it/s, Loss=0.0000989, Gaussian number=182276, print grad=4.389720743347425e-06, Depth Loss=0.0000000]
Training progress:  90%|████████▉ | 1790/2000 [13:01<01:23,  2.53it/s, Loss=0.0000989, Gaussian number=182276, print grad=4.389720743347425e-06, Depth Loss=0.0000000]
Training progress:  90%|████████▉ | 1790/2000 [13:05<01:23,  2.53it/s, Loss=0.0000986, Gaussian number=182276, print grad=4.929564511257922e-06, Depth Loss=0.0000000]
Training progress:  90%|█████████ | 1800/2000 [13:05<01:19,  2.53it/s, Loss=0.0000986, Gaussian number=182276, print grad=4.929564511257922e-06, Depth Loss=0.0000000]
Training progress:  90%|█████████ | 1800/2000 [13:09<01:19,  2.53it/s, Loss=0.0001032, Gaussian number=182226, print grad=4.925807957079087e-07, Depth Loss=0.0000000]
Training progress:  90%|█████████ | 1810/2000 [13:09<01:15,  2.53it/s, Loss=0.0001032, Gaussian number=182226, print grad=4.925807957079087e-07, Depth Loss=0.0000000]
Training progress:  90%|█████████ | 1810/2000 [13:13<01:15,  2.53it/s, Loss=0.0000926, Gaussian number=182226, print grad=1.0455231631567585e-06, Depth Loss=0.0000000]
Training progress:  91%|█████████ | 1820/2000 [13:13<01:11,  2.53it/s, Loss=0.0000926, Gaussian number=182226, print grad=1.0455231631567585e-06, Depth Loss=0.0000000]
Training progress:  91%|█████████ | 1820/2000 [13:17<01:11,  2.53it/s, Loss=0.0000776, Gaussian number=182226, print grad=1.4646136605733773e-06, Depth Loss=0.0000000]
Training progress:  92%|█████████▏| 1830/2000 [13:17<01:07,  2.53it/s, Loss=0.0000776, Gaussian number=182226, print grad=1.4646136605733773e-06, Depth Loss=0.0000000]
Training progress:  92%|█████████▏| 1830/2000 [13:21<01:07,  2.53it/s, Loss=0.0000881, Gaussian number=182226, print grad=2.0011998458357994e-06, Depth Loss=0.0000000]
Training progress:  92%|█████████▏| 1840/2000 [13:21<01:03,  2.53it/s, Loss=0.0000881, Gaussian number=182226, print grad=2.0011998458357994e-06, Depth Loss=0.0000000]
Training progress:  92%|█████████▏| 1840/2000 [13:25<01:03,  2.53it/s, Loss=0.0000939, Gaussian number=182226, print grad=2.501177732483484e-06, Depth Loss=0.0000000] 
Training progress:  92%|█████████▎| 1850/2000 [13:25<00:59,  2.53it/s, Loss=0.0000939, Gaussian number=182226, print grad=2.501177732483484e-06, Depth Loss=0.0000000]
Training progress:  92%|█████████▎| 1850/2000 [13:29<00:59,  2.53it/s, Loss=0.0000987, Gaussian number=182226, print grad=2.937370709332754e-06, Depth Loss=0.0000000]
Training progress:  93%|█████████▎| 1860/2000 [13:29<00:55,  2.53it/s, Loss=0.0000987, Gaussian number=182226, print grad=2.937370709332754e-06, Depth Loss=0.0000000]
Training progress:  93%|█████████▎| 1860/2000 [13:33<00:55,  2.53it/s, Loss=0.0001120, Gaussian number=182226, print grad=3.5061343623965513e-06, Depth Loss=0.0000000]
Training progress:  94%|█████████▎| 1870/2000 [13:33<00:51,  2.53it/s, Loss=0.0001120, Gaussian number=182226, print grad=3.5061343623965513e-06, Depth Loss=0.0000000]
Training progress:  94%|█████████▎| 1870/2000 [13:37<00:51,  2.53it/s, Loss=0.0000864, Gaussian number=182226, print grad=4.008872110716766e-06, Depth Loss=0.0000000] 
Training progress:  94%|█████████▍| 1880/2000 [13:37<00:47,  2.52it/s, Loss=0.0000864, Gaussian number=182226, print grad=4.008872110716766e-06, Depth Loss=0.0000000]
Training progress:  94%|█████████▍| 1880/2000 [13:41<00:47,  2.52it/s, Loss=0.0000964, Gaussian number=182226, print grad=4.507674020715058e-06, Depth Loss=0.0000000]
Training progress:  94%|█████████▍| 1890/2000 [13:41<00:43,  2.52it/s, Loss=0.0000964, Gaussian number=182226, print grad=4.507674020715058e-06, Depth Loss=0.0000000]
Training progress:  94%|█████████▍| 1890/2000 [13:45<00:43,  2.52it/s, Loss=0.0001169, Gaussian number=182226, print grad=5.025581685913494e-06, Depth Loss=0.0000000]
Training progress:  95%|█████████▌| 1900/2000 [13:45<00:39,  2.52it/s, Loss=0.0001169, Gaussian number=182226, print grad=5.025581685913494e-06, Depth Loss=0.0000000]
Training progress:  95%|█████████▌| 1900/2000 [13:49<00:39,  2.52it/s, Loss=0.0001067, Gaussian number=182194, print grad=4.2349427076260326e-07, Depth Loss=0.0000000]
Training progress:  96%|█████████▌| 1910/2000 [13:49<00:35,  2.52it/s, Loss=0.0001067, Gaussian number=182194, print grad=4.2349427076260326e-07, Depth Loss=0.0000000]
Training progress:  96%|█████████▌| 1910/2000 [13:53<00:35,  2.52it/s, Loss=0.0000819, Gaussian number=182194, print grad=9.053395615410409e-07, Depth Loss=0.0000000] 
Training progress:  96%|█████████▌| 1920/2000 [13:53<00:31,  2.52it/s, Loss=0.0000819, Gaussian number=182194, print grad=9.053395615410409e-07, Depth Loss=0.0000000]
Training progress:  96%|█████████▌| 1920/2000 [13:57<00:31,  2.52it/s, Loss=0.0000753, Gaussian number=182194, print grad=1.4177628600009484e-06, Depth Loss=0.0000000]
Training progress:  96%|█████████▋| 1930/2000 [13:57<00:27,  2.53it/s, Loss=0.0000753, Gaussian number=182194, print grad=1.4177628600009484e-06, Depth Loss=0.0000000]
Training progress:  96%|█████████▋| 1930/2000 [14:01<00:27,  2.53it/s, Loss=0.0001072, Gaussian number=182194, print grad=1.91346862266073e-06, Depth Loss=0.0000000]  
Training progress:  97%|█████████▋| 1940/2000 [14:01<00:23,  2.53it/s, Loss=0.0001072, Gaussian number=182194, print grad=1.91346862266073e-06, Depth Loss=0.0000000]
Training progress:  97%|█████████▋| 1940/2000 [14:05<00:23,  2.53it/s, Loss=0.0000834, Gaussian number=182194, print grad=2.4005223622225458e-06, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1950/2000 [14:05<00:19,  2.53it/s, Loss=0.0000834, Gaussian number=182194, print grad=2.4005223622225458e-06, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1950/2000 [14:09<00:19,  2.53it/s, Loss=0.0001305, Gaussian number=182194, print grad=2.875382506317692e-06, Depth Loss=0.0000000] 
Training progress:  98%|█████████▊| 1960/2000 [14:09<00:15,  2.53it/s, Loss=0.0001305, Gaussian number=182194, print grad=2.875382506317692e-06, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1960/2000 [14:13<00:15,  2.53it/s, Loss=0.0001083, Gaussian number=182194, print grad=3.3683897981973132e-06, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1970/2000 [14:13<00:11,  2.53it/s, Loss=0.0001083, Gaussian number=182194, print grad=3.3683897981973132e-06, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1970/2000 [14:17<00:11,  2.53it/s, Loss=0.0000969, Gaussian number=182194, print grad=3.872863089782186e-06, Depth Loss=0.0000000] 
Training progress:  99%|█████████▉| 1980/2000 [14:17<00:07,  2.53it/s, Loss=0.0000969, Gaussian number=182194, print grad=3.872863089782186e-06, Depth Loss=0.0000000]
Training progress:  99%|█████████▉| 1980/2000 [14:21<00:07,  2.53it/s, Loss=0.0000926, Gaussian number=182194, print grad=4.4113394324085675e-06, Depth Loss=0.0000000]
Training progress: 100%|█████████▉| 1990/2000 [14:21<00:03,  2.53it/s, Loss=0.0000926, Gaussian number=182194, print grad=4.4113394324085675e-06, Depth Loss=0.0000000]
Training progress: 100%|█████████▉| 1990/2000 [14:25<00:03,  2.53it/s, Loss=0.0000781, Gaussian number=182194, print grad=4.958716090186499e-06, Depth Loss=0.0000000] 
Training progress: 100%|██████████| 2000/2000 [14:25<00:00,  2.53it/s, Loss=0.0000781, Gaussian number=182194, print grad=4.958716090186499e-06, Depth Loss=0.0000000]
Training progress: 100%|██████████| 2000/2000 [14:25<00:00,  2.31it/s, Loss=0.0000781, Gaussian number=182194, print grad=4.958716090186499e-06, Depth Loss=0.0000000]
Iteration 100 [15/11 01:21:55]

[ITER 100] Evaluating test: WD 0.000198, PSNR 12.9384 [15/11 01:22:00]

[ITER 100] Evaluating train: WD 0.000206, PSNR 13.2949 [15/11 01:22:01]
Gaussian number:182686,print gradients:2.8085084480267142e-08 [15/11 01:22:01]
Iteration 200 [15/11 01:22:41]

[ITER 200] Evaluating test: WD 0.000175, PSNR 14.2234 [15/11 01:22:47]

[ITER 200] Evaluating train: WD 0.000178, PSNR 14.3945 [15/11 01:22:48]
Gaussian number:182686,print gradients:3.626205113960168e-08 [15/11 01:22:48]
Iteration 300 [15/11 01:23:28]

[ITER 300] Evaluating test: WD 0.000160, PSNR 14.9485 [15/11 01:23:33]

[ITER 300] Evaluating train: WD 0.000162, PSNR 15.2129 [15/11 01:23:34]
Gaussian number:182686,print gradients:4.136991194059192e-08 [15/11 01:23:34]
Iteration 400 [15/11 01:24:14]

[ITER 400] Evaluating test: WD 0.000153, PSNR 15.3903 [15/11 01:24:19]

[ITER 400] Evaluating train: WD 0.000155, PSNR 15.7944 [15/11 01:24:20]
Gaussian number:182686,print gradients:4.463142388999586e-08 [15/11 01:24:20]
Iteration 500 [15/11 01:25:00]

[ITER 500] Evaluating test: WD 0.000145, PSNR 15.8249 [15/11 01:25:05]

[ITER 500] Evaluating train: WD 0.000156, PSNR 15.8559 [15/11 01:25:06]
Gaussian number:182686,print gradients:4.825687582865612e-08 [15/11 01:25:06]
Iteration 600 [15/11 01:25:46]

[ITER 600] Evaluating test: WD 0.000138, PSNR 16.0792 [15/11 01:25:51]

[ITER 600] Evaluating train: WD 0.000145, PSNR 16.1131 [15/11 01:25:52]
Gaussian number:182686,print gradients:5.08407858035298e-08 [15/11 01:25:52]
Iteration 700 [15/11 01:26:31]

[ITER 700] Evaluating test: WD 0.000136, PSNR 16.2421 [15/11 01:26:37]

[ITER 700] Evaluating train: WD 0.000141, PSNR 16.2245 [15/11 01:26:38]
Gaussian number:182665,print gradients:6.771109894998517e-08 [15/11 01:26:38]
Iteration 800 [15/11 01:27:17]

[ITER 800] Evaluating test: WD 0.000128, PSNR 16.4770 [15/11 01:27:23]

[ITER 800] Evaluating train: WD 0.000133, PSNR 16.5441 [15/11 01:27:24]
Gaussian number:182639,print gradients:6.65327206661459e-08 [15/11 01:27:24]
Iteration 900 [15/11 01:28:03]

[ITER 900] Evaluating test: WD 0.000127, PSNR 16.5819 [15/11 01:28:09]

[ITER 900] Evaluating train: WD 0.000136, PSNR 16.6019 [15/11 01:28:09]
Gaussian number:182614,print gradients:6.874648050825272e-08 [15/11 01:28:09]
Iteration 1000 [15/11 01:28:49]

[ITER 1000] Evaluating test: WD 0.000125, PSNR 16.6938 [15/11 01:28:55]

[ITER 1000] Evaluating train: WD 0.000136, PSNR 16.5965 [15/11 01:28:55]
Gaussian number:182579,print gradients:6.825847265190532e-08 [15/11 01:28:55]
Iteration 1100 [15/11 01:29:35]
Iteration 1200 [15/11 01:30:14]
Iteration 1300 [15/11 01:30:54]
Iteration 1400 [15/11 01:31:34]
Iteration 1500 [15/11 01:32:13]

[ITER 1500] Evaluating test: WD 0.000112, PSNR 17.2003 [15/11 01:32:19]

[ITER 1500] Evaluating train: WD 0.000120, PSNR 17.2800 [15/11 01:32:20]
Gaussian number:182409,print gradients:7.471673768577602e-08 [15/11 01:32:20]
Iteration 1600 [15/11 01:32:59]
Iteration 1700 [15/11 01:33:39]
Iteration 1800 [15/11 01:34:18]
Iteration 1900 [15/11 01:34:58]
Iteration 2000 [15/11 01:35:37]

[ITER 2000] Evaluating test: WD 0.000104, PSNR 17.5998 [15/11 01:35:43]

[ITER 2000] Evaluating train: WD 0.000115, PSNR 17.7085 [15/11 01:35:44]
Gaussian number:182194,print gradients:7.583681593814617e-08 [15/11 01:35:44]

[ITER 2000] Saving Gaussians [15/11 01:35:44]

Training complete. [15/11 01:35:45]
