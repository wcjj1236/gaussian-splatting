Optimizing /home/cw4287/gaussian-model/train1
Output folder: /home/cw4287/gaussian-model/train1 [15/11 00:38:46]
Tensorboard not available: not logging progress [15/11 00:38:46]
------------LLFF HOLD------------- [15/11 00:38:47]

Reading camera 1/301
Reading camera 2/301
Reading camera 3/301
Reading camera 4/301
Reading camera 5/301
Reading camera 6/301
Reading camera 7/301
Reading camera 8/301
Reading camera 9/301
Reading camera 10/301
Reading camera 11/301
Reading camera 12/301
Reading camera 13/301
Reading camera 14/301
Reading camera 15/301
Reading camera 16/301
Reading camera 17/301
Reading camera 18/301
Reading camera 19/301
Reading camera 20/301
Reading camera 21/301
Reading camera 22/301
Reading camera 23/301
Reading camera 24/301
Reading camera 25/301
Reading camera 26/301
Reading camera 27/301
Reading camera 28/301
Reading camera 29/301
Reading camera 30/301
Reading camera 31/301
Reading camera 32/301
Reading camera 33/301
Reading camera 34/301
Reading camera 35/301
Reading camera 36/301
Reading camera 37/301
Reading camera 38/301
Reading camera 39/301
Reading camera 40/301
Reading camera 41/301
Reading camera 42/301
Reading camera 43/301
Reading camera 44/301
Reading camera 45/301
Reading camera 46/301
Reading camera 47/301
Reading camera 48/301
Reading camera 49/301
Reading camera 50/301
Reading camera 51/301
Reading camera 52/301
Reading camera 53/301
Reading camera 54/301
Reading camera 55/301
Reading camera 56/301
Reading camera 57/301
Reading camera 58/301
Reading camera 59/301
Reading camera 60/301
Reading camera 61/301
Reading camera 62/301
Reading camera 63/301
Reading camera 64/301
Reading camera 65/301
Reading camera 66/301
Reading camera 67/301
Reading camera 68/301
Reading camera 69/301
Reading camera 70/301
Reading camera 71/301
Reading camera 72/301
Reading camera 73/301
Reading camera 74/301
Reading camera 75/301
Reading camera 76/301
Reading camera 77/301
Reading camera 78/301
Reading camera 79/301
Reading camera 80/301
Reading camera 81/301
Reading camera 82/301
Reading camera 83/301
Reading camera 84/301
Reading camera 85/301
Reading camera 86/301
Reading camera 87/301
Reading camera 88/301
Reading camera 89/301
Reading camera 90/301
Reading camera 91/301
Reading camera 92/301
Reading camera 93/301
Reading camera 94/301
Reading camera 95/301
Reading camera 96/301
Reading camera 97/301
Reading camera 98/301
Reading camera 99/301
Reading camera 100/301
Reading camera 101/301
Reading camera 102/301
Reading camera 103/301
Reading camera 104/301
Reading camera 105/301
Reading camera 106/301
Reading camera 107/301
Reading camera 108/301
Reading camera 109/301
Reading camera 110/301
Reading camera 111/301
Reading camera 112/301
Reading camera 113/301
Reading camera 114/301
Reading camera 115/301
Reading camera 116/301
Reading camera 117/301
Reading camera 118/301
Reading camera 119/301
Reading camera 120/301
Reading camera 121/301
Reading camera 122/301
Reading camera 123/301
Reading camera 124/301
Reading camera 125/301
Reading camera 126/301
Reading camera 127/301
Reading camera 128/301
Reading camera 129/301
Reading camera 130/301
Reading camera 131/301
Reading camera 132/301
Reading camera 133/301
Reading camera 134/301
Reading camera 135/301
Reading camera 136/301
Reading camera 137/301
Reading camera 138/301
Reading camera 139/301
Reading camera 140/301
Reading camera 141/301
Reading camera 142/301
Reading camera 143/301
Reading camera 144/301
Reading camera 145/301
Reading camera 146/301
Reading camera 147/301
Reading camera 148/301
Reading camera 149/301
Reading camera 150/301
Reading camera 151/301
Reading camera 152/301
Reading camera 153/301
Reading camera 154/301
Reading camera 155/301
Reading camera 156/301
Reading camera 157/301
Reading camera 158/301
Reading camera 159/301
Reading camera 160/301
Reading camera 161/301
Reading camera 162/301
Reading camera 163/301
Reading camera 164/301
Reading camera 165/301
Reading camera 166/301
Reading camera 167/301
Reading camera 168/301
Reading camera 169/301
Reading camera 170/301
Reading camera 171/301
Reading camera 172/301
Reading camera 173/301
Reading camera 174/301
Reading camera 175/301
Reading camera 176/301
Reading camera 177/301
Reading camera 178/301
Reading camera 179/301
Reading camera 180/301
Reading camera 181/301
Reading camera 182/301
Reading camera 183/301
Reading camera 184/301
Reading camera 185/301
Reading camera 186/301
Reading camera 187/301
Reading camera 188/301
Reading camera 189/301
Reading camera 190/301
Reading camera 191/301
Reading camera 192/301
Reading camera 193/301
Reading camera 194/301
Reading camera 195/301
Reading camera 196/301
Reading camera 197/301
Reading camera 198/301
Reading camera 199/301
Reading camera 200/301
Reading camera 201/301
Reading camera 202/301
Reading camera 203/301
Reading camera 204/301
Reading camera 205/301
Reading camera 206/301
Reading camera 207/301
Reading camera 208/301
Reading camera 209/301
Reading camera 210/301
Reading camera 211/301
Reading camera 212/301
Reading camera 213/301
Reading camera 214/301
Reading camera 215/301
Reading camera 216/301
Reading camera 217/301
Reading camera 218/301
Reading camera 219/301
Reading camera 220/301
Reading camera 221/301
Reading camera 222/301
Reading camera 223/301
Reading camera 224/301
Reading camera 225/301
Reading camera 226/301
Reading camera 227/301
Reading camera 228/301
Reading camera 229/301
Reading camera 230/301
Reading camera 231/301
Reading camera 232/301
Reading camera 233/301
Reading camera 234/301
Reading camera 235/301
Reading camera 236/301
Reading camera 237/301
Reading camera 238/301
Reading camera 239/301
Reading camera 240/301
Reading camera 241/301
Reading camera 242/301
Reading camera 243/301
Reading camera 244/301
Reading camera 245/301
Reading camera 246/301
Reading camera 247/301
Reading camera 248/301
Reading camera 249/301
Reading camera 250/301
Reading camera 251/301
Reading camera 252/301
Reading camera 253/301
Reading camera 254/301
Reading camera 255/301
Reading camera 256/301
Reading camera 257/301
Reading camera 258/301
Reading camera 259/301
Reading camera 260/301
Reading camera 261/301
Reading camera 262/301
Reading camera 263/301
Reading camera 264/301
Reading camera 265/301
Reading camera 266/301
Reading camera 267/301
Reading camera 268/301
Reading camera 269/301
Reading camera 270/301
Reading camera 271/301
Reading camera 272/301
Reading camera 273/301
Reading camera 274/301
Reading camera 275/301
Reading camera 276/301
Reading camera 277/301
Reading camera 278/301
Reading camera 279/301
Reading camera 280/301
Reading camera 281/301
Reading camera 282/301
Reading camera 283/301
Reading camera 284/301
Reading camera 285/301
Reading camera 286/301
Reading camera 287/301
Reading camera 288/301
Reading camera 289/301
Reading camera 290/301
Reading camera 291/301
Reading camera 292/301
Reading camera 293/301
Reading camera 294/301
Reading camera 295/301
Reading camera 296/301
Reading camera 297/301
Reading camera 298/301
Reading camera 299/301
Reading camera 300/301
Reading camera 301/301 [15/11 00:38:47]
Loading Training Cameras [15/11 00:38:47]
Loading Test Cameras [15/11 00:38:59]
Number of points at initialisation :  182686 [15/11 00:39:00]

Training progress:   0%|          | 0/2000 [00:00<?, ?it/s]/ext3/conda/envs/3dgs/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/ext3/conda/envs/3dgs/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)

Training progress:   0%|          | 0/2000 [00:05<?, ?it/s, Loss=0.0015183, Gaussian number=182686, print grad=6.168578465803876e-07, Depth Loss=0.0000000]
Training progress:   0%|          | 10/2000 [00:05<17:40,  1.88it/s, Loss=0.0015183, Gaussian number=182686, print grad=6.168578465803876e-07, Depth Loss=0.0000000]
Training progress:   0%|          | 10/2000 [00:08<17:40,  1.88it/s, Loss=0.0014706, Gaussian number=182686, print grad=1.6373511471101665e-06, Depth Loss=0.0000000]
Training progress:   1%|          | 20/2000 [00:08<14:20,  2.30it/s, Loss=0.0014706, Gaussian number=182686, print grad=1.6373511471101665e-06, Depth Loss=0.0000000]
Training progress:   1%|          | 20/2000 [00:12<14:20,  2.30it/s, Loss=0.0014598, Gaussian number=182686, print grad=2.5977028599299956e-06, Depth Loss=0.0000000]
Training progress:   2%|▏         | 30/2000 [00:12<13:16,  2.47it/s, Loss=0.0014598, Gaussian number=182686, print grad=2.5977028599299956e-06, Depth Loss=0.0000000]
Training progress:   2%|▏         | 30/2000 [00:16<13:16,  2.47it/s, Loss=0.0015734, Gaussian number=182686, print grad=3.6271430872147903e-06, Depth Loss=0.0000000]
Training progress:   2%|▏         | 40/2000 [00:16<12:42,  2.57it/s, Loss=0.0015734, Gaussian number=182686, print grad=3.6271430872147903e-06, Depth Loss=0.0000000]
Training progress:   2%|▏         | 40/2000 [00:19<12:42,  2.57it/s, Loss=0.0011990, Gaussian number=182686, print grad=4.418878688738914e-06, Depth Loss=0.0000000] 
Training progress:   2%|▎         | 50/2000 [00:19<12:22,  2.63it/s, Loss=0.0011990, Gaussian number=182686, print grad=4.418878688738914e-06, Depth Loss=0.0000000]
Training progress:   2%|▎         | 50/2000 [00:23<12:22,  2.63it/s, Loss=0.0013769, Gaussian number=182686, print grad=5.656303983414546e-06, Depth Loss=0.0000000]
Training progress:   3%|▎         | 60/2000 [00:23<12:07,  2.67it/s, Loss=0.0013769, Gaussian number=182686, print grad=5.656303983414546e-06, Depth Loss=0.0000000]
Training progress:   3%|▎         | 60/2000 [00:27<12:07,  2.67it/s, Loss=0.0012406, Gaussian number=182686, print grad=7.254236152220983e-06, Depth Loss=0.0000000]
Training progress:   4%|▎         | 70/2000 [00:27<11:57,  2.69it/s, Loss=0.0012406, Gaussian number=182686, print grad=7.254236152220983e-06, Depth Loss=0.0000000]
Training progress:   4%|▎         | 70/2000 [00:30<11:57,  2.69it/s, Loss=0.0014368, Gaussian number=182686, print grad=8.41403380036354e-06, Depth Loss=0.0000000] 
Training progress:   4%|▍         | 80/2000 [00:30<11:50,  2.70it/s, Loss=0.0014368, Gaussian number=182686, print grad=8.41403380036354e-06, Depth Loss=0.0000000]
Training progress:   4%|▍         | 80/2000 [00:34<11:50,  2.70it/s, Loss=0.0012354, Gaussian number=182686, print grad=9.616060197004117e-06, Depth Loss=0.0000000]
Training progress:   4%|▍         | 90/2000 [00:34<11:44,  2.71it/s, Loss=0.0012354, Gaussian number=182686, print grad=9.616060197004117e-06, Depth Loss=0.0000000]
Training progress:   4%|▍         | 90/2000 [00:38<11:44,  2.71it/s, Loss=0.0012348, Gaussian number=182686, print grad=1.1076682312705088e-05, Depth Loss=0.0000000]
Training progress:   5%|▌         | 100/2000 [00:38<11:39,  2.72it/s, Loss=0.0012348, Gaussian number=182686, print grad=1.1076682312705088e-05, Depth Loss=0.0000000]
Training progress:   5%|▌         | 100/2000 [00:47<11:39,  2.72it/s, Loss=0.0014432, Gaussian number=182686, print grad=1.2689608411164954e-05, Depth Loss=0.0000000]
Training progress:   6%|▌         | 110/2000 [00:47<16:58,  1.86it/s, Loss=0.0014432, Gaussian number=182686, print grad=1.2689608411164954e-05, Depth Loss=0.0000000]
Training progress:   6%|▌         | 110/2000 [00:51<16:58,  1.86it/s, Loss=0.0011970, Gaussian number=182686, print grad=1.4254259440349415e-05, Depth Loss=0.0000000]
Training progress:   6%|▌         | 120/2000 [00:51<15:12,  2.06it/s, Loss=0.0011970, Gaussian number=182686, print grad=1.4254259440349415e-05, Depth Loss=0.0000000]
Training progress:   6%|▌         | 120/2000 [00:54<15:12,  2.06it/s, Loss=0.0013971, Gaussian number=182686, print grad=1.6259753465419635e-05, Depth Loss=0.0000000]
Training progress:   6%|▋         | 130/2000 [00:54<14:00,  2.23it/s, Loss=0.0013971, Gaussian number=182686, print grad=1.6259753465419635e-05, Depth Loss=0.0000000]
Training progress:   6%|▋         | 130/2000 [00:58<14:00,  2.23it/s, Loss=0.0012695, Gaussian number=182686, print grad=1.8300499505130574e-05, Depth Loss=0.0000000]
Training progress:   7%|▋         | 140/2000 [00:58<13:08,  2.36it/s, Loss=0.0012695, Gaussian number=182686, print grad=1.8300499505130574e-05, Depth Loss=0.0000000]
Training progress:   7%|▋         | 140/2000 [01:02<13:08,  2.36it/s, Loss=0.0010988, Gaussian number=182686, print grad=2.0087432858417742e-05, Depth Loss=0.0000000]
Training progress:   8%|▊         | 150/2000 [01:02<12:30,  2.46it/s, Loss=0.0010988, Gaussian number=182686, print grad=2.0087432858417742e-05, Depth Loss=0.0000000]
Training progress:   8%|▊         | 150/2000 [01:05<12:30,  2.46it/s, Loss=0.0011737, Gaussian number=182686, print grad=2.2474845536635257e-05, Depth Loss=0.0000000]
Training progress:   8%|▊         | 160/2000 [01:05<12:02,  2.55it/s, Loss=0.0011737, Gaussian number=182686, print grad=2.2474845536635257e-05, Depth Loss=0.0000000]
Training progress:   8%|▊         | 160/2000 [01:09<12:02,  2.55it/s, Loss=0.0011601, Gaussian number=182686, print grad=2.419947304588277e-05, Depth Loss=0.0000000] 
Training progress:   8%|▊         | 170/2000 [01:09<11:42,  2.60it/s, Loss=0.0011601, Gaussian number=182686, print grad=2.419947304588277e-05, Depth Loss=0.0000000]
Training progress:   8%|▊         | 170/2000 [01:13<11:42,  2.60it/s, Loss=0.0010210, Gaussian number=182686, print grad=2.6343703211750835e-05, Depth Loss=0.0000000]
Training progress:   9%|▉         | 180/2000 [01:13<11:28,  2.64it/s, Loss=0.0010210, Gaussian number=182686, print grad=2.6343703211750835e-05, Depth Loss=0.0000000]
Training progress:   9%|▉         | 180/2000 [01:16<11:28,  2.64it/s, Loss=0.0012853, Gaussian number=182686, print grad=2.81106804322917e-05, Depth Loss=0.0000000]  
Training progress:  10%|▉         | 190/2000 [01:16<11:16,  2.68it/s, Loss=0.0012853, Gaussian number=182686, print grad=2.81106804322917e-05, Depth Loss=0.0000000]
Training progress:  10%|▉         | 190/2000 [01:20<11:16,  2.68it/s, Loss=0.0011558, Gaussian number=182686, print grad=3.0342154786922038e-05, Depth Loss=0.0000000]
Training progress:  10%|█         | 200/2000 [01:20<11:06,  2.70it/s, Loss=0.0011558, Gaussian number=182686, print grad=3.0342154786922038e-05, Depth Loss=0.0000000]
Training progress:  10%|█         | 200/2000 [01:29<11:06,  2.70it/s, Loss=0.0012842, Gaussian number=182686, print grad=3.2725685741752386e-05, Depth Loss=0.0000000]
Training progress:  10%|█         | 210/2000 [01:29<16:00,  1.86it/s, Loss=0.0012842, Gaussian number=182686, print grad=3.2725685741752386e-05, Depth Loss=0.0000000]
Training progress:  10%|█         | 210/2000 [01:33<16:00,  1.86it/s, Loss=0.0010711, Gaussian number=182686, print grad=3.481917519820854e-05, Depth Loss=0.0000000] 
Training progress:  11%|█         | 220/2000 [01:33<14:22,  2.06it/s, Loss=0.0010711, Gaussian number=182686, print grad=3.481917519820854e-05, Depth Loss=0.0000000]
Training progress:  11%|█         | 220/2000 [01:36<14:22,  2.06it/s, Loss=0.0011852, Gaussian number=182686, print grad=3.6956658732378855e-05, Depth Loss=0.0000000]
Training progress:  12%|█▏        | 230/2000 [01:36<13:13,  2.23it/s, Loss=0.0011852, Gaussian number=182686, print grad=3.6956658732378855e-05, Depth Loss=0.0000000]
Training progress:  12%|█▏        | 230/2000 [01:40<13:13,  2.23it/s, Loss=0.0014256, Gaussian number=182686, print grad=3.903215838363394e-05, Depth Loss=0.0000000] 
Training progress:  12%|█▏        | 240/2000 [01:40<12:23,  2.37it/s, Loss=0.0014256, Gaussian number=182686, print grad=3.903215838363394e-05, Depth Loss=0.0000000]
Training progress:  12%|█▏        | 240/2000 [01:44<12:23,  2.37it/s, Loss=0.0010954, Gaussian number=182686, print grad=4.1423074435442686e-05, Depth Loss=0.0000000]
Training progress:  12%|█▎        | 250/2000 [01:44<11:47,  2.47it/s, Loss=0.0010954, Gaussian number=182686, print grad=4.1423074435442686e-05, Depth Loss=0.0000000]
Training progress:  12%|█▎        | 250/2000 [01:47<11:47,  2.47it/s, Loss=0.0012319, Gaussian number=182686, print grad=4.362253821454942e-05, Depth Loss=0.0000000] 
Training progress:  13%|█▎        | 260/2000 [01:47<11:21,  2.55it/s, Loss=0.0012319, Gaussian number=182686, print grad=4.362253821454942e-05, Depth Loss=0.0000000]
Training progress:  13%|█▎        | 260/2000 [01:51<11:21,  2.55it/s, Loss=0.0009113, Gaussian number=182686, print grad=4.591906690620817e-05, Depth Loss=0.0000000]
Training progress:  14%|█▎        | 270/2000 [01:51<11:01,  2.61it/s, Loss=0.0009113, Gaussian number=182686, print grad=4.591906690620817e-05, Depth Loss=0.0000000]
Training progress:  14%|█▎        | 270/2000 [01:54<11:01,  2.61it/s, Loss=0.0011744, Gaussian number=182686, print grad=4.876398088526912e-05, Depth Loss=0.0000000]
Training progress:  14%|█▍        | 280/2000 [01:54<10:46,  2.66it/s, Loss=0.0011744, Gaussian number=182686, print grad=4.876398088526912e-05, Depth Loss=0.0000000]
Training progress:  14%|█▍        | 280/2000 [01:58<10:46,  2.66it/s, Loss=0.0011437, Gaussian number=182686, print grad=5.127381155034527e-05, Depth Loss=0.0000000]
Training progress:  14%|█▍        | 290/2000 [01:58<10:34,  2.69it/s, Loss=0.0011437, Gaussian number=182686, print grad=5.127381155034527e-05, Depth Loss=0.0000000]
Training progress:  14%|█▍        | 290/2000 [02:02<10:34,  2.69it/s, Loss=0.0010653, Gaussian number=182686, print grad=5.378032074077055e-05, Depth Loss=0.0000000]
Training progress:  15%|█▌        | 300/2000 [02:02<10:26,  2.71it/s, Loss=0.0010653, Gaussian number=182686, print grad=5.378032074077055e-05, Depth Loss=0.0000000]
Training progress:  15%|█▌        | 300/2000 [02:11<10:26,  2.71it/s, Loss=0.0009088, Gaussian number=182686, print grad=5.659105227096006e-05, Depth Loss=0.0000000]
Training progress:  16%|█▌        | 310/2000 [02:11<15:04,  1.87it/s, Loss=0.0009088, Gaussian number=182686, print grad=5.659105227096006e-05, Depth Loss=0.0000000]
Training progress:  16%|█▌        | 310/2000 [02:14<15:04,  1.87it/s, Loss=0.0009415, Gaussian number=182686, print grad=5.844991028425284e-05, Depth Loss=0.0000000]
Training progress:  16%|█▌        | 320/2000 [02:14<13:30,  2.07it/s, Loss=0.0009415, Gaussian number=182686, print grad=5.844991028425284e-05, Depth Loss=0.0000000]
Training progress:  16%|█▌        | 320/2000 [02:18<13:30,  2.07it/s, Loss=0.0012247, Gaussian number=182686, print grad=6.086895155021921e-05, Depth Loss=0.0000000]
Training progress:  16%|█▋        | 330/2000 [02:18<12:25,  2.24it/s, Loss=0.0012247, Gaussian number=182686, print grad=6.086895155021921e-05, Depth Loss=0.0000000]
Training progress:  16%|█▋        | 330/2000 [02:22<12:25,  2.24it/s, Loss=0.0009204, Gaussian number=182686, print grad=6.353523349389434e-05, Depth Loss=0.0000000]
Training progress:  17%|█▋        | 340/2000 [02:22<11:37,  2.38it/s, Loss=0.0009204, Gaussian number=182686, print grad=6.353523349389434e-05, Depth Loss=0.0000000]
Training progress:  17%|█▋        | 340/2000 [02:25<11:37,  2.38it/s, Loss=0.0009520, Gaussian number=182686, print grad=6.612015567952767e-05, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 350/2000 [02:25<11:03,  2.49it/s, Loss=0.0009520, Gaussian number=182686, print grad=6.612015567952767e-05, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 350/2000 [02:29<11:03,  2.49it/s, Loss=0.0009071, Gaussian number=182686, print grad=6.926502828719094e-05, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 360/2000 [02:29<10:39,  2.56it/s, Loss=0.0009071, Gaussian number=182686, print grad=6.926502828719094e-05, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 360/2000 [02:32<10:39,  2.56it/s, Loss=0.0009257, Gaussian number=182686, print grad=7.203321001725271e-05, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 370/2000 [02:32<10:21,  2.62it/s, Loss=0.0009257, Gaussian number=182686, print grad=7.203321001725271e-05, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 370/2000 [02:36<10:21,  2.62it/s, Loss=0.0011761, Gaussian number=182686, print grad=7.423308852594346e-05, Depth Loss=0.0000000]
Training progress:  19%|█▉        | 380/2000 [02:36<10:07,  2.67it/s, Loss=0.0011761, Gaussian number=182686, print grad=7.423308852594346e-05, Depth Loss=0.0000000]
Training progress:  19%|█▉        | 380/2000 [02:40<10:07,  2.67it/s, Loss=0.0010818, Gaussian number=182686, print grad=7.694516534684226e-05, Depth Loss=0.0000000]
Training progress:  20%|█▉        | 390/2000 [02:40<09:56,  2.70it/s, Loss=0.0010818, Gaussian number=182686, print grad=7.694516534684226e-05, Depth Loss=0.0000000]
Training progress:  20%|█▉        | 390/2000 [02:43<09:56,  2.70it/s, Loss=0.0012679, Gaussian number=182686, print grad=7.943906530272216e-05, Depth Loss=0.0000000]
Training progress:  20%|██        | 400/2000 [02:43<09:45,  2.73it/s, Loss=0.0012679, Gaussian number=182686, print grad=7.943906530272216e-05, Depth Loss=0.0000000]
Training progress:  20%|██        | 400/2000 [02:52<09:45,  2.73it/s, Loss=0.0010841, Gaussian number=182686, print grad=8.257318404503167e-05, Depth Loss=0.0000000]
Training progress:  20%|██        | 410/2000 [02:52<14:07,  1.88it/s, Loss=0.0010841, Gaussian number=182686, print grad=8.257318404503167e-05, Depth Loss=0.0000000]
Training progress:  20%|██        | 410/2000 [02:56<14:07,  1.88it/s, Loss=0.0009762, Gaussian number=182686, print grad=8.551271457690746e-05, Depth Loss=0.0000000]
Training progress:  21%|██        | 420/2000 [02:56<12:40,  2.08it/s, Loss=0.0009762, Gaussian number=182686, print grad=8.551271457690746e-05, Depth Loss=0.0000000]
Training progress:  21%|██        | 420/2000 [03:00<12:40,  2.08it/s, Loss=0.0012046, Gaussian number=182686, print grad=8.854275074554607e-05, Depth Loss=0.0000000]
Training progress:  22%|██▏       | 430/2000 [03:00<11:38,  2.25it/s, Loss=0.0012046, Gaussian number=182686, print grad=8.854275074554607e-05, Depth Loss=0.0000000]
Training progress:  22%|██▏       | 430/2000 [03:03<11:38,  2.25it/s, Loss=0.0009588, Gaussian number=182686, print grad=9.138733003055677e-05, Depth Loss=0.0000000]
Training progress:  22%|██▏       | 440/2000 [03:03<10:53,  2.39it/s, Loss=0.0009588, Gaussian number=182686, print grad=9.138733003055677e-05, Depth Loss=0.0000000]
Training progress:  22%|██▏       | 440/2000 [03:07<10:53,  2.39it/s, Loss=0.0010641, Gaussian number=182686, print grad=9.442478767596185e-05, Depth Loss=0.0000000]
Training progress:  22%|██▎       | 450/2000 [03:07<10:21,  2.49it/s, Loss=0.0010641, Gaussian number=182686, print grad=9.442478767596185e-05, Depth Loss=0.0000000]
Training progress:  22%|██▎       | 450/2000 [03:10<10:21,  2.49it/s, Loss=0.0010794, Gaussian number=182686, print grad=9.732226317282766e-05, Depth Loss=0.0000000]
Training progress:  23%|██▎       | 460/2000 [03:10<09:58,  2.57it/s, Loss=0.0010794, Gaussian number=182686, print grad=9.732226317282766e-05, Depth Loss=0.0000000]
Training progress:  23%|██▎       | 460/2000 [03:14<09:58,  2.57it/s, Loss=0.0012934, Gaussian number=182686, print grad=0.00010002713679568842, Depth Loss=0.0000000]
Training progress:  24%|██▎       | 470/2000 [03:14<09:40,  2.64it/s, Loss=0.0012934, Gaussian number=182686, print grad=0.00010002713679568842, Depth Loss=0.0000000]
Training progress:  24%|██▎       | 470/2000 [03:18<09:40,  2.64it/s, Loss=0.0008848, Gaussian number=182686, print grad=0.00010308917990187183, Depth Loss=0.0000000]
Training progress:  24%|██▍       | 480/2000 [03:18<09:27,  2.68it/s, Loss=0.0008848, Gaussian number=182686, print grad=0.00010308917990187183, Depth Loss=0.0000000]
Training progress:  24%|██▍       | 480/2000 [03:21<09:27,  2.68it/s, Loss=0.0009367, Gaussian number=182686, print grad=0.00010590334568405524, Depth Loss=0.0000000]
Training progress:  24%|██▍       | 490/2000 [03:21<09:17,  2.71it/s, Loss=0.0009367, Gaussian number=182686, print grad=0.00010590334568405524, Depth Loss=0.0000000]
Training progress:  24%|██▍       | 490/2000 [03:25<09:17,  2.71it/s, Loss=0.0007685, Gaussian number=182686, print grad=0.00010877502791117877, Depth Loss=0.0000000]
Training progress:  25%|██▌       | 500/2000 [03:25<09:08,  2.73it/s, Loss=0.0007685, Gaussian number=182686, print grad=0.00010877502791117877, Depth Loss=0.0000000]
Training progress:  25%|██▌       | 500/2000 [03:34<09:08,  2.73it/s, Loss=0.0008888, Gaussian number=182686, print grad=0.00011172247468493879, Depth Loss=0.0000000]
Training progress:  26%|██▌       | 510/2000 [03:34<13:13,  1.88it/s, Loss=0.0008888, Gaussian number=182686, print grad=0.00011172247468493879, Depth Loss=0.0000000]
Training progress:  26%|██▌       | 510/2000 [03:38<13:13,  1.88it/s, Loss=0.0009082, Gaussian number=182686, print grad=0.00011483623529784381, Depth Loss=0.0000000]
Training progress:  26%|██▌       | 520/2000 [03:38<11:50,  2.08it/s, Loss=0.0009082, Gaussian number=182686, print grad=0.00011483623529784381, Depth Loss=0.0000000]
Training progress:  26%|██▌       | 520/2000 [03:41<11:50,  2.08it/s, Loss=0.0007390, Gaussian number=182686, print grad=0.00011744083894882351, Depth Loss=0.0000000]
Training progress:  26%|██▋       | 530/2000 [03:41<10:51,  2.26it/s, Loss=0.0007390, Gaussian number=182686, print grad=0.00011744083894882351, Depth Loss=0.0000000]
Training progress:  26%|██▋       | 530/2000 [03:45<10:51,  2.26it/s, Loss=0.0009952, Gaussian number=182686, print grad=0.00012035752297379076, Depth Loss=0.0000000]
Training progress:  27%|██▋       | 540/2000 [03:45<10:09,  2.39it/s, Loss=0.0009952, Gaussian number=182686, print grad=0.00012035752297379076, Depth Loss=0.0000000]
Training progress:  27%|██▋       | 540/2000 [03:48<10:09,  2.39it/s, Loss=0.0009477, Gaussian number=182686, print grad=0.00012352870544418693, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 550/2000 [03:48<09:39,  2.50it/s, Loss=0.0009477, Gaussian number=182686, print grad=0.00012352870544418693, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 550/2000 [03:52<09:39,  2.50it/s, Loss=0.0007756, Gaussian number=182686, print grad=0.00012656219769269228, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 560/2000 [03:52<09:17,  2.58it/s, Loss=0.0007756, Gaussian number=182686, print grad=0.00012656219769269228, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 560/2000 [03:55<09:17,  2.58it/s, Loss=0.0009932, Gaussian number=182686, print grad=0.00013000056787859648, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 570/2000 [03:55<09:01,  2.64it/s, Loss=0.0009932, Gaussian number=182686, print grad=0.00013000056787859648, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 570/2000 [03:59<09:01,  2.64it/s, Loss=0.0008569, Gaussian number=182686, print grad=0.0001330003869952634, Depth Loss=0.0000000] 
Training progress:  29%|██▉       | 580/2000 [03:59<08:49,  2.68it/s, Loss=0.0008569, Gaussian number=182686, print grad=0.0001330003869952634, Depth Loss=0.0000000]
Training progress:  29%|██▉       | 580/2000 [04:03<08:49,  2.68it/s, Loss=0.0009701, Gaussian number=182686, print grad=0.00013614603085443377, Depth Loss=0.0000000]
Training progress:  30%|██▉       | 590/2000 [04:03<08:39,  2.71it/s, Loss=0.0009701, Gaussian number=182686, print grad=0.00013614603085443377, Depth Loss=0.0000000]
Training progress:  30%|██▉       | 590/2000 [04:06<08:39,  2.71it/s, Loss=0.0009983, Gaussian number=182686, print grad=0.0001390517281834036, Depth Loss=0.0000000] 
Training progress:  30%|███       | 600/2000 [04:06<08:31,  2.74it/s, Loss=0.0009983, Gaussian number=182686, print grad=0.0001390517281834036, Depth Loss=0.0000000]
Training progress:  30%|███       | 600/2000 [04:15<08:31,  2.74it/s, Loss=0.0008411, Gaussian number=182626, print grad=2.8930080588907003e-06, Depth Loss=0.0000000]
Training progress:  30%|███       | 610/2000 [04:15<12:19,  1.88it/s, Loss=0.0008411, Gaussian number=182626, print grad=2.8930080588907003e-06, Depth Loss=0.0000000]
Training progress:  30%|███       | 610/2000 [04:19<12:19,  1.88it/s, Loss=0.0010882, Gaussian number=182626, print grad=6.192713954078499e-06, Depth Loss=0.0000000] 
Training progress:  31%|███       | 620/2000 [04:19<11:01,  2.09it/s, Loss=0.0010882, Gaussian number=182626, print grad=6.192713954078499e-06, Depth Loss=0.0000000]
Training progress:  31%|███       | 620/2000 [04:23<11:01,  2.09it/s, Loss=0.0007908, Gaussian number=182626, print grad=8.911282748158555e-06, Depth Loss=0.0000000]
Training progress:  32%|███▏      | 630/2000 [04:23<10:07,  2.26it/s, Loss=0.0007908, Gaussian number=182626, print grad=8.911282748158555e-06, Depth Loss=0.0000000]
Training progress:  32%|███▏      | 630/2000 [04:26<10:07,  2.26it/s, Loss=0.0008625, Gaussian number=182626, print grad=1.2602256902027875e-05, Depth Loss=0.0000000]
Training progress:  32%|███▏      | 640/2000 [04:26<09:27,  2.40it/s, Loss=0.0008625, Gaussian number=182626, print grad=1.2602256902027875e-05, Depth Loss=0.0000000]
Training progress:  32%|███▏      | 640/2000 [04:30<09:27,  2.40it/s, Loss=0.0009813, Gaussian number=182626, print grad=1.5337853255914524e-05, Depth Loss=0.0000000]
Training progress:  32%|███▎      | 650/2000 [04:30<08:59,  2.50it/s, Loss=0.0009813, Gaussian number=182626, print grad=1.5337853255914524e-05, Depth Loss=0.0000000]
Training progress:  32%|███▎      | 650/2000 [04:33<08:59,  2.50it/s, Loss=0.0010326, Gaussian number=182626, print grad=1.8729553630691953e-05, Depth Loss=0.0000000]
Training progress:  33%|███▎      | 660/2000 [04:33<08:38,  2.58it/s, Loss=0.0010326, Gaussian number=182626, print grad=1.8729553630691953e-05, Depth Loss=0.0000000]
Training progress:  33%|███▎      | 660/2000 [04:37<08:38,  2.58it/s, Loss=0.0008836, Gaussian number=182626, print grad=2.1820942492922768e-05, Depth Loss=0.0000000]
Training progress:  34%|███▎      | 670/2000 [04:37<08:22,  2.65it/s, Loss=0.0008836, Gaussian number=182626, print grad=2.1820942492922768e-05, Depth Loss=0.0000000]
Training progress:  34%|███▎      | 670/2000 [04:40<08:22,  2.65it/s, Loss=0.0008424, Gaussian number=182626, print grad=2.5377848942298442e-05, Depth Loss=0.0000000]
Training progress:  34%|███▍      | 680/2000 [04:40<08:10,  2.69it/s, Loss=0.0008424, Gaussian number=182626, print grad=2.5377848942298442e-05, Depth Loss=0.0000000]
Training progress:  34%|███▍      | 680/2000 [04:44<08:10,  2.69it/s, Loss=0.0009895, Gaussian number=182626, print grad=2.8451462640077807e-05, Depth Loss=0.0000000]
Training progress:  34%|███▍      | 690/2000 [04:44<08:01,  2.72it/s, Loss=0.0009895, Gaussian number=182626, print grad=2.8451462640077807e-05, Depth Loss=0.0000000]
Training progress:  34%|███▍      | 690/2000 [04:48<08:01,  2.72it/s, Loss=0.0009900, Gaussian number=182626, print grad=3.1408588256454095e-05, Depth Loss=0.0000000]
Training progress:  35%|███▌      | 700/2000 [04:48<07:54,  2.74it/s, Loss=0.0009900, Gaussian number=182626, print grad=3.1408588256454095e-05, Depth Loss=0.0000000]
Training progress:  35%|███▌      | 700/2000 [04:57<07:54,  2.74it/s, Loss=0.0008381, Gaussian number=182588, print grad=2.6477305254957173e-06, Depth Loss=0.0000000]
Training progress:  36%|███▌      | 710/2000 [04:57<11:24,  1.88it/s, Loss=0.0008381, Gaussian number=182588, print grad=2.6477305254957173e-06, Depth Loss=0.0000000]
Training progress:  36%|███▌      | 710/2000 [05:00<11:24,  1.88it/s, Loss=0.0007824, Gaussian number=182588, print grad=5.7687057051225565e-06, Depth Loss=0.0000000]
Training progress:  36%|███▌      | 720/2000 [05:00<10:12,  2.09it/s, Loss=0.0007824, Gaussian number=182588, print grad=5.7687057051225565e-06, Depth Loss=0.0000000]
Training progress:  36%|███▌      | 720/2000 [05:04<10:12,  2.09it/s, Loss=0.0009858, Gaussian number=182588, print grad=8.652345059090294e-06, Depth Loss=0.0000000] 
Training progress:  36%|███▋      | 730/2000 [05:04<09:20,  2.26it/s, Loss=0.0009858, Gaussian number=182588, print grad=8.652345059090294e-06, Depth Loss=0.0000000]
Training progress:  36%|███▋      | 730/2000 [05:07<09:20,  2.26it/s, Loss=0.0012177, Gaussian number=182588, print grad=1.2231476830493193e-05, Depth Loss=0.0000000]
Training progress:  37%|███▋      | 740/2000 [05:07<08:44,  2.40it/s, Loss=0.0012177, Gaussian number=182588, print grad=1.2231476830493193e-05, Depth Loss=0.0000000]
Training progress:  37%|███▋      | 740/2000 [05:11<08:44,  2.40it/s, Loss=0.0008879, Gaussian number=182588, print grad=1.564247941132635e-05, Depth Loss=0.0000000] 
Training progress:  38%|███▊      | 750/2000 [05:11<08:17,  2.51it/s, Loss=0.0008879, Gaussian number=182588, print grad=1.564247941132635e-05, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 750/2000 [05:15<08:17,  2.51it/s, Loss=0.0008226, Gaussian number=182588, print grad=1.8861848730011843e-05, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 760/2000 [05:15<07:57,  2.60it/s, Loss=0.0008226, Gaussian number=182588, print grad=1.8861848730011843e-05, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 760/2000 [05:18<07:57,  2.60it/s, Loss=0.0007759, Gaussian number=182588, print grad=2.219329689978622e-05, Depth Loss=0.0000000] 
Training progress:  38%|███▊      | 770/2000 [05:18<07:42,  2.66it/s, Loss=0.0007759, Gaussian number=182588, print grad=2.219329689978622e-05, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 770/2000 [05:22<07:42,  2.66it/s, Loss=0.0009726, Gaussian number=182588, print grad=2.5269033358199522e-05, Depth Loss=0.0000000]
Training progress:  39%|███▉      | 780/2000 [05:22<07:30,  2.71it/s, Loss=0.0009726, Gaussian number=182588, print grad=2.5269033358199522e-05, Depth Loss=0.0000000]
Training progress:  39%|███▉      | 780/2000 [05:25<07:30,  2.71it/s, Loss=0.0011368, Gaussian number=182588, print grad=2.846274946932681e-05, Depth Loss=0.0000000] 
Training progress:  40%|███▉      | 790/2000 [05:25<07:22,  2.74it/s, Loss=0.0011368, Gaussian number=182588, print grad=2.846274946932681e-05, Depth Loss=0.0000000]
Training progress:  40%|███▉      | 790/2000 [05:29<07:22,  2.74it/s, Loss=0.0009790, Gaussian number=182588, print grad=3.197787009412423e-05, Depth Loss=0.0000000]
Training progress:  40%|████      | 800/2000 [05:29<07:14,  2.76it/s, Loss=0.0009790, Gaussian number=182588, print grad=3.197787009412423e-05, Depth Loss=0.0000000]
Training progress:  40%|████      | 800/2000 [05:38<07:14,  2.76it/s, Loss=0.0009562, Gaussian number=182548, print grad=2.982944806717569e-06, Depth Loss=0.0000000]
Training progress:  40%|████      | 810/2000 [05:38<10:29,  1.89it/s, Loss=0.0009562, Gaussian number=182548, print grad=2.982944806717569e-06, Depth Loss=0.0000000]
Training progress:  40%|████      | 810/2000 [05:42<10:29,  1.89it/s, Loss=0.0009252, Gaussian number=182548, print grad=6.0453653532022145e-06, Depth Loss=0.0000000]
Training progress:  41%|████      | 820/2000 [05:42<09:22,  2.10it/s, Loss=0.0009252, Gaussian number=182548, print grad=6.0453653532022145e-06, Depth Loss=0.0000000]
Training progress:  41%|████      | 820/2000 [05:45<09:22,  2.10it/s, Loss=0.0007514, Gaussian number=182548, print grad=9.895269613480195e-06, Depth Loss=0.0000000] 
Training progress:  42%|████▏     | 830/2000 [05:45<08:34,  2.27it/s, Loss=0.0007514, Gaussian number=182548, print grad=9.895269613480195e-06, Depth Loss=0.0000000]
Training progress:  42%|████▏     | 830/2000 [05:49<08:34,  2.27it/s, Loss=0.0007954, Gaussian number=182548, print grad=1.3238557585282251e-05, Depth Loss=0.0000000]
Training progress:  42%|████▏     | 840/2000 [05:49<08:00,  2.42it/s, Loss=0.0007954, Gaussian number=182548, print grad=1.3238557585282251e-05, Depth Loss=0.0000000]
Training progress:  42%|████▏     | 840/2000 [05:52<08:00,  2.42it/s, Loss=0.0008901, Gaussian number=182548, print grad=1.6823016267153434e-05, Depth Loss=0.0000000]
Training progress:  42%|████▎     | 850/2000 [05:52<07:35,  2.52it/s, Loss=0.0008901, Gaussian number=182548, print grad=1.6823016267153434e-05, Depth Loss=0.0000000]
Training progress:  42%|████▎     | 850/2000 [05:56<07:35,  2.52it/s, Loss=0.0008279, Gaussian number=182548, print grad=2.0080893591511995e-05, Depth Loss=0.0000000]
Training progress:  43%|████▎     | 860/2000 [05:56<07:17,  2.61it/s, Loss=0.0008279, Gaussian number=182548, print grad=2.0080893591511995e-05, Depth Loss=0.0000000]
Training progress:  43%|████▎     | 860/2000 [05:59<07:17,  2.61it/s, Loss=0.0010018, Gaussian number=182548, print grad=2.3349168259301223e-05, Depth Loss=0.0000000]
Training progress:  44%|████▎     | 870/2000 [05:59<07:03,  2.67it/s, Loss=0.0010018, Gaussian number=182548, print grad=2.3349168259301223e-05, Depth Loss=0.0000000]
Training progress:  44%|████▎     | 870/2000 [06:03<07:03,  2.67it/s, Loss=0.0009512, Gaussian number=182548, print grad=2.6541942133917473e-05, Depth Loss=0.0000000]
Training progress:  44%|████▍     | 880/2000 [06:03<06:53,  2.71it/s, Loss=0.0009512, Gaussian number=182548, print grad=2.6541942133917473e-05, Depth Loss=0.0000000]
Training progress:  44%|████▍     | 880/2000 [06:06<06:53,  2.71it/s, Loss=0.0007527, Gaussian number=182548, print grad=3.0017190510989167e-05, Depth Loss=0.0000000]
Training progress:  44%|████▍     | 890/2000 [06:06<06:44,  2.75it/s, Loss=0.0007527, Gaussian number=182548, print grad=3.0017190510989167e-05, Depth Loss=0.0000000]
Training progress:  44%|████▍     | 890/2000 [06:10<06:44,  2.75it/s, Loss=0.0009390, Gaussian number=182548, print grad=3.3226046070922166e-05, Depth Loss=0.0000000]
Training progress:  45%|████▌     | 900/2000 [06:10<06:37,  2.77it/s, Loss=0.0009390, Gaussian number=182548, print grad=3.3226046070922166e-05, Depth Loss=0.0000000]
Training progress:  45%|████▌     | 900/2000 [06:19<06:37,  2.77it/s, Loss=0.0007187, Gaussian number=182511, print grad=2.961363406939199e-06, Depth Loss=0.0000000] 
Training progress:  46%|████▌     | 910/2000 [06:19<09:35,  1.90it/s, Loss=0.0007187, Gaussian number=182511, print grad=2.961363406939199e-06, Depth Loss=0.0000000]
Training progress:  46%|████▌     | 910/2000 [06:23<09:35,  1.90it/s, Loss=0.0008915, Gaussian number=182511, print grad=5.628822691505775e-06, Depth Loss=0.0000000]
Training progress:  46%|████▌     | 920/2000 [06:23<08:33,  2.10it/s, Loss=0.0008915, Gaussian number=182511, print grad=5.628822691505775e-06, Depth Loss=0.0000000]
Training progress:  46%|████▌     | 920/2000 [06:26<08:33,  2.10it/s, Loss=0.0009331, Gaussian number=182511, print grad=9.258077625418082e-06, Depth Loss=0.0000000]
Training progress:  46%|████▋     | 930/2000 [06:26<07:50,  2.28it/s, Loss=0.0009331, Gaussian number=182511, print grad=9.258077625418082e-06, Depth Loss=0.0000000]
Training progress:  46%|████▋     | 930/2000 [06:30<07:50,  2.28it/s, Loss=0.0008610, Gaussian number=182511, print grad=1.2391346899676137e-05, Depth Loss=0.0000000]
Training progress:  47%|████▋     | 940/2000 [06:30<07:18,  2.41it/s, Loss=0.0008610, Gaussian number=182511, print grad=1.2391346899676137e-05, Depth Loss=0.0000000]
Training progress:  47%|████▋     | 940/2000 [06:33<07:18,  2.41it/s, Loss=0.0007964, Gaussian number=182511, print grad=1.5852050637477078e-05, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 950/2000 [06:33<06:55,  2.53it/s, Loss=0.0007964, Gaussian number=182511, print grad=1.5852050637477078e-05, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 950/2000 [06:37<06:55,  2.53it/s, Loss=0.0008294, Gaussian number=182511, print grad=1.9090983187197708e-05, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 960/2000 [06:37<06:38,  2.61it/s, Loss=0.0008294, Gaussian number=182511, print grad=1.9090983187197708e-05, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 960/2000 [06:40<06:38,  2.61it/s, Loss=0.0010296, Gaussian number=182511, print grad=2.2580346922040917e-05, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 970/2000 [06:40<06:25,  2.67it/s, Loss=0.0010296, Gaussian number=182511, print grad=2.2580346922040917e-05, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 970/2000 [06:44<06:25,  2.67it/s, Loss=0.0007231, Gaussian number=182511, print grad=2.594725083326921e-05, Depth Loss=0.0000000] 
Training progress:  49%|████▉     | 980/2000 [06:44<06:15,  2.72it/s, Loss=0.0007231, Gaussian number=182511, print grad=2.594725083326921e-05, Depth Loss=0.0000000]
Training progress:  49%|████▉     | 980/2000 [06:47<06:15,  2.72it/s, Loss=0.0007247, Gaussian number=182511, print grad=2.8882455808343366e-05, Depth Loss=0.0000000]
Training progress:  50%|████▉     | 990/2000 [06:47<06:07,  2.75it/s, Loss=0.0007247, Gaussian number=182511, print grad=2.8882455808343366e-05, Depth Loss=0.0000000]
Training progress:  50%|████▉     | 990/2000 [06:51<06:07,  2.75it/s, Loss=0.0009448, Gaussian number=182511, print grad=3.1698258680989966e-05, Depth Loss=0.0000000]
Training progress:  50%|█████     | 1000/2000 [06:51<06:00,  2.77it/s, Loss=0.0009448, Gaussian number=182511, print grad=3.1698258680989966e-05, Depth Loss=0.0000000]
Training progress:  50%|█████     | 1000/2000 [07:00<06:00,  2.77it/s, Loss=0.0008437, Gaussian number=182467, print grad=2.706101440708153e-06, Depth Loss=0.0000000] 
Training progress:  50%|█████     | 1010/2000 [07:00<08:42,  1.90it/s, Loss=0.0008437, Gaussian number=182467, print grad=2.706101440708153e-06, Depth Loss=0.0000000]
Training progress:  50%|█████     | 1010/2000 [07:04<08:42,  1.90it/s, Loss=0.0010304, Gaussian number=182467, print grad=6.490385203505866e-06, Depth Loss=0.0000000]
Training progress:  51%|█████     | 1020/2000 [07:04<07:45,  2.10it/s, Loss=0.0010304, Gaussian number=182467, print grad=6.490385203505866e-06, Depth Loss=0.0000000]
Training progress:  51%|█████     | 1020/2000 [07:07<07:45,  2.10it/s, Loss=0.0008796, Gaussian number=182467, print grad=9.991730621550232e-06, Depth Loss=0.0000000]
Training progress:  52%|█████▏    | 1030/2000 [07:07<07:05,  2.28it/s, Loss=0.0008796, Gaussian number=182467, print grad=9.991730621550232e-06, Depth Loss=0.0000000]
Training progress:  52%|█████▏    | 1030/2000 [07:11<07:05,  2.28it/s, Loss=0.0009119, Gaussian number=182467, print grad=1.3726077668252401e-05, Depth Loss=0.0000000]
Training progress:  52%|█████▏    | 1040/2000 [07:11<06:36,  2.42it/s, Loss=0.0009119, Gaussian number=182467, print grad=1.3726077668252401e-05, Depth Loss=0.0000000]
Training progress:  52%|█████▏    | 1040/2000 [07:14<06:36,  2.42it/s, Loss=0.0008301, Gaussian number=182467, print grad=1.663669536355883e-05, Depth Loss=0.0000000] 
Training progress:  52%|█████▎    | 1050/2000 [07:14<06:15,  2.53it/s, Loss=0.0008301, Gaussian number=182467, print grad=1.663669536355883e-05, Depth Loss=0.0000000]
Training progress:  52%|█████▎    | 1050/2000 [07:18<06:15,  2.53it/s, Loss=0.0008328, Gaussian number=182467, print grad=1.9931439965148456e-05, Depth Loss=0.0000000]
Training progress:  53%|█████▎    | 1060/2000 [07:18<05:59,  2.61it/s, Loss=0.0008328, Gaussian number=182467, print grad=1.9931439965148456e-05, Depth Loss=0.0000000]
Training progress:  53%|█████▎    | 1060/2000 [07:21<05:59,  2.61it/s, Loss=0.0006780, Gaussian number=182467, print grad=2.3715854695183225e-05, Depth Loss=0.0000000]
Training progress:  54%|█████▎    | 1070/2000 [07:21<05:47,  2.68it/s, Loss=0.0006780, Gaussian number=182467, print grad=2.3715854695183225e-05, Depth Loss=0.0000000]
Training progress:  54%|█████▎    | 1070/2000 [07:25<05:47,  2.68it/s, Loss=0.0007278, Gaussian number=182467, print grad=2.6943544071400538e-05, Depth Loss=0.0000000]
Training progress:  54%|█████▍    | 1080/2000 [07:25<05:38,  2.72it/s, Loss=0.0007278, Gaussian number=182467, print grad=2.6943544071400538e-05, Depth Loss=0.0000000]
Training progress:  54%|█████▍    | 1080/2000 [07:28<05:38,  2.72it/s, Loss=0.0009074, Gaussian number=182467, print grad=3.0489878554362804e-05, Depth Loss=0.0000000]
Training progress:  55%|█████▍    | 1090/2000 [07:28<05:30,  2.75it/s, Loss=0.0009074, Gaussian number=182467, print grad=3.0489878554362804e-05, Depth Loss=0.0000000]
Training progress:  55%|█████▍    | 1090/2000 [07:32<05:30,  2.75it/s, Loss=0.0008924, Gaussian number=182467, print grad=3.393613951629959e-05, Depth Loss=0.0000000] 
Training progress:  55%|█████▌    | 1100/2000 [07:32<05:24,  2.77it/s, Loss=0.0008924, Gaussian number=182467, print grad=3.393613951629959e-05, Depth Loss=0.0000000]
Training progress:  55%|█████▌    | 1100/2000 [07:35<05:24,  2.77it/s, Loss=0.0009114, Gaussian number=182417, print grad=2.867715011234395e-06, Depth Loss=0.0000000]
Training progress:  56%|█████▌    | 1110/2000 [07:35<05:19,  2.79it/s, Loss=0.0009114, Gaussian number=182417, print grad=2.867715011234395e-06, Depth Loss=0.0000000]
Training progress:  56%|█████▌    | 1110/2000 [07:39<05:19,  2.79it/s, Loss=0.0008619, Gaussian number=182417, print grad=6.375977136485744e-06, Depth Loss=0.0000000]
Training progress:  56%|█████▌    | 1120/2000 [07:39<05:15,  2.79it/s, Loss=0.0008619, Gaussian number=182417, print grad=6.375977136485744e-06, Depth Loss=0.0000000]
Training progress:  56%|█████▌    | 1120/2000 [07:43<05:15,  2.79it/s, Loss=0.0007104, Gaussian number=182417, print grad=1.005421654554084e-05, Depth Loss=0.0000000]
Training progress:  56%|█████▋    | 1130/2000 [07:43<05:10,  2.80it/s, Loss=0.0007104, Gaussian number=182417, print grad=1.005421654554084e-05, Depth Loss=0.0000000]
Training progress:  56%|█████▋    | 1130/2000 [07:46<05:10,  2.80it/s, Loss=0.0008686, Gaussian number=182417, print grad=1.3628964552481193e-05, Depth Loss=0.0000000]
Training progress:  57%|█████▋    | 1140/2000 [07:46<05:06,  2.80it/s, Loss=0.0008686, Gaussian number=182417, print grad=1.3628964552481193e-05, Depth Loss=0.0000000]
Training progress:  57%|█████▋    | 1140/2000 [07:50<05:06,  2.80it/s, Loss=0.0006481, Gaussian number=182417, print grad=1.7248998119612224e-05, Depth Loss=0.0000000]
Training progress:  57%|█████▊    | 1150/2000 [07:50<05:02,  2.81it/s, Loss=0.0006481, Gaussian number=182417, print grad=1.7248998119612224e-05, Depth Loss=0.0000000]
Training progress:  57%|█████▊    | 1150/2000 [07:53<05:02,  2.81it/s, Loss=0.0006998, Gaussian number=182417, print grad=2.0229052097420208e-05, Depth Loss=0.0000000]
Training progress:  58%|█████▊    | 1160/2000 [07:53<04:59,  2.81it/s, Loss=0.0006998, Gaussian number=182417, print grad=2.0229052097420208e-05, Depth Loss=0.0000000]
Training progress:  58%|█████▊    | 1160/2000 [07:57<04:59,  2.81it/s, Loss=0.0008442, Gaussian number=182417, print grad=2.36690066230949e-05, Depth Loss=0.0000000]  
Training progress:  58%|█████▊    | 1170/2000 [07:57<04:55,  2.81it/s, Loss=0.0008442, Gaussian number=182417, print grad=2.36690066230949e-05, Depth Loss=0.0000000]
Training progress:  58%|█████▊    | 1170/2000 [08:00<04:55,  2.81it/s, Loss=0.0008346, Gaussian number=182417, print grad=2.7285506803309545e-05, Depth Loss=0.0000000]
Training progress:  59%|█████▉    | 1180/2000 [08:00<04:51,  2.81it/s, Loss=0.0008346, Gaussian number=182417, print grad=2.7285506803309545e-05, Depth Loss=0.0000000]
Training progress:  59%|█████▉    | 1180/2000 [08:04<04:51,  2.81it/s, Loss=0.0008502, Gaussian number=182417, print grad=3.0947270715842023e-05, Depth Loss=0.0000000]
Training progress:  60%|█████▉    | 1190/2000 [08:04<04:48,  2.81it/s, Loss=0.0008502, Gaussian number=182417, print grad=3.0947270715842023e-05, Depth Loss=0.0000000]
Training progress:  60%|█████▉    | 1190/2000 [08:07<04:48,  2.81it/s, Loss=0.0009220, Gaussian number=182417, print grad=3.390846177353524e-05, Depth Loss=0.0000000] 
Training progress:  60%|██████    | 1200/2000 [08:07<04:44,  2.81it/s, Loss=0.0009220, Gaussian number=182417, print grad=3.390846177353524e-05, Depth Loss=0.0000000]
Training progress:  60%|██████    | 1200/2000 [08:11<04:44,  2.81it/s, Loss=0.0007446, Gaussian number=182370, print grad=3.2740556434873724e-06, Depth Loss=0.0000000]
Training progress:  60%|██████    | 1210/2000 [08:11<04:41,  2.81it/s, Loss=0.0007446, Gaussian number=182370, print grad=3.2740556434873724e-06, Depth Loss=0.0000000]
Training progress:  60%|██████    | 1210/2000 [08:15<04:41,  2.81it/s, Loss=0.0006333, Gaussian number=182370, print grad=7.048739462334197e-06, Depth Loss=0.0000000] 
Training progress:  61%|██████    | 1220/2000 [08:15<04:37,  2.81it/s, Loss=0.0006333, Gaussian number=182370, print grad=7.048739462334197e-06, Depth Loss=0.0000000]
Training progress:  61%|██████    | 1220/2000 [08:18<04:37,  2.81it/s, Loss=0.0006860, Gaussian number=182370, print grad=1.0408321031718515e-05, Depth Loss=0.0000000]
Training progress:  62%|██████▏   | 1230/2000 [08:18<04:33,  2.81it/s, Loss=0.0006860, Gaussian number=182370, print grad=1.0408321031718515e-05, Depth Loss=0.0000000]
Training progress:  62%|██████▏   | 1230/2000 [08:22<04:33,  2.81it/s, Loss=0.0006665, Gaussian number=182370, print grad=1.4162290426611435e-05, Depth Loss=0.0000000]
Training progress:  62%|██████▏   | 1240/2000 [08:22<04:29,  2.82it/s, Loss=0.0006665, Gaussian number=182370, print grad=1.4162290426611435e-05, Depth Loss=0.0000000]
Training progress:  62%|██████▏   | 1240/2000 [08:25<04:29,  2.82it/s, Loss=0.0006861, Gaussian number=182370, print grad=1.7253378246095963e-05, Depth Loss=0.0000000]
Training progress:  62%|██████▎   | 1250/2000 [08:25<04:26,  2.82it/s, Loss=0.0006861, Gaussian number=182370, print grad=1.7253378246095963e-05, Depth Loss=0.0000000]
Training progress:  62%|██████▎   | 1250/2000 [08:29<04:26,  2.82it/s, Loss=0.0007077, Gaussian number=182370, print grad=2.0279256204958074e-05, Depth Loss=0.0000000]
Training progress:  63%|██████▎   | 1260/2000 [08:29<04:22,  2.82it/s, Loss=0.0007077, Gaussian number=182370, print grad=2.0279256204958074e-05, Depth Loss=0.0000000]
Training progress:  63%|██████▎   | 1260/2000 [08:32<04:22,  2.82it/s, Loss=0.0008456, Gaussian number=182370, print grad=2.3923470507725142e-05, Depth Loss=0.0000000]
Training progress:  64%|██████▎   | 1270/2000 [08:32<04:19,  2.81it/s, Loss=0.0008456, Gaussian number=182370, print grad=2.3923470507725142e-05, Depth Loss=0.0000000]
Training progress:  64%|██████▎   | 1270/2000 [08:36<04:19,  2.81it/s, Loss=0.0008692, Gaussian number=182370, print grad=2.7101419618702494e-05, Depth Loss=0.0000000]
Training progress:  64%|██████▍   | 1280/2000 [08:36<04:16,  2.81it/s, Loss=0.0008692, Gaussian number=182370, print grad=2.7101419618702494e-05, Depth Loss=0.0000000]
Training progress:  64%|██████▍   | 1280/2000 [08:39<04:16,  2.81it/s, Loss=0.0006752, Gaussian number=182370, print grad=3.081137765548192e-05, Depth Loss=0.0000000] 
Training progress:  64%|██████▍   | 1290/2000 [08:39<04:12,  2.81it/s, Loss=0.0006752, Gaussian number=182370, print grad=3.081137765548192e-05, Depth Loss=0.0000000]
Training progress:  64%|██████▍   | 1290/2000 [08:43<04:12,  2.81it/s, Loss=0.0010093, Gaussian number=182370, print grad=3.410172575968318e-05, Depth Loss=0.0000000]
Training progress:  65%|██████▌   | 1300/2000 [08:43<04:08,  2.81it/s, Loss=0.0010093, Gaussian number=182370, print grad=3.410172575968318e-05, Depth Loss=0.0000000]
Training progress:  65%|██████▌   | 1300/2000 [08:46<04:08,  2.81it/s, Loss=0.0009192, Gaussian number=182322, print grad=3.4926761145470664e-06, Depth Loss=0.0000000]
Training progress:  66%|██████▌   | 1310/2000 [08:46<04:05,  2.81it/s, Loss=0.0009192, Gaussian number=182322, print grad=3.4926761145470664e-06, Depth Loss=0.0000000]
Training progress:  66%|██████▌   | 1310/2000 [08:50<04:05,  2.81it/s, Loss=0.0009015, Gaussian number=182322, print grad=6.7872665567847434e-06, Depth Loss=0.0000000]
Training progress:  66%|██████▌   | 1320/2000 [08:50<04:01,  2.81it/s, Loss=0.0009015, Gaussian number=182322, print grad=6.7872665567847434e-06, Depth Loss=0.0000000]
Training progress:  66%|██████▌   | 1320/2000 [08:54<04:01,  2.81it/s, Loss=0.0007138, Gaussian number=182322, print grad=1.0340389962948393e-05, Depth Loss=0.0000000]
Training progress:  66%|██████▋   | 1330/2000 [08:54<03:58,  2.81it/s, Loss=0.0007138, Gaussian number=182322, print grad=1.0340389962948393e-05, Depth Loss=0.0000000]
Training progress:  66%|██████▋   | 1330/2000 [08:57<03:58,  2.81it/s, Loss=0.0007937, Gaussian number=182322, print grad=1.3965515790914651e-05, Depth Loss=0.0000000]
Training progress:  67%|██████▋   | 1340/2000 [08:57<03:54,  2.81it/s, Loss=0.0007937, Gaussian number=182322, print grad=1.3965515790914651e-05, Depth Loss=0.0000000]
Training progress:  67%|██████▋   | 1340/2000 [09:01<03:54,  2.81it/s, Loss=0.0010472, Gaussian number=182322, print grad=1.6906187738641165e-05, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1350/2000 [09:01<03:50,  2.82it/s, Loss=0.0010472, Gaussian number=182322, print grad=1.6906187738641165e-05, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1350/2000 [09:04<03:50,  2.82it/s, Loss=0.0006450, Gaussian number=182322, print grad=2.0154144294792786e-05, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1360/2000 [09:04<03:47,  2.82it/s, Loss=0.0006450, Gaussian number=182322, print grad=2.0154144294792786e-05, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1360/2000 [09:08<03:47,  2.82it/s, Loss=0.0011552, Gaussian number=182322, print grad=2.4035169190028682e-05, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1370/2000 [09:08<03:44,  2.81it/s, Loss=0.0011552, Gaussian number=182322, print grad=2.4035169190028682e-05, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1370/2000 [09:11<03:44,  2.81it/s, Loss=0.0007793, Gaussian number=182322, print grad=2.7278207198833115e-05, Depth Loss=0.0000000]
Training progress:  69%|██████▉   | 1380/2000 [09:11<03:40,  2.81it/s, Loss=0.0007793, Gaussian number=182322, print grad=2.7278207198833115e-05, Depth Loss=0.0000000]
Training progress:  69%|██████▉   | 1380/2000 [09:15<03:40,  2.81it/s, Loss=0.0007258, Gaussian number=182322, print grad=3.0538823921233416e-05, Depth Loss=0.0000000]
Training progress:  70%|██████▉   | 1390/2000 [09:15<03:36,  2.81it/s, Loss=0.0007258, Gaussian number=182322, print grad=3.0538823921233416e-05, Depth Loss=0.0000000]
Training progress:  70%|██████▉   | 1390/2000 [09:18<03:36,  2.81it/s, Loss=0.0008036, Gaussian number=182322, print grad=3.399703200557269e-05, Depth Loss=0.0000000] 
Training progress:  70%|███████   | 1400/2000 [09:18<03:33,  2.81it/s, Loss=0.0008036, Gaussian number=182322, print grad=3.399703200557269e-05, Depth Loss=0.0000000]
Training progress:  70%|███████   | 1400/2000 [09:22<03:33,  2.81it/s, Loss=0.0008669, Gaussian number=182273, print grad=3.604625817388296e-06, Depth Loss=0.0000000]
Training progress:  70%|███████   | 1410/2000 [09:22<03:30,  2.81it/s, Loss=0.0008669, Gaussian number=182273, print grad=3.604625817388296e-06, Depth Loss=0.0000000]
Training progress:  70%|███████   | 1410/2000 [09:26<03:30,  2.81it/s, Loss=0.0007733, Gaussian number=182273, print grad=7.140044999687234e-06, Depth Loss=0.0000000]
Training progress:  71%|███████   | 1420/2000 [09:26<03:26,  2.81it/s, Loss=0.0007733, Gaussian number=182273, print grad=7.140044999687234e-06, Depth Loss=0.0000000]
Training progress:  71%|███████   | 1420/2000 [09:29<03:26,  2.81it/s, Loss=0.0007547, Gaussian number=182273, print grad=1.1109762453997973e-05, Depth Loss=0.0000000]
Training progress:  72%|███████▏  | 1430/2000 [09:29<03:23,  2.80it/s, Loss=0.0007547, Gaussian number=182273, print grad=1.1109762453997973e-05, Depth Loss=0.0000000]
Training progress:  72%|███████▏  | 1430/2000 [09:33<03:23,  2.80it/s, Loss=0.0007491, Gaussian number=182273, print grad=1.4253272638597991e-05, Depth Loss=0.0000000]
Training progress:  72%|███████▏  | 1440/2000 [09:33<03:19,  2.81it/s, Loss=0.0007491, Gaussian number=182273, print grad=1.4253272638597991e-05, Depth Loss=0.0000000]
Training progress:  72%|███████▏  | 1440/2000 [09:36<03:19,  2.81it/s, Loss=0.0006550, Gaussian number=182273, print grad=1.755643097567372e-05, Depth Loss=0.0000000] 
Training progress:  72%|███████▎  | 1450/2000 [09:36<03:15,  2.81it/s, Loss=0.0006550, Gaussian number=182273, print grad=1.755643097567372e-05, Depth Loss=0.0000000]
Training progress:  72%|███████▎  | 1450/2000 [09:40<03:15,  2.81it/s, Loss=0.0006051, Gaussian number=182273, print grad=2.104426130244974e-05, Depth Loss=0.0000000]
Training progress:  73%|███████▎  | 1460/2000 [09:40<03:12,  2.81it/s, Loss=0.0006051, Gaussian number=182273, print grad=2.104426130244974e-05, Depth Loss=0.0000000]
Training progress:  73%|███████▎  | 1460/2000 [09:43<03:12,  2.81it/s, Loss=0.0008179, Gaussian number=182273, print grad=2.4557593860663474e-05, Depth Loss=0.0000000]
Training progress:  74%|███████▎  | 1470/2000 [09:43<03:08,  2.81it/s, Loss=0.0008179, Gaussian number=182273, print grad=2.4557593860663474e-05, Depth Loss=0.0000000]
Training progress:  74%|███████▎  | 1470/2000 [09:47<03:08,  2.81it/s, Loss=0.0008439, Gaussian number=182273, print grad=2.822641545208171e-05, Depth Loss=0.0000000] 
Training progress:  74%|███████▍  | 1480/2000 [09:47<03:05,  2.81it/s, Loss=0.0008439, Gaussian number=182273, print grad=2.822641545208171e-05, Depth Loss=0.0000000]
Training progress:  74%|███████▍  | 1480/2000 [09:51<03:05,  2.81it/s, Loss=0.0008671, Gaussian number=182273, print grad=3.1832769309403375e-05, Depth Loss=0.0000000]
Training progress:  74%|███████▍  | 1490/2000 [09:51<03:01,  2.80it/s, Loss=0.0008671, Gaussian number=182273, print grad=3.1832769309403375e-05, Depth Loss=0.0000000]
Training progress:  74%|███████▍  | 1490/2000 [09:54<03:01,  2.80it/s, Loss=0.0008190, Gaussian number=182273, print grad=3.5454351746011525e-05, Depth Loss=0.0000000]
Training progress:  75%|███████▌  | 1500/2000 [09:54<02:58,  2.81it/s, Loss=0.0008190, Gaussian number=182273, print grad=3.5454351746011525e-05, Depth Loss=0.0000000]
Training progress:  75%|███████▌  | 1500/2000 [10:03<02:58,  2.81it/s, Loss=0.0009155, Gaussian number=182231, print grad=3.173237928422168e-06, Depth Loss=0.0000000] 
Training progress:  76%|███████▌  | 1510/2000 [10:03<04:17,  1.90it/s, Loss=0.0009155, Gaussian number=182231, print grad=3.173237928422168e-06, Depth Loss=0.0000000]
Training progress:  76%|███████▌  | 1510/2000 [10:07<04:17,  1.90it/s, Loss=0.0007831, Gaussian number=182231, print grad=6.378361376846442e-06, Depth Loss=0.0000000]
Training progress:  76%|███████▌  | 1520/2000 [10:07<03:47,  2.11it/s, Loss=0.0007831, Gaussian number=182231, print grad=6.378361376846442e-06, Depth Loss=0.0000000]
Training progress:  76%|███████▌  | 1520/2000 [10:10<03:47,  2.11it/s, Loss=0.0005119, Gaussian number=182231, print grad=1.031318970490247e-05, Depth Loss=0.0000000]
Training progress:  76%|███████▋  | 1530/2000 [10:10<03:26,  2.28it/s, Loss=0.0005119, Gaussian number=182231, print grad=1.031318970490247e-05, Depth Loss=0.0000000]
Training progress:  76%|███████▋  | 1530/2000 [10:14<03:26,  2.28it/s, Loss=0.0006801, Gaussian number=182231, print grad=1.3908647815696895e-05, Depth Loss=0.0000000]
Training progress:  77%|███████▋  | 1540/2000 [10:14<03:10,  2.42it/s, Loss=0.0006801, Gaussian number=182231, print grad=1.3908647815696895e-05, Depth Loss=0.0000000]
Training progress:  77%|███████▋  | 1540/2000 [10:18<03:10,  2.42it/s, Loss=0.0007626, Gaussian number=182231, print grad=1.761730163707398e-05, Depth Loss=0.0000000] 
Training progress:  78%|███████▊  | 1550/2000 [10:18<02:58,  2.52it/s, Loss=0.0007626, Gaussian number=182231, print grad=1.761730163707398e-05, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1550/2000 [10:21<02:58,  2.52it/s, Loss=0.0007994, Gaussian number=182231, print grad=2.160678013751749e-05, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1560/2000 [10:21<02:49,  2.60it/s, Loss=0.0007994, Gaussian number=182231, print grad=2.160678013751749e-05, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1560/2000 [10:25<02:49,  2.60it/s, Loss=0.0007163, Gaussian number=182231, print grad=2.5480992917437106e-05, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1570/2000 [10:25<02:41,  2.66it/s, Loss=0.0007163, Gaussian number=182231, print grad=2.5480992917437106e-05, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1570/2000 [10:28<02:41,  2.66it/s, Loss=0.0005501, Gaussian number=182231, print grad=2.85066562355496e-05, Depth Loss=0.0000000]  
Training progress:  79%|███████▉  | 1580/2000 [10:28<02:35,  2.70it/s, Loss=0.0005501, Gaussian number=182231, print grad=2.85066562355496e-05, Depth Loss=0.0000000]
Training progress:  79%|███████▉  | 1580/2000 [10:32<02:35,  2.70it/s, Loss=0.0007732, Gaussian number=182231, print grad=3.185565583407879e-05, Depth Loss=0.0000000]
Training progress:  80%|███████▉  | 1590/2000 [10:32<02:30,  2.73it/s, Loss=0.0007732, Gaussian number=182231, print grad=3.185565583407879e-05, Depth Loss=0.0000000]
Training progress:  80%|███████▉  | 1590/2000 [10:35<02:30,  2.73it/s, Loss=0.0007053, Gaussian number=182231, print grad=3.5668643249664456e-05, Depth Loss=0.0000000]
Training progress:  80%|████████  | 1600/2000 [10:35<02:25,  2.76it/s, Loss=0.0007053, Gaussian number=182231, print grad=3.5668643249664456e-05, Depth Loss=0.0000000]
Training progress:  80%|████████  | 1600/2000 [10:39<02:25,  2.76it/s, Loss=0.0007661, Gaussian number=182178, print grad=3.4949580367538147e-06, Depth Loss=0.0000000]
Training progress:  80%|████████  | 1610/2000 [10:39<02:20,  2.77it/s, Loss=0.0007661, Gaussian number=182178, print grad=3.4949580367538147e-06, Depth Loss=0.0000000]
Training progress:  80%|████████  | 1610/2000 [10:43<02:20,  2.77it/s, Loss=0.0007920, Gaussian number=182178, print grad=7.606423878314672e-06, Depth Loss=0.0000000] 
Training progress:  81%|████████  | 1620/2000 [10:43<02:16,  2.78it/s, Loss=0.0007920, Gaussian number=182178, print grad=7.606423878314672e-06, Depth Loss=0.0000000]
Training progress:  81%|████████  | 1620/2000 [10:46<02:16,  2.78it/s, Loss=0.0007082, Gaussian number=182178, print grad=1.120138040278107e-05, Depth Loss=0.0000000]
Training progress:  82%|████████▏ | 1630/2000 [10:46<02:12,  2.79it/s, Loss=0.0007082, Gaussian number=182178, print grad=1.120138040278107e-05, Depth Loss=0.0000000]
Training progress:  82%|████████▏ | 1630/2000 [10:50<02:12,  2.79it/s, Loss=0.0005393, Gaussian number=182178, print grad=1.4821755030425265e-05, Depth Loss=0.0000000]
Training progress:  82%|████████▏ | 1640/2000 [10:50<02:08,  2.80it/s, Loss=0.0005393, Gaussian number=182178, print grad=1.4821755030425265e-05, Depth Loss=0.0000000]
Training progress:  82%|████████▏ | 1640/2000 [10:53<02:08,  2.80it/s, Loss=0.0007052, Gaussian number=182178, print grad=1.835426337493118e-05, Depth Loss=0.0000000] 
Training progress:  82%|████████▎ | 1650/2000 [10:53<02:04,  2.80it/s, Loss=0.0007052, Gaussian number=182178, print grad=1.835426337493118e-05, Depth Loss=0.0000000]
Training progress:  82%|████████▎ | 1650/2000 [10:57<02:04,  2.80it/s, Loss=0.0006943, Gaussian number=182178, print grad=2.171306186937727e-05, Depth Loss=0.0000000]
Training progress:  83%|████████▎ | 1660/2000 [10:57<02:01,  2.81it/s, Loss=0.0006943, Gaussian number=182178, print grad=2.171306186937727e-05, Depth Loss=0.0000000]
Training progress:  83%|████████▎ | 1660/2000 [11:00<02:01,  2.81it/s, Loss=0.0006648, Gaussian number=182178, print grad=2.5194605768774636e-05, Depth Loss=0.0000000]
Training progress:  84%|████████▎ | 1670/2000 [11:00<01:57,  2.81it/s, Loss=0.0006648, Gaussian number=182178, print grad=2.5194605768774636e-05, Depth Loss=0.0000000]
Training progress:  84%|████████▎ | 1670/2000 [11:04<01:57,  2.81it/s, Loss=0.0006201, Gaussian number=182178, print grad=2.8751062927767634e-05, Depth Loss=0.0000000]
Training progress:  84%|████████▍ | 1680/2000 [11:04<01:53,  2.81it/s, Loss=0.0006201, Gaussian number=182178, print grad=2.8751062927767634e-05, Depth Loss=0.0000000]
Training progress:  84%|████████▍ | 1680/2000 [11:07<01:53,  2.81it/s, Loss=0.0007175, Gaussian number=182178, print grad=3.2559830287937075e-05, Depth Loss=0.0000000]
Training progress:  84%|████████▍ | 1690/2000 [11:07<01:50,  2.81it/s, Loss=0.0007175, Gaussian number=182178, print grad=3.2559830287937075e-05, Depth Loss=0.0000000]
Training progress:  84%|████████▍ | 1690/2000 [11:11<01:50,  2.81it/s, Loss=0.0007851, Gaussian number=182178, print grad=3.5960591048933566e-05, Depth Loss=0.0000000]
Training progress:  85%|████████▌ | 1700/2000 [11:11<01:46,  2.81it/s, Loss=0.0007851, Gaussian number=182178, print grad=3.5960591048933566e-05, Depth Loss=0.0000000]
Training progress:  85%|████████▌ | 1700/2000 [11:15<01:46,  2.81it/s, Loss=0.0007879, Gaussian number=182126, print grad=3.808514293268672e-06, Depth Loss=0.0000000] 
Training progress:  86%|████████▌ | 1710/2000 [11:15<01:43,  2.81it/s, Loss=0.0007879, Gaussian number=182126, print grad=3.808514293268672e-06, Depth Loss=0.0000000]
Training progress:  86%|████████▌ | 1710/2000 [11:18<01:43,  2.81it/s, Loss=0.0007637, Gaussian number=182126, print grad=6.9845764301135205e-06, Depth Loss=0.0000000]
Training progress:  86%|████████▌ | 1720/2000 [11:18<01:39,  2.81it/s, Loss=0.0007637, Gaussian number=182126, print grad=6.9845764301135205e-06, Depth Loss=0.0000000]
Training progress:  86%|████████▌ | 1720/2000 [11:22<01:39,  2.81it/s, Loss=0.0007678, Gaussian number=182126, print grad=1.054607673722785e-05, Depth Loss=0.0000000] 
Training progress:  86%|████████▋ | 1730/2000 [11:22<01:36,  2.81it/s, Loss=0.0007678, Gaussian number=182126, print grad=1.054607673722785e-05, Depth Loss=0.0000000]
Training progress:  86%|████████▋ | 1730/2000 [11:25<01:36,  2.81it/s, Loss=0.0008910, Gaussian number=182126, print grad=1.4433191608986817e-05, Depth Loss=0.0000000]
Training progress:  87%|████████▋ | 1740/2000 [11:25<01:32,  2.81it/s, Loss=0.0008910, Gaussian number=182126, print grad=1.4433191608986817e-05, Depth Loss=0.0000000]
Training progress:  87%|████████▋ | 1740/2000 [11:29<01:32,  2.81it/s, Loss=0.0008931, Gaussian number=182126, print grad=1.8272612578584813e-05, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1750/2000 [11:29<01:28,  2.81it/s, Loss=0.0008931, Gaussian number=182126, print grad=1.8272612578584813e-05, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1750/2000 [11:32<01:28,  2.81it/s, Loss=0.0007733, Gaussian number=182126, print grad=2.1943842511973344e-05, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1760/2000 [11:32<01:25,  2.81it/s, Loss=0.0007733, Gaussian number=182126, print grad=2.1943842511973344e-05, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1760/2000 [11:36<01:25,  2.81it/s, Loss=0.0006236, Gaussian number=182126, print grad=2.5287465177825652e-05, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1770/2000 [11:36<01:21,  2.81it/s, Loss=0.0006236, Gaussian number=182126, print grad=2.5287465177825652e-05, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1770/2000 [11:39<01:21,  2.81it/s, Loss=0.0007361, Gaussian number=182126, print grad=2.8688446036539972e-05, Depth Loss=0.0000000]
Training progress:  89%|████████▉ | 1780/2000 [11:39<01:18,  2.81it/s, Loss=0.0007361, Gaussian number=182126, print grad=2.8688446036539972e-05, Depth Loss=0.0000000]
Training progress:  89%|████████▉ | 1780/2000 [11:43<01:18,  2.81it/s, Loss=0.0006823, Gaussian number=182126, print grad=3.167808972648345e-05, Depth Loss=0.0000000] 
Training progress:  90%|████████▉ | 1790/2000 [11:43<01:14,  2.81it/s, Loss=0.0006823, Gaussian number=182126, print grad=3.167808972648345e-05, Depth Loss=0.0000000]
Training progress:  90%|████████▉ | 1790/2000 [11:47<01:14,  2.81it/s, Loss=0.0007092, Gaussian number=182126, print grad=3.554688737494871e-05, Depth Loss=0.0000000]
Training progress:  90%|█████████ | 1800/2000 [11:47<01:11,  2.81it/s, Loss=0.0007092, Gaussian number=182126, print grad=3.554688737494871e-05, Depth Loss=0.0000000]
Training progress:  90%|█████████ | 1800/2000 [11:50<01:11,  2.81it/s, Loss=0.0007300, Gaussian number=182085, print grad=3.4628549201443093e-06, Depth Loss=0.0000000]
Training progress:  90%|█████████ | 1810/2000 [11:50<01:07,  2.81it/s, Loss=0.0007300, Gaussian number=182085, print grad=3.4628549201443093e-06, Depth Loss=0.0000000]
Training progress:  90%|█████████ | 1810/2000 [11:54<01:07,  2.81it/s, Loss=0.0006681, Gaussian number=182085, print grad=7.516612186009297e-06, Depth Loss=0.0000000] 
Training progress:  91%|█████████ | 1820/2000 [11:54<01:04,  2.81it/s, Loss=0.0006681, Gaussian number=182085, print grad=7.516612186009297e-06, Depth Loss=0.0000000]
Training progress:  91%|█████████ | 1820/2000 [11:57<01:04,  2.81it/s, Loss=0.0005554, Gaussian number=182085, print grad=1.0450834452058189e-05, Depth Loss=0.0000000]
Training progress:  92%|█████████▏| 1830/2000 [11:57<01:00,  2.81it/s, Loss=0.0005554, Gaussian number=182085, print grad=1.0450834452058189e-05, Depth Loss=0.0000000]
Training progress:  92%|█████████▏| 1830/2000 [12:01<01:00,  2.81it/s, Loss=0.0006364, Gaussian number=182085, print grad=1.4427992027776781e-05, Depth Loss=0.0000000]
Training progress:  92%|█████████▏| 1840/2000 [12:01<00:56,  2.81it/s, Loss=0.0006364, Gaussian number=182085, print grad=1.4427992027776781e-05, Depth Loss=0.0000000]
Training progress:  92%|█████████▏| 1840/2000 [12:04<00:56,  2.81it/s, Loss=0.0006749, Gaussian number=182085, print grad=1.8006478057941422e-05, Depth Loss=0.0000000]
Training progress:  92%|█████████▎| 1850/2000 [12:04<00:53,  2.81it/s, Loss=0.0006749, Gaussian number=182085, print grad=1.8006478057941422e-05, Depth Loss=0.0000000]
Training progress:  92%|█████████▎| 1850/2000 [12:08<00:53,  2.81it/s, Loss=0.0006935, Gaussian number=182085, print grad=2.1207208192208782e-05, Depth Loss=0.0000000]
Training progress:  93%|█████████▎| 1860/2000 [12:08<00:49,  2.82it/s, Loss=0.0006935, Gaussian number=182085, print grad=2.1207208192208782e-05, Depth Loss=0.0000000]
Training progress:  93%|█████████▎| 1860/2000 [12:11<00:49,  2.82it/s, Loss=0.0007920, Gaussian number=182085, print grad=2.5411422029719688e-05, Depth Loss=0.0000000]
Training progress:  94%|█████████▎| 1870/2000 [12:11<00:46,  2.82it/s, Loss=0.0007920, Gaussian number=182085, print grad=2.5411422029719688e-05, Depth Loss=0.0000000]
Training progress:  94%|█████████▎| 1870/2000 [12:15<00:46,  2.82it/s, Loss=0.0006313, Gaussian number=182085, print grad=2.9125329092494212e-05, Depth Loss=0.0000000]
Training progress:  94%|█████████▍| 1880/2000 [12:15<00:42,  2.82it/s, Loss=0.0006313, Gaussian number=182085, print grad=2.9125329092494212e-05, Depth Loss=0.0000000]
Training progress:  94%|█████████▍| 1880/2000 [12:18<00:42,  2.82it/s, Loss=0.0006939, Gaussian number=182085, print grad=3.283238402218558e-05, Depth Loss=0.0000000] 
Training progress:  94%|█████████▍| 1890/2000 [12:18<00:39,  2.82it/s, Loss=0.0006939, Gaussian number=182085, print grad=3.283238402218558e-05, Depth Loss=0.0000000]
Training progress:  94%|█████████▍| 1890/2000 [12:22<00:39,  2.82it/s, Loss=0.0008030, Gaussian number=182085, print grad=3.6489836929831654e-05, Depth Loss=0.0000000]
Training progress:  95%|█████████▌| 1900/2000 [12:22<00:35,  2.81it/s, Loss=0.0008030, Gaussian number=182085, print grad=3.6489836929831654e-05, Depth Loss=0.0000000]
Training progress:  95%|█████████▌| 1900/2000 [12:26<00:35,  2.81it/s, Loss=0.0007630, Gaussian number=182045, print grad=2.9703296604566276e-06, Depth Loss=0.0000000]
Training progress:  96%|█████████▌| 1910/2000 [12:26<00:31,  2.81it/s, Loss=0.0007630, Gaussian number=182045, print grad=2.9703296604566276e-06, Depth Loss=0.0000000]
Training progress:  96%|█████████▌| 1910/2000 [12:29<00:31,  2.81it/s, Loss=0.0005823, Gaussian number=182045, print grad=6.508438218588708e-06, Depth Loss=0.0000000] 
Training progress:  96%|█████████▌| 1920/2000 [12:29<00:28,  2.82it/s, Loss=0.0005823, Gaussian number=182045, print grad=6.508438218588708e-06, Depth Loss=0.0000000]
Training progress:  96%|█████████▌| 1920/2000 [12:33<00:28,  2.82it/s, Loss=0.0005376, Gaussian number=182045, print grad=1.0189719432673883e-05, Depth Loss=0.0000000]
Training progress:  96%|█████████▋| 1930/2000 [12:33<00:24,  2.82it/s, Loss=0.0005376, Gaussian number=182045, print grad=1.0189719432673883e-05, Depth Loss=0.0000000]
Training progress:  96%|█████████▋| 1930/2000 [12:36<00:24,  2.82it/s, Loss=0.0007496, Gaussian number=182045, print grad=1.3792028767056763e-05, Depth Loss=0.0000000]
Training progress:  97%|█████████▋| 1940/2000 [12:36<00:21,  2.82it/s, Loss=0.0007496, Gaussian number=182045, print grad=1.3792028767056763e-05, Depth Loss=0.0000000]
Training progress:  97%|█████████▋| 1940/2000 [12:40<00:21,  2.82it/s, Loss=0.0006052, Gaussian number=182045, print grad=1.728778806864284e-05, Depth Loss=0.0000000] 
Training progress:  98%|█████████▊| 1950/2000 [12:40<00:17,  2.82it/s, Loss=0.0006052, Gaussian number=182045, print grad=1.728778806864284e-05, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1950/2000 [12:43<00:17,  2.82it/s, Loss=0.0009227, Gaussian number=182045, print grad=2.073447649308946e-05, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1960/2000 [12:43<00:14,  2.82it/s, Loss=0.0009227, Gaussian number=182045, print grad=2.073447649308946e-05, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1960/2000 [12:47<00:14,  2.82it/s, Loss=0.0007580, Gaussian number=182045, print grad=2.4262768420157954e-05, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1970/2000 [12:47<00:10,  2.82it/s, Loss=0.0007580, Gaussian number=182045, print grad=2.4262768420157954e-05, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1970/2000 [12:50<00:10,  2.82it/s, Loss=0.0006520, Gaussian number=182045, print grad=2.7995689379167743e-05, Depth Loss=0.0000000]
Training progress:  99%|█████████▉| 1980/2000 [12:50<00:07,  2.82it/s, Loss=0.0006520, Gaussian number=182045, print grad=2.7995689379167743e-05, Depth Loss=0.0000000]
Training progress:  99%|█████████▉| 1980/2000 [12:54<00:07,  2.82it/s, Loss=0.0006543, Gaussian number=182045, print grad=3.18532511300873e-05, Depth Loss=0.0000000]  
Training progress: 100%|█████████▉| 1990/2000 [12:54<00:03,  2.82it/s, Loss=0.0006543, Gaussian number=182045, print grad=3.18532511300873e-05, Depth Loss=0.0000000]
Training progress: 100%|█████████▉| 1990/2000 [12:58<00:03,  2.82it/s, Loss=0.0005621, Gaussian number=182045, print grad=3.5954173654317856e-05, Depth Loss=0.0000000]
Training progress: 100%|██████████| 2000/2000 [12:58<00:00,  2.82it/s, Loss=0.0005621, Gaussian number=182045, print grad=3.5954173654317856e-05, Depth Loss=0.0000000]
Training progress: 100%|██████████| 2000/2000 [12:58<00:00,  2.57it/s, Loss=0.0005621, Gaussian number=182045, print grad=3.5954173654317856e-05, Depth Loss=0.0000000]
Iteration 100 [15/11 00:39:38]

[ITER 100] Evaluating test: WD 0.001319, PSNR 12.8689 [15/11 00:39:44]

[ITER 100] Evaluating train: WD 0.001346, PSNR 13.2667 [15/11 00:39:44]
Gaussian number:182686,print gradients:1.5947678377870034e-07 [15/11 00:39:44]
Iteration 200 [15/11 00:40:20]

[ITER 200] Evaluating test: WD 0.001187, PSNR 14.1799 [15/11 00:40:26]

[ITER 200] Evaluating train: WD 0.001190, PSNR 14.6067 [15/11 00:40:26]
Gaussian number:182686,print gradients:2.1411521800018818e-07 [15/11 00:40:26]
Iteration 300 [15/11 00:41:02]

[ITER 300] Evaluating test: WD 0.001096, PSNR 14.9717 [15/11 00:41:08]

[ITER 300] Evaluating train: WD 0.001097, PSNR 15.5147 [15/11 00:41:08]
Gaussian number:182686,print gradients:2.528007883029204e-07 [15/11 00:41:08]
Iteration 400 [15/11 00:41:44]

[ITER 400] Evaluating test: WD 0.001051, PSNR 15.4912 [15/11 00:41:49]

[ITER 400] Evaluating train: WD 0.001045, PSNR 16.2022 [15/11 00:41:50]
Gaussian number:182686,print gradients:2.802570122639736e-07 [15/11 00:41:50]
Iteration 500 [15/11 00:42:25]

[ITER 500] Evaluating test: WD 0.000990, PSNR 15.9571 [15/11 00:42:31]

[ITER 500] Evaluating train: WD 0.001040, PSNR 16.2192 [15/11 00:42:31]
Gaussian number:182686,print gradients:3.088457845024095e-07 [15/11 00:42:31]
Iteration 600 [15/11 00:43:07]

[ITER 600] Evaluating test: WD 0.000956, PSNR 16.2297 [15/11 00:43:12]

[ITER 600] Evaluating train: WD 0.000982, PSNR 16.5087 [15/11 00:43:13]
Gaussian number:182686,print gradients:3.303568405499391e-07 [15/11 00:43:13]
Iteration 700 [15/11 00:43:48]

[ITER 700] Evaluating test: WD 0.000939, PSNR 16.3791 [15/11 00:43:54]

[ITER 700] Evaluating train: WD 0.000957, PSNR 16.6856 [15/11 00:43:54]
Gaussian number:182626,print gradients:4.697968165601196e-07 [15/11 00:43:54]
Iteration 800 [15/11 00:44:29]

[ITER 800] Evaluating test: WD 0.000893, PSNR 16.6010 [15/11 00:44:35]

[ITER 800] Evaluating train: WD 0.000913, PSNR 16.9851 [15/11 00:44:35]
Gaussian number:182588,print gradients:4.659462717881979e-07 [15/11 00:44:35]
Iteration 900 [15/11 00:45:11]

[ITER 900] Evaluating test: WD 0.000880, PSNR 16.7138 [15/11 00:45:16]

[ITER 900] Evaluating train: WD 0.000926, PSNR 17.0661 [15/11 00:45:16]
Gaussian number:182548,print gradients:4.87316242470115e-07 [15/11 00:45:16]
Iteration 1000 [15/11 00:45:52]

[ITER 1000] Evaluating test: WD 0.000869, PSNR 16.8637 [15/11 00:45:57]

[ITER 1000] Evaluating train: WD 0.000927, PSNR 17.0962 [15/11 00:45:57]
Gaussian number:182511,print gradients:4.793839707417646e-07 [15/11 00:45:57]
Iteration 1100 [15/11 00:46:32]
Iteration 1200 [15/11 00:47:08]
Iteration 1300 [15/11 00:47:44]
Iteration 1400 [15/11 00:48:19]
Iteration 1500 [15/11 00:48:55]

[ITER 1500] Evaluating test: WD 0.000778, PSNR 17.3889 [15/11 00:49:00]

[ITER 1500] Evaluating train: WD 0.000824, PSNR 17.7301 [15/11 00:49:01]
Gaussian number:182273,print gradients:5.305871582095278e-07 [15/11 00:49:01]
Iteration 1600 [15/11 00:49:36]
Iteration 1700 [15/11 00:50:12]
Iteration 1800 [15/11 00:50:47]
Iteration 1900 [15/11 00:51:23]
Iteration 2000 [15/11 00:51:58]

[ITER 2000] Evaluating test: WD 0.000720, PSNR 17.8118 [15/11 00:52:03]

[ITER 2000] Evaluating train: WD 0.000785, PSNR 18.0129 [15/11 00:52:04]
Gaussian number:182045,print gradients:5.448409865493886e-07 [15/11 00:52:04]

[ITER 2000] Saving Gaussians [15/11 00:52:04]

Training complete. [15/11 00:52:06]
