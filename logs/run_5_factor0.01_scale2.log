Optimizing /home/cw4287/gaussian-model/train1
Output folder: /home/cw4287/gaussian-model/train1 [14/11 19:25:18]
Tensorboard not available: not logging progress [14/11 19:25:18]
------------LLFF HOLD------------- [14/11 19:25:19]

Reading camera 1/301
Reading camera 2/301
Reading camera 3/301
Reading camera 4/301
Reading camera 5/301
Reading camera 6/301
Reading camera 7/301
Reading camera 8/301
Reading camera 9/301
Reading camera 10/301
Reading camera 11/301
Reading camera 12/301
Reading camera 13/301
Reading camera 14/301
Reading camera 15/301
Reading camera 16/301
Reading camera 17/301
Reading camera 18/301
Reading camera 19/301
Reading camera 20/301
Reading camera 21/301
Reading camera 22/301
Reading camera 23/301
Reading camera 24/301
Reading camera 25/301
Reading camera 26/301
Reading camera 27/301
Reading camera 28/301
Reading camera 29/301
Reading camera 30/301
Reading camera 31/301
Reading camera 32/301
Reading camera 33/301
Reading camera 34/301
Reading camera 35/301
Reading camera 36/301
Reading camera 37/301
Reading camera 38/301
Reading camera 39/301
Reading camera 40/301
Reading camera 41/301
Reading camera 42/301
Reading camera 43/301
Reading camera 44/301
Reading camera 45/301
Reading camera 46/301
Reading camera 47/301
Reading camera 48/301
Reading camera 49/301
Reading camera 50/301
Reading camera 51/301
Reading camera 52/301
Reading camera 53/301
Reading camera 54/301
Reading camera 55/301
Reading camera 56/301
Reading camera 57/301
Reading camera 58/301
Reading camera 59/301
Reading camera 60/301
Reading camera 61/301
Reading camera 62/301
Reading camera 63/301
Reading camera 64/301
Reading camera 65/301
Reading camera 66/301
Reading camera 67/301
Reading camera 68/301
Reading camera 69/301
Reading camera 70/301
Reading camera 71/301
Reading camera 72/301
Reading camera 73/301
Reading camera 74/301
Reading camera 75/301
Reading camera 76/301
Reading camera 77/301
Reading camera 78/301
Reading camera 79/301
Reading camera 80/301
Reading camera 81/301
Reading camera 82/301
Reading camera 83/301
Reading camera 84/301
Reading camera 85/301
Reading camera 86/301
Reading camera 87/301
Reading camera 88/301
Reading camera 89/301
Reading camera 90/301
Reading camera 91/301
Reading camera 92/301
Reading camera 93/301
Reading camera 94/301
Reading camera 95/301
Reading camera 96/301
Reading camera 97/301
Reading camera 98/301
Reading camera 99/301
Reading camera 100/301
Reading camera 101/301
Reading camera 102/301
Reading camera 103/301
Reading camera 104/301
Reading camera 105/301
Reading camera 106/301
Reading camera 107/301
Reading camera 108/301
Reading camera 109/301
Reading camera 110/301
Reading camera 111/301
Reading camera 112/301
Reading camera 113/301
Reading camera 114/301
Reading camera 115/301
Reading camera 116/301
Reading camera 117/301
Reading camera 118/301
Reading camera 119/301
Reading camera 120/301
Reading camera 121/301
Reading camera 122/301
Reading camera 123/301
Reading camera 124/301
Reading camera 125/301
Reading camera 126/301
Reading camera 127/301
Reading camera 128/301
Reading camera 129/301
Reading camera 130/301
Reading camera 131/301
Reading camera 132/301
Reading camera 133/301
Reading camera 134/301
Reading camera 135/301
Reading camera 136/301
Reading camera 137/301
Reading camera 138/301
Reading camera 139/301
Reading camera 140/301
Reading camera 141/301
Reading camera 142/301
Reading camera 143/301
Reading camera 144/301
Reading camera 145/301
Reading camera 146/301
Reading camera 147/301
Reading camera 148/301
Reading camera 149/301
Reading camera 150/301
Reading camera 151/301
Reading camera 152/301
Reading camera 153/301
Reading camera 154/301
Reading camera 155/301
Reading camera 156/301
Reading camera 157/301
Reading camera 158/301
Reading camera 159/301
Reading camera 160/301
Reading camera 161/301
Reading camera 162/301
Reading camera 163/301
Reading camera 164/301
Reading camera 165/301
Reading camera 166/301
Reading camera 167/301
Reading camera 168/301
Reading camera 169/301
Reading camera 170/301
Reading camera 171/301
Reading camera 172/301
Reading camera 173/301
Reading camera 174/301
Reading camera 175/301
Reading camera 176/301
Reading camera 177/301
Reading camera 178/301
Reading camera 179/301
Reading camera 180/301
Reading camera 181/301
Reading camera 182/301
Reading camera 183/301
Reading camera 184/301
Reading camera 185/301
Reading camera 186/301
Reading camera 187/301
Reading camera 188/301
Reading camera 189/301
Reading camera 190/301
Reading camera 191/301
Reading camera 192/301
Reading camera 193/301
Reading camera 194/301
Reading camera 195/301
Reading camera 196/301
Reading camera 197/301
Reading camera 198/301
Reading camera 199/301
Reading camera 200/301
Reading camera 201/301
Reading camera 202/301
Reading camera 203/301
Reading camera 204/301
Reading camera 205/301
Reading camera 206/301
Reading camera 207/301
Reading camera 208/301
Reading camera 209/301
Reading camera 210/301
Reading camera 211/301
Reading camera 212/301
Reading camera 213/301
Reading camera 214/301
Reading camera 215/301
Reading camera 216/301
Reading camera 217/301
Reading camera 218/301
Reading camera 219/301
Reading camera 220/301
Reading camera 221/301
Reading camera 222/301
Reading camera 223/301
Reading camera 224/301
Reading camera 225/301
Reading camera 226/301
Reading camera 227/301
Reading camera 228/301
Reading camera 229/301
Reading camera 230/301
Reading camera 231/301
Reading camera 232/301
Reading camera 233/301
Reading camera 234/301
Reading camera 235/301
Reading camera 236/301
Reading camera 237/301
Reading camera 238/301
Reading camera 239/301
Reading camera 240/301
Reading camera 241/301
Reading camera 242/301
Reading camera 243/301
Reading camera 244/301
Reading camera 245/301
Reading camera 246/301
Reading camera 247/301
Reading camera 248/301
Reading camera 249/301
Reading camera 250/301
Reading camera 251/301
Reading camera 252/301
Reading camera 253/301
Reading camera 254/301
Reading camera 255/301
Reading camera 256/301
Reading camera 257/301
Reading camera 258/301
Reading camera 259/301
Reading camera 260/301
Reading camera 261/301
Reading camera 262/301
Reading camera 263/301
Reading camera 264/301
Reading camera 265/301
Reading camera 266/301
Reading camera 267/301
Reading camera 268/301
Reading camera 269/301
Reading camera 270/301
Reading camera 271/301
Reading camera 272/301
Reading camera 273/301
Reading camera 274/301
Reading camera 275/301
Reading camera 276/301
Reading camera 277/301
Reading camera 278/301
Reading camera 279/301
Reading camera 280/301
Reading camera 281/301
Reading camera 282/301
Reading camera 283/301
Reading camera 284/301
Reading camera 285/301
Reading camera 286/301
Reading camera 287/301
Reading camera 288/301
Reading camera 289/301
Reading camera 290/301
Reading camera 291/301
Reading camera 292/301
Reading camera 293/301
Reading camera 294/301
Reading camera 295/301
Reading camera 296/301
Reading camera 297/301
Reading camera 298/301
Reading camera 299/301
Reading camera 300/301
Reading camera 301/301 [14/11 19:25:19]
Loading Training Cameras [14/11 19:25:20]
Loading Test Cameras [14/11 19:25:47]
Number of points at initialisation :  182686 [14/11 19:25:50]

Training progress:   0%|          | 0/2000 [00:00<?, ?it/s]/ext3/conda/envs/3dgs/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/ext3/conda/envs/3dgs/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
/ext3/conda/envs/3dgs/lib/python3.12/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at /opt/conda/conda-bld/pytorch_1712609048481/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)
  return F.conv2d(input, weight, bias, self.stride,

Training progress:   0%|          | 0/2000 [00:04<?, ?it/s, Loss=0.1518297, Gaussian number=182686, print grad=6.170714186737314e-05, Depth Loss=0.0000000]
Training progress:   0%|          | 10/2000 [00:04<15:20,  2.16it/s, Loss=0.1518297, Gaussian number=182686, print grad=6.170714186737314e-05, Depth Loss=0.0000000]
Training progress:   0%|          | 10/2000 [00:06<15:20,  2.16it/s, Loss=0.1470647, Gaussian number=182686, print grad=0.00016379040607716888, Depth Loss=0.0000000]
Training progress:   1%|          | 20/2000 [00:06<09:47,  3.37it/s, Loss=0.1470647, Gaussian number=182686, print grad=0.00016379040607716888, Depth Loss=0.0000000]
Training progress:   1%|          | 20/2000 [00:08<09:47,  3.37it/s, Loss=0.1459927, Gaussian number=182686, print grad=0.00025991350412368774, Depth Loss=0.0000000]
Training progress:   2%|▏         | 30/2000 [00:08<07:58,  4.12it/s, Loss=0.1459927, Gaussian number=182686, print grad=0.00025991350412368774, Depth Loss=0.0000000]
Training progress:   2%|▏         | 30/2000 [00:10<07:58,  4.12it/s, Loss=0.1573271, Gaussian number=182686, print grad=0.00036275925231166184, Depth Loss=0.0000000]
Training progress:   2%|▏         | 40/2000 [00:10<07:06,  4.59it/s, Loss=0.1573271, Gaussian number=182686, print grad=0.00036275925231166184, Depth Loss=0.0000000]
Training progress:   2%|▏         | 40/2000 [00:11<07:06,  4.59it/s, Loss=0.1198990, Gaussian number=182686, print grad=0.0004420084005687386, Depth Loss=0.0000000] 
Training progress:   2%|▎         | 50/2000 [00:11<06:38,  4.90it/s, Loss=0.1198990, Gaussian number=182686, print grad=0.0004420084005687386, Depth Loss=0.0000000]
Training progress:   2%|▎         | 50/2000 [00:13<06:38,  4.90it/s, Loss=0.1376885, Gaussian number=182686, print grad=0.0005656550638377666, Depth Loss=0.0000000]
Training progress:   3%|▎         | 60/2000 [00:13<06:19,  5.11it/s, Loss=0.1376885, Gaussian number=182686, print grad=0.0005656550638377666, Depth Loss=0.0000000]
Training progress:   3%|▎         | 60/2000 [00:15<06:19,  5.11it/s, Loss=0.1240934, Gaussian number=182686, print grad=0.0007256853277795017, Depth Loss=0.0000000]
Training progress:   4%|▎         | 70/2000 [00:15<06:09,  5.23it/s, Loss=0.1240934, Gaussian number=182686, print grad=0.0007256853277795017, Depth Loss=0.0000000]
Training progress:   4%|▎         | 70/2000 [00:17<06:09,  5.23it/s, Loss=0.1436176, Gaussian number=182686, print grad=0.0008417566423304379, Depth Loss=0.0000000]
Training progress:   4%|▍         | 80/2000 [00:17<05:58,  5.36it/s, Loss=0.1436176, Gaussian number=182686, print grad=0.0008417566423304379, Depth Loss=0.0000000]
Training progress:   4%|▍         | 80/2000 [00:18<05:58,  5.36it/s, Loss=0.1235305, Gaussian number=182686, print grad=0.0009620379423722625, Depth Loss=0.0000000]
Training progress:   4%|▍         | 90/2000 [00:18<05:52,  5.42it/s, Loss=0.1235305, Gaussian number=182686, print grad=0.0009620379423722625, Depth Loss=0.0000000]
Training progress:   4%|▍         | 90/2000 [00:20<05:52,  5.42it/s, Loss=0.1235153, Gaussian number=182686, print grad=0.0011084082070738077, Depth Loss=0.0000000]
Training progress:   5%|▌         | 100/2000 [00:20<05:46,  5.48it/s, Loss=0.1235153, Gaussian number=182686, print grad=0.0011084082070738077, Depth Loss=0.0000000]
Training progress:   5%|▌         | 100/2000 [00:24<05:46,  5.48it/s, Loss=0.1443365, Gaussian number=182686, print grad=0.0012698597274720669, Depth Loss=0.0000000]
Training progress:   6%|▌         | 110/2000 [00:24<07:53,  3.99it/s, Loss=0.1443365, Gaussian number=182686, print grad=0.0012698597274720669, Depth Loss=0.0000000]
Training progress:   6%|▌         | 110/2000 [00:26<07:53,  3.99it/s, Loss=0.1197448, Gaussian number=182686, print grad=0.001426229951903224, Depth Loss=0.0000000] 
Training progress:   6%|▌         | 120/2000 [00:26<07:09,  4.38it/s, Loss=0.1197448, Gaussian number=182686, print grad=0.001426229951903224, Depth Loss=0.0000000]
Training progress:   6%|▌         | 120/2000 [00:28<07:09,  4.38it/s, Loss=0.1397336, Gaussian number=182686, print grad=0.0016267909668385983, Depth Loss=0.0000000]
Training progress:   6%|▋         | 130/2000 [00:28<06:38,  4.70it/s, Loss=0.1397336, Gaussian number=182686, print grad=0.0016267909668385983, Depth Loss=0.0000000]
Training progress:   6%|▋         | 130/2000 [00:30<06:38,  4.70it/s, Loss=0.1269095, Gaussian number=182686, print grad=0.001830599270761013, Depth Loss=0.0000000] 
Training progress:   7%|▋         | 140/2000 [00:30<06:17,  4.93it/s, Loss=0.1269095, Gaussian number=182686, print grad=0.001830599270761013, Depth Loss=0.0000000]
Training progress:   7%|▋         | 140/2000 [00:31<06:17,  4.93it/s, Loss=0.1099963, Gaussian number=182686, print grad=0.002009371295571327, Depth Loss=0.0000000]
Training progress:   8%|▊         | 150/2000 [00:31<06:01,  5.12it/s, Loss=0.1099963, Gaussian number=182686, print grad=0.002009371295571327, Depth Loss=0.0000000]
Training progress:   8%|▊         | 150/2000 [00:33<06:01,  5.12it/s, Loss=0.1173312, Gaussian number=182686, print grad=0.0022481761407107115, Depth Loss=0.0000000]
Training progress:   8%|▊         | 160/2000 [00:33<05:48,  5.27it/s, Loss=0.1173312, Gaussian number=182686, print grad=0.0022481761407107115, Depth Loss=0.0000000]
Training progress:   8%|▊         | 160/2000 [00:35<05:48,  5.27it/s, Loss=0.1160707, Gaussian number=182686, print grad=0.002420335542410612, Depth Loss=0.0000000] 
Training progress:   8%|▊         | 170/2000 [00:35<05:39,  5.39it/s, Loss=0.1160707, Gaussian number=182686, print grad=0.002420335542410612, Depth Loss=0.0000000]
Training progress:   8%|▊         | 170/2000 [00:37<05:39,  5.39it/s, Loss=0.1020929, Gaussian number=182686, print grad=0.0026340908370912075, Depth Loss=0.0000000]
Training progress:   9%|▉         | 180/2000 [00:37<05:31,  5.48it/s, Loss=0.1020929, Gaussian number=182686, print grad=0.0026340908370912075, Depth Loss=0.0000000]
Training progress:   9%|▉         | 180/2000 [00:38<05:31,  5.48it/s, Loss=0.1287686, Gaussian number=182686, print grad=0.002811281243339181, Depth Loss=0.0000000] 
Training progress:  10%|▉         | 190/2000 [00:38<05:26,  5.54it/s, Loss=0.1287686, Gaussian number=182686, print grad=0.002811281243339181, Depth Loss=0.0000000]
Training progress:  10%|▉         | 190/2000 [00:40<05:26,  5.54it/s, Loss=0.1155612, Gaussian number=182686, print grad=0.0030347961001098156, Depth Loss=0.0000000]
Training progress:  10%|█         | 200/2000 [00:40<05:21,  5.59it/s, Loss=0.1155612, Gaussian number=182686, print grad=0.0030347961001098156, Depth Loss=0.0000000]
Training progress:  10%|█         | 200/2000 [00:44<05:21,  5.59it/s, Loss=0.1281554, Gaussian number=182686, print grad=0.0032732137478888035, Depth Loss=0.0000000]
Training progress:  10%|█         | 210/2000 [00:44<07:23,  4.04it/s, Loss=0.1281554, Gaussian number=182686, print grad=0.0032732137478888035, Depth Loss=0.0000000]
Training progress:  10%|█         | 210/2000 [00:46<07:23,  4.04it/s, Loss=0.1071883, Gaussian number=182686, print grad=0.0034827825147658587, Depth Loss=0.0000000]
Training progress:  11%|█         | 220/2000 [00:46<06:41,  4.43it/s, Loss=0.1071883, Gaussian number=182686, print grad=0.0034827825147658587, Depth Loss=0.0000000]
Training progress:  11%|█         | 220/2000 [00:48<06:41,  4.43it/s, Loss=0.1184754, Gaussian number=182686, print grad=0.0036959731951355934, Depth Loss=0.0000000]
Training progress:  12%|█▏        | 230/2000 [00:48<06:12,  4.75it/s, Loss=0.1184754, Gaussian number=182686, print grad=0.0036959731951355934, Depth Loss=0.0000000]
Training progress:  12%|█▏        | 230/2000 [00:50<06:12,  4.75it/s, Loss=0.1425787, Gaussian number=182686, print grad=0.0039032401982694864, Depth Loss=0.0000000]
Training progress:  12%|█▏        | 240/2000 [00:50<05:51,  5.00it/s, Loss=0.1425787, Gaussian number=182686, print grad=0.0039032401982694864, Depth Loss=0.0000000]
Training progress:  12%|█▏        | 240/2000 [00:51<05:51,  5.00it/s, Loss=0.1095431, Gaussian number=182686, print grad=0.0041441284120082855, Depth Loss=0.0000000]
Training progress:  12%|█▎        | 250/2000 [00:51<05:36,  5.20it/s, Loss=0.1095431, Gaussian number=182686, print grad=0.0041441284120082855, Depth Loss=0.0000000]
Training progress:  12%|█▎        | 250/2000 [00:53<05:36,  5.20it/s, Loss=0.1235601, Gaussian number=182686, print grad=0.00436484394595027, Depth Loss=0.0000000]  
Training progress:  13%|█▎        | 260/2000 [00:53<05:25,  5.34it/s, Loss=0.1235601, Gaussian number=182686, print grad=0.00436484394595027, Depth Loss=0.0000000]
Training progress:  13%|█▎        | 260/2000 [00:55<05:25,  5.34it/s, Loss=0.0911333, Gaussian number=182686, print grad=0.0045958273112773895, Depth Loss=0.0000000]
Training progress:  14%|█▎        | 270/2000 [00:55<05:17,  5.46it/s, Loss=0.0911333, Gaussian number=182686, print grad=0.0045958273112773895, Depth Loss=0.0000000]
Training progress:  14%|█▎        | 270/2000 [00:57<05:17,  5.46it/s, Loss=0.1174459, Gaussian number=182686, print grad=0.004881392233073711, Depth Loss=0.0000000] 
Training progress:  14%|█▍        | 280/2000 [00:57<05:11,  5.52it/s, Loss=0.1174459, Gaussian number=182686, print grad=0.004881392233073711, Depth Loss=0.0000000]
Training progress:  14%|█▍        | 280/2000 [00:58<05:11,  5.52it/s, Loss=0.1144845, Gaussian number=182686, print grad=0.005131761077791452, Depth Loss=0.0000000]
Training progress:  14%|█▍        | 290/2000 [00:58<05:06,  5.57it/s, Loss=0.1144845, Gaussian number=182686, print grad=0.005131761077791452, Depth Loss=0.0000000]
Training progress:  14%|█▍        | 290/2000 [01:00<05:06,  5.57it/s, Loss=0.1066231, Gaussian number=182686, print grad=0.005382256116718054, Depth Loss=0.0000000]
Training progress:  15%|█▌        | 300/2000 [01:00<05:03,  5.60it/s, Loss=0.1066231, Gaussian number=182686, print grad=0.005382256116718054, Depth Loss=0.0000000]
Training progress:  15%|█▌        | 300/2000 [01:04<05:03,  5.60it/s, Loss=0.0907848, Gaussian number=182686, print grad=0.0056649427860975266, Depth Loss=0.0000000]
Training progress:  16%|█▌        | 310/2000 [01:04<06:55,  4.07it/s, Loss=0.0907848, Gaussian number=182686, print grad=0.0056649427860975266, Depth Loss=0.0000000]
Training progress:  16%|█▌        | 310/2000 [01:06<06:55,  4.07it/s, Loss=0.0941651, Gaussian number=182686, print grad=0.00585221080109477, Depth Loss=0.0000000]  
Training progress:  16%|█▌        | 320/2000 [01:06<06:14,  4.48it/s, Loss=0.0941651, Gaussian number=182686, print grad=0.00585221080109477, Depth Loss=0.0000000]
Training progress:  16%|█▌        | 320/2000 [01:08<06:14,  4.48it/s, Loss=0.1222832, Gaussian number=182686, print grad=0.006094364915043116, Depth Loss=0.0000000]
Training progress:  16%|█▋        | 330/2000 [01:08<05:47,  4.81it/s, Loss=0.1222832, Gaussian number=182686, print grad=0.006094364915043116, Depth Loss=0.0000000]
Training progress:  16%|█▋        | 330/2000 [01:09<05:47,  4.81it/s, Loss=0.0920336, Gaussian number=182686, print grad=0.006361319217830896, Depth Loss=0.0000000]
Training progress:  17%|█▋        | 340/2000 [01:09<05:27,  5.06it/s, Loss=0.0920336, Gaussian number=182686, print grad=0.006361319217830896, Depth Loss=0.0000000]
Training progress:  17%|█▋        | 340/2000 [01:11<05:27,  5.06it/s, Loss=0.0950562, Gaussian number=182686, print grad=0.006620297208428383, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 350/2000 [01:11<05:13,  5.26it/s, Loss=0.0950562, Gaussian number=182686, print grad=0.006620297208428383, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 350/2000 [01:13<05:13,  5.26it/s, Loss=0.0903905, Gaussian number=182686, print grad=0.006933681201189756, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 360/2000 [01:13<05:02,  5.42it/s, Loss=0.0903905, Gaussian number=182686, print grad=0.006933681201189756, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 360/2000 [01:14<05:02,  5.42it/s, Loss=0.0923557, Gaussian number=182686, print grad=0.007212154567241669, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 370/2000 [01:14<04:56,  5.51it/s, Loss=0.0923557, Gaussian number=182686, print grad=0.007212154567241669, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 370/2000 [01:16<04:56,  5.51it/s, Loss=0.1181109, Gaussian number=182686, print grad=0.007432251237332821, Depth Loss=0.0000000]
Training progress:  19%|█▉        | 380/2000 [01:16<04:49,  5.59it/s, Loss=0.1181109, Gaussian number=182686, print grad=0.007432251237332821, Depth Loss=0.0000000]
Training progress:  19%|█▉        | 380/2000 [01:18<04:49,  5.59it/s, Loss=0.1082773, Gaussian number=182686, print grad=0.00770360603928566, Depth Loss=0.0000000] 
Training progress:  20%|█▉        | 390/2000 [01:18<04:44,  5.67it/s, Loss=0.1082773, Gaussian number=182686, print grad=0.00770360603928566, Depth Loss=0.0000000]
Training progress:  20%|█▉        | 390/2000 [01:20<04:44,  5.67it/s, Loss=0.1269733, Gaussian number=182686, print grad=0.00795405637472868, Depth Loss=0.0000000]
Training progress:  20%|██        | 400/2000 [01:20<04:39,  5.73it/s, Loss=0.1269733, Gaussian number=182686, print grad=0.00795405637472868, Depth Loss=0.0000000]
Training progress:  20%|██        | 400/2000 [01:24<04:39,  5.73it/s, Loss=0.1085802, Gaussian number=182686, print grad=0.008268436416983604, Depth Loss=0.0000000]
Training progress:  20%|██        | 410/2000 [01:24<06:24,  4.13it/s, Loss=0.1085802, Gaussian number=182686, print grad=0.008268436416983604, Depth Loss=0.0000000]
Training progress:  20%|██        | 410/2000 [01:25<06:24,  4.13it/s, Loss=0.0977348, Gaussian number=182686, print grad=0.008561993949115276, Depth Loss=0.0000000]
Training progress:  21%|██        | 420/2000 [01:25<05:48,  4.53it/s, Loss=0.0977348, Gaussian number=182686, print grad=0.008561993949115276, Depth Loss=0.0000000]
Training progress:  21%|██        | 420/2000 [01:27<05:48,  4.53it/s, Loss=0.1208309, Gaussian number=182686, print grad=0.00886459369212389, Depth Loss=0.0000000] 
Training progress:  22%|██▏       | 430/2000 [01:27<05:22,  4.86it/s, Loss=0.1208309, Gaussian number=182686, print grad=0.00886459369212389, Depth Loss=0.0000000]
Training progress:  22%|██▏       | 430/2000 [01:29<05:22,  4.86it/s, Loss=0.0958830, Gaussian number=182686, print grad=0.00914902426302433, Depth Loss=0.0000000]
Training progress:  22%|██▏       | 440/2000 [01:29<05:04,  5.13it/s, Loss=0.0958830, Gaussian number=182686, print grad=0.00914902426302433, Depth Loss=0.0000000]
Training progress:  22%|██▏       | 440/2000 [01:30<05:04,  5.13it/s, Loss=0.1069333, Gaussian number=182686, print grad=0.009454200975596905, Depth Loss=0.0000000]
Training progress:  22%|██▎       | 450/2000 [01:30<04:51,  5.33it/s, Loss=0.1069333, Gaussian number=182686, print grad=0.009454200975596905, Depth Loss=0.0000000]
Training progress:  22%|██▎       | 450/2000 [01:32<04:51,  5.33it/s, Loss=0.1083221, Gaussian number=182686, print grad=0.009742981754243374, Depth Loss=0.0000000]
Training progress:  23%|██▎       | 460/2000 [01:32<04:42,  5.46it/s, Loss=0.1083221, Gaussian number=182686, print grad=0.009742981754243374, Depth Loss=0.0000000]
Training progress:  23%|██▎       | 460/2000 [01:34<04:42,  5.46it/s, Loss=0.1299403, Gaussian number=182686, print grad=0.01001151092350483, Depth Loss=0.0000000] 
Training progress:  24%|██▎       | 470/2000 [01:34<04:34,  5.58it/s, Loss=0.1299403, Gaussian number=182686, print grad=0.01001151092350483, Depth Loss=0.0000000]
Training progress:  24%|██▎       | 470/2000 [01:36<04:34,  5.58it/s, Loss=0.0884890, Gaussian number=182686, print grad=0.010318000800907612, Depth Loss=0.0000000]
Training progress:  24%|██▍       | 480/2000 [01:36<04:28,  5.66it/s, Loss=0.0884890, Gaussian number=182686, print grad=0.010318000800907612, Depth Loss=0.0000000]
Training progress:  24%|██▍       | 480/2000 [01:37<04:28,  5.66it/s, Loss=0.0938914, Gaussian number=182686, print grad=0.010600085370242596, Depth Loss=0.0000000]
Training progress:  24%|██▍       | 490/2000 [01:37<04:24,  5.72it/s, Loss=0.0938914, Gaussian number=182686, print grad=0.010600085370242596, Depth Loss=0.0000000]
Training progress:  24%|██▍       | 490/2000 [01:39<04:24,  5.72it/s, Loss=0.0769320, Gaussian number=182686, print grad=0.010888539254665375, Depth Loss=0.0000000]
Training progress:  25%|██▌       | 500/2000 [01:39<04:20,  5.76it/s, Loss=0.0769320, Gaussian number=182686, print grad=0.010888539254665375, Depth Loss=0.0000000]
Training progress:  25%|██▌       | 500/2000 [01:43<04:20,  5.76it/s, Loss=0.0886473, Gaussian number=182686, print grad=0.011183444410562515, Depth Loss=0.0000000]
Training progress:  26%|██▌       | 510/2000 [01:43<05:58,  4.15it/s, Loss=0.0886473, Gaussian number=182686, print grad=0.011183444410562515, Depth Loss=0.0000000]
Training progress:  26%|██▌       | 510/2000 [01:45<05:58,  4.15it/s, Loss=0.0915229, Gaussian number=182686, print grad=0.011495322920382023, Depth Loss=0.0000000]
Training progress:  26%|██▌       | 520/2000 [01:45<05:25,  4.54it/s, Loss=0.0915229, Gaussian number=182686, print grad=0.011495322920382023, Depth Loss=0.0000000]
Training progress:  26%|██▌       | 520/2000 [01:46<05:25,  4.54it/s, Loss=0.0744244, Gaussian number=182686, print grad=0.01175673771649599, Depth Loss=0.0000000] 
Training progress:  26%|██▋       | 530/2000 [01:46<05:01,  4.87it/s, Loss=0.0744244, Gaussian number=182686, print grad=0.01175673771649599, Depth Loss=0.0000000]
Training progress:  26%|██▋       | 530/2000 [01:48<05:01,  4.87it/s, Loss=0.0995680, Gaussian number=182686, print grad=0.012049245648086071, Depth Loss=0.0000000]
Training progress:  27%|██▋       | 540/2000 [01:48<04:44,  5.13it/s, Loss=0.0995680, Gaussian number=182686, print grad=0.012049245648086071, Depth Loss=0.0000000]
Training progress:  27%|██▋       | 540/2000 [01:50<04:44,  5.13it/s, Loss=0.0952313, Gaussian number=182686, print grad=0.012364962138235569, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 550/2000 [01:50<04:31,  5.33it/s, Loss=0.0952313, Gaussian number=182686, print grad=0.012364962138235569, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 550/2000 [01:51<04:31,  5.33it/s, Loss=0.0774983, Gaussian number=182686, print grad=0.012665510177612305, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 560/2000 [01:51<04:23,  5.47it/s, Loss=0.0774983, Gaussian number=182686, print grad=0.012665510177612305, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 560/2000 [01:53<04:23,  5.47it/s, Loss=0.1001711, Gaussian number=182686, print grad=0.013008574955165386, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 570/2000 [01:53<04:16,  5.58it/s, Loss=0.1001711, Gaussian number=182686, print grad=0.013008574955165386, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 570/2000 [01:55<04:16,  5.58it/s, Loss=0.0857899, Gaussian number=182686, print grad=0.013308283872902393, Depth Loss=0.0000000]
Training progress:  29%|██▉       | 580/2000 [01:55<04:10,  5.67it/s, Loss=0.0857899, Gaussian number=182686, print grad=0.013308283872902393, Depth Loss=0.0000000]
Training progress:  29%|██▉       | 580/2000 [01:57<04:10,  5.67it/s, Loss=0.0972237, Gaussian number=182686, print grad=0.013621946796774864, Depth Loss=0.0000000]
Training progress:  30%|██▉       | 590/2000 [01:57<04:06,  5.73it/s, Loss=0.0972237, Gaussian number=182686, print grad=0.013621946796774864, Depth Loss=0.0000000]
Training progress:  30%|██▉       | 590/2000 [01:58<04:06,  5.73it/s, Loss=0.0991886, Gaussian number=182686, print grad=0.01391192339360714, Depth Loss=0.0000000] 
Training progress:  30%|███       | 600/2000 [01:58<04:02,  5.78it/s, Loss=0.0991886, Gaussian number=182686, print grad=0.01391192339360714, Depth Loss=0.0000000]
Training progress:  30%|███       | 600/2000 [02:02<04:02,  5.78it/s, Loss=0.0871842, Gaussian number=184683, print grad=0.00030130238155834377, Depth Loss=0.0000000]
Training progress:  30%|███       | 610/2000 [02:02<05:35,  4.14it/s, Loss=0.0871842, Gaussian number=184683, print grad=0.00030130238155834377, Depth Loss=0.0000000]
Training progress:  30%|███       | 610/2000 [02:04<05:35,  4.14it/s, Loss=0.1131770, Gaussian number=184683, print grad=0.0006487196078523993, Depth Loss=0.0000000] 
Training progress:  31%|███       | 620/2000 [02:04<05:03,  4.55it/s, Loss=0.1131770, Gaussian number=184683, print grad=0.0006487196078523993, Depth Loss=0.0000000]
Training progress:  31%|███       | 620/2000 [02:06<05:03,  4.55it/s, Loss=0.0816364, Gaussian number=184683, print grad=0.0009308911394327879, Depth Loss=0.0000000]
Training progress:  32%|███▏      | 630/2000 [02:06<04:41,  4.87it/s, Loss=0.0816364, Gaussian number=184683, print grad=0.0009308911394327879, Depth Loss=0.0000000]
Training progress:  32%|███▏      | 630/2000 [02:08<04:41,  4.87it/s, Loss=0.0881679, Gaussian number=184683, print grad=0.0013042561477050185, Depth Loss=0.0000000]
Training progress:  32%|███▏      | 640/2000 [02:08<04:30,  5.02it/s, Loss=0.0881679, Gaussian number=184683, print grad=0.0013042561477050185, Depth Loss=0.0000000]
Training progress:  32%|███▏      | 640/2000 [02:09<04:30,  5.02it/s, Loss=0.0994134, Gaussian number=184683, print grad=0.001581035554409027, Depth Loss=0.0000000] 
Training progress:  32%|███▎      | 650/2000 [02:09<04:17,  5.25it/s, Loss=0.0994134, Gaussian number=184683, print grad=0.001581035554409027, Depth Loss=0.0000000]
Training progress:  32%|███▎      | 650/2000 [02:11<04:17,  5.25it/s, Loss=0.1037304, Gaussian number=184683, print grad=0.0019218329107388854, Depth Loss=0.0000000]
Training progress:  33%|███▎      | 660/2000 [02:11<04:06,  5.43it/s, Loss=0.1037304, Gaussian number=184683, print grad=0.0019218329107388854, Depth Loss=0.0000000]
Training progress:  33%|███▎      | 660/2000 [02:13<04:06,  5.43it/s, Loss=0.0888611, Gaussian number=184683, print grad=0.0022323832381516695, Depth Loss=0.0000000]
Training progress:  34%|███▎      | 670/2000 [02:13<03:58,  5.57it/s, Loss=0.0888611, Gaussian number=184683, print grad=0.0022323832381516695, Depth Loss=0.0000000]
Training progress:  34%|███▎      | 670/2000 [02:14<03:58,  5.57it/s, Loss=0.0851700, Gaussian number=184683, print grad=0.002582622691988945, Depth Loss=0.0000000] 
Training progress:  34%|███▍      | 680/2000 [02:14<03:54,  5.62it/s, Loss=0.0851700, Gaussian number=184683, print grad=0.002582622691988945, Depth Loss=0.0000000]
Training progress:  34%|███▍      | 680/2000 [02:16<03:54,  5.62it/s, Loss=0.0990446, Gaussian number=184683, print grad=0.0028884587809443474, Depth Loss=0.0000000]
Training progress:  34%|███▍      | 690/2000 [02:16<03:49,  5.70it/s, Loss=0.0990446, Gaussian number=184683, print grad=0.0028884587809443474, Depth Loss=0.0000000]
Training progress:  34%|███▍      | 690/2000 [02:18<03:49,  5.70it/s, Loss=0.0997761, Gaussian number=184683, print grad=0.003186344401910901, Depth Loss=0.0000000] 
Training progress:  35%|███▌      | 700/2000 [02:18<03:46,  5.75it/s, Loss=0.0997761, Gaussian number=184683, print grad=0.003186344401910901, Depth Loss=0.0000000]
Training progress:  35%|███▌      | 700/2000 [02:22<03:46,  5.75it/s, Loss=0.0888483, Gaussian number=191893, print grad=0.000285538932075724, Depth Loss=0.0000000]
Training progress:  36%|███▌      | 710/2000 [02:22<05:11,  4.14it/s, Loss=0.0888483, Gaussian number=191893, print grad=0.000285538932075724, Depth Loss=0.0000000]
Training progress:  36%|███▌      | 710/2000 [02:23<05:11,  4.14it/s, Loss=0.0810039, Gaussian number=191893, print grad=0.0006226179539225996, Depth Loss=0.0000000]
Training progress:  36%|███▌      | 720/2000 [02:23<04:41,  4.55it/s, Loss=0.0810039, Gaussian number=191893, print grad=0.0006226179539225996, Depth Loss=0.0000000]
Training progress:  36%|███▌      | 720/2000 [02:25<04:41,  4.55it/s, Loss=0.1013589, Gaussian number=191893, print grad=0.0009170109406113625, Depth Loss=0.0000000]
Training progress:  36%|███▋      | 730/2000 [02:25<04:20,  4.88it/s, Loss=0.1013589, Gaussian number=191893, print grad=0.0009170109406113625, Depth Loss=0.0000000]
Training progress:  36%|███▋      | 730/2000 [02:27<04:20,  4.88it/s, Loss=0.1263616, Gaussian number=191893, print grad=0.0012884227326139808, Depth Loss=0.0000000]
Training progress:  37%|███▋      | 740/2000 [02:27<04:04,  5.15it/s, Loss=0.1263616, Gaussian number=191893, print grad=0.0012884227326139808, Depth Loss=0.0000000]
Training progress:  37%|███▋      | 740/2000 [02:29<04:04,  5.15it/s, Loss=0.0891030, Gaussian number=191893, print grad=0.0016319324495270848, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 750/2000 [02:29<03:54,  5.33it/s, Loss=0.0891030, Gaussian number=191893, print grad=0.0016319324495270848, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 750/2000 [02:30<03:54,  5.33it/s, Loss=0.0834991, Gaussian number=191893, print grad=0.0019592202734202147, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 760/2000 [02:30<03:45,  5.51it/s, Loss=0.0834991, Gaussian number=191893, print grad=0.0019592202734202147, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 760/2000 [02:32<03:45,  5.51it/s, Loss=0.0787045, Gaussian number=191893, print grad=0.002296122256666422, Depth Loss=0.0000000] 
Training progress:  38%|███▊      | 770/2000 [02:32<03:38,  5.62it/s, Loss=0.0787045, Gaussian number=191893, print grad=0.002296122256666422, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 770/2000 [02:34<03:38,  5.62it/s, Loss=0.0999965, Gaussian number=191893, print grad=0.002603411441668868, Depth Loss=0.0000000]
Training progress:  39%|███▉      | 780/2000 [02:34<03:33,  5.70it/s, Loss=0.0999965, Gaussian number=191893, print grad=0.002603411441668868, Depth Loss=0.0000000]
Training progress:  39%|███▉      | 780/2000 [02:35<03:33,  5.70it/s, Loss=0.1144324, Gaussian number=191893, print grad=0.0029253819957375526, Depth Loss=0.0000000]
Training progress:  40%|███▉      | 790/2000 [02:35<03:31,  5.73it/s, Loss=0.1144324, Gaussian number=191893, print grad=0.0029253819957375526, Depth Loss=0.0000000]
Training progress:  40%|███▉      | 790/2000 [02:37<03:31,  5.73it/s, Loss=0.0982072, Gaussian number=191893, print grad=0.0032832068391144276, Depth Loss=0.0000000]
Training progress:  40%|████      | 800/2000 [02:37<03:28,  5.77it/s, Loss=0.0982072, Gaussian number=191893, print grad=0.0032832068391144276, Depth Loss=0.0000000]
Training progress:  40%|████      | 800/2000 [02:41<03:28,  5.77it/s, Loss=0.1022536, Gaussian number=199836, print grad=0.00032305109198205173, Depth Loss=0.0000000]
Training progress:  40%|████      | 810/2000 [02:41<04:47,  4.14it/s, Loss=0.1022536, Gaussian number=199836, print grad=0.00032305109198205173, Depth Loss=0.0000000]
Training progress:  40%|████      | 810/2000 [02:43<04:47,  4.14it/s, Loss=0.0956797, Gaussian number=199836, print grad=0.0006479035364463925, Depth Loss=0.0000000] 
Training progress:  41%|████      | 820/2000 [02:43<04:19,  4.55it/s, Loss=0.0956797, Gaussian number=199836, print grad=0.0006479035364463925, Depth Loss=0.0000000]
Training progress:  41%|████      | 820/2000 [02:44<04:19,  4.55it/s, Loss=0.0799821, Gaussian number=199836, print grad=0.0010547913843765855, Depth Loss=0.0000000]
Training progress:  42%|████▏     | 830/2000 [02:44<03:59,  4.88it/s, Loss=0.0799821, Gaussian number=199836, print grad=0.0010547913843765855, Depth Loss=0.0000000]
Training progress:  42%|████▏     | 830/2000 [02:46<03:59,  4.88it/s, Loss=0.0813066, Gaussian number=199836, print grad=0.001397302490659058, Depth Loss=0.0000000] 
Training progress:  42%|████▏     | 840/2000 [02:46<03:45,  5.15it/s, Loss=0.0813066, Gaussian number=199836, print grad=0.001397302490659058, Depth Loss=0.0000000]
Training progress:  42%|████▏     | 840/2000 [02:48<03:45,  5.15it/s, Loss=0.0906853, Gaussian number=199836, print grad=0.001762743224389851, Depth Loss=0.0000000]
Training progress:  42%|████▎     | 850/2000 [02:48<03:34,  5.35it/s, Loss=0.0906853, Gaussian number=199836, print grad=0.001762743224389851, Depth Loss=0.0000000]
Training progress:  42%|████▎     | 850/2000 [02:50<03:34,  5.35it/s, Loss=0.0855597, Gaussian number=199836, print grad=0.0020906957797706127, Depth Loss=0.0000000]
Training progress:  43%|████▎     | 860/2000 [02:50<03:26,  5.51it/s, Loss=0.0855597, Gaussian number=199836, print grad=0.0020906957797706127, Depth Loss=0.0000000]
Training progress:  43%|████▎     | 860/2000 [02:51<03:26,  5.51it/s, Loss=0.1002549, Gaussian number=199836, print grad=0.002419063588604331, Depth Loss=0.0000000] 
Training progress:  44%|████▎     | 870/2000 [02:51<03:21,  5.62it/s, Loss=0.1002549, Gaussian number=199836, print grad=0.002419063588604331, Depth Loss=0.0000000]
Training progress:  44%|████▎     | 870/2000 [02:53<03:21,  5.62it/s, Loss=0.0959730, Gaussian number=199836, print grad=0.0027368180453777313, Depth Loss=0.0000000]
Training progress:  44%|████▍     | 880/2000 [02:53<03:16,  5.71it/s, Loss=0.0959730, Gaussian number=199836, print grad=0.0027368180453777313, Depth Loss=0.0000000]
Training progress:  44%|████▍     | 880/2000 [02:55<03:16,  5.71it/s, Loss=0.0751884, Gaussian number=199836, print grad=0.0030854390934109688, Depth Loss=0.0000000]
Training progress:  44%|████▍     | 890/2000 [02:55<03:12,  5.76it/s, Loss=0.0751884, Gaussian number=199836, print grad=0.0030854390934109688, Depth Loss=0.0000000]
Training progress:  44%|████▍     | 890/2000 [02:56<03:12,  5.76it/s, Loss=0.0944162, Gaussian number=199836, print grad=0.0034010373055934906, Depth Loss=0.0000000]
Training progress:  45%|████▌     | 900/2000 [02:56<03:09,  5.80it/s, Loss=0.0944162, Gaussian number=199836, print grad=0.0034010373055934906, Depth Loss=0.0000000]
Training progress:  45%|████▌     | 900/2000 [03:00<03:09,  5.80it/s, Loss=0.0785449, Gaussian number=208627, print grad=0.00030026829335838556, Depth Loss=0.0000000]
Training progress:  46%|████▌     | 910/2000 [03:00<04:22,  4.15it/s, Loss=0.0785449, Gaussian number=208627, print grad=0.00030026829335838556, Depth Loss=0.0000000]
Training progress:  46%|████▌     | 910/2000 [03:02<04:22,  4.15it/s, Loss=0.0921170, Gaussian number=208627, print grad=0.0005850944435223937, Depth Loss=0.0000000] 
Training progress:  46%|████▌     | 920/2000 [03:02<03:57,  4.55it/s, Loss=0.0921170, Gaussian number=208627, print grad=0.0005850944435223937, Depth Loss=0.0000000]
Training progress:  46%|████▌     | 920/2000 [03:04<03:57,  4.55it/s, Loss=0.0980180, Gaussian number=208627, print grad=0.0009705705451779068, Depth Loss=0.0000000]
Training progress:  46%|████▋     | 930/2000 [03:04<03:39,  4.89it/s, Loss=0.0980180, Gaussian number=208627, print grad=0.0009705705451779068, Depth Loss=0.0000000]
Training progress:  46%|████▋     | 930/2000 [03:05<03:39,  4.89it/s, Loss=0.0880193, Gaussian number=208627, print grad=0.0012847974430769682, Depth Loss=0.0000000]
Training progress:  47%|████▋     | 940/2000 [03:05<03:26,  5.14it/s, Loss=0.0880193, Gaussian number=208627, print grad=0.0012847974430769682, Depth Loss=0.0000000]
Training progress:  47%|████▋     | 940/2000 [03:07<03:26,  5.14it/s, Loss=0.0828594, Gaussian number=208627, print grad=0.0016351350350305438, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 950/2000 [03:07<03:16,  5.35it/s, Loss=0.0828594, Gaussian number=208627, print grad=0.0016351350350305438, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 950/2000 [03:09<03:16,  5.35it/s, Loss=0.0852353, Gaussian number=208627, print grad=0.0019575096666812897, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 960/2000 [03:09<03:08,  5.53it/s, Loss=0.0852353, Gaussian number=208627, print grad=0.0019575096666812897, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 960/2000 [03:10<03:08,  5.53it/s, Loss=0.1062954, Gaussian number=208627, print grad=0.002306547714397311, Depth Loss=0.0000000] 
Training progress:  48%|████▊     | 970/2000 [03:10<03:01,  5.67it/s, Loss=0.1062954, Gaussian number=208627, print grad=0.002306547714397311, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 970/2000 [03:12<03:01,  5.67it/s, Loss=0.0720443, Gaussian number=208627, print grad=0.0026342151686549187, Depth Loss=0.0000000]
Training progress:  49%|████▉     | 980/2000 [03:12<02:56,  5.76it/s, Loss=0.0720443, Gaussian number=208627, print grad=0.0026342151686549187, Depth Loss=0.0000000]
Training progress:  49%|████▉     | 980/2000 [03:14<02:56,  5.76it/s, Loss=0.0735906, Gaussian number=208627, print grad=0.002919459715485573, Depth Loss=0.0000000] 
Training progress:  50%|████▉     | 990/2000 [03:14<02:53,  5.83it/s, Loss=0.0735906, Gaussian number=208627, print grad=0.002919459715485573, Depth Loss=0.0000000]
Training progress:  50%|████▉     | 990/2000 [03:15<02:53,  5.83it/s, Loss=0.0946519, Gaussian number=208627, print grad=0.0031938296742737293, Depth Loss=0.0000000]
Training progress:  50%|█████     | 1000/2000 [03:15<02:49,  5.89it/s, Loss=0.0946519, Gaussian number=208627, print grad=0.0031938296742737293, Depth Loss=0.0000000]
Training progress:  50%|█████     | 1000/2000 [03:19<02:49,  5.89it/s, Loss=0.0899769, Gaussian number=217263, print grad=0.0002761760260909796, Depth Loss=0.0000000]
Training progress:  50%|█████     | 1010/2000 [03:19<03:55,  4.20it/s, Loss=0.0899769, Gaussian number=217263, print grad=0.0002761760260909796, Depth Loss=0.0000000]
Training progress:  50%|█████     | 1010/2000 [03:21<03:55,  4.20it/s, Loss=0.1102159, Gaussian number=217263, print grad=0.0006636269390583038, Depth Loss=0.0000000]
Training progress:  51%|█████     | 1020/2000 [03:21<03:32,  4.61it/s, Loss=0.1102159, Gaussian number=217263, print grad=0.0006636269390583038, Depth Loss=0.0000000]
Training progress:  51%|█████     | 1020/2000 [03:23<03:32,  4.61it/s, Loss=0.0928027, Gaussian number=217263, print grad=0.0010029206750914454, Depth Loss=0.0000000]
Training progress:  52%|█████▏    | 1030/2000 [03:23<03:16,  4.93it/s, Loss=0.0928027, Gaussian number=217263, print grad=0.0010029206750914454, Depth Loss=0.0000000]
Training progress:  52%|█████▏    | 1030/2000 [03:24<03:16,  4.93it/s, Loss=0.0946523, Gaussian number=217263, print grad=0.0013772840611636639, Depth Loss=0.0000000]
Training progress:  52%|█████▏    | 1040/2000 [03:24<03:04,  5.20it/s, Loss=0.0946523, Gaussian number=217263, print grad=0.0013772840611636639, Depth Loss=0.0000000]
Training progress:  52%|█████▏    | 1040/2000 [03:26<03:04,  5.20it/s, Loss=0.0858889, Gaussian number=217263, print grad=0.0016619316302239895, Depth Loss=0.0000000]
Training progress:  52%|█████▎    | 1050/2000 [03:26<02:55,  5.41it/s, Loss=0.0858889, Gaussian number=217263, print grad=0.0016619316302239895, Depth Loss=0.0000000]
Training progress:  52%|█████▎    | 1050/2000 [03:28<02:55,  5.41it/s, Loss=0.0843414, Gaussian number=217263, print grad=0.0019778741989284754, Depth Loss=0.0000000]
Training progress:  53%|█████▎    | 1060/2000 [03:28<02:48,  5.56it/s, Loss=0.0843414, Gaussian number=217263, print grad=0.0019778741989284754, Depth Loss=0.0000000]
Training progress:  53%|█████▎    | 1060/2000 [03:30<02:48,  5.56it/s, Loss=0.0695329, Gaussian number=217263, print grad=0.0023442183155566454, Depth Loss=0.0000000]
Training progress:  54%|█████▎    | 1070/2000 [03:30<02:44,  5.64it/s, Loss=0.0695329, Gaussian number=217263, print grad=0.0023442183155566454, Depth Loss=0.0000000]
Training progress:  54%|█████▎    | 1070/2000 [03:31<02:44,  5.64it/s, Loss=0.0726855, Gaussian number=217263, print grad=0.0026503365952521563, Depth Loss=0.0000000]
Training progress:  54%|█████▍    | 1080/2000 [03:31<02:41,  5.69it/s, Loss=0.0726855, Gaussian number=217263, print grad=0.0026503365952521563, Depth Loss=0.0000000]
Training progress:  54%|█████▍    | 1080/2000 [03:33<02:41,  5.69it/s, Loss=0.0896342, Gaussian number=217263, print grad=0.0029861186631023884, Depth Loss=0.0000000]
Training progress:  55%|█████▍    | 1090/2000 [03:33<02:38,  5.73it/s, Loss=0.0896342, Gaussian number=217263, print grad=0.0029861186631023884, Depth Loss=0.0000000]
Training progress:  55%|█████▍    | 1090/2000 [03:35<02:38,  5.73it/s, Loss=0.0898475, Gaussian number=217263, print grad=0.003313262015581131, Depth Loss=0.0000000] 
Training progress:  55%|█████▌    | 1100/2000 [03:35<02:36,  5.76it/s, Loss=0.0898475, Gaussian number=217263, print grad=0.003313262015581131, Depth Loss=0.0000000]
Training progress:  55%|█████▌    | 1100/2000 [03:36<02:36,  5.76it/s, Loss=0.0978316, Gaussian number=226829, print grad=0.00028564062085933983, Depth Loss=0.0000000]
Training progress:  56%|█████▌    | 1110/2000 [03:36<02:33,  5.79it/s, Loss=0.0978316, Gaussian number=226829, print grad=0.00028564062085933983, Depth Loss=0.0000000]
Training progress:  56%|█████▌    | 1110/2000 [03:38<02:33,  5.79it/s, Loss=0.0946514, Gaussian number=226829, print grad=0.00063286442309618, Depth Loss=0.0000000]   
Training progress:  56%|█████▌    | 1120/2000 [03:38<02:33,  5.74it/s, Loss=0.0946514, Gaussian number=226829, print grad=0.00063286442309618, Depth Loss=0.0000000]
Training progress:  56%|█████▌    | 1120/2000 [03:40<02:33,  5.74it/s, Loss=0.0750964, Gaussian number=226829, print grad=0.001005592872388661, Depth Loss=0.0000000]
Training progress:  56%|█████▋    | 1130/2000 [03:40<02:31,  5.74it/s, Loss=0.0750964, Gaussian number=226829, print grad=0.001005592872388661, Depth Loss=0.0000000]
Training progress:  56%|█████▋    | 1130/2000 [03:42<02:31,  5.74it/s, Loss=0.0895161, Gaussian number=226829, print grad=0.001346331788226962, Depth Loss=0.0000000]
Training progress:  57%|█████▋    | 1140/2000 [03:42<02:29,  5.77it/s, Loss=0.0895161, Gaussian number=226829, print grad=0.001346331788226962, Depth Loss=0.0000000]
Training progress:  57%|█████▋    | 1140/2000 [03:43<02:29,  5.77it/s, Loss=0.0666618, Gaussian number=226829, print grad=0.001696386025287211, Depth Loss=0.0000000]
Training progress:  57%|█████▊    | 1150/2000 [03:43<02:26,  5.80it/s, Loss=0.0666618, Gaussian number=226829, print grad=0.001696386025287211, Depth Loss=0.0000000]
Training progress:  57%|█████▊    | 1150/2000 [03:45<02:26,  5.80it/s, Loss=0.0709578, Gaussian number=226829, print grad=0.001980109605938196, Depth Loss=0.0000000]
Training progress:  58%|█████▊    | 1160/2000 [03:45<02:24,  5.80it/s, Loss=0.0709578, Gaussian number=226829, print grad=0.001980109605938196, Depth Loss=0.0000000]
Training progress:  58%|█████▊    | 1160/2000 [03:47<02:24,  5.80it/s, Loss=0.0854162, Gaussian number=226829, print grad=0.0023050669115036726, Depth Loss=0.0000000]
Training progress:  58%|█████▊    | 1170/2000 [03:47<02:23,  5.80it/s, Loss=0.0854162, Gaussian number=226829, print grad=0.0023050669115036726, Depth Loss=0.0000000]
Training progress:  58%|█████▊    | 1170/2000 [03:48<02:23,  5.80it/s, Loss=0.0866553, Gaussian number=226829, print grad=0.002640279708430171, Depth Loss=0.0000000] 
Training progress:  59%|█████▉    | 1180/2000 [03:48<02:21,  5.82it/s, Loss=0.0866553, Gaussian number=226829, print grad=0.002640279708430171, Depth Loss=0.0000000]
Training progress:  59%|█████▉    | 1180/2000 [03:50<02:21,  5.82it/s, Loss=0.0861193, Gaussian number=226829, print grad=0.0029821968637406826, Depth Loss=0.0000000]
Training progress:  60%|█████▉    | 1190/2000 [03:50<02:19,  5.81it/s, Loss=0.0861193, Gaussian number=226829, print grad=0.0029821968637406826, Depth Loss=0.0000000]
Training progress:  60%|█████▉    | 1190/2000 [03:52<02:19,  5.81it/s, Loss=0.0948246, Gaussian number=226829, print grad=0.0032604492735117674, Depth Loss=0.0000000]
Training progress:  60%|██████    | 1200/2000 [03:52<02:17,  5.83it/s, Loss=0.0948246, Gaussian number=226829, print grad=0.0032604492735117674, Depth Loss=0.0000000]
Training progress:  60%|██████    | 1200/2000 [03:54<02:17,  5.83it/s, Loss=0.0777512, Gaussian number=236748, print grad=0.00031473187846131623, Depth Loss=0.0000000]
Training progress:  60%|██████    | 1210/2000 [03:54<02:15,  5.84it/s, Loss=0.0777512, Gaussian number=236748, print grad=0.00031473187846131623, Depth Loss=0.0000000]
Training progress:  60%|██████    | 1210/2000 [03:55<02:15,  5.84it/s, Loss=0.0694132, Gaussian number=236748, print grad=0.0006888947100378573, Depth Loss=0.0000000] 
Training progress:  61%|██████    | 1220/2000 [03:55<02:13,  5.86it/s, Loss=0.0694132, Gaussian number=236748, print grad=0.0006888947100378573, Depth Loss=0.0000000]
Training progress:  61%|██████    | 1220/2000 [03:57<02:13,  5.86it/s, Loss=0.0720383, Gaussian number=236748, print grad=0.0010117761557921767, Depth Loss=0.0000000]
Training progress:  62%|██████▏   | 1230/2000 [03:57<02:11,  5.87it/s, Loss=0.0720383, Gaussian number=236748, print grad=0.0010117761557921767, Depth Loss=0.0000000]
Training progress:  62%|██████▏   | 1230/2000 [03:59<02:11,  5.87it/s, Loss=0.0691368, Gaussian number=236748, print grad=0.001365038100630045, Depth Loss=0.0000000] 
Training progress:  62%|██████▏   | 1240/2000 [03:59<02:08,  5.90it/s, Loss=0.0691368, Gaussian number=236748, print grad=0.001365038100630045, Depth Loss=0.0000000]
Training progress:  62%|██████▏   | 1240/2000 [04:00<02:08,  5.90it/s, Loss=0.0694555, Gaussian number=236748, print grad=0.0016519426135346293, Depth Loss=0.0000000]
Training progress:  62%|██████▎   | 1250/2000 [04:00<02:07,  5.90it/s, Loss=0.0694555, Gaussian number=236748, print grad=0.0016519426135346293, Depth Loss=0.0000000]
Training progress:  62%|██████▎   | 1250/2000 [04:02<02:07,  5.90it/s, Loss=0.0720288, Gaussian number=236748, print grad=0.001928465673699975, Depth Loss=0.0000000] 
Training progress:  63%|██████▎   | 1260/2000 [04:02<02:04,  5.93it/s, Loss=0.0720288, Gaussian number=236748, print grad=0.001928465673699975, Depth Loss=0.0000000]
Training progress:  63%|██████▎   | 1260/2000 [04:04<02:04,  5.93it/s, Loss=0.0860135, Gaussian number=236748, print grad=0.0022595252376049757, Depth Loss=0.0000000]
Training progress:  64%|██████▎   | 1270/2000 [04:04<02:02,  5.94it/s, Loss=0.0860135, Gaussian number=236748, print grad=0.0022595252376049757, Depth Loss=0.0000000]
Training progress:  64%|██████▎   | 1270/2000 [04:05<02:02,  5.94it/s, Loss=0.0867435, Gaussian number=236748, print grad=0.0025452354457229376, Depth Loss=0.0000000]
Training progress:  64%|██████▍   | 1280/2000 [04:05<02:01,  5.93it/s, Loss=0.0867435, Gaussian number=236748, print grad=0.0025452354457229376, Depth Loss=0.0000000]
Training progress:  64%|██████▍   | 1280/2000 [04:07<02:01,  5.93it/s, Loss=0.0668084, Gaussian number=236748, print grad=0.00288223079405725, Depth Loss=0.0000000]  
Training progress:  64%|██████▍   | 1290/2000 [04:07<01:59,  5.92it/s, Loss=0.0668084, Gaussian number=236748, print grad=0.00288223079405725, Depth Loss=0.0000000]
Training progress:  64%|██████▍   | 1290/2000 [04:09<01:59,  5.92it/s, Loss=0.1017227, Gaussian number=236748, print grad=0.003178287297487259, Depth Loss=0.0000000]
Training progress:  65%|██████▌   | 1300/2000 [04:09<01:58,  5.92it/s, Loss=0.1017227, Gaussian number=236748, print grad=0.003178287297487259, Depth Loss=0.0000000]
Training progress:  65%|██████▌   | 1300/2000 [04:11<01:58,  5.92it/s, Loss=0.0969599, Gaussian number=247204, print grad=0.0003335629589855671, Depth Loss=0.0000000]
Training progress:  66%|██████▌   | 1310/2000 [04:11<01:57,  5.89it/s, Loss=0.0969599, Gaussian number=247204, print grad=0.0003335629589855671, Depth Loss=0.0000000]
Training progress:  66%|██████▌   | 1310/2000 [04:12<01:57,  5.89it/s, Loss=0.0996326, Gaussian number=247204, print grad=0.0006508097285404801, Depth Loss=0.0000000]
Training progress:  66%|██████▌   | 1320/2000 [04:12<01:55,  5.90it/s, Loss=0.0996326, Gaussian number=247204, print grad=0.0006508097285404801, Depth Loss=0.0000000]
Training progress:  66%|██████▌   | 1320/2000 [04:14<01:55,  5.90it/s, Loss=0.0786438, Gaussian number=247204, print grad=0.0009895351249724627, Depth Loss=0.0000000]
Training progress:  66%|██████▋   | 1330/2000 [04:14<01:54,  5.87it/s, Loss=0.0786438, Gaussian number=247204, print grad=0.0009895351249724627, Depth Loss=0.0000000]
Training progress:  66%|██████▋   | 1330/2000 [04:16<01:54,  5.87it/s, Loss=0.0824930, Gaussian number=247204, print grad=0.0013176645152270794, Depth Loss=0.0000000]
Training progress:  67%|██████▋   | 1340/2000 [04:16<01:51,  5.89it/s, Loss=0.0824930, Gaussian number=247204, print grad=0.0013176645152270794, Depth Loss=0.0000000]
Training progress:  67%|██████▋   | 1340/2000 [04:17<01:51,  5.89it/s, Loss=0.1068131, Gaussian number=247204, print grad=0.001585712656378746, Depth Loss=0.0000000] 
Training progress:  68%|██████▊   | 1350/2000 [04:17<01:49,  5.91it/s, Loss=0.1068131, Gaussian number=247204, print grad=0.001585712656378746, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1350/2000 [04:19<01:49,  5.91it/s, Loss=0.0642594, Gaussian number=247204, print grad=0.0018765199929475784, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1360/2000 [04:19<01:48,  5.92it/s, Loss=0.0642594, Gaussian number=247204, print grad=0.0018765199929475784, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1360/2000 [04:21<01:48,  5.92it/s, Loss=0.1176133, Gaussian number=247204, print grad=0.0022207016590982676, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1370/2000 [04:21<01:46,  5.93it/s, Loss=0.1176133, Gaussian number=247204, print grad=0.0022207016590982676, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1370/2000 [04:22<01:46,  5.93it/s, Loss=0.0783737, Gaussian number=247204, print grad=0.0025058549363166094, Depth Loss=0.0000000]
Training progress:  69%|██████▉   | 1380/2000 [04:22<01:44,  5.93it/s, Loss=0.0783737, Gaussian number=247204, print grad=0.0025058549363166094, Depth Loss=0.0000000]
Training progress:  69%|██████▉   | 1380/2000 [04:24<01:44,  5.93it/s, Loss=0.0727659, Gaussian number=247204, print grad=0.0027957905549556017, Depth Loss=0.0000000]
Training progress:  70%|██████▉   | 1390/2000 [04:24<01:43,  5.92it/s, Loss=0.0727659, Gaussian number=247204, print grad=0.0027957905549556017, Depth Loss=0.0000000]
Training progress:  70%|██████▉   | 1390/2000 [04:26<01:43,  5.92it/s, Loss=0.0801152, Gaussian number=247204, print grad=0.0030925320461392403, Depth Loss=0.0000000]
Training progress:  70%|███████   | 1400/2000 [04:26<01:41,  5.92it/s, Loss=0.0801152, Gaussian number=247204, print grad=0.0030925320461392403, Depth Loss=0.0000000]
Training progress:  70%|███████   | 1400/2000 [04:27<01:41,  5.92it/s, Loss=0.0932445, Gaussian number=257238, print grad=0.00033795094350352883, Depth Loss=0.0000000]
Training progress:  70%|███████   | 1410/2000 [04:27<01:40,  5.87it/s, Loss=0.0932445, Gaussian number=257238, print grad=0.00033795094350352883, Depth Loss=0.0000000]
Training progress:  70%|███████   | 1410/2000 [04:29<01:40,  5.87it/s, Loss=0.0809268, Gaussian number=257238, print grad=0.0006664192187599838, Depth Loss=0.0000000] 
Training progress:  71%|███████   | 1420/2000 [04:29<01:38,  5.87it/s, Loss=0.0809268, Gaussian number=257238, print grad=0.0006664192187599838, Depth Loss=0.0000000]
Training progress:  71%|███████   | 1420/2000 [04:31<01:38,  5.87it/s, Loss=0.0802765, Gaussian number=257238, print grad=0.0010226754238829017, Depth Loss=0.0000000]
Training progress:  72%|███████▏  | 1430/2000 [04:31<01:37,  5.87it/s, Loss=0.0802765, Gaussian number=257238, print grad=0.0010226754238829017, Depth Loss=0.0000000]
Training progress:  72%|███████▏  | 1430/2000 [04:33<01:37,  5.87it/s, Loss=0.0769826, Gaussian number=257238, print grad=0.0013064771192148328, Depth Loss=0.0000000]
Training progress:  72%|███████▏  | 1440/2000 [04:33<01:35,  5.86it/s, Loss=0.0769826, Gaussian number=257238, print grad=0.0013064771192148328, Depth Loss=0.0000000]
Training progress:  72%|███████▏  | 1440/2000 [04:34<01:35,  5.86it/s, Loss=0.0659457, Gaussian number=257238, print grad=0.0015937814023345709, Depth Loss=0.0000000]
Training progress:  72%|███████▎  | 1450/2000 [04:34<01:33,  5.86it/s, Loss=0.0659457, Gaussian number=257238, print grad=0.0015937814023345709, Depth Loss=0.0000000]
Training progress:  72%|███████▎  | 1450/2000 [04:36<01:33,  5.86it/s, Loss=0.0609940, Gaussian number=257238, print grad=0.0018933732062578201, Depth Loss=0.0000000]
Training progress:  73%|███████▎  | 1460/2000 [04:36<01:32,  5.84it/s, Loss=0.0609940, Gaussian number=257238, print grad=0.0018933732062578201, Depth Loss=0.0000000]
Training progress:  73%|███████▎  | 1460/2000 [04:38<01:32,  5.84it/s, Loss=0.0830480, Gaussian number=257238, print grad=0.00220546149648726, Depth Loss=0.0000000]  
Training progress:  74%|███████▎  | 1470/2000 [04:38<01:30,  5.84it/s, Loss=0.0830480, Gaussian number=257238, print grad=0.00220546149648726, Depth Loss=0.0000000]
Training progress:  74%|███████▎  | 1470/2000 [04:39<01:30,  5.84it/s, Loss=0.0841865, Gaussian number=257238, print grad=0.0025284963194280863, Depth Loss=0.0000000]
Training progress:  74%|███████▍  | 1480/2000 [04:39<01:29,  5.84it/s, Loss=0.0841865, Gaussian number=257238, print grad=0.0025284963194280863, Depth Loss=0.0000000]
Training progress:  74%|███████▍  | 1480/2000 [04:41<01:29,  5.84it/s, Loss=0.0875426, Gaussian number=257238, print grad=0.002837889129295945, Depth Loss=0.0000000] 
Training progress:  74%|███████▍  | 1490/2000 [04:41<01:27,  5.86it/s, Loss=0.0875426, Gaussian number=257238, print grad=0.002837889129295945, Depth Loss=0.0000000]
Training progress:  74%|███████▍  | 1490/2000 [04:43<01:27,  5.86it/s, Loss=0.0836613, Gaussian number=257238, print grad=0.003153680358082056, Depth Loss=0.0000000]
Training progress:  75%|███████▌  | 1500/2000 [04:43<01:25,  5.87it/s, Loss=0.0836613, Gaussian number=257238, print grad=0.003153680358082056, Depth Loss=0.0000000]
Training progress:  75%|███████▌  | 1500/2000 [04:47<01:25,  5.87it/s, Loss=0.0974486, Gaussian number=267159, print grad=0.00029753538547083735, Depth Loss=0.0000000]
Training progress:  76%|███████▌  | 1510/2000 [04:47<01:57,  4.15it/s, Loss=0.0974486, Gaussian number=267159, print grad=0.00029753538547083735, Depth Loss=0.0000000]
Training progress:  76%|███████▌  | 1510/2000 [04:49<01:57,  4.15it/s, Loss=0.0886039, Gaussian number=267159, print grad=0.0005899092648178339, Depth Loss=0.0000000] 
Training progress:  76%|███████▌  | 1520/2000 [04:49<01:45,  4.55it/s, Loss=0.0886039, Gaussian number=267159, print grad=0.0005899092648178339, Depth Loss=0.0000000]
Training progress:  76%|███████▌  | 1520/2000 [04:50<01:45,  4.55it/s, Loss=0.0524299, Gaussian number=267159, print grad=0.0009410334751009941, Depth Loss=0.0000000]
Training progress:  76%|███████▋  | 1530/2000 [04:50<01:36,  4.87it/s, Loss=0.0524299, Gaussian number=267159, print grad=0.0009410334751009941, Depth Loss=0.0000000]
Training progress:  76%|███████▋  | 1530/2000 [04:52<01:36,  4.87it/s, Loss=0.0700626, Gaussian number=267159, print grad=0.0012585781514644623, Depth Loss=0.0000000]
Training progress:  77%|███████▋  | 1540/2000 [04:52<01:29,  5.13it/s, Loss=0.0700626, Gaussian number=267159, print grad=0.0012585781514644623, Depth Loss=0.0000000]
Training progress:  77%|███████▋  | 1540/2000 [04:54<01:29,  5.13it/s, Loss=0.0798343, Gaussian number=267159, print grad=0.0015765769639983773, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1550/2000 [04:54<01:24,  5.32it/s, Loss=0.0798343, Gaussian number=267159, print grad=0.0015765769639983773, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1550/2000 [04:55<01:24,  5.32it/s, Loss=0.0832946, Gaussian number=267159, print grad=0.001919361762702465, Depth Loss=0.0000000] 
Training progress:  78%|███████▊  | 1560/2000 [04:55<01:20,  5.45it/s, Loss=0.0832946, Gaussian number=267159, print grad=0.001919361762702465, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1560/2000 [04:57<01:20,  5.45it/s, Loss=0.0734269, Gaussian number=267159, print grad=0.0022440848406404257, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1570/2000 [04:57<01:17,  5.56it/s, Loss=0.0734269, Gaussian number=267159, print grad=0.0022440848406404257, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1570/2000 [04:59<01:17,  5.56it/s, Loss=0.0541368, Gaussian number=267159, print grad=0.002499148715287447, Depth Loss=0.0000000] 
Training progress:  79%|███████▉  | 1580/2000 [04:59<01:14,  5.63it/s, Loss=0.0541368, Gaussian number=267159, print grad=0.002499148715287447, Depth Loss=0.0000000]
Training progress:  79%|███████▉  | 1580/2000 [05:01<01:14,  5.63it/s, Loss=0.0771806, Gaussian number=267159, print grad=0.002788423327729106, Depth Loss=0.0000000]
Training progress:  80%|███████▉  | 1590/2000 [05:01<01:11,  5.70it/s, Loss=0.0771806, Gaussian number=267159, print grad=0.002788423327729106, Depth Loss=0.0000000]
Training progress:  80%|███████▉  | 1590/2000 [05:02<01:11,  5.70it/s, Loss=0.0705993, Gaussian number=267159, print grad=0.003112277714535594, Depth Loss=0.0000000]
Training progress:  80%|████████  | 1600/2000 [05:02<01:09,  5.74it/s, Loss=0.0705993, Gaussian number=267159, print grad=0.003112277714535594, Depth Loss=0.0000000]
Training progress:  80%|████████  | 1600/2000 [05:04<01:09,  5.74it/s, Loss=0.0851137, Gaussian number=277412, print grad=0.00030836137011647224, Depth Loss=0.0000000]
Training progress:  80%|████████  | 1610/2000 [05:04<01:07,  5.78it/s, Loss=0.0851137, Gaussian number=277412, print grad=0.00030836137011647224, Depth Loss=0.0000000]
Training progress:  80%|████████  | 1610/2000 [05:06<01:07,  5.78it/s, Loss=0.0831826, Gaussian number=277412, print grad=0.0006748075247742236, Depth Loss=0.0000000] 
Training progress:  81%|████████  | 1620/2000 [05:06<01:05,  5.81it/s, Loss=0.0831826, Gaussian number=277412, print grad=0.0006748075247742236, Depth Loss=0.0000000]
Training progress:  81%|████████  | 1620/2000 [05:07<01:05,  5.81it/s, Loss=0.0723169, Gaussian number=277412, print grad=0.0009852112270891666, Depth Loss=0.0000000]
Training progress:  82%|████████▏ | 1630/2000 [05:07<01:03,  5.84it/s, Loss=0.0723169, Gaussian number=277412, print grad=0.0009852112270891666, Depth Loss=0.0000000]
Training progress:  82%|████████▏ | 1630/2000 [05:09<01:03,  5.84it/s, Loss=0.0576163, Gaussian number=277412, print grad=0.001285000005736947, Depth Loss=0.0000000] 
Training progress:  82%|████████▏ | 1640/2000 [05:09<01:01,  5.86it/s, Loss=0.0576163, Gaussian number=277412, print grad=0.001285000005736947, Depth Loss=0.0000000]
Training progress:  82%|████████▏ | 1640/2000 [05:11<01:01,  5.86it/s, Loss=0.0710755, Gaussian number=277412, print grad=0.0015834224177524447, Depth Loss=0.0000000]
Training progress:  82%|████████▎ | 1650/2000 [05:11<00:59,  5.88it/s, Loss=0.0710755, Gaussian number=277412, print grad=0.0015834224177524447, Depth Loss=0.0000000]
Training progress:  82%|████████▎ | 1650/2000 [05:12<00:59,  5.88it/s, Loss=0.0699909, Gaussian number=277412, print grad=0.0018585941288620234, Depth Loss=0.0000000]
Training progress:  83%|████████▎ | 1660/2000 [05:12<00:57,  5.89it/s, Loss=0.0699909, Gaussian number=277412, print grad=0.0018585941288620234, Depth Loss=0.0000000]
Training progress:  83%|████████▎ | 1660/2000 [05:14<00:57,  5.89it/s, Loss=0.0660295, Gaussian number=277412, print grad=0.00214522797614336, Depth Loss=0.0000000]  
Training progress:  84%|████████▎ | 1670/2000 [05:14<00:56,  5.87it/s, Loss=0.0660295, Gaussian number=277412, print grad=0.00214522797614336, Depth Loss=0.0000000]
Training progress:  84%|████████▎ | 1670/2000 [05:16<00:56,  5.87it/s, Loss=0.0626800, Gaussian number=277412, print grad=0.002429225016385317, Depth Loss=0.0000000]
Training progress:  84%|████████▍ | 1680/2000 [05:16<00:54,  5.89it/s, Loss=0.0626800, Gaussian number=277412, print grad=0.002429225016385317, Depth Loss=0.0000000]
Training progress:  84%|████████▍ | 1680/2000 [05:18<00:54,  5.89it/s, Loss=0.0716284, Gaussian number=277412, print grad=0.0027321032248437405, Depth Loss=0.0000000]
Training progress:  84%|████████▍ | 1690/2000 [05:18<00:52,  5.89it/s, Loss=0.0716284, Gaussian number=277412, print grad=0.0027321032248437405, Depth Loss=0.0000000]
Training progress:  84%|████████▍ | 1690/2000 [05:19<00:52,  5.89it/s, Loss=0.0778266, Gaussian number=277412, print grad=0.003007061081007123, Depth Loss=0.0000000] 
Training progress:  85%|████████▌ | 1700/2000 [05:19<00:50,  5.91it/s, Loss=0.0778266, Gaussian number=277412, print grad=0.003007061081007123, Depth Loss=0.0000000]
Training progress:  85%|████████▌ | 1700/2000 [05:21<00:50,  5.91it/s, Loss=0.0832363, Gaussian number=287230, print grad=0.0003262328973505646, Depth Loss=0.0000000]
Training progress:  86%|████████▌ | 1710/2000 [05:21<00:49,  5.91it/s, Loss=0.0832363, Gaussian number=287230, print grad=0.0003262328973505646, Depth Loss=0.0000000]
Training progress:  86%|████████▌ | 1710/2000 [05:23<00:49,  5.91it/s, Loss=0.0876531, Gaussian number=287230, print grad=0.0006010123761370778, Depth Loss=0.0000000]
Training progress:  86%|████████▌ | 1720/2000 [05:23<00:47,  5.91it/s, Loss=0.0876531, Gaussian number=287230, print grad=0.0006010123761370778, Depth Loss=0.0000000]
Training progress:  86%|████████▌ | 1720/2000 [05:24<00:47,  5.91it/s, Loss=0.0806121, Gaussian number=287230, print grad=0.0008932832861319184, Depth Loss=0.0000000]
Training progress:  86%|████████▋ | 1730/2000 [05:24<00:45,  5.90it/s, Loss=0.0806121, Gaussian number=287230, print grad=0.0008932832861319184, Depth Loss=0.0000000]
Training progress:  86%|████████▋ | 1730/2000 [05:26<00:45,  5.90it/s, Loss=0.0994660, Gaussian number=287230, print grad=0.0012096152640879154, Depth Loss=0.0000000]
Training progress:  87%|████████▋ | 1740/2000 [05:26<00:44,  5.89it/s, Loss=0.0994660, Gaussian number=287230, print grad=0.0012096152640879154, Depth Loss=0.0000000]
Training progress:  87%|████████▋ | 1740/2000 [05:28<00:44,  5.89it/s, Loss=0.0926161, Gaussian number=287230, print grad=0.0015231193974614143, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1750/2000 [05:28<00:42,  5.89it/s, Loss=0.0926161, Gaussian number=287230, print grad=0.0015231193974614143, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1750/2000 [05:29<00:42,  5.89it/s, Loss=0.0777938, Gaussian number=287230, print grad=0.0018086167983710766, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1760/2000 [05:29<00:40,  5.88it/s, Loss=0.0777938, Gaussian number=287230, print grad=0.0018086167983710766, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1760/2000 [05:31<00:40,  5.88it/s, Loss=0.0634420, Gaussian number=287230, print grad=0.0020784176886081696, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1770/2000 [05:31<00:39,  5.89it/s, Loss=0.0634420, Gaussian number=287230, print grad=0.0020784176886081696, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1770/2000 [05:33<00:39,  5.89it/s, Loss=0.0727930, Gaussian number=287230, print grad=0.0023540323600172997, Depth Loss=0.0000000]
Training progress:  89%|████████▉ | 1780/2000 [05:33<00:37,  5.88it/s, Loss=0.0727930, Gaussian number=287230, print grad=0.0023540323600172997, Depth Loss=0.0000000]
Training progress:  89%|████████▉ | 1780/2000 [05:35<00:37,  5.88it/s, Loss=0.0684012, Gaussian number=287230, print grad=0.002586966147646308, Depth Loss=0.0000000] 
Training progress:  90%|████████▉ | 1790/2000 [05:35<00:35,  5.90it/s, Loss=0.0684012, Gaussian number=287230, print grad=0.002586966147646308, Depth Loss=0.0000000]
Training progress:  90%|████████▉ | 1790/2000 [05:36<00:35,  5.90it/s, Loss=0.0705010, Gaussian number=287230, print grad=0.002891560783609748, Depth Loss=0.0000000]
Training progress:  90%|█████████ | 1800/2000 [05:36<00:33,  5.91it/s, Loss=0.0705010, Gaussian number=287230, print grad=0.002891560783609748, Depth Loss=0.0000000]
Training progress:  90%|█████████ | 1800/2000 [05:38<00:33,  5.91it/s, Loss=0.0787197, Gaussian number=297420, print grad=0.0002879578387364745, Depth Loss=0.0000000]
Training progress:  90%|█████████ | 1810/2000 [05:38<00:32,  5.91it/s, Loss=0.0787197, Gaussian number=297420, print grad=0.0002879578387364745, Depth Loss=0.0000000]
Training progress:  90%|█████████ | 1810/2000 [05:40<00:32,  5.91it/s, Loss=0.0712663, Gaussian number=297420, print grad=0.0006240428192541003, Depth Loss=0.0000000]
Training progress:  91%|█████████ | 1820/2000 [05:40<00:30,  5.92it/s, Loss=0.0712663, Gaussian number=297420, print grad=0.0006240428192541003, Depth Loss=0.0000000]
Training progress:  91%|█████████ | 1820/2000 [05:41<00:30,  5.92it/s, Loss=0.0602931, Gaussian number=297420, print grad=0.0008584879105910659, Depth Loss=0.0000000]
Training progress:  92%|█████████▏| 1830/2000 [05:41<00:28,  5.91it/s, Loss=0.0602931, Gaussian number=297420, print grad=0.0008584879105910659, Depth Loss=0.0000000]
Training progress:  92%|█████████▏| 1830/2000 [05:43<00:28,  5.91it/s, Loss=0.0636622, Gaussian number=297420, print grad=0.0011642355239018798, Depth Loss=0.0000000]
Training progress:  92%|█████████▏| 1840/2000 [05:43<00:27,  5.88it/s, Loss=0.0636622, Gaussian number=297420, print grad=0.0011642355239018798, Depth Loss=0.0000000]
Training progress:  92%|█████████▏| 1840/2000 [05:45<00:27,  5.88it/s, Loss=0.0683358, Gaussian number=297420, print grad=0.0014438781654462218, Depth Loss=0.0000000]
Training progress:  92%|█████████▎| 1850/2000 [05:45<00:25,  5.89it/s, Loss=0.0683358, Gaussian number=297420, print grad=0.0014438781654462218, Depth Loss=0.0000000]
Training progress:  92%|█████████▎| 1850/2000 [05:46<00:25,  5.89it/s, Loss=0.0717215, Gaussian number=297420, print grad=0.0016972619341686368, Depth Loss=0.0000000]
Training progress:  93%|█████████▎| 1860/2000 [05:46<00:23,  5.89it/s, Loss=0.0717215, Gaussian number=297420, print grad=0.0016972619341686368, Depth Loss=0.0000000]
Training progress:  93%|█████████▎| 1860/2000 [05:48<00:23,  5.89it/s, Loss=0.0814824, Gaussian number=297420, print grad=0.0020225003827363253, Depth Loss=0.0000000]
Training progress:  94%|█████████▎| 1870/2000 [05:48<00:22,  5.89it/s, Loss=0.0814824, Gaussian number=297420, print grad=0.0020225003827363253, Depth Loss=0.0000000]
Training progress:  94%|█████████▎| 1870/2000 [05:50<00:22,  5.89it/s, Loss=0.0624174, Gaussian number=297420, print grad=0.0023116522934287786, Depth Loss=0.0000000]
Training progress:  94%|█████████▍| 1880/2000 [05:50<00:20,  5.93it/s, Loss=0.0624174, Gaussian number=297420, print grad=0.0023116522934287786, Depth Loss=0.0000000]
Training progress:  94%|█████████▍| 1880/2000 [05:51<00:20,  5.93it/s, Loss=0.0700009, Gaussian number=297420, print grad=0.002599928295239806, Depth Loss=0.0000000] 
Training progress:  94%|█████████▍| 1890/2000 [05:51<00:18,  5.93it/s, Loss=0.0700009, Gaussian number=297420, print grad=0.002599928295239806, Depth Loss=0.0000000]
Training progress:  94%|█████████▍| 1890/2000 [05:53<00:18,  5.93it/s, Loss=0.0832913, Gaussian number=297420, print grad=0.0028893142007291317, Depth Loss=0.0000000]
Training progress:  95%|█████████▌| 1900/2000 [05:53<00:16,  5.94it/s, Loss=0.0832913, Gaussian number=297420, print grad=0.0028893142007291317, Depth Loss=0.0000000]
Training progress:  95%|█████████▌| 1900/2000 [05:55<00:16,  5.94it/s, Loss=0.0783915, Gaussian number=308244, print grad=0.00024325829872395843, Depth Loss=0.0000000]
Training progress:  96%|█████████▌| 1910/2000 [05:55<00:15,  5.93it/s, Loss=0.0783915, Gaussian number=308244, print grad=0.00024325829872395843, Depth Loss=0.0000000]
Training progress:  96%|█████████▌| 1910/2000 [05:57<00:15,  5.93it/s, Loss=0.0697927, Gaussian number=308244, print grad=0.0005351646104827523, Depth Loss=0.0000000] 
Training progress:  96%|█████████▌| 1920/2000 [05:57<00:13,  5.91it/s, Loss=0.0697927, Gaussian number=308244, print grad=0.0005351646104827523, Depth Loss=0.0000000]
Training progress:  96%|█████████▌| 1920/2000 [05:58<00:13,  5.91it/s, Loss=0.0571961, Gaussian number=308244, print grad=0.0008292518905363977, Depth Loss=0.0000000]
Training progress:  96%|█████████▋| 1930/2000 [05:58<00:11,  5.91it/s, Loss=0.0571961, Gaussian number=308244, print grad=0.0008292518905363977, Depth Loss=0.0000000]
Training progress:  96%|█████████▋| 1930/2000 [06:00<00:11,  5.91it/s, Loss=0.0767021, Gaussian number=308244, print grad=0.0011085261357948184, Depth Loss=0.0000000]
Training progress:  97%|█████████▋| 1940/2000 [06:00<00:10,  5.91it/s, Loss=0.0767021, Gaussian number=308244, print grad=0.0011085261357948184, Depth Loss=0.0000000]
Training progress:  97%|█████████▋| 1940/2000 [06:02<00:10,  5.91it/s, Loss=0.0620378, Gaussian number=308244, print grad=0.0013791769742965698, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1950/2000 [06:02<00:08,  5.91it/s, Loss=0.0620378, Gaussian number=308244, print grad=0.0013791769742965698, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1950/2000 [06:03<00:08,  5.91it/s, Loss=0.0932020, Gaussian number=308244, print grad=0.0016372594982385635, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1960/2000 [06:03<00:06,  5.92it/s, Loss=0.0932020, Gaussian number=308244, print grad=0.0016372594982385635, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1960/2000 [06:05<00:06,  5.92it/s, Loss=0.0788161, Gaussian number=308244, print grad=0.0019080359488725662, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1970/2000 [06:05<00:05,  5.91it/s, Loss=0.0788161, Gaussian number=308244, print grad=0.0019080359488725662, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1970/2000 [06:07<00:05,  5.91it/s, Loss=0.0677757, Gaussian number=308244, print grad=0.002199514303356409, Depth Loss=0.0000000] 
Training progress:  99%|█████████▉| 1980/2000 [06:07<00:03,  5.92it/s, Loss=0.0677757, Gaussian number=308244, print grad=0.002199514303356409, Depth Loss=0.0000000]
Training progress:  99%|█████████▉| 1980/2000 [06:08<00:03,  5.92it/s, Loss=0.0664444, Gaussian number=308244, print grad=0.0024892331566661596, Depth Loss=0.0000000]
Training progress: 100%|█████████▉| 1990/2000 [06:08<00:01,  5.92it/s, Loss=0.0664444, Gaussian number=308244, print grad=0.0024892331566661596, Depth Loss=0.0000000]
Training progress: 100%|█████████▉| 1990/2000 [06:10<00:01,  5.92it/s, Loss=0.0537871, Gaussian number=308244, print grad=0.0028070227708667517, Depth Loss=0.0000000]
Training progress: 100%|██████████| 2000/2000 [06:10<00:00,  5.92it/s, Loss=0.0537871, Gaussian number=308244, print grad=0.0028070227708667517, Depth Loss=0.0000000]
Training progress: 100%|██████████| 2000/2000 [06:10<00:00,  5.40it/s, Loss=0.0537871, Gaussian number=308244, print grad=0.0028070227708667517, Depth Loss=0.0000000]
Iteration 100 [14/11 19:26:11]

[ITER 100] Evaluating test: WD 0.131909, PSNR 12.8688 [14/11 19:26:13]

[ITER 100] Evaluating train: WD 0.134579, PSNR 13.2676 [14/11 19:26:13]
Gaussian number:182686,print gradients:1.5958099538693205e-05 [14/11 19:26:13]
Iteration 200 [14/11 19:26:31]

[ITER 200] Evaluating test: WD 0.118757, PSNR 14.1796 [14/11 19:26:33]

[ITER 200] Evaluating train: WD 0.118904, PSNR 14.6094 [14/11 19:26:33]
Gaussian number:182686,print gradients:2.141336699423846e-05 [14/11 19:26:33]
Iteration 300 [14/11 19:26:51]

[ITER 300] Evaluating test: WD 0.109635, PSNR 14.9735 [14/11 19:26:53]

[ITER 300] Evaluating train: WD 0.109204, PSNR 15.5192 [14/11 19:26:53]
Gaussian number:182686,print gradients:2.529739504097961e-05 [14/11 19:26:53]
Iteration 400 [14/11 19:27:10]

[ITER 400] Evaluating test: WD 0.105130, PSNR 15.4922 [14/11 19:27:12]

[ITER 400] Evaluating train: WD 0.104333, PSNR 16.1906 [14/11 19:27:13]
Gaussian number:182686,print gradients:2.8055828806827776e-05 [14/11 19:27:13]
Iteration 500 [14/11 19:27:30]

[ITER 500] Evaluating test: WD 0.099245, PSNR 15.9482 [14/11 19:27:32]

[ITER 500] Evaluating train: WD 0.104441, PSNR 16.1816 [14/11 19:27:32]
Gaussian number:182686,print gradients:3.090869722655043e-05 [14/11 19:27:32]
Iteration 600 [14/11 19:27:49]

[ITER 600] Evaluating test: WD 0.095717, PSNR 16.2287 [14/11 19:27:51]

[ITER 600] Evaluating train: WD 0.097868, PSNR 16.5093 [14/11 19:27:51]
Gaussian number:182686,print gradients:3.30423608829733e-05 [14/11 19:27:51]
Iteration 700 [14/11 19:28:08]

[ITER 700] Evaluating test: WD 0.094317, PSNR 16.2536 [14/11 19:28:11]

[ITER 700] Evaluating train: WD 0.096108, PSNR 16.4325 [14/11 19:28:11]
Gaussian number:184683,print gradients:4.77816465718206e-05 [14/11 19:28:11]
Iteration 800 [14/11 19:28:28]

[ITER 800] Evaluating test: WD 0.089598, PSNR 16.5608 [14/11 19:28:30]

[ITER 800] Evaluating train: WD 0.091670, PSNR 16.9722 [14/11 19:28:30]
Gaussian number:191893,print gradients:4.824277857551351e-05 [14/11 19:28:30]
Iteration 900 [14/11 19:28:47]

[ITER 900] Evaluating test: WD 0.088258, PSNR 16.7173 [14/11 19:28:49]

[ITER 900] Evaluating train: WD 0.092894, PSNR 17.2277 [14/11 19:28:49]
Gaussian number:199836,print gradients:5.077285459265113e-05 [14/11 19:28:49]
Iteration 1000 [14/11 19:29:06]

[ITER 1000] Evaluating test: WD 0.086506, PSNR 16.9234 [14/11 19:29:08]

[ITER 1000] Evaluating train: WD 0.092231, PSNR 17.3057 [14/11 19:29:09]
Gaussian number:208627,print gradients:4.921416621073149e-05 [14/11 19:29:09]
Iteration 1100 [14/11 19:29:25]
Iteration 1200 [14/11 19:29:43]
Iteration 1300 [14/11 19:29:59]
Iteration 1400 [14/11 19:30:16]
Iteration 1500 [14/11 19:30:34]

[ITER 1500] Evaluating test: WD 0.078296, PSNR 17.3987 [14/11 19:30:36]

[ITER 1500] Evaluating train: WD 0.082668, PSNR 17.7969 [14/11 19:30:36]
Gaussian number:257238,print gradients:4.9344205763190985e-05 [14/11 19:30:36]
Iteration 1600 [14/11 19:30:53]
Iteration 1700 [14/11 19:31:10]
Iteration 1800 [14/11 19:31:27]
Iteration 1900 [14/11 19:31:44]
Iteration 2000 [14/11 19:32:01]

[ITER 2000] Evaluating test: WD 0.072085, PSNR 17.8752 [14/11 19:32:03]

[ITER 2000] Evaluating train: WD 0.079262, PSNR 18.3404 [14/11 19:32:03]
Gaussian number:308244,print gradients:4.503645686781965e-05 [14/11 19:32:03]

[ITER 2000] Saving Gaussians [14/11 19:32:03]

Training complete. [14/11 19:32:07]
