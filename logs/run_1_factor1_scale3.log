Optimizing /home/cw4287/gaussian-model/train1
Output folder: /home/cw4287/gaussian-model/train1 [14/11 18:25:27]
Tensorboard not available: not logging progress [14/11 18:25:27]
------------LLFF HOLD------------- [14/11 18:25:28]

Reading camera 1/301
Reading camera 2/301
Reading camera 3/301
Reading camera 4/301
Reading camera 5/301
Reading camera 6/301
Reading camera 7/301
Reading camera 8/301
Reading camera 9/301
Reading camera 10/301
Reading camera 11/301
Reading camera 12/301
Reading camera 13/301
Reading camera 14/301
Reading camera 15/301
Reading camera 16/301
Reading camera 17/301
Reading camera 18/301
Reading camera 19/301
Reading camera 20/301
Reading camera 21/301
Reading camera 22/301
Reading camera 23/301
Reading camera 24/301
Reading camera 25/301
Reading camera 26/301
Reading camera 27/301
Reading camera 28/301
Reading camera 29/301
Reading camera 30/301
Reading camera 31/301
Reading camera 32/301
Reading camera 33/301
Reading camera 34/301
Reading camera 35/301
Reading camera 36/301
Reading camera 37/301
Reading camera 38/301
Reading camera 39/301
Reading camera 40/301
Reading camera 41/301
Reading camera 42/301
Reading camera 43/301
Reading camera 44/301
Reading camera 45/301
Reading camera 46/301
Reading camera 47/301
Reading camera 48/301
Reading camera 49/301
Reading camera 50/301
Reading camera 51/301
Reading camera 52/301
Reading camera 53/301
Reading camera 54/301
Reading camera 55/301
Reading camera 56/301
Reading camera 57/301
Reading camera 58/301
Reading camera 59/301
Reading camera 60/301
Reading camera 61/301
Reading camera 62/301
Reading camera 63/301
Reading camera 64/301
Reading camera 65/301
Reading camera 66/301
Reading camera 67/301
Reading camera 68/301
Reading camera 69/301
Reading camera 70/301
Reading camera 71/301
Reading camera 72/301
Reading camera 73/301
Reading camera 74/301
Reading camera 75/301
Reading camera 76/301
Reading camera 77/301
Reading camera 78/301
Reading camera 79/301
Reading camera 80/301
Reading camera 81/301
Reading camera 82/301
Reading camera 83/301
Reading camera 84/301
Reading camera 85/301
Reading camera 86/301
Reading camera 87/301
Reading camera 88/301
Reading camera 89/301
Reading camera 90/301
Reading camera 91/301
Reading camera 92/301
Reading camera 93/301
Reading camera 94/301
Reading camera 95/301
Reading camera 96/301
Reading camera 97/301
Reading camera 98/301
Reading camera 99/301
Reading camera 100/301
Reading camera 101/301
Reading camera 102/301
Reading camera 103/301
Reading camera 104/301
Reading camera 105/301
Reading camera 106/301
Reading camera 107/301
Reading camera 108/301
Reading camera 109/301
Reading camera 110/301
Reading camera 111/301
Reading camera 112/301
Reading camera 113/301
Reading camera 114/301
Reading camera 115/301
Reading camera 116/301
Reading camera 117/301
Reading camera 118/301
Reading camera 119/301
Reading camera 120/301
Reading camera 121/301
Reading camera 122/301
Reading camera 123/301
Reading camera 124/301
Reading camera 125/301
Reading camera 126/301
Reading camera 127/301
Reading camera 128/301
Reading camera 129/301
Reading camera 130/301
Reading camera 131/301
Reading camera 132/301
Reading camera 133/301
Reading camera 134/301
Reading camera 135/301
Reading camera 136/301
Reading camera 137/301
Reading camera 138/301
Reading camera 139/301
Reading camera 140/301
Reading camera 141/301
Reading camera 142/301
Reading camera 143/301
Reading camera 144/301
Reading camera 145/301
Reading camera 146/301
Reading camera 147/301
Reading camera 148/301
Reading camera 149/301
Reading camera 150/301
Reading camera 151/301
Reading camera 152/301
Reading camera 153/301
Reading camera 154/301
Reading camera 155/301
Reading camera 156/301
Reading camera 157/301
Reading camera 158/301
Reading camera 159/301
Reading camera 160/301
Reading camera 161/301
Reading camera 162/301
Reading camera 163/301
Reading camera 164/301
Reading camera 165/301
Reading camera 166/301
Reading camera 167/301
Reading camera 168/301
Reading camera 169/301
Reading camera 170/301
Reading camera 171/301
Reading camera 172/301
Reading camera 173/301
Reading camera 174/301
Reading camera 175/301
Reading camera 176/301
Reading camera 177/301
Reading camera 178/301
Reading camera 179/301
Reading camera 180/301
Reading camera 181/301
Reading camera 182/301
Reading camera 183/301
Reading camera 184/301
Reading camera 185/301
Reading camera 186/301
Reading camera 187/301
Reading camera 188/301
Reading camera 189/301
Reading camera 190/301
Reading camera 191/301
Reading camera 192/301
Reading camera 193/301
Reading camera 194/301
Reading camera 195/301
Reading camera 196/301
Reading camera 197/301
Reading camera 198/301
Reading camera 199/301
Reading camera 200/301
Reading camera 201/301
Reading camera 202/301
Reading camera 203/301
Reading camera 204/301
Reading camera 205/301
Reading camera 206/301
Reading camera 207/301
Reading camera 208/301
Reading camera 209/301
Reading camera 210/301
Reading camera 211/301
Reading camera 212/301
Reading camera 213/301
Reading camera 214/301
Reading camera 215/301
Reading camera 216/301
Reading camera 217/301
Reading camera 218/301
Reading camera 219/301
Reading camera 220/301
Reading camera 221/301
Reading camera 222/301
Reading camera 223/301
Reading camera 224/301
Reading camera 225/301
Reading camera 226/301
Reading camera 227/301
Reading camera 228/301
Reading camera 229/301
Reading camera 230/301
Reading camera 231/301
Reading camera 232/301
Reading camera 233/301
Reading camera 234/301
Reading camera 235/301
Reading camera 236/301
Reading camera 237/301
Reading camera 238/301
Reading camera 239/301
Reading camera 240/301
Reading camera 241/301
Reading camera 242/301
Reading camera 243/301
Reading camera 244/301
Reading camera 245/301
Reading camera 246/301
Reading camera 247/301
Reading camera 248/301
Reading camera 249/301
Reading camera 250/301
Reading camera 251/301
Reading camera 252/301
Reading camera 253/301
Reading camera 254/301
Reading camera 255/301
Reading camera 256/301
Reading camera 257/301
Reading camera 258/301
Reading camera 259/301
Reading camera 260/301
Reading camera 261/301
Reading camera 262/301
Reading camera 263/301
Reading camera 264/301
Reading camera 265/301
Reading camera 266/301
Reading camera 267/301
Reading camera 268/301
Reading camera 269/301
Reading camera 270/301
Reading camera 271/301
Reading camera 272/301
Reading camera 273/301
Reading camera 274/301
Reading camera 275/301
Reading camera 276/301
Reading camera 277/301
Reading camera 278/301
Reading camera 279/301
Reading camera 280/301
Reading camera 281/301
Reading camera 282/301
Reading camera 283/301
Reading camera 284/301
Reading camera 285/301
Reading camera 286/301
Reading camera 287/301
Reading camera 288/301
Reading camera 289/301
Reading camera 290/301
Reading camera 291/301
Reading camera 292/301
Reading camera 293/301
Reading camera 294/301
Reading camera 295/301
Reading camera 296/301
Reading camera 297/301
Reading camera 298/301
Reading camera 299/301
Reading camera 300/301
Reading camera 301/301 [14/11 18:25:28]
Loading Training Cameras [14/11 18:25:29]
Loading Test Cameras [14/11 18:25:46]
Number of points at initialisation :  182686 [14/11 18:25:49]

Training progress:   0%|          | 0/2000 [00:00<?, ?it/s]/ext3/conda/envs/3dgs/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/ext3/conda/envs/3dgs/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)

Training progress:   0%|          | 0/2000 [00:05<?, ?it/s, Loss=23.7835923, Gaussian number=182686, print grad=0.01135403010994196, Depth Loss=0.0000000]
Training progress:   0%|          | 10/2000 [00:05<19:32,  1.70it/s, Loss=23.7835923, Gaussian number=182686, print grad=0.01135403010994196, Depth Loss=0.0000000]
Training progress:   0%|          | 10/2000 [00:09<19:32,  1.70it/s, Loss=22.3142407, Gaussian number=182686, print grad=0.029376206919550896, Depth Loss=0.0000000]
Training progress:   1%|          | 20/2000 [00:09<15:52,  2.08it/s, Loss=22.3142407, Gaussian number=182686, print grad=0.029376206919550896, Depth Loss=0.0000000]
Training progress:   1%|          | 20/2000 [00:13<15:52,  2.08it/s, Loss=22.1719809, Gaussian number=182686, print grad=0.04621732607483864, Depth Loss=0.0000000] 
Training progress:   2%|▏         | 30/2000 [00:13<14:38,  2.24it/s, Loss=22.1719809, Gaussian number=182686, print grad=0.04621732607483864, Depth Loss=0.0000000]
Training progress:   2%|▏         | 30/2000 [00:18<14:38,  2.24it/s, Loss=23.9455042, Gaussian number=182686, print grad=0.06381039321422577, Depth Loss=0.0000000]
Training progress:   2%|▏         | 40/2000 [00:18<14:02,  2.33it/s, Loss=23.9455042, Gaussian number=182686, print grad=0.06381039321422577, Depth Loss=0.0000000]
Training progress:   2%|▏         | 40/2000 [00:22<14:02,  2.33it/s, Loss=18.3358939, Gaussian number=182686, print grad=0.0780932828783989, Depth Loss=0.0000000] 
Training progress:   2%|▎         | 50/2000 [00:22<13:39,  2.38it/s, Loss=18.3358939, Gaussian number=182686, print grad=0.0780932828783989, Depth Loss=0.0000000]
Training progress:   2%|▎         | 50/2000 [00:26<13:39,  2.38it/s, Loss=20.3870405, Gaussian number=182686, print grad=0.09883177280426025, Depth Loss=0.0000000]
Training progress:   3%|▎         | 60/2000 [00:26<13:23,  2.42it/s, Loss=20.3870405, Gaussian number=182686, print grad=0.09883177280426025, Depth Loss=0.0000000]
Training progress:   3%|▎         | 60/2000 [00:30<13:23,  2.42it/s, Loss=18.2842429, Gaussian number=182686, print grad=0.12493458390235901, Depth Loss=0.0000000]
Training progress:   4%|▎         | 70/2000 [00:30<13:12,  2.44it/s, Loss=18.2842429, Gaussian number=182686, print grad=0.12493458390235901, Depth Loss=0.0000000]
Training progress:   4%|▎         | 70/2000 [00:34<13:12,  2.44it/s, Loss=22.3517002, Gaussian number=182686, print grad=0.14549268782138824, Depth Loss=0.0000000]
Training progress:   4%|▍         | 80/2000 [00:34<13:04,  2.45it/s, Loss=22.3517002, Gaussian number=182686, print grad=0.14549268782138824, Depth Loss=0.0000000]
Training progress:   4%|▍         | 80/2000 [00:38<13:04,  2.45it/s, Loss=18.8597886, Gaussian number=182686, print grad=0.16661830246448517, Depth Loss=0.0000000]
Training progress:   4%|▍         | 90/2000 [00:38<12:58,  2.45it/s, Loss=18.8597886, Gaussian number=182686, print grad=0.16661830246448517, Depth Loss=0.0000000]
Training progress:   4%|▍         | 90/2000 [00:42<12:58,  2.45it/s, Loss=18.4410582, Gaussian number=182686, print grad=0.19176115095615387, Depth Loss=0.0000000]
Training progress:   5%|▌         | 100/2000 [00:42<12:55,  2.45it/s, Loss=18.4410582, Gaussian number=182686, print grad=0.19176115095615387, Depth Loss=0.0000000]
Training progress:   5%|▌         | 100/2000 [00:52<12:55,  2.45it/s, Loss=21.3332231, Gaussian number=182686, print grad=0.2190324068069458, Depth Loss=0.0000000] 
Training progress:   6%|▌         | 110/2000 [00:52<19:04,  1.65it/s, Loss=21.3332231, Gaussian number=182686, print grad=0.2190324068069458, Depth Loss=0.0000000]
Training progress:   6%|▌         | 110/2000 [00:56<19:04,  1.65it/s, Loss=17.8380693, Gaussian number=182686, print grad=0.24485564231872559, Depth Loss=0.0000000]
Training progress:   6%|▌         | 120/2000 [00:56<17:01,  1.84it/s, Loss=17.8380693, Gaussian number=182686, print grad=0.24485564231872559, Depth Loss=0.0000000]
Training progress:   6%|▌         | 120/2000 [01:00<17:01,  1.84it/s, Loss=20.4080601, Gaussian number=182686, print grad=0.27727100253105164, Depth Loss=0.0000000]
Training progress:   6%|▋         | 130/2000 [01:00<15:36,  2.00it/s, Loss=20.4080601, Gaussian number=182686, print grad=0.27727100253105164, Depth Loss=0.0000000]
Training progress:   6%|▋         | 130/2000 [01:04<15:36,  2.00it/s, Loss=18.6812948, Gaussian number=182686, print grad=0.30977579951286316, Depth Loss=0.0000000]
Training progress:   7%|▋         | 140/2000 [01:04<14:36,  2.12it/s, Loss=18.6812948, Gaussian number=182686, print grad=0.30977579951286316, Depth Loss=0.0000000]
Training progress:   7%|▋         | 140/2000 [01:08<14:36,  2.12it/s, Loss=16.5042698, Gaussian number=182686, print grad=0.33902448415756226, Depth Loss=0.0000000]
Training progress:   8%|▊         | 150/2000 [01:08<13:52,  2.22it/s, Loss=16.5042698, Gaussian number=182686, print grad=0.33902448415756226, Depth Loss=0.0000000]
Training progress:   8%|▊         | 150/2000 [01:12<13:52,  2.22it/s, Loss=17.4041789, Gaussian number=182686, print grad=0.3756788671016693, Depth Loss=0.0000000] 
Training progress:   8%|▊         | 160/2000 [01:12<13:19,  2.30it/s, Loss=17.4041789, Gaussian number=182686, print grad=0.3756788671016693, Depth Loss=0.0000000]
Training progress:   8%|▊         | 160/2000 [01:16<13:19,  2.30it/s, Loss=17.2670014, Gaussian number=182686, print grad=0.40478968620300293, Depth Loss=0.0000000]
Training progress:   8%|▊         | 170/2000 [01:16<12:56,  2.36it/s, Loss=17.2670014, Gaussian number=182686, print grad=0.40478968620300293, Depth Loss=0.0000000]
Training progress:   8%|▊         | 170/2000 [01:20<12:56,  2.36it/s, Loss=14.8299868, Gaussian number=182686, print grad=0.4382321238517761, Depth Loss=0.0000000] 
Training progress:   9%|▉         | 180/2000 [01:20<12:39,  2.40it/s, Loss=14.8299868, Gaussian number=182686, print grad=0.4382321238517761, Depth Loss=0.0000000]
Training progress:   9%|▉         | 180/2000 [01:24<12:39,  2.40it/s, Loss=19.1259603, Gaussian number=182686, print grad=0.4673112630844116, Depth Loss=0.0000000]
Training progress:  10%|▉         | 190/2000 [01:24<12:26,  2.42it/s, Loss=19.1259603, Gaussian number=182686, print grad=0.4673112630844116, Depth Loss=0.0000000]
Training progress:  10%|▉         | 190/2000 [01:28<12:26,  2.42it/s, Loss=16.5939792, Gaussian number=182686, print grad=0.5033327341079712, Depth Loss=0.0000000]
Training progress:  10%|█         | 200/2000 [01:28<12:15,  2.45it/s, Loss=16.5939792, Gaussian number=182686, print grad=0.5033327341079712, Depth Loss=0.0000000]
Training progress:  10%|█         | 200/2000 [01:38<12:15,  2.45it/s, Loss=18.7411971, Gaussian number=182686, print grad=0.5397737622261047, Depth Loss=0.0000000]
Training progress:  10%|█         | 210/2000 [01:38<17:31,  1.70it/s, Loss=18.7411971, Gaussian number=182686, print grad=0.5397737622261047, Depth Loss=0.0000000]
Training progress:  10%|█         | 210/2000 [01:42<17:31,  1.70it/s, Loss=15.2834813, Gaussian number=182686, print grad=0.5725588798522949, Depth Loss=0.0000000]
Training progress:  11%|█         | 220/2000 [01:42<15:45,  1.88it/s, Loss=15.2834813, Gaussian number=182686, print grad=0.5725588798522949, Depth Loss=0.0000000]
Training progress:  11%|█         | 220/2000 [01:46<15:45,  1.88it/s, Loss=17.1275453, Gaussian number=182686, print grad=0.6069892048835754, Depth Loss=0.0000000]
Training progress:  12%|█▏        | 230/2000 [01:46<14:29,  2.03it/s, Loss=17.1275453, Gaussian number=182686, print grad=0.6069892048835754, Depth Loss=0.0000000]
Training progress:  12%|█▏        | 230/2000 [01:50<14:29,  2.03it/s, Loss=20.9448546, Gaussian number=182686, print grad=0.6395135521888733, Depth Loss=0.0000000]
Training progress:  12%|█▏        | 240/2000 [01:50<13:36,  2.15it/s, Loss=20.9448546, Gaussian number=182686, print grad=0.6395135521888733, Depth Loss=0.0000000]
Training progress:  12%|█▏        | 240/2000 [01:54<13:36,  2.15it/s, Loss=16.1976571, Gaussian number=182686, print grad=0.6754047870635986, Depth Loss=0.0000000]
Training progress:  12%|█▎        | 250/2000 [01:54<12:59,  2.25it/s, Loss=16.1976571, Gaussian number=182686, print grad=0.6754047870635986, Depth Loss=0.0000000]
Training progress:  12%|█▎        | 250/2000 [01:58<12:59,  2.25it/s, Loss=18.2451856, Gaussian number=182686, print grad=0.7088605761528015, Depth Loss=0.0000000]
Training progress:  13%|█▎        | 260/2000 [01:58<12:29,  2.32it/s, Loss=18.2451856, Gaussian number=182686, print grad=0.7088605761528015, Depth Loss=0.0000000]
Training progress:  13%|█▎        | 260/2000 [02:02<12:29,  2.32it/s, Loss=12.7915665, Gaussian number=182686, print grad=0.7442202568054199, Depth Loss=0.0000000]
Training progress:  14%|█▎        | 270/2000 [02:02<12:09,  2.37it/s, Loss=12.7915665, Gaussian number=182686, print grad=0.7442202568054199, Depth Loss=0.0000000]
Training progress:  14%|█▎        | 270/2000 [02:06<12:09,  2.37it/s, Loss=16.4193430, Gaussian number=182686, print grad=0.7844569683074951, Depth Loss=0.0000000]
Training progress:  14%|█▍        | 280/2000 [02:06<11:53,  2.41it/s, Loss=16.4193430, Gaussian number=182686, print grad=0.7844569683074951, Depth Loss=0.0000000]
Training progress:  14%|█▍        | 280/2000 [02:10<11:53,  2.41it/s, Loss=16.8021503, Gaussian number=182686, print grad=0.822205662727356, Depth Loss=0.0000000] 
Training progress:  14%|█▍        | 290/2000 [02:10<11:42,  2.43it/s, Loss=16.8021503, Gaussian number=182686, print grad=0.822205662727356, Depth Loss=0.0000000]
Training progress:  14%|█▍        | 290/2000 [02:14<11:42,  2.43it/s, Loss=15.6734620, Gaussian number=182686, print grad=0.8611191511154175, Depth Loss=0.0000000]
Training progress:  15%|█▌        | 300/2000 [02:14<11:32,  2.45it/s, Loss=15.6734620, Gaussian number=182686, print grad=0.8611191511154175, Depth Loss=0.0000000]
Training progress:  15%|█▌        | 300/2000 [02:24<11:32,  2.45it/s, Loss=13.0569255, Gaussian number=182686, print grad=0.9017362594604492, Depth Loss=0.0000000]
Training progress:  16%|█▌        | 310/2000 [02:24<16:30,  1.71it/s, Loss=13.0569255, Gaussian number=182686, print grad=0.9017362594604492, Depth Loss=0.0000000]
Training progress:  16%|█▌        | 310/2000 [02:28<16:30,  1.71it/s, Loss=13.5925808, Gaussian number=182686, print grad=0.931039571762085, Depth Loss=0.0000000] 
Training progress:  16%|█▌        | 320/2000 [02:28<14:50,  1.89it/s, Loss=13.5925808, Gaussian number=182686, print grad=0.931039571762085, Depth Loss=0.0000000]
Training progress:  16%|█▌        | 320/2000 [02:32<14:50,  1.89it/s, Loss=17.9164904, Gaussian number=182686, print grad=0.966170072555542, Depth Loss=0.0000000]
Training progress:  16%|█▋        | 330/2000 [02:32<13:38,  2.04it/s, Loss=17.9164904, Gaussian number=182686, print grad=0.966170072555542, Depth Loss=0.0000000]
Training progress:  16%|█▋        | 330/2000 [02:36<13:38,  2.04it/s, Loss=13.0214721, Gaussian number=182686, print grad=1.005914330482483, Depth Loss=0.0000000]
Training progress:  17%|█▋        | 340/2000 [02:36<12:47,  2.16it/s, Loss=13.0214721, Gaussian number=182686, print grad=1.005914330482483, Depth Loss=0.0000000]
Training progress:  17%|█▋        | 340/2000 [02:40<12:47,  2.16it/s, Loss=13.8035658, Gaussian number=182686, print grad=1.0430729389190674, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 350/2000 [02:40<12:11,  2.26it/s, Loss=13.8035658, Gaussian number=182686, print grad=1.0430729389190674, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 350/2000 [02:44<12:11,  2.26it/s, Loss=13.1810069, Gaussian number=182686, print grad=1.0875189304351807, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 360/2000 [02:44<11:44,  2.33it/s, Loss=13.1810069, Gaussian number=182686, print grad=1.0875189304351807, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 360/2000 [02:48<11:44,  2.33it/s, Loss=12.8569893, Gaussian number=182686, print grad=1.1266535520553589, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 370/2000 [02:48<11:24,  2.38it/s, Loss=12.8569893, Gaussian number=182686, print grad=1.1266535520553589, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 370/2000 [02:52<11:24,  2.38it/s, Loss=17.3201155, Gaussian number=182686, print grad=1.1598012447357178, Depth Loss=0.0000000]
Training progress:  19%|█▉        | 380/2000 [02:52<11:09,  2.42it/s, Loss=17.3201155, Gaussian number=182686, print grad=1.1598012447357178, Depth Loss=0.0000000]
Training progress:  19%|█▉        | 380/2000 [02:56<11:09,  2.42it/s, Loss=15.2866086, Gaussian number=182686, print grad=1.2004590034484863, Depth Loss=0.0000000]
Training progress:  20%|█▉        | 390/2000 [02:56<10:57,  2.45it/s, Loss=15.2866086, Gaussian number=182686, print grad=1.2004590034484863, Depth Loss=0.0000000]
Training progress:  20%|█▉        | 390/2000 [03:00<10:57,  2.45it/s, Loss=18.3764665, Gaussian number=182686, print grad=1.2383553981781006, Depth Loss=0.0000000]
Training progress:  20%|██        | 400/2000 [03:00<10:47,  2.47it/s, Loss=18.3764665, Gaussian number=182686, print grad=1.2383553981781006, Depth Loss=0.0000000]
Training progress:  20%|██        | 400/2000 [03:10<10:47,  2.47it/s, Loss=15.6898341, Gaussian number=182686, print grad=1.2838294506072998, Depth Loss=0.0000000]
Training progress:  20%|██        | 410/2000 [03:10<15:29,  1.71it/s, Loss=15.6898341, Gaussian number=182686, print grad=1.2838294506072998, Depth Loss=0.0000000]
Training progress:  20%|██        | 410/2000 [03:14<15:29,  1.71it/s, Loss=14.0286301, Gaussian number=182686, print grad=1.3269494771957397, Depth Loss=0.0000000]
Training progress:  21%|██        | 420/2000 [03:14<13:55,  1.89it/s, Loss=14.0286301, Gaussian number=182686, print grad=1.3269494771957397, Depth Loss=0.0000000]
Training progress:  21%|██        | 420/2000 [03:18<13:55,  1.89it/s, Loss=17.6054140, Gaussian number=182686, print grad=1.3710659742355347, Depth Loss=0.0000000]
Training progress:  22%|██▏       | 430/2000 [03:18<12:48,  2.04it/s, Loss=17.6054140, Gaussian number=182686, print grad=1.3710659742355347, Depth Loss=0.0000000]
Training progress:  22%|██▏       | 430/2000 [03:22<12:48,  2.04it/s, Loss=13.6781241, Gaussian number=182686, print grad=1.4124199151992798, Depth Loss=0.0000000]
Training progress:  22%|██▏       | 440/2000 [03:22<12:00,  2.16it/s, Loss=13.6781241, Gaussian number=182686, print grad=1.4124199151992798, Depth Loss=0.0000000]
Training progress:  22%|██▏       | 440/2000 [03:26<12:00,  2.16it/s, Loss=15.7341320, Gaussian number=182686, print grad=1.4555021524429321, Depth Loss=0.0000000]
Training progress:  22%|██▎       | 450/2000 [03:26<11:26,  2.26it/s, Loss=15.7341320, Gaussian number=182686, print grad=1.4555021524429321, Depth Loss=0.0000000]
Training progress:  22%|██▎       | 450/2000 [03:30<11:26,  2.26it/s, Loss=16.3054608, Gaussian number=182686, print grad=1.4974476099014282, Depth Loss=0.0000000]
Training progress:  23%|██▎       | 460/2000 [03:30<11:01,  2.33it/s, Loss=16.3054608, Gaussian number=182686, print grad=1.4974476099014282, Depth Loss=0.0000000]
Training progress:  23%|██▎       | 460/2000 [03:34<11:01,  2.33it/s, Loss=19.3737431, Gaussian number=182686, print grad=1.5371686220169067, Depth Loss=0.0000000]
Training progress:  24%|██▎       | 470/2000 [03:34<10:41,  2.38it/s, Loss=19.3737431, Gaussian number=182686, print grad=1.5371686220169067, Depth Loss=0.0000000]
Training progress:  24%|██▎       | 470/2000 [03:38<10:41,  2.38it/s, Loss=12.5540002, Gaussian number=182686, print grad=1.582527756690979, Depth Loss=0.0000000] 
Training progress:  24%|██▍       | 480/2000 [03:38<10:27,  2.42it/s, Loss=12.5540002, Gaussian number=182686, print grad=1.582527756690979, Depth Loss=0.0000000]
Training progress:  24%|██▍       | 480/2000 [03:42<10:27,  2.42it/s, Loss=13.8986628, Gaussian number=182686, print grad=1.6235202550888062, Depth Loss=0.0000000]
Training progress:  24%|██▍       | 490/2000 [03:42<10:16,  2.45it/s, Loss=13.8986628, Gaussian number=182686, print grad=1.6235202550888062, Depth Loss=0.0000000]
Training progress:  24%|██▍       | 490/2000 [03:46<10:16,  2.45it/s, Loss=10.9280995, Gaussian number=182686, print grad=1.665726900100708, Depth Loss=0.0000000] 
Training progress:  25%|██▌       | 500/2000 [03:46<10:07,  2.47it/s, Loss=10.9280995, Gaussian number=182686, print grad=1.665726900100708, Depth Loss=0.0000000]
Training progress:  25%|██▌       | 500/2000 [03:56<10:07,  2.47it/s, Loss=12.8451829, Gaussian number=182686, print grad=1.7081384658813477, Depth Loss=0.0000000]
Training progress:  26%|██▌       | 510/2000 [03:56<14:32,  1.71it/s, Loss=12.8451829, Gaussian number=182686, print grad=1.7081384658813477, Depth Loss=0.0000000]
Training progress:  26%|██▌       | 510/2000 [04:00<14:32,  1.71it/s, Loss=13.2399807, Gaussian number=182686, print grad=1.752989649772644, Depth Loss=0.0000000] 
Training progress:  26%|██▌       | 520/2000 [04:00<13:04,  1.89it/s, Loss=13.2399807, Gaussian number=182686, print grad=1.752989649772644, Depth Loss=0.0000000]
Training progress:  26%|██▌       | 520/2000 [04:04<13:04,  1.89it/s, Loss=10.4574285, Gaussian number=182686, print grad=1.7914857864379883, Depth Loss=0.0000000]
Training progress:  26%|██▋       | 530/2000 [04:04<12:00,  2.04it/s, Loss=10.4574285, Gaussian number=182686, print grad=1.7914857864379883, Depth Loss=0.0000000]
Training progress:  26%|██▋       | 530/2000 [04:08<12:00,  2.04it/s, Loss=14.1815386, Gaussian number=182686, print grad=1.834202766418457, Depth Loss=0.0000000] 
Training progress:  27%|██▋       | 540/2000 [04:08<11:15,  2.16it/s, Loss=14.1815386, Gaussian number=182686, print grad=1.834202766418457, Depth Loss=0.0000000]
Training progress:  27%|██▋       | 540/2000 [04:12<11:15,  2.16it/s, Loss=13.4958675, Gaussian number=182686, print grad=1.8801171779632568, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 550/2000 [04:12<10:41,  2.26it/s, Loss=13.4958675, Gaussian number=182686, print grad=1.8801171779632568, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 550/2000 [04:16<10:41,  2.26it/s, Loss=10.8284775, Gaussian number=182686, print grad=1.9220396280288696, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 560/2000 [04:16<10:17,  2.33it/s, Loss=10.8284775, Gaussian number=182686, print grad=1.9220396280288696, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 560/2000 [04:20<10:17,  2.33it/s, Loss=14.4113448, Gaussian number=182686, print grad=1.9690800905227661, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 570/2000 [04:20<09:58,  2.39it/s, Loss=14.4113448, Gaussian number=182686, print grad=1.9690800905227661, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 570/2000 [04:24<09:58,  2.39it/s, Loss=12.4540828, Gaussian number=182686, print grad=2.0122487545013428, Depth Loss=0.0000000]
Training progress:  29%|██▉       | 580/2000 [04:24<09:45,  2.43it/s, Loss=12.4540828, Gaussian number=182686, print grad=2.0122487545013428, Depth Loss=0.0000000]
Training progress:  29%|██▉       | 580/2000 [04:28<09:45,  2.43it/s, Loss=14.3664749, Gaussian number=182686, print grad=2.057342052459717, Depth Loss=0.0000000] 
Training progress:  30%|██▉       | 590/2000 [04:28<09:34,  2.45it/s, Loss=14.3664749, Gaussian number=182686, print grad=2.057342052459717, Depth Loss=0.0000000]
Training progress:  30%|██▉       | 590/2000 [04:32<09:34,  2.45it/s, Loss=14.3791752, Gaussian number=182686, print grad=2.0992894172668457, Depth Loss=0.0000000]
Training progress:  30%|███       | 600/2000 [04:32<09:25,  2.47it/s, Loss=14.3791752, Gaussian number=182686, print grad=2.0992894172668457, Depth Loss=0.0000000]
Training progress:  30%|███       | 600/2000 [04:43<09:25,  2.47it/s, Loss=14.6380353, Gaussian number=364361, print grad=0.02675042115151882, Depth Loss=0.0000000]
Training progress:  30%|███       | 610/2000 [04:43<13:59,  1.66it/s, Loss=14.6380353, Gaussian number=364361, print grad=0.02675042115151882, Depth Loss=0.0000000]
Training progress:  30%|███       | 610/2000 [04:47<13:59,  1.66it/s, Loss=19.0680596, Gaussian number=364361, print grad=0.05995941162109375, Depth Loss=0.0000000]
Training progress:  31%|███       | 620/2000 [04:47<12:30,  1.84it/s, Loss=19.0680596, Gaussian number=364361, print grad=0.05995941162109375, Depth Loss=0.0000000]
Training progress:  31%|███       | 620/2000 [04:51<12:30,  1.84it/s, Loss=13.7709508, Gaussian number=364361, print grad=0.08630870282649994, Depth Loss=0.0000000]
Training progress:  32%|███▏      | 630/2000 [04:51<11:27,  1.99it/s, Loss=13.7709508, Gaussian number=364361, print grad=0.08630870282649994, Depth Loss=0.0000000]
Training progress:  32%|███▏      | 630/2000 [04:55<11:27,  1.99it/s, Loss=14.5200290, Gaussian number=364361, print grad=0.11869141459465027, Depth Loss=0.0000000]
Training progress:  32%|███▏      | 640/2000 [04:55<10:42,  2.12it/s, Loss=14.5200290, Gaussian number=364361, print grad=0.11869141459465027, Depth Loss=0.0000000]
Training progress:  32%|███▏      | 640/2000 [04:59<10:42,  2.12it/s, Loss=15.8472448, Gaussian number=364361, print grad=0.1434219777584076, Depth Loss=0.0000000] 
Training progress:  32%|███▎      | 650/2000 [04:59<10:10,  2.21it/s, Loss=15.8472448, Gaussian number=364361, print grad=0.1434219777584076, Depth Loss=0.0000000]
Training progress:  32%|███▎      | 650/2000 [05:03<10:10,  2.21it/s, Loss=15.7670699, Gaussian number=364361, print grad=0.1720152050256729, Depth Loss=0.0000000]
Training progress:  33%|███▎      | 660/2000 [05:03<09:46,  2.28it/s, Loss=15.7670699, Gaussian number=364361, print grad=0.1720152050256729, Depth Loss=0.0000000]
Training progress:  33%|███▎      | 660/2000 [05:07<09:46,  2.28it/s, Loss=13.6083388, Gaussian number=364361, print grad=0.19845080375671387, Depth Loss=0.0000000]
Training progress:  34%|███▎      | 670/2000 [05:07<09:28,  2.34it/s, Loss=13.6083388, Gaussian number=364361, print grad=0.19845080375671387, Depth Loss=0.0000000]
Training progress:  34%|███▎      | 670/2000 [05:11<09:28,  2.34it/s, Loss=12.4212737, Gaussian number=364361, print grad=0.2276928722858429, Depth Loss=0.0000000] 
Training progress:  34%|███▍      | 680/2000 [05:11<09:14,  2.38it/s, Loss=12.4212737, Gaussian number=364361, print grad=0.2276928722858429, Depth Loss=0.0000000]
Training progress:  34%|███▍      | 680/2000 [05:15<09:14,  2.38it/s, Loss=14.3817366, Gaussian number=364361, print grad=0.2546049654483795, Depth Loss=0.0000000]
Training progress:  34%|███▍      | 690/2000 [05:15<09:03,  2.41it/s, Loss=14.3817366, Gaussian number=364361, print grad=0.2546049654483795, Depth Loss=0.0000000]
Training progress:  34%|███▍      | 690/2000 [05:19<09:03,  2.41it/s, Loss=14.3786876, Gaussian number=364361, print grad=0.28092095255851746, Depth Loss=0.0000000]
Training progress:  35%|███▌      | 700/2000 [05:19<08:55,  2.43it/s, Loss=14.3786876, Gaussian number=364361, print grad=0.28092095255851746, Depth Loss=0.0000000]
Training progress:  35%|███▌      | 700/2000 [05:29<08:55,  2.43it/s, Loss=14.9520304, Gaussian number=706229, print grad=0.014312171377241611, Depth Loss=0.0000000]
Training progress:  36%|███▌      | 710/2000 [05:29<12:49,  1.68it/s, Loss=14.9520304, Gaussian number=706229, print grad=0.014312171377241611, Depth Loss=0.0000000]
Training progress:  36%|███▌      | 710/2000 [05:33<12:49,  1.68it/s, Loss=13.6732732, Gaussian number=706229, print grad=0.03090788796544075, Depth Loss=0.0000000] 
Training progress:  36%|███▌      | 720/2000 [05:33<11:32,  1.85it/s, Loss=13.6732732, Gaussian number=706229, print grad=0.03090788796544075, Depth Loss=0.0000000]
Training progress:  36%|███▌      | 720/2000 [05:37<11:32,  1.85it/s, Loss=16.9862191, Gaussian number=706229, print grad=0.045923929661512375, Depth Loss=0.0000000]
Training progress:  36%|███▋      | 730/2000 [05:37<10:37,  1.99it/s, Loss=16.9862191, Gaussian number=706229, print grad=0.045923929661512375, Depth Loss=0.0000000]
Training progress:  36%|███▋      | 730/2000 [05:42<10:37,  1.99it/s, Loss=19.8286893, Gaussian number=706229, print grad=0.06418593972921371, Depth Loss=0.0000000] 
Training progress:  37%|███▋      | 740/2000 [05:42<09:58,  2.11it/s, Loss=19.8286893, Gaussian number=706229, print grad=0.06418593972921371, Depth Loss=0.0000000]
Training progress:  37%|███▋      | 740/2000 [05:46<09:58,  2.11it/s, Loss=14.1076013, Gaussian number=706229, print grad=0.0816551223397255, Depth Loss=0.0000000] 
Training progress:  38%|███▊      | 750/2000 [05:46<09:29,  2.20it/s, Loss=14.1076013, Gaussian number=706229, print grad=0.0816551223397255, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 750/2000 [05:50<09:29,  2.20it/s, Loss=13.5928205, Gaussian number=706229, print grad=0.0980762243270874, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 760/2000 [05:50<09:08,  2.26it/s, Loss=13.5928205, Gaussian number=706229, print grad=0.0980762243270874, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 760/2000 [05:54<09:08,  2.26it/s, Loss=11.6934590, Gaussian number=706229, print grad=0.11486949771642685, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 770/2000 [05:54<08:53,  2.31it/s, Loss=11.6934590, Gaussian number=706229, print grad=0.11486949771642685, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 770/2000 [05:58<08:53,  2.31it/s, Loss=16.0150921, Gaussian number=706229, print grad=0.1305263191461563, Depth Loss=0.0000000] 
Training progress:  39%|███▉      | 780/2000 [05:58<08:40,  2.34it/s, Loss=16.0150921, Gaussian number=706229, print grad=0.1305263191461563, Depth Loss=0.0000000]
Training progress:  39%|███▉      | 780/2000 [06:02<08:40,  2.34it/s, Loss=17.9355270, Gaussian number=706229, print grad=0.14655037224292755, Depth Loss=0.0000000]
Training progress:  40%|███▉      | 790/2000 [06:02<08:31,  2.37it/s, Loss=17.9355270, Gaussian number=706229, print grad=0.14655037224292755, Depth Loss=0.0000000]
Training progress:  40%|███▉      | 790/2000 [06:06<08:31,  2.37it/s, Loss=15.2627512, Gaussian number=706229, print grad=0.16386796534061432, Depth Loss=0.0000000]
Training progress:  40%|████      | 800/2000 [06:06<08:22,  2.39it/s, Loss=15.2627512, Gaussian number=706229, print grad=0.16386796534061432, Depth Loss=0.0000000]
Training progress:  40%|████      | 800/2000 [06:17<08:22,  2.39it/s, Loss=19.1888955, Gaussian number=1239815, print grad=0.010161192156374454, Depth Loss=0.0000000]
Training progress:  40%|████      | 810/2000 [06:17<12:06,  1.64it/s, Loss=19.1888955, Gaussian number=1239815, print grad=0.010161192156374454, Depth Loss=0.0000000]
Training progress:  40%|████      | 810/2000 [06:21<12:06,  1.64it/s, Loss=16.9296736, Gaussian number=1239815, print grad=0.020739052444696426, Depth Loss=0.0000000]
Training progress:  41%|████      | 820/2000 [06:21<10:55,  1.80it/s, Loss=16.9296736, Gaussian number=1239815, print grad=0.020739052444696426, Depth Loss=0.0000000]
Training progress:  41%|████      | 820/2000 [06:25<10:55,  1.80it/s, Loss=14.1131264, Gaussian number=1239815, print grad=0.033578258007764816, Depth Loss=0.0000000]
Training progress:  42%|████▏     | 830/2000 [06:25<10:03,  1.94it/s, Loss=14.1131264, Gaussian number=1239815, print grad=0.033578258007764816, Depth Loss=0.0000000]
Training progress:  42%|████▏     | 830/2000 [06:30<10:03,  1.94it/s, Loss=14.0140084, Gaussian number=1239815, print grad=0.04466009885072708, Depth Loss=0.0000000] 
Training progress:  42%|████▏     | 840/2000 [06:30<09:26,  2.05it/s, Loss=14.0140084, Gaussian number=1239815, print grad=0.04466009885072708, Depth Loss=0.0000000]
Training progress:  42%|████▏     | 840/2000 [06:34<09:26,  2.05it/s, Loss=13.7958802, Gaussian number=1239815, print grad=0.055841460824012756, Depth Loss=0.0000000]
Training progress:  42%|████▎     | 850/2000 [06:34<09:00,  2.13it/s, Loss=13.7958802, Gaussian number=1239815, print grad=0.055841460824012756, Depth Loss=0.0000000]
Training progress:  42%|████▎     | 850/2000 [06:38<09:00,  2.13it/s, Loss=14.5665700, Gaussian number=1239815, print grad=0.06607908010482788, Depth Loss=0.0000000] 
Training progress:  43%|████▎     | 860/2000 [06:38<08:40,  2.19it/s, Loss=14.5665700, Gaussian number=1239815, print grad=0.06607908010482788, Depth Loss=0.0000000]
Training progress:  43%|████▎     | 860/2000 [06:42<08:40,  2.19it/s, Loss=16.3172101, Gaussian number=1239815, print grad=0.07647612690925598, Depth Loss=0.0000000]
Training progress:  44%|████▎     | 870/2000 [06:42<08:25,  2.24it/s, Loss=16.3172101, Gaussian number=1239815, print grad=0.07647612690925598, Depth Loss=0.0000000]
Training progress:  44%|████▎     | 870/2000 [06:47<08:25,  2.24it/s, Loss=15.0548048, Gaussian number=1239815, print grad=0.08674400299787521, Depth Loss=0.0000000]
Training progress:  44%|████▍     | 880/2000 [06:47<08:13,  2.27it/s, Loss=15.0548048, Gaussian number=1239815, print grad=0.08674400299787521, Depth Loss=0.0000000]
Training progress:  44%|████▍     | 880/2000 [06:51<08:13,  2.27it/s, Loss=12.0737225, Gaussian number=1239815, print grad=0.09769545495510101, Depth Loss=0.0000000]
Training progress:  44%|████▍     | 890/2000 [06:51<08:04,  2.29it/s, Loss=12.0737225, Gaussian number=1239815, print grad=0.09769545495510101, Depth Loss=0.0000000]
Training progress:  44%|████▍     | 890/2000 [06:55<08:04,  2.29it/s, Loss=15.6303266, Gaussian number=1239815, print grad=0.10769936442375183, Depth Loss=0.0000000]
Training progress:  45%|████▌     | 900/2000 [06:55<07:56,  2.31it/s, Loss=15.6303266, Gaussian number=1239815, print grad=0.10769936442375183, Depth Loss=0.0000000]
Training progress:  45%|████▌     | 900/2000 [07:06<07:56,  2.31it/s, Loss=14.8502477, Gaussian number=1981574, print grad=0.007221603766083717, Depth Loss=0.0000000]
Training progress:  46%|████▌     | 910/2000 [07:06<11:30,  1.58it/s, Loss=14.8502477, Gaussian number=1981574, print grad=0.007221603766083717, Depth Loss=0.0000000]
Training progress:  46%|████▌     | 910/2000 [07:11<11:30,  1.58it/s, Loss=16.9349093, Gaussian number=1981574, print grad=0.013725950382649899, Depth Loss=0.0000000]
Training progress:  46%|████▌     | 920/2000 [07:11<10:26,  1.73it/s, Loss=16.9349093, Gaussian number=1981574, print grad=0.013725950382649899, Depth Loss=0.0000000]
Training progress:  46%|████▌     | 920/2000 [07:15<10:26,  1.73it/s, Loss=18.2420327, Gaussian number=1981574, print grad=0.022115420550107956, Depth Loss=0.0000000]
Training progress:  46%|████▋     | 930/2000 [07:15<09:39,  1.85it/s, Loss=18.2420327, Gaussian number=1981574, print grad=0.022115420550107956, Depth Loss=0.0000000]
Training progress:  46%|████▋     | 930/2000 [07:20<09:39,  1.85it/s, Loss=15.7738077, Gaussian number=1981574, print grad=0.029283858835697174, Depth Loss=0.0000000]
Training progress:  47%|████▋     | 940/2000 [07:20<09:07,  1.94it/s, Loss=15.7738077, Gaussian number=1981574, print grad=0.029283858835697174, Depth Loss=0.0000000]
Training progress:  47%|████▋     | 940/2000 [07:24<09:07,  1.94it/s, Loss=16.0127969, Gaussian number=1981574, print grad=0.036869555711746216, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 950/2000 [07:24<08:42,  2.01it/s, Loss=16.0127969, Gaussian number=1981574, print grad=0.036869555711746216, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 950/2000 [07:29<08:42,  2.01it/s, Loss=15.2380349, Gaussian number=1981574, print grad=0.04389989376068115, Depth Loss=0.0000000] 
Training progress:  48%|████▊     | 960/2000 [07:29<08:23,  2.07it/s, Loss=15.2380349, Gaussian number=1981574, print grad=0.04389989376068115, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 960/2000 [07:33<08:23,  2.07it/s, Loss=18.9074528, Gaussian number=1981574, print grad=0.05128639191389084, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 970/2000 [07:33<08:09,  2.10it/s, Loss=18.9074528, Gaussian number=1981574, print grad=0.05128639191389084, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 970/2000 [07:38<08:09,  2.10it/s, Loss=12.1831992, Gaussian number=1981574, print grad=0.05828040465712547, Depth Loss=0.0000000]
Training progress:  49%|████▉     | 980/2000 [07:38<07:58,  2.13it/s, Loss=12.1831992, Gaussian number=1981574, print grad=0.05828040465712547, Depth Loss=0.0000000]
Training progress:  49%|████▉     | 980/2000 [07:43<07:58,  2.13it/s, Loss=12.8043942, Gaussian number=1981574, print grad=0.06508629769086838, Depth Loss=0.0000000]
Training progress:  50%|████▉     | 990/2000 [07:43<07:50,  2.15it/s, Loss=12.8043942, Gaussian number=1981574, print grad=0.06508629769086838, Depth Loss=0.0000000]
Training progress:  50%|████▉     | 990/2000 [07:47<07:50,  2.15it/s, Loss=15.4470741, Gaussian number=1981574, print grad=0.07121505588293076, Depth Loss=0.0000000]
Training progress:  50%|█████     | 1000/2000 [07:47<07:41,  2.17it/s, Loss=15.4470741, Gaussian number=1981574, print grad=0.07121505588293076, Depth Loss=0.0000000]
Training progress:  50%|█████     | 1000/2000 [07:59<07:41,  2.17it/s, Loss=17.3700046, Gaussian number=2940293, print grad=0.004103715065866709, Depth Loss=0.0000000]
Training progress:  50%|█████     | 1010/2000 [07:59<11:02,  1.50it/s, Loss=17.3700046, Gaussian number=2940293, print grad=0.004103715065866709, Depth Loss=0.0000000]
Training progress:  50%|█████     | 1010/2000 [08:03<11:02,  1.50it/s, Loss=21.4628780, Gaussian number=2940293, print grad=0.009781445376574993, Depth Loss=0.0000000]
Training progress:  51%|█████     | 1020/2000 [08:03<10:00,  1.63it/s, Loss=21.4628780, Gaussian number=2940293, print grad=0.009781445376574993, Depth Loss=0.0000000]
Training progress:  51%|█████     | 1020/2000 [08:08<10:00,  1.63it/s, Loss=19.6917014, Gaussian number=2940293, print grad=0.014827611856162548, Depth Loss=0.0000000]
Training progress:  52%|█████▏    | 1030/2000 [08:08<09:16,  1.74it/s, Loss=19.6917014, Gaussian number=2940293, print grad=0.014827611856162548, Depth Loss=0.0000000]
Training progress:  52%|█████▏    | 1030/2000 [08:13<09:16,  1.74it/s, Loss=18.5528640, Gaussian number=2940293, print grad=0.020878257229924202, Depth Loss=0.0000000]
Training progress:  52%|█████▏    | 1040/2000 [08:13<08:43,  1.83it/s, Loss=18.5528640, Gaussian number=2940293, print grad=0.020878257229924202, Depth Loss=0.0000000]
Training progress:  52%|█████▏    | 1040/2000 [08:18<08:43,  1.83it/s, Loss=16.1891954, Gaussian number=2940293, print grad=0.025738224387168884, Depth Loss=0.0000000]
Training progress:  52%|█████▎    | 1050/2000 [08:18<08:19,  1.90it/s, Loss=16.1891954, Gaussian number=2940293, print grad=0.025738224387168884, Depth Loss=0.0000000]
Training progress:  52%|█████▎    | 1050/2000 [08:23<08:19,  1.90it/s, Loss=16.3431339, Gaussian number=2940293, print grad=0.03113759681582451, Depth Loss=0.0000000] 
Training progress:  53%|█████▎    | 1060/2000 [08:23<08:01,  1.95it/s, Loss=16.3431339, Gaussian number=2940293, print grad=0.03113759681582451, Depth Loss=0.0000000]
Training progress:  53%|█████▎    | 1060/2000 [08:27<08:01,  1.95it/s, Loss=13.2028127, Gaussian number=2940293, print grad=0.03694472461938858, Depth Loss=0.0000000]
Training progress:  54%|█████▎    | 1070/2000 [08:27<07:47,  1.99it/s, Loss=13.2028127, Gaussian number=2940293, print grad=0.03694472461938858, Depth Loss=0.0000000]
Training progress:  54%|█████▎    | 1070/2000 [08:32<07:47,  1.99it/s, Loss=13.1478896, Gaussian number=2940293, print grad=0.04160583019256592, Depth Loss=0.0000000]
Training progress:  54%|█████▍    | 1080/2000 [08:32<07:36,  2.01it/s, Loss=13.1478896, Gaussian number=2940293, print grad=0.04160583019256592, Depth Loss=0.0000000]
Training progress:  54%|█████▍    | 1080/2000 [08:37<07:36,  2.01it/s, Loss=16.6312707, Gaussian number=2940293, print grad=0.04696759209036827, Depth Loss=0.0000000]
Training progress:  55%|█████▍    | 1090/2000 [08:37<07:27,  2.03it/s, Loss=16.6312707, Gaussian number=2940293, print grad=0.04696759209036827, Depth Loss=0.0000000]
Training progress:  55%|█████▍    | 1090/2000 [08:42<07:27,  2.03it/s, Loss=16.8372593, Gaussian number=2940293, print grad=0.05203649029135704, Depth Loss=0.0000000]
Training progress:  55%|█████▌    | 1100/2000 [08:42<07:19,  2.05it/s, Loss=16.8372593, Gaussian number=2940293, print grad=0.05203649029135704, Depth Loss=0.0000000]
Training progress:  55%|█████▌    | 1100/2000 [08:47<07:19,  2.05it/s, Loss=19.3943394, Gaussian number=4108812, print grad=0.0032169248443096876, Depth Loss=0.0000000]
Training progress:  56%|█████▌    | 1110/2000 [08:47<07:20,  2.02it/s, Loss=19.3943394, Gaussian number=4108812, print grad=0.0032169248443096876, Depth Loss=0.0000000]
Training progress:  56%|█████▌    | 1110/2000 [08:52<07:20,  2.02it/s, Loss=20.2842998, Gaussian number=4108812, print grad=0.006989105138927698, Depth Loss=0.0000000] 
Training progress:  56%|█████▌    | 1120/2000 [08:52<07:19,  2.00it/s, Loss=20.2842998, Gaussian number=4108812, print grad=0.006989105138927698, Depth Loss=0.0000000]
Training progress:  56%|█████▌    | 1120/2000 [08:57<07:19,  2.00it/s, Loss=16.2349439, Gaussian number=4108812, print grad=0.011239307001233101, Depth Loss=0.0000000]
Training progress:  56%|█████▋    | 1130/2000 [08:57<07:15,  2.00it/s, Loss=16.2349439, Gaussian number=4108812, print grad=0.011239307001233101, Depth Loss=0.0000000]
Training progress:  56%|█████▋    | 1130/2000 [09:02<07:15,  2.00it/s, Loss=18.4045208, Gaussian number=4108812, print grad=0.015344919636845589, Depth Loss=0.0000000]
Training progress:  57%|█████▋    | 1140/2000 [09:02<07:10,  2.00it/s, Loss=18.4045208, Gaussian number=4108812, print grad=0.015344919636845589, Depth Loss=0.0000000]
Training progress:  57%|█████▋    | 1140/2000 [09:07<07:10,  2.00it/s, Loss=15.0052541, Gaussian number=4108812, print grad=0.019731521606445312, Depth Loss=0.0000000]
Training progress:  57%|█████▊    | 1150/2000 [09:07<07:06,  1.99it/s, Loss=15.0052541, Gaussian number=4108812, print grad=0.019731521606445312, Depth Loss=0.0000000]
Training progress:  57%|█████▊    | 1150/2000 [09:12<07:06,  1.99it/s, Loss=14.9667173, Gaussian number=4108812, print grad=0.02312975935637951, Depth Loss=0.0000000] 
Training progress:  58%|█████▊    | 1160/2000 [09:12<07:02,  1.99it/s, Loss=14.9667173, Gaussian number=4108812, print grad=0.02312975935637951, Depth Loss=0.0000000]
Training progress:  58%|█████▊    | 1160/2000 [09:17<07:02,  1.99it/s, Loss=16.3686873, Gaussian number=4108812, print grad=0.026957344263792038, Depth Loss=0.0000000]
Training progress:  58%|█████▊    | 1170/2000 [09:17<06:57,  1.99it/s, Loss=16.3686873, Gaussian number=4108812, print grad=0.026957344263792038, Depth Loss=0.0000000]
Training progress:  58%|█████▊    | 1170/2000 [09:22<06:57,  1.99it/s, Loss=17.4172552, Gaussian number=4108812, print grad=0.03093772754073143, Depth Loss=0.0000000] 
Training progress:  59%|█████▉    | 1180/2000 [09:22<06:52,  1.99it/s, Loss=17.4172552, Gaussian number=4108812, print grad=0.03093772754073143, Depth Loss=0.0000000]
Training progress:  59%|█████▉    | 1180/2000 [09:27<06:52,  1.99it/s, Loss=16.8979000, Gaussian number=4108812, print grad=0.034954119473695755, Depth Loss=0.0000000]
Training progress:  60%|█████▉    | 1190/2000 [09:27<06:48,  1.98it/s, Loss=16.8979000, Gaussian number=4108812, print grad=0.034954119473695755, Depth Loss=0.0000000]
Training progress:  60%|█████▉    | 1190/2000 [09:32<06:48,  1.98it/s, Loss=18.3747628, Gaussian number=4108812, print grad=0.038567058742046356, Depth Loss=0.0000000]
Training progress:  60%|██████    | 1200/2000 [09:32<06:42,  1.99it/s, Loss=18.3747628, Gaussian number=4108812, print grad=0.038567058742046356, Depth Loss=0.0000000]
Training progress:  60%|██████    | 1200/2000 [09:38<06:42,  1.99it/s, Loss=16.5136628, Gaussian number=5483547, print grad=0.002757301786914468, Depth Loss=0.0000000]
Training progress:  60%|██████    | 1210/2000 [09:38<06:51,  1.92it/s, Loss=16.5136628, Gaussian number=5483547, print grad=0.002757301786914468, Depth Loss=0.0000000]
Training progress:  60%|██████    | 1210/2000 [09:43<06:51,  1.92it/s, Loss=17.4666920, Gaussian number=5483547, print grad=0.006117855664342642, Depth Loss=0.0000000]
Training progress:  61%|██████    | 1220/2000 [09:43<06:52,  1.89it/s, Loss=17.4666920, Gaussian number=5483547, print grad=0.006117855664342642, Depth Loss=0.0000000]
Training progress:  61%|██████    | 1220/2000 [09:49<06:52,  1.89it/s, Loss=16.1635817, Gaussian number=5483547, print grad=0.009651227854192257, Depth Loss=0.0000000]
Training progress:  62%|██████▏   | 1230/2000 [09:49<06:50,  1.87it/s, Loss=16.1635817, Gaussian number=5483547, print grad=0.009651227854192257, Depth Loss=0.0000000]
Training progress:  62%|██████▏   | 1230/2000 [09:54<06:50,  1.87it/s, Loss=16.3315655, Gaussian number=5483547, print grad=0.012849383056163788, Depth Loss=0.0000000]
Training progress:  62%|██████▏   | 1240/2000 [09:54<06:49,  1.85it/s, Loss=16.3315655, Gaussian number=5483547, print grad=0.012849383056163788, Depth Loss=0.0000000]
Training progress:  62%|██████▏   | 1240/2000 [10:00<06:49,  1.85it/s, Loss=15.7085411, Gaussian number=5483547, print grad=0.01569630205631256, Depth Loss=0.0000000] 
Training progress:  62%|██████▎   | 1250/2000 [10:00<06:46,  1.85it/s, Loss=15.7085411, Gaussian number=5483547, print grad=0.01569630205631256, Depth Loss=0.0000000]
Training progress:  62%|██████▎   | 1250/2000 [10:05<06:46,  1.85it/s, Loss=15.2362371, Gaussian number=5483547, print grad=0.018305357545614243, Depth Loss=0.0000000]
Training progress:  63%|██████▎   | 1260/2000 [10:05<06:43,  1.83it/s, Loss=15.2362371, Gaussian number=5483547, print grad=0.018305357545614243, Depth Loss=0.0000000]
Training progress:  63%|██████▎   | 1260/2000 [10:11<06:43,  1.83it/s, Loss=17.9084511, Gaussian number=5483547, print grad=0.021379927173256874, Depth Loss=0.0000000]
Training progress:  64%|██████▎   | 1270/2000 [10:11<06:38,  1.83it/s, Loss=17.9084511, Gaussian number=5483547, print grad=0.021379927173256874, Depth Loss=0.0000000]
Training progress:  64%|██████▎   | 1270/2000 [10:16<06:38,  1.83it/s, Loss=17.5607571, Gaussian number=5483547, print grad=0.023844050243496895, Depth Loss=0.0000000]
Training progress:  64%|██████▍   | 1280/2000 [10:16<06:35,  1.82it/s, Loss=17.5607571, Gaussian number=5483547, print grad=0.023844050243496895, Depth Loss=0.0000000]
Training progress:  64%|██████▍   | 1280/2000 [10:22<06:35,  1.82it/s, Loss=13.8749833, Gaussian number=5483547, print grad=0.026972314342856407, Depth Loss=0.0000000]
Training progress:  64%|██████▍   | 1290/2000 [10:22<06:29,  1.82it/s, Loss=13.8749833, Gaussian number=5483547, print grad=0.026972314342856407, Depth Loss=0.0000000]
Training progress:  64%|██████▍   | 1290/2000 [10:27<06:29,  1.82it/s, Loss=21.1287921, Gaussian number=5483547, print grad=0.029817994683980942, Depth Loss=0.0000000]
Training progress:  65%|██████▌   | 1300/2000 [10:27<06:24,  1.82it/s, Loss=21.1287921, Gaussian number=5483547, print grad=0.029817994683980942, Depth Loss=0.0000000]
Training progress:  65%|██████▌   | 1300/2000 [10:33<06:24,  1.82it/s, Loss=21.4620906, Gaussian number=7088433, print grad=0.0021995825227349997, Depth Loss=0.0000000]
Training progress:  66%|██████▌   | 1310/2000 [10:33<06:27,  1.78it/s, Loss=21.4620906, Gaussian number=7088433, print grad=0.0021995825227349997, Depth Loss=0.0000000]
Training progress:  66%|██████▌   | 1310/2000 [10:39<06:27,  1.78it/s, Loss=22.2736280, Gaussian number=7088433, print grad=0.0043389578349888325, Depth Loss=0.0000000]
Training progress:  66%|██████▌   | 1320/2000 [10:39<06:24,  1.77it/s, Loss=22.2736280, Gaussian number=7088433, print grad=0.0043389578349888325, Depth Loss=0.0000000]
Training progress:  66%|██████▌   | 1320/2000 [10:45<06:24,  1.77it/s, Loss=19.9482144, Gaussian number=7088433, print grad=0.006969190668314695, Depth Loss=0.0000000] 
Training progress:  66%|██████▋   | 1330/2000 [10:45<06:21,  1.76it/s, Loss=19.9482144, Gaussian number=7088433, print grad=0.006969190668314695, Depth Loss=0.0000000]
Training progress:  66%|██████▋   | 1330/2000 [10:51<06:21,  1.76it/s, Loss=19.3323123, Gaussian number=7088433, print grad=0.009158781729638577, Depth Loss=0.0000000]
Training progress:  67%|██████▋   | 1340/2000 [10:51<06:16,  1.75it/s, Loss=19.3323123, Gaussian number=7088433, print grad=0.009158781729638577, Depth Loss=0.0000000]
Training progress:  67%|██████▋   | 1340/2000 [10:56<06:16,  1.75it/s, Loss=22.6204274, Gaussian number=7088433, print grad=0.011038917116820812, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1350/2000 [10:56<06:09,  1.76it/s, Loss=22.6204274, Gaussian number=7088433, print grad=0.011038917116820812, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1350/2000 [11:02<06:09,  1.76it/s, Loss=15.1760083, Gaussian number=7088433, print grad=0.013209838420152664, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1360/2000 [11:02<06:04,  1.76it/s, Loss=15.1760083, Gaussian number=7088433, print grad=0.013209838420152664, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1360/2000 [11:08<06:04,  1.76it/s, Loss=24.8874495, Gaussian number=7088433, print grad=0.015742557123303413, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1370/2000 [11:08<05:59,  1.75it/s, Loss=24.8874495, Gaussian number=7088433, print grad=0.015742557123303413, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1370/2000 [11:13<05:59,  1.75it/s, Loss=18.3178519, Gaussian number=7088433, print grad=0.017858972772955894, Depth Loss=0.0000000]
Training progress:  69%|██████▉   | 1380/2000 [11:13<05:54,  1.75it/s, Loss=18.3178519, Gaussian number=7088433, print grad=0.017858972772955894, Depth Loss=0.0000000]
Training progress:  69%|██████▉   | 1380/2000 [11:19<05:54,  1.75it/s, Loss=15.9252716, Gaussian number=7088433, print grad=0.02002817951142788, Depth Loss=0.0000000] 
Training progress:  70%|██████▉   | 1390/2000 [11:19<05:48,  1.75it/s, Loss=15.9252716, Gaussian number=7088433, print grad=0.02002817951142788, Depth Loss=0.0000000]
Training progress:  70%|██████▉   | 1390/2000 [11:25<05:48,  1.75it/s, Loss=17.9159484, Gaussian number=7088433, print grad=0.02206920087337494, Depth Loss=0.0000000]
Training progress:  70%|███████   | 1400/2000 [11:25<05:43,  1.74it/s, Loss=17.9159484, Gaussian number=7088433, print grad=0.02206920087337494, Depth Loss=0.0000000]
Training progress:  70%|███████   | 1400/2000 [11:31<05:43,  1.74it/s, Loss=21.6254263, Gaussian number=8829775, print grad=0.001832702779211104, Depth Loss=0.0000000]
Training progress:  70%|███████   | 1410/2000 [11:31<05:49,  1.69it/s, Loss=21.6254263, Gaussian number=8829775, print grad=0.001832702779211104, Depth Loss=0.0000000]
Training progress:  70%|███████   | 1410/2000 [11:38<05:49,  1.69it/s, Loss=18.3051448, Gaussian number=8829775, print grad=0.0032628935296088457, Depth Loss=0.0000000]
Training progress:  71%|███████   | 1420/2000 [11:38<05:50,  1.65it/s, Loss=18.3051448, Gaussian number=8829775, print grad=0.0032628935296088457, Depth Loss=0.0000000]
Training progress:  71%|███████   | 1420/2000 [11:44<05:50,  1.65it/s, Loss=20.3319308, Gaussian number=8829775, print grad=0.0053305355831980705, Depth Loss=0.0000000]
Training progress:  72%|███████▏  | 1430/2000 [11:44<05:49,  1.63it/s, Loss=20.3319308, Gaussian number=8829775, print grad=0.0053305355831980705, Depth Loss=0.0000000]
Training progress:  72%|███████▏  | 1430/2000 [11:50<05:49,  1.63it/s, Loss=18.2451372, Gaussian number=8829775, print grad=0.006854103412479162, Depth Loss=0.0000000] 
Training progress:  72%|███████▏  | 1440/2000 [11:50<05:45,  1.62it/s, Loss=18.2451372, Gaussian number=8829775, print grad=0.006854103412479162, Depth Loss=0.0000000]
Training progress:  72%|███████▏  | 1440/2000 [11:57<05:45,  1.62it/s, Loss=17.5562441, Gaussian number=8829775, print grad=0.00879577361047268, Depth Loss=0.0000000] 
Training progress:  72%|███████▎  | 1450/2000 [11:57<05:40,  1.61it/s, Loss=17.5562441, Gaussian number=8829775, print grad=0.00879577361047268, Depth Loss=0.0000000]
Training progress:  72%|███████▎  | 1450/2000 [12:03<05:40,  1.61it/s, Loss=16.0532171, Gaussian number=8829775, print grad=0.010556278750300407, Depth Loss=0.0000000]
Training progress:  73%|███████▎  | 1460/2000 [12:03<05:35,  1.61it/s, Loss=16.0532171, Gaussian number=8829775, print grad=0.010556278750300407, Depth Loss=0.0000000]
Training progress:  73%|███████▎  | 1460/2000 [12:09<05:35,  1.61it/s, Loss=20.1598328, Gaussian number=8829775, print grad=0.012495236471295357, Depth Loss=0.0000000]
Training progress:  74%|███████▎  | 1470/2000 [12:09<05:30,  1.61it/s, Loss=20.1598328, Gaussian number=8829775, print grad=0.012495236471295357, Depth Loss=0.0000000]
Training progress:  74%|███████▎  | 1470/2000 [12:15<05:30,  1.61it/s, Loss=21.3774060, Gaussian number=8829775, print grad=0.014362309128046036, Depth Loss=0.0000000]
Training progress:  74%|███████▍  | 1480/2000 [12:15<05:25,  1.60it/s, Loss=21.3774060, Gaussian number=8829775, print grad=0.014362309128046036, Depth Loss=0.0000000]
Training progress:  74%|███████▍  | 1480/2000 [12:22<05:25,  1.60it/s, Loss=20.8970662, Gaussian number=8829775, print grad=0.015916837379336357, Depth Loss=0.0000000]
Training progress:  74%|███████▍  | 1490/2000 [12:22<05:19,  1.60it/s, Loss=20.8970662, Gaussian number=8829775, print grad=0.015916837379336357, Depth Loss=0.0000000]
Training progress:  74%|███████▍  | 1490/2000 [12:28<05:19,  1.60it/s, Loss=19.5832165, Gaussian number=8829775, print grad=0.017832519486546516, Depth Loss=0.0000000]
Training progress:  75%|███████▌  | 1500/2000 [12:28<05:13,  1.60it/s, Loss=19.5832165, Gaussian number=8829775, print grad=0.017832519486546516, Depth Loss=0.0000000]
Training progress:  75%|███████▌  | 1500/2000 [12:43<05:13,  1.60it/s, Loss=23.2335307, Gaussian number=10744981, print grad=0.0015524189220741391, Depth Loss=0.0000000]
Training progress:  76%|███████▌  | 1510/2000 [12:43<07:20,  1.11it/s, Loss=23.2335307, Gaussian number=10744981, print grad=0.0015524189220741391, Depth Loss=0.0000000]
Training progress:  76%|███████▌  | 1510/2000 [12:50<07:20,  1.11it/s, Loss=23.1707423, Gaussian number=10744981, print grad=0.003002648241817951, Depth Loss=0.0000000] 
Training progress:  76%|███████▌  | 1520/2000 [12:50<06:38,  1.21it/s, Loss=23.1707423, Gaussian number=10744981, print grad=0.003002648241817951, Depth Loss=0.0000000]
Training progress:  76%|███████▌  | 1520/2000 [12:57<06:38,  1.21it/s, Loss=15.6320172, Gaussian number=10744981, print grad=0.0048612081445753574, Depth Loss=0.0000000]
Training progress:  76%|███████▋  | 1530/2000 [12:57<06:06,  1.28it/s, Loss=15.6320172, Gaussian number=10744981, print grad=0.0048612081445753574, Depth Loss=0.0000000]
Training progress:  76%|███████▋  | 1530/2000 [13:03<06:06,  1.28it/s, Loss=19.1456933, Gaussian number=10744981, print grad=0.006366514600813389, Depth Loss=0.0000000] 
Training progress:  77%|███████▋  | 1540/2000 [13:03<05:43,  1.34it/s, Loss=19.1456933, Gaussian number=10744981, print grad=0.006366514600813389, Depth Loss=0.0000000]
Training progress:  77%|███████▋  | 1540/2000 [13:10<05:43,  1.34it/s, Loss=22.2624630, Gaussian number=10744981, print grad=0.007831450551748276, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1550/2000 [13:10<05:25,  1.38it/s, Loss=22.2624630, Gaussian number=10744981, print grad=0.007831450551748276, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1550/2000 [13:17<05:25,  1.38it/s, Loss=23.6717393, Gaussian number=10744981, print grad=0.009553726762533188, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1560/2000 [13:17<05:12,  1.41it/s, Loss=23.6717393, Gaussian number=10744981, print grad=0.009553726762533188, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1560/2000 [13:23<05:12,  1.41it/s, Loss=20.6695819, Gaussian number=10744981, print grad=0.011186892166733742, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1570/2000 [13:23<04:59,  1.43it/s, Loss=20.6695819, Gaussian number=10744981, print grad=0.011186892166733742, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1570/2000 [13:30<04:59,  1.43it/s, Loss=15.5975261, Gaussian number=10744981, print grad=0.012492992915213108, Depth Loss=0.0000000]
Training progress:  79%|███████▉  | 1580/2000 [13:30<04:47,  1.46it/s, Loss=15.5975261, Gaussian number=10744981, print grad=0.012492992915213108, Depth Loss=0.0000000]
Training progress:  79%|███████▉  | 1580/2000 [13:37<04:47,  1.46it/s, Loss=19.7446868, Gaussian number=10744981, print grad=0.013884827494621277, Depth Loss=0.0000000]
Training progress:  80%|███████▉  | 1590/2000 [13:37<04:38,  1.47it/s, Loss=19.7446868, Gaussian number=10744981, print grad=0.013884827494621277, Depth Loss=0.0000000]
Training progress:  80%|███████▉  | 1590/2000 [13:43<04:38,  1.47it/s, Loss=17.7264754, Gaussian number=10744981, print grad=0.015552454628050327, Depth Loss=0.0000000]
Training progress:  80%|████████  | 1600/2000 [13:43<04:31,  1.48it/s, Loss=17.7264754, Gaussian number=10744981, print grad=0.015552454628050327, Depth Loss=0.0000000]
Training progress:  80%|████████  | 1600/2000 [13:51<04:31,  1.48it/s, Loss=24.1413411, Gaussian number=12760487, print grad=0.0008970547933131456, Depth Loss=0.0000000]
Training progress:  80%|████████  | 1610/2000 [13:51<04:33,  1.43it/s, Loss=24.1413411, Gaussian number=12760487, print grad=0.0008970547933131456, Depth Loss=0.0000000]
Training progress:  80%|████████  | 1610/2000 [13:58<04:33,  1.43it/s, Loss=23.0619066, Gaussian number=12760487, print grad=0.0023782134521752596, Depth Loss=0.0000000]
Training progress:  81%|████████  | 1620/2000 [13:58<04:28,  1.41it/s, Loss=23.0619066, Gaussian number=12760487, print grad=0.0023782134521752596, Depth Loss=0.0000000]
Training progress:  81%|████████  | 1620/2000 [14:05<04:28,  1.41it/s, Loss=19.4761225, Gaussian number=12760487, print grad=0.0036374498158693314, Depth Loss=0.0000000]
Training progress:  82%|████████▏ | 1630/2000 [14:05<04:21,  1.41it/s, Loss=19.4761225, Gaussian number=12760487, print grad=0.0036374498158693314, Depth Loss=0.0000000]
Training progress:  82%|████████▏ | 1630/2000 [14:12<04:21,  1.41it/s, Loss=18.8478520, Gaussian number=12760487, print grad=0.0046997410245239735, Depth Loss=0.0000000]
Training progress:  82%|████████▏ | 1640/2000 [14:12<04:16,  1.40it/s, Loss=18.8478520, Gaussian number=12760487, print grad=0.0046997410245239735, Depth Loss=0.0000000]
Training progress:  82%|████████▏ | 1640/2000 [14:20<04:16,  1.40it/s, Loss=19.8708657, Gaussian number=12760487, print grad=0.006127619184553623, Depth Loss=0.0000000] 
Training progress:  82%|████████▎ | 1650/2000 [14:20<04:09,  1.40it/s, Loss=19.8708657, Gaussian number=12760487, print grad=0.006127619184553623, Depth Loss=0.0000000]
Training progress:  82%|████████▎ | 1650/2000 [14:27<04:09,  1.40it/s, Loss=19.6688736, Gaussian number=12760487, print grad=0.0069739785976707935, Depth Loss=0.0000000]
Training progress:  83%|████████▎ | 1660/2000 [14:27<04:03,  1.40it/s, Loss=19.6688736, Gaussian number=12760487, print grad=0.0069739785976707935, Depth Loss=0.0000000]
Training progress:  83%|████████▎ | 1660/2000 [14:34<04:03,  1.40it/s, Loss=19.7064870, Gaussian number=12760487, print grad=0.007956182584166527, Depth Loss=0.0000000] 
Training progress:  84%|████████▎ | 1670/2000 [14:34<03:56,  1.40it/s, Loss=19.7064870, Gaussian number=12760487, print grad=0.007956182584166527, Depth Loss=0.0000000]
Training progress:  84%|████████▎ | 1670/2000 [14:41<03:56,  1.40it/s, Loss=19.6557045, Gaussian number=12760487, print grad=0.008890840224921703, Depth Loss=0.0000000]
Training progress:  84%|████████▍ | 1680/2000 [14:41<03:48,  1.40it/s, Loss=19.6557045, Gaussian number=12760487, print grad=0.008890840224921703, Depth Loss=0.0000000]
Training progress:  84%|████████▍ | 1680/2000 [14:48<03:48,  1.40it/s, Loss=20.4462032, Gaussian number=12760487, print grad=0.010136015713214874, Depth Loss=0.0000000]
Training progress:  84%|████████▍ | 1690/2000 [14:48<03:41,  1.40it/s, Loss=20.4462032, Gaussian number=12760487, print grad=0.010136015713214874, Depth Loss=0.0000000]
Training progress:  84%|████████▍ | 1690/2000 [14:55<03:41,  1.40it/s, Loss=22.8085948, Gaussian number=12760487, print grad=0.011297301389276981, Depth Loss=0.0000000]
Training progress:  85%|████████▌ | 1700/2000 [14:55<03:33,  1.40it/s, Loss=22.8085948, Gaussian number=12760487, print grad=0.011297301389276981, Depth Loss=0.0000000]
Training progress:  85%|████████▌ | 1700/2000 [15:03<03:33,  1.40it/s, Loss=22.0611500, Gaussian number=14557821, print grad=0.0010244576260447502, Depth Loss=0.0000000]
Training progress:  86%|████████▌ | 1710/2000 [15:03<03:32,  1.36it/s, Loss=22.0611500, Gaussian number=14557821, print grad=0.0010244576260447502, Depth Loss=0.0000000]
Training progress:  86%|████████▌ | 1710/2000 [15:11<03:32,  1.36it/s, Loss=23.0888644, Gaussian number=14557821, print grad=0.0019529052078723907, Depth Loss=0.0000000]
Training progress:  86%|████████▌ | 1720/2000 [15:11<03:26,  1.36it/s, Loss=23.0888644, Gaussian number=14557821, print grad=0.0019529052078723907, Depth Loss=0.0000000]
Training progress:  86%|████████▌ | 1720/2000 [15:18<03:26,  1.36it/s, Loss=24.3039948, Gaussian number=14557821, print grad=0.0027047700714319944, Depth Loss=0.0000000]
Training progress:  86%|████████▋ | 1730/2000 [15:18<03:20,  1.35it/s, Loss=24.3039948, Gaussian number=14557821, print grad=0.0027047700714319944, Depth Loss=0.0000000]
Training progress:  86%|████████▋ | 1730/2000 [15:26<03:20,  1.35it/s, Loss=25.7110757, Gaussian number=14557821, print grad=0.003504539607092738, Depth Loss=0.0000000] 
Training progress:  87%|████████▋ | 1740/2000 [15:26<03:14,  1.34it/s, Loss=25.7110757, Gaussian number=14557821, print grad=0.003504539607092738, Depth Loss=0.0000000]
Training progress:  87%|████████▋ | 1740/2000 [15:33<03:14,  1.34it/s, Loss=23.8900952, Gaussian number=14557821, print grad=0.004331641830503941, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1750/2000 [15:33<03:07,  1.33it/s, Loss=23.8900952, Gaussian number=14557821, print grad=0.004331641830503941, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1750/2000 [15:41<03:07,  1.33it/s, Loss=23.2552267, Gaussian number=14557821, print grad=0.005350620485842228, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1760/2000 [15:41<03:00,  1.33it/s, Loss=23.2552267, Gaussian number=14557821, print grad=0.005350620485842228, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1760/2000 [15:48<03:00,  1.33it/s, Loss=18.9687191, Gaussian number=14557821, print grad=0.0062064118683338165, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1770/2000 [15:48<02:52,  1.33it/s, Loss=18.9687191, Gaussian number=14557821, print grad=0.0062064118683338165, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1770/2000 [15:56<02:52,  1.33it/s, Loss=19.4533672, Gaussian number=14557821, print grad=0.007106896489858627, Depth Loss=0.0000000] 
Training progress:  89%|████████▉ | 1780/2000 [15:56<02:44,  1.34it/s, Loss=19.4533672, Gaussian number=14557821, print grad=0.007106896489858627, Depth Loss=0.0000000]
Training progress:  89%|████████▉ | 1780/2000 [16:03<02:44,  1.34it/s, Loss=20.6371115, Gaussian number=14557821, print grad=0.007947553880512714, Depth Loss=0.0000000]
Training progress:  90%|████████▉ | 1790/2000 [16:03<02:36,  1.34it/s, Loss=20.6371115, Gaussian number=14557821, print grad=0.007947553880512714, Depth Loss=0.0000000]
Training progress:  90%|████████▉ | 1790/2000 [16:11<02:36,  1.34it/s, Loss=21.5453726, Gaussian number=14557821, print grad=0.008894291706383228, Depth Loss=0.0000000]
Training progress:  90%|█████████ | 1800/2000 [16:11<02:29,  1.33it/s, Loss=21.5453726, Gaussian number=14557821, print grad=0.008894291706383228, Depth Loss=0.0000000]
Training progress:  90%|█████████ | 1800/2000 [16:19<02:29,  1.33it/s, Loss=23.0989323, Gaussian number=16401254, print grad=0.0004926680121570826, Depth Loss=0.0000000]
Training progress:  90%|█████████ | 1810/2000 [16:19<02:26,  1.30it/s, Loss=23.0989323, Gaussian number=16401254, print grad=0.0004926680121570826, Depth Loss=0.0000000]
Training progress:  90%|█████████ | 1810/2000 [16:27<02:26,  1.30it/s, Loss=21.1635634, Gaussian number=16401254, print grad=0.0013453492429107428, Depth Loss=0.0000000]
Training progress:  91%|█████████ | 1820/2000 [16:27<02:20,  1.28it/s, Loss=21.1635634, Gaussian number=16401254, print grad=0.0013453492429107428, Depth Loss=0.0000000]
Training progress:  91%|█████████ | 1820/2000 [16:35<02:20,  1.28it/s, Loss=19.7235923, Gaussian number=16401254, print grad=0.0017738965107128024, Depth Loss=0.0000000]
Training progress:  92%|█████████▏| 1830/2000 [16:35<02:12,  1.29it/s, Loss=19.7235923, Gaussian number=16401254, print grad=0.0017738965107128024, Depth Loss=0.0000000]
Training progress:  92%|█████████▏| 1830/2000 [16:43<02:12,  1.29it/s, Loss=19.5650669, Gaussian number=16401254, print grad=0.0026192781515419483, Depth Loss=0.0000000]
Training progress:  92%|█████████▏| 1840/2000 [16:43<02:05,  1.28it/s, Loss=19.5650669, Gaussian number=16401254, print grad=0.0026192781515419483, Depth Loss=0.0000000]
Training progress:  92%|█████████▏| 1840/2000 [16:51<02:05,  1.28it/s, Loss=20.7106282, Gaussian number=16401254, print grad=0.0033616023138165474, Depth Loss=0.0000000]
Training progress:  92%|█████████▎| 1850/2000 [16:51<01:57,  1.27it/s, Loss=20.7106282, Gaussian number=16401254, print grad=0.0033616023138165474, Depth Loss=0.0000000]
Training progress:  92%|█████████▎| 1850/2000 [16:58<01:57,  1.27it/s, Loss=22.5723446, Gaussian number=16401254, print grad=0.0041551366448402405, Depth Loss=0.0000000]
Training progress:  93%|█████████▎| 1860/2000 [16:58<01:49,  1.27it/s, Loss=22.5723446, Gaussian number=16401254, print grad=0.0041551366448402405, Depth Loss=0.0000000]
Training progress:  93%|█████████▎| 1860/2000 [17:06<01:49,  1.27it/s, Loss=27.2526999, Gaussian number=16401254, print grad=0.004882395267486572, Depth Loss=0.0000000] 
Training progress:  94%|█████████▎| 1870/2000 [17:06<01:42,  1.27it/s, Loss=27.2526999, Gaussian number=16401254, print grad=0.004882395267486572, Depth Loss=0.0000000]
Training progress:  94%|█████████▎| 1870/2000 [17:14<01:42,  1.27it/s, Loss=22.9456920, Gaussian number=16401254, print grad=0.005759004037827253, Depth Loss=0.0000000]
Training progress:  94%|█████████▍| 1880/2000 [17:14<01:34,  1.27it/s, Loss=22.9456920, Gaussian number=16401254, print grad=0.005759004037827253, Depth Loss=0.0000000]
Training progress:  94%|█████████▍| 1880/2000 [17:22<01:34,  1.27it/s, Loss=23.1433386, Gaussian number=16401254, print grad=0.006633483339101076, Depth Loss=0.0000000]
Training progress:  94%|█████████▍| 1890/2000 [17:22<01:26,  1.27it/s, Loss=23.1433386, Gaussian number=16401254, print grad=0.006633483339101076, Depth Loss=0.0000000]
Training progress:  94%|█████████▍| 1890/2000 [17:30<01:26,  1.27it/s, Loss=23.6327718, Gaussian number=16401254, print grad=0.007231514900922775, Depth Loss=0.0000000]
Training progress:  95%|█████████▌| 1900/2000 [17:30<01:18,  1.27it/s, Loss=23.6327718, Gaussian number=16401254, print grad=0.007231514900922775, Depth Loss=0.0000000]
Training progress:  95%|█████████▌| 1900/2000 [17:39<01:18,  1.27it/s, Loss=21.4934014, Gaussian number=18013715, print grad=0.00037999110645614564, Depth Loss=0.0000000]
Training progress:  96%|█████████▌| 1910/2000 [17:39<01:13,  1.22it/s, Loss=21.4934014, Gaussian number=18013715, print grad=0.00037999110645614564, Depth Loss=0.0000000]
Training progress:  96%|█████████▌| 1910/2000 [17:47<01:13,  1.22it/s, Loss=22.1920774, Gaussian number=18013715, print grad=0.00086150475544855, Depth Loss=0.0000000]   
Training progress:  96%|█████████▌| 1920/2000 [17:47<01:05,  1.22it/s, Loss=22.1920774, Gaussian number=18013715, print grad=0.00086150475544855, Depth Loss=0.0000000]
Training progress:  96%|█████████▌| 1920/2000 [17:55<01:05,  1.22it/s, Loss=20.8701028, Gaussian number=18013715, print grad=0.001379626919515431, Depth Loss=0.0000000]
Training progress:  96%|█████████▋| 1930/2000 [17:55<00:57,  1.22it/s, Loss=20.8701028, Gaussian number=18013715, print grad=0.001379626919515431, Depth Loss=0.0000000]
Training progress:  96%|█████████▋| 1930/2000 [18:04<00:57,  1.22it/s, Loss=23.0039103, Gaussian number=18013715, print grad=0.0020125340670347214, Depth Loss=0.0000000]
Training progress:  97%|█████████▋| 1940/2000 [18:04<00:49,  1.22it/s, Loss=23.0039103, Gaussian number=18013715, print grad=0.0020125340670347214, Depth Loss=0.0000000]
Training progress:  97%|█████████▋| 1940/2000 [18:12<00:49,  1.22it/s, Loss=22.2705755, Gaussian number=18013715, print grad=0.002649629022926092, Depth Loss=0.0000000] 
Training progress:  98%|█████████▊| 1950/2000 [18:12<00:40,  1.23it/s, Loss=22.2705755, Gaussian number=18013715, print grad=0.002649629022926092, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1950/2000 [18:20<00:40,  1.23it/s, Loss=24.4039084, Gaussian number=18013715, print grad=0.003282537218183279, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1960/2000 [18:20<00:32,  1.23it/s, Loss=24.4039084, Gaussian number=18013715, print grad=0.003282537218183279, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1960/2000 [18:28<00:32,  1.23it/s, Loss=24.3246872, Gaussian number=18013715, print grad=0.003701907116919756, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1970/2000 [18:28<00:24,  1.23it/s, Loss=24.3246872, Gaussian number=18013715, print grad=0.003701907116919756, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1970/2000 [18:36<00:24,  1.23it/s, Loss=24.2973204, Gaussian number=18013715, print grad=0.004315837286412716, Depth Loss=0.0000000]
Training progress:  99%|█████████▉| 1980/2000 [18:36<00:16,  1.23it/s, Loss=24.2973204, Gaussian number=18013715, print grad=0.004315837286412716, Depth Loss=0.0000000]
Training progress:  99%|█████████▉| 1980/2000 [18:44<00:16,  1.23it/s, Loss=23.3866124, Gaussian number=18013715, print grad=0.004658425226807594, Depth Loss=0.0000000]
Training progress: 100%|█████████▉| 1990/2000 [18:44<00:08,  1.23it/s, Loss=23.3866124, Gaussian number=18013715, print grad=0.004658425226807594, Depth Loss=0.0000000]
Training progress: 100%|█████████▉| 1990/2000 [18:52<00:08,  1.23it/s, Loss=19.0229501, Gaussian number=18013715, print grad=0.005397787317633629, Depth Loss=0.0000000]
Training progress: 100%|██████████| 2000/2000 [18:52<00:00,  1.23it/s, Loss=19.0229501, Gaussian number=18013715, print grad=0.005397787317633629, Depth Loss=0.0000000]
Training progress: 100%|██████████| 2000/2000 [18:52<00:00,  1.77it/s, Loss=19.0229501, Gaussian number=18013715, print grad=0.005397787317633629, Depth Loss=0.0000000]
