Optimizing /home/cw4287/gaussian-model/train1
Output folder: /home/cw4287/gaussian-model/train1 [15/11 00:23:34]
Tensorboard not available: not logging progress [15/11 00:23:34]
------------LLFF HOLD------------- [15/11 00:23:36]

Reading camera 1/301
Reading camera 2/301
Reading camera 3/301
Reading camera 4/301
Reading camera 5/301
Reading camera 6/301
Reading camera 7/301
Reading camera 8/301
Reading camera 9/301
Reading camera 10/301
Reading camera 11/301
Reading camera 12/301
Reading camera 13/301
Reading camera 14/301
Reading camera 15/301
Reading camera 16/301
Reading camera 17/301
Reading camera 18/301
Reading camera 19/301
Reading camera 20/301
Reading camera 21/301
Reading camera 22/301
Reading camera 23/301
Reading camera 24/301
Reading camera 25/301
Reading camera 26/301
Reading camera 27/301
Reading camera 28/301
Reading camera 29/301
Reading camera 30/301
Reading camera 31/301
Reading camera 32/301
Reading camera 33/301
Reading camera 34/301
Reading camera 35/301
Reading camera 36/301
Reading camera 37/301
Reading camera 38/301
Reading camera 39/301
Reading camera 40/301
Reading camera 41/301
Reading camera 42/301
Reading camera 43/301
Reading camera 44/301
Reading camera 45/301
Reading camera 46/301
Reading camera 47/301
Reading camera 48/301
Reading camera 49/301
Reading camera 50/301
Reading camera 51/301
Reading camera 52/301
Reading camera 53/301
Reading camera 54/301
Reading camera 55/301
Reading camera 56/301
Reading camera 57/301
Reading camera 58/301
Reading camera 59/301
Reading camera 60/301
Reading camera 61/301
Reading camera 62/301
Reading camera 63/301
Reading camera 64/301
Reading camera 65/301
Reading camera 66/301
Reading camera 67/301
Reading camera 68/301
Reading camera 69/301
Reading camera 70/301
Reading camera 71/301
Reading camera 72/301
Reading camera 73/301
Reading camera 74/301
Reading camera 75/301
Reading camera 76/301
Reading camera 77/301
Reading camera 78/301
Reading camera 79/301
Reading camera 80/301
Reading camera 81/301
Reading camera 82/301
Reading camera 83/301
Reading camera 84/301
Reading camera 85/301
Reading camera 86/301
Reading camera 87/301
Reading camera 88/301
Reading camera 89/301
Reading camera 90/301
Reading camera 91/301
Reading camera 92/301
Reading camera 93/301
Reading camera 94/301
Reading camera 95/301
Reading camera 96/301
Reading camera 97/301
Reading camera 98/301
Reading camera 99/301
Reading camera 100/301
Reading camera 101/301
Reading camera 102/301
Reading camera 103/301
Reading camera 104/301
Reading camera 105/301
Reading camera 106/301
Reading camera 107/301
Reading camera 108/301
Reading camera 109/301
Reading camera 110/301
Reading camera 111/301
Reading camera 112/301
Reading camera 113/301
Reading camera 114/301
Reading camera 115/301
Reading camera 116/301
Reading camera 117/301
Reading camera 118/301
Reading camera 119/301
Reading camera 120/301
Reading camera 121/301
Reading camera 122/301
Reading camera 123/301
Reading camera 124/301
Reading camera 125/301
Reading camera 126/301
Reading camera 127/301
Reading camera 128/301
Reading camera 129/301
Reading camera 130/301
Reading camera 131/301
Reading camera 132/301
Reading camera 133/301
Reading camera 134/301
Reading camera 135/301
Reading camera 136/301
Reading camera 137/301
Reading camera 138/301
Reading camera 139/301
Reading camera 140/301
Reading camera 141/301
Reading camera 142/301
Reading camera 143/301
Reading camera 144/301
Reading camera 145/301
Reading camera 146/301
Reading camera 147/301
Reading camera 148/301
Reading camera 149/301
Reading camera 150/301
Reading camera 151/301
Reading camera 152/301
Reading camera 153/301
Reading camera 154/301
Reading camera 155/301
Reading camera 156/301
Reading camera 157/301
Reading camera 158/301
Reading camera 159/301
Reading camera 160/301
Reading camera 161/301
Reading camera 162/301
Reading camera 163/301
Reading camera 164/301
Reading camera 165/301
Reading camera 166/301
Reading camera 167/301
Reading camera 168/301
Reading camera 169/301
Reading camera 170/301
Reading camera 171/301
Reading camera 172/301
Reading camera 173/301
Reading camera 174/301
Reading camera 175/301
Reading camera 176/301
Reading camera 177/301
Reading camera 178/301
Reading camera 179/301
Reading camera 180/301
Reading camera 181/301
Reading camera 182/301
Reading camera 183/301
Reading camera 184/301
Reading camera 185/301
Reading camera 186/301
Reading camera 187/301
Reading camera 188/301
Reading camera 189/301
Reading camera 190/301
Reading camera 191/301
Reading camera 192/301
Reading camera 193/301
Reading camera 194/301
Reading camera 195/301
Reading camera 196/301
Reading camera 197/301
Reading camera 198/301
Reading camera 199/301
Reading camera 200/301
Reading camera 201/301
Reading camera 202/301
Reading camera 203/301
Reading camera 204/301
Reading camera 205/301
Reading camera 206/301
Reading camera 207/301
Reading camera 208/301
Reading camera 209/301
Reading camera 210/301
Reading camera 211/301
Reading camera 212/301
Reading camera 213/301
Reading camera 214/301
Reading camera 215/301
Reading camera 216/301
Reading camera 217/301
Reading camera 218/301
Reading camera 219/301
Reading camera 220/301
Reading camera 221/301
Reading camera 222/301
Reading camera 223/301
Reading camera 224/301
Reading camera 225/301
Reading camera 226/301
Reading camera 227/301
Reading camera 228/301
Reading camera 229/301
Reading camera 230/301
Reading camera 231/301
Reading camera 232/301
Reading camera 233/301
Reading camera 234/301
Reading camera 235/301
Reading camera 236/301
Reading camera 237/301
Reading camera 238/301
Reading camera 239/301
Reading camera 240/301
Reading camera 241/301
Reading camera 242/301
Reading camera 243/301
Reading camera 244/301
Reading camera 245/301
Reading camera 246/301
Reading camera 247/301
Reading camera 248/301
Reading camera 249/301
Reading camera 250/301
Reading camera 251/301
Reading camera 252/301
Reading camera 253/301
Reading camera 254/301
Reading camera 255/301
Reading camera 256/301
Reading camera 257/301
Reading camera 258/301
Reading camera 259/301
Reading camera 260/301
Reading camera 261/301
Reading camera 262/301
Reading camera 263/301
Reading camera 264/301
Reading camera 265/301
Reading camera 266/301
Reading camera 267/301
Reading camera 268/301
Reading camera 269/301
Reading camera 270/301
Reading camera 271/301
Reading camera 272/301
Reading camera 273/301
Reading camera 274/301
Reading camera 275/301
Reading camera 276/301
Reading camera 277/301
Reading camera 278/301
Reading camera 279/301
Reading camera 280/301
Reading camera 281/301
Reading camera 282/301
Reading camera 283/301
Reading camera 284/301
Reading camera 285/301
Reading camera 286/301
Reading camera 287/301
Reading camera 288/301
Reading camera 289/301
Reading camera 290/301
Reading camera 291/301
Reading camera 292/301
Reading camera 293/301
Reading camera 294/301
Reading camera 295/301
Reading camera 296/301
Reading camera 297/301
Reading camera 298/301
Reading camera 299/301
Reading camera 300/301
Reading camera 301/301 [15/11 00:23:36]
Loading Training Cameras [15/11 00:23:36]
Loading Test Cameras [15/11 00:23:48]
Number of points at initialisation :  182686 [15/11 00:23:49]

Training progress:   0%|          | 0/2000 [00:00<?, ?it/s]/ext3/conda/envs/3dgs/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/ext3/conda/envs/3dgs/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)

Training progress:   0%|          | 0/2000 [00:06<?, ?it/s, Loss=0.0237835, Gaussian number=182686, print grad=1.1354450180078857e-05, Depth Loss=0.0000000]
Training progress:   0%|          | 10/2000 [00:06<20:28,  1.62it/s, Loss=0.0237835, Gaussian number=182686, print grad=1.1354450180078857e-05, Depth Loss=0.0000000]
Training progress:   0%|          | 10/2000 [00:10<20:28,  1.62it/s, Loss=0.0223146, Gaussian number=182686, print grad=2.9375742087722756e-05, Depth Loss=0.0000000]
Training progress:   1%|          | 20/2000 [00:10<16:18,  2.02it/s, Loss=0.0223146, Gaussian number=182686, print grad=2.9375742087722756e-05, Depth Loss=0.0000000]
Training progress:   1%|          | 20/2000 [00:14<16:18,  2.02it/s, Loss=0.0221725, Gaussian number=182686, print grad=4.622025153366849e-05, Depth Loss=0.0000000] 
Training progress:   2%|▏         | 30/2000 [00:14<14:56,  2.20it/s, Loss=0.0221725, Gaussian number=182686, print grad=4.622025153366849e-05, Depth Loss=0.0000000]
Training progress:   2%|▏         | 30/2000 [00:18<14:56,  2.20it/s, Loss=0.0239453, Gaussian number=182686, print grad=6.381965067703277e-05, Depth Loss=0.0000000]
Training progress:   2%|▏         | 40/2000 [00:18<14:16,  2.29it/s, Loss=0.0239453, Gaussian number=182686, print grad=6.381965067703277e-05, Depth Loss=0.0000000]
Training progress:   2%|▏         | 40/2000 [00:22<14:16,  2.29it/s, Loss=0.0183354, Gaussian number=182686, print grad=7.809481030562893e-05, Depth Loss=0.0000000]
Training progress:   2%|▎         | 50/2000 [00:22<13:50,  2.35it/s, Loss=0.0183354, Gaussian number=182686, print grad=7.809481030562893e-05, Depth Loss=0.0000000]
Training progress:   2%|▎         | 50/2000 [00:26<13:50,  2.35it/s, Loss=0.0203890, Gaussian number=182686, print grad=9.8836884717457e-05, Depth Loss=0.0000000]  
Training progress:   3%|▎         | 60/2000 [00:26<13:32,  2.39it/s, Loss=0.0203890, Gaussian number=182686, print grad=9.8836884717457e-05, Depth Loss=0.0000000]
Training progress:   3%|▎         | 60/2000 [00:30<13:32,  2.39it/s, Loss=0.0182812, Gaussian number=182686, print grad=0.00012492558744270355, Depth Loss=0.0000000]
Training progress:   4%|▎         | 70/2000 [00:30<13:20,  2.41it/s, Loss=0.0182812, Gaussian number=182686, print grad=0.00012492558744270355, Depth Loss=0.0000000]
Training progress:   4%|▎         | 70/2000 [00:34<13:20,  2.41it/s, Loss=0.0223557, Gaussian number=182686, print grad=0.00014547300816047937, Depth Loss=0.0000000]
Training progress:   4%|▍         | 80/2000 [00:34<13:12,  2.42it/s, Loss=0.0223557, Gaussian number=182686, print grad=0.00014547300816047937, Depth Loss=0.0000000]
Training progress:   4%|▍         | 80/2000 [00:38<13:12,  2.42it/s, Loss=0.0188545, Gaussian number=182686, print grad=0.00016662450798321515, Depth Loss=0.0000000]
Training progress:   4%|▍         | 90/2000 [00:38<13:04,  2.44it/s, Loss=0.0188545, Gaussian number=182686, print grad=0.00016662450798321515, Depth Loss=0.0000000]
Training progress:   4%|▍         | 90/2000 [00:42<13:04,  2.44it/s, Loss=0.0184462, Gaussian number=182686, print grad=0.0001917569898068905, Depth Loss=0.0000000] 
Training progress:   5%|▌         | 100/2000 [00:42<13:03,  2.43it/s, Loss=0.0184462, Gaussian number=182686, print grad=0.0001917569898068905, Depth Loss=0.0000000]
Training progress:   5%|▌         | 100/2000 [00:53<13:03,  2.43it/s, Loss=0.0213295, Gaussian number=182686, print grad=0.00021902700245846063, Depth Loss=0.0000000]
Training progress:   6%|▌         | 110/2000 [00:53<18:46,  1.68it/s, Loss=0.0213295, Gaussian number=182686, print grad=0.00021902700245846063, Depth Loss=0.0000000]
Training progress:   6%|▌         | 110/2000 [00:57<18:46,  1.68it/s, Loss=0.0178360, Gaussian number=182686, print grad=0.00024489787756465375, Depth Loss=0.0000000]
Training progress:   6%|▌         | 120/2000 [00:57<16:52,  1.86it/s, Loss=0.0178360, Gaussian number=182686, print grad=0.00024489787756465375, Depth Loss=0.0000000]
Training progress:   6%|▌         | 120/2000 [01:01<16:52,  1.86it/s, Loss=0.0204097, Gaussian number=182686, print grad=0.0002772133448161185, Depth Loss=0.0000000] 
Training progress:   6%|▋         | 130/2000 [01:01<15:32,  2.01it/s, Loss=0.0204097, Gaussian number=182686, print grad=0.0002772133448161185, Depth Loss=0.0000000]
Training progress:   6%|▋         | 130/2000 [01:05<15:32,  2.01it/s, Loss=0.0186781, Gaussian number=182686, print grad=0.00030969982617534697, Depth Loss=0.0000000]
Training progress:   7%|▋         | 140/2000 [01:05<14:36,  2.12it/s, Loss=0.0186781, Gaussian number=182686, print grad=0.00030969982617534697, Depth Loss=0.0000000]
Training progress:   7%|▋         | 140/2000 [01:09<14:36,  2.12it/s, Loss=0.0164902, Gaussian number=182686, print grad=0.0003390093916095793, Depth Loss=0.0000000] 
Training progress:   8%|▊         | 150/2000 [01:09<13:56,  2.21it/s, Loss=0.0164902, Gaussian number=182686, print grad=0.0003390093916095793, Depth Loss=0.0000000]
Training progress:   8%|▊         | 150/2000 [01:13<13:56,  2.21it/s, Loss=0.0174028, Gaussian number=182686, print grad=0.000375650473870337, Depth Loss=0.0000000] 
Training progress:   8%|▊         | 160/2000 [01:13<13:25,  2.29it/s, Loss=0.0174028, Gaussian number=182686, print grad=0.000375650473870337, Depth Loss=0.0000000]
Training progress:   8%|▊         | 160/2000 [01:17<13:25,  2.29it/s, Loss=0.0172661, Gaussian number=182686, print grad=0.0004048397531732917, Depth Loss=0.0000000]
Training progress:   8%|▊         | 170/2000 [01:17<13:03,  2.33it/s, Loss=0.0172661, Gaussian number=182686, print grad=0.0004048397531732917, Depth Loss=0.0000000]
Training progress:   8%|▊         | 170/2000 [01:21<13:03,  2.33it/s, Loss=0.0148261, Gaussian number=182686, print grad=0.0004383363120723516, Depth Loss=0.0000000]
Training progress:   9%|▉         | 180/2000 [01:21<12:47,  2.37it/s, Loss=0.0148261, Gaussian number=182686, print grad=0.0004383363120723516, Depth Loss=0.0000000]
Training progress:   9%|▉         | 180/2000 [01:25<12:47,  2.37it/s, Loss=0.0191526, Gaussian number=182686, print grad=0.0004673963994719088, Depth Loss=0.0000000]
Training progress:  10%|▉         | 190/2000 [01:25<12:34,  2.40it/s, Loss=0.0191526, Gaussian number=182686, print grad=0.0004673963994719088, Depth Loss=0.0000000]
Training progress:  10%|▉         | 190/2000 [01:29<12:34,  2.40it/s, Loss=0.0166119, Gaussian number=182686, print grad=0.000503451912663877, Depth Loss=0.0000000] 
Training progress:  10%|█         | 200/2000 [01:29<12:23,  2.42it/s, Loss=0.0166119, Gaussian number=182686, print grad=0.000503451912663877, Depth Loss=0.0000000]
Training progress:  10%|█         | 200/2000 [01:39<12:23,  2.42it/s, Loss=0.0187556, Gaussian number=182686, print grad=0.0005398615030571818, Depth Loss=0.0000000]
Training progress:  10%|█         | 210/2000 [01:39<17:40,  1.69it/s, Loss=0.0187556, Gaussian number=182686, print grad=0.0005398615030571818, Depth Loss=0.0000000]
Training progress:  10%|█         | 210/2000 [01:43<17:40,  1.69it/s, Loss=0.0153050, Gaussian number=182686, print grad=0.0005726920790039003, Depth Loss=0.0000000]
Training progress:  11%|█         | 220/2000 [01:43<15:54,  1.87it/s, Loss=0.0153050, Gaussian number=182686, print grad=0.0005726920790039003, Depth Loss=0.0000000]
Training progress:  11%|█         | 220/2000 [01:47<15:54,  1.87it/s, Loss=0.0171148, Gaussian number=182686, print grad=0.0006070364615879953, Depth Loss=0.0000000]
Training progress:  12%|█▏        | 230/2000 [01:47<14:41,  2.01it/s, Loss=0.0171148, Gaussian number=182686, print grad=0.0006070364615879953, Depth Loss=0.0000000]
Training progress:  12%|█▏        | 230/2000 [01:51<14:41,  2.01it/s, Loss=0.0209746, Gaussian number=182686, print grad=0.0006394998054020107, Depth Loss=0.0000000]
Training progress:  12%|█▏        | 240/2000 [01:51<13:46,  2.13it/s, Loss=0.0209746, Gaussian number=182686, print grad=0.0006394998054020107, Depth Loss=0.0000000]
Training progress:  12%|█▏        | 240/2000 [01:55<13:46,  2.13it/s, Loss=0.0161947, Gaussian number=182686, print grad=0.0006753280758857727, Depth Loss=0.0000000]
Training progress:  12%|█▎        | 250/2000 [01:55<13:06,  2.23it/s, Loss=0.0161947, Gaussian number=182686, print grad=0.0006753280758857727, Depth Loss=0.0000000]
Training progress:  12%|█▎        | 250/2000 [01:59<13:06,  2.23it/s, Loss=0.0181872, Gaussian number=182686, print grad=0.0007089428836479783, Depth Loss=0.0000000]
Training progress:  13%|█▎        | 260/2000 [01:59<12:37,  2.30it/s, Loss=0.0181872, Gaussian number=182686, print grad=0.0007089428836479783, Depth Loss=0.0000000]
Training progress:  13%|█▎        | 260/2000 [02:03<12:37,  2.30it/s, Loss=0.0127838, Gaussian number=182686, print grad=0.000744280347134918, Depth Loss=0.0000000] 
Training progress:  14%|█▎        | 270/2000 [02:03<12:16,  2.35it/s, Loss=0.0127838, Gaussian number=182686, print grad=0.000744280347134918, Depth Loss=0.0000000]
Training progress:  14%|█▎        | 270/2000 [02:07<12:16,  2.35it/s, Loss=0.0164211, Gaussian number=182686, print grad=0.0007845647050999105, Depth Loss=0.0000000]
Training progress:  14%|█▍        | 280/2000 [02:07<11:59,  2.39it/s, Loss=0.0164211, Gaussian number=182686, print grad=0.0007845647050999105, Depth Loss=0.0000000]
Training progress:  14%|█▍        | 280/2000 [02:12<11:59,  2.39it/s, Loss=0.0168023, Gaussian number=182686, print grad=0.0008225982310250401, Depth Loss=0.0000000]
Training progress:  14%|█▍        | 290/2000 [02:12<11:49,  2.41it/s, Loss=0.0168023, Gaussian number=182686, print grad=0.0008225982310250401, Depth Loss=0.0000000]
Training progress:  14%|█▍        | 290/2000 [02:16<11:49,  2.41it/s, Loss=0.0156633, Gaussian number=182686, print grad=0.0008615225087851286, Depth Loss=0.0000000]
Training progress:  15%|█▌        | 300/2000 [02:16<11:40,  2.43it/s, Loss=0.0156633, Gaussian number=182686, print grad=0.0008615225087851286, Depth Loss=0.0000000]
Training progress:  15%|█▌        | 300/2000 [02:26<11:40,  2.43it/s, Loss=0.0130691, Gaussian number=182686, print grad=0.000902213912922889, Depth Loss=0.0000000] 
Training progress:  16%|█▌        | 310/2000 [02:26<16:38,  1.69it/s, Loss=0.0130691, Gaussian number=182686, print grad=0.000902213912922889, Depth Loss=0.0000000]
Training progress:  16%|█▌        | 310/2000 [02:30<16:38,  1.69it/s, Loss=0.0135737, Gaussian number=182686, print grad=0.0009315606439486146, Depth Loss=0.0000000]
Training progress:  16%|█▌        | 320/2000 [02:30<14:57,  1.87it/s, Loss=0.0135737, Gaussian number=182686, print grad=0.0009315606439486146, Depth Loss=0.0000000]
Training progress:  16%|█▌        | 320/2000 [02:34<14:57,  1.87it/s, Loss=0.0179008, Gaussian number=182686, print grad=0.0009666078258305788, Depth Loss=0.0000000]
Training progress:  16%|█▋        | 330/2000 [02:34<13:46,  2.02it/s, Loss=0.0179008, Gaussian number=182686, print grad=0.0009666078258305788, Depth Loss=0.0000000]
Training progress:  16%|█▋        | 330/2000 [02:38<13:46,  2.02it/s, Loss=0.0130070, Gaussian number=182686, print grad=0.0010064292000606656, Depth Loss=0.0000000]
Training progress:  17%|█▋        | 340/2000 [02:38<12:54,  2.14it/s, Loss=0.0130070, Gaussian number=182686, print grad=0.0010064292000606656, Depth Loss=0.0000000]
Training progress:  17%|█▋        | 340/2000 [02:42<12:54,  2.14it/s, Loss=0.0137500, Gaussian number=182686, print grad=0.0010439233155921102, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 350/2000 [02:42<12:17,  2.24it/s, Loss=0.0137500, Gaussian number=182686, print grad=0.0010439233155921102, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 350/2000 [02:46<12:17,  2.24it/s, Loss=0.0131582, Gaussian number=182686, print grad=0.0010885100346058607, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 360/2000 [02:46<11:50,  2.31it/s, Loss=0.0131582, Gaussian number=182686, print grad=0.0010885100346058607, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 360/2000 [02:50<11:50,  2.31it/s, Loss=0.0129259, Gaussian number=182686, print grad=0.0011278938036412, Depth Loss=0.0000000]   
Training progress:  18%|█▊        | 370/2000 [02:50<11:30,  2.36it/s, Loss=0.0129259, Gaussian number=182686, print grad=0.0011278938036412, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 370/2000 [02:54<11:30,  2.36it/s, Loss=0.0172895, Gaussian number=182686, print grad=0.001161098713055253, Depth Loss=0.0000000]
Training progress:  19%|█▉        | 380/2000 [02:54<11:14,  2.40it/s, Loss=0.0172895, Gaussian number=182686, print grad=0.001161098713055253, Depth Loss=0.0000000]
Training progress:  19%|█▉        | 380/2000 [02:58<11:14,  2.40it/s, Loss=0.0153603, Gaussian number=182686, print grad=0.0012018397683277726, Depth Loss=0.0000000]
Training progress:  20%|█▉        | 390/2000 [02:58<11:03,  2.43it/s, Loss=0.0153603, Gaussian number=182686, print grad=0.0012018397683277726, Depth Loss=0.0000000]
Training progress:  20%|█▉        | 390/2000 [03:02<11:03,  2.43it/s, Loss=0.0183304, Gaussian number=182686, print grad=0.0012400998966768384, Depth Loss=0.0000000]
Training progress:  20%|██        | 400/2000 [03:02<10:53,  2.45it/s, Loss=0.0183304, Gaussian number=182686, print grad=0.0012400998966768384, Depth Loss=0.0000000]
Training progress:  20%|██        | 400/2000 [03:12<10:53,  2.45it/s, Loss=0.0156310, Gaussian number=182686, print grad=0.001285556354559958, Depth Loss=0.0000000] 
Training progress:  20%|██        | 410/2000 [03:12<15:37,  1.70it/s, Loss=0.0156310, Gaussian number=182686, print grad=0.001285556354559958, Depth Loss=0.0000000]
Training progress:  20%|██        | 410/2000 [03:16<15:37,  1.70it/s, Loss=0.0139781, Gaussian number=182686, print grad=0.0013284003362059593, Depth Loss=0.0000000]
Training progress:  21%|██        | 420/2000 [03:16<14:03,  1.87it/s, Loss=0.0139781, Gaussian number=182686, print grad=0.0013284003362059593, Depth Loss=0.0000000]
Training progress:  21%|██        | 420/2000 [03:20<14:03,  1.87it/s, Loss=0.0175632, Gaussian number=182686, print grad=0.0013725240714848042, Depth Loss=0.0000000]
Training progress:  22%|██▏       | 430/2000 [03:20<12:55,  2.02it/s, Loss=0.0175632, Gaussian number=182686, print grad=0.0013725240714848042, Depth Loss=0.0000000]
Training progress:  22%|██▏       | 430/2000 [03:24<12:55,  2.02it/s, Loss=0.0136698, Gaussian number=182686, print grad=0.001413868274539709, Depth Loss=0.0000000] 
Training progress:  22%|██▏       | 440/2000 [03:24<12:09,  2.14it/s, Loss=0.0136698, Gaussian number=182686, print grad=0.001413868274539709, Depth Loss=0.0000000]
Training progress:  22%|██▏       | 440/2000 [03:28<12:09,  2.14it/s, Loss=0.0157781, Gaussian number=182686, print grad=0.0014569088816642761, Depth Loss=0.0000000]
Training progress:  22%|██▎       | 450/2000 [03:28<11:34,  2.23it/s, Loss=0.0157781, Gaussian number=182686, print grad=0.0014569088816642761, Depth Loss=0.0000000]
Training progress:  22%|██▎       | 450/2000 [03:32<11:34,  2.23it/s, Loss=0.0162974, Gaussian number=182686, print grad=0.0014988358598202467, Depth Loss=0.0000000]
Training progress:  23%|██▎       | 460/2000 [03:32<11:10,  2.30it/s, Loss=0.0162974, Gaussian number=182686, print grad=0.0014988358598202467, Depth Loss=0.0000000]
Training progress:  23%|██▎       | 460/2000 [03:36<11:10,  2.30it/s, Loss=0.0193145, Gaussian number=182686, print grad=0.0015386122977361083, Depth Loss=0.0000000]
Training progress:  24%|██▎       | 470/2000 [03:36<10:51,  2.35it/s, Loss=0.0193145, Gaussian number=182686, print grad=0.0015386122977361083, Depth Loss=0.0000000]
Training progress:  24%|██▎       | 470/2000 [03:40<10:51,  2.35it/s, Loss=0.0125499, Gaussian number=182686, print grad=0.001583864213898778, Depth Loss=0.0000000] 
Training progress:  24%|██▍       | 480/2000 [03:40<10:36,  2.39it/s, Loss=0.0125499, Gaussian number=182686, print grad=0.001583864213898778, Depth Loss=0.0000000]
Training progress:  24%|██▍       | 480/2000 [03:44<10:36,  2.39it/s, Loss=0.0139225, Gaussian number=182686, print grad=0.0016249489272013307, Depth Loss=0.0000000]
Training progress:  24%|██▍       | 490/2000 [03:44<10:24,  2.42it/s, Loss=0.0139225, Gaussian number=182686, print grad=0.0016249489272013307, Depth Loss=0.0000000]
Training progress:  24%|██▍       | 490/2000 [03:48<10:24,  2.42it/s, Loss=0.0109344, Gaussian number=182686, print grad=0.0016669129254296422, Depth Loss=0.0000000]
Training progress:  25%|██▌       | 500/2000 [03:48<10:15,  2.44it/s, Loss=0.0109344, Gaussian number=182686, print grad=0.0016669129254296422, Depth Loss=0.0000000]
Training progress:  25%|██▌       | 500/2000 [03:58<10:15,  2.44it/s, Loss=0.0129587, Gaussian number=182686, print grad=0.0017092495691031218, Depth Loss=0.0000000]
Training progress:  26%|██▌       | 510/2000 [03:58<14:39,  1.69it/s, Loss=0.0129587, Gaussian number=182686, print grad=0.0017092495691031218, Depth Loss=0.0000000]
Training progress:  26%|██▌       | 510/2000 [04:02<14:39,  1.69it/s, Loss=0.0132272, Gaussian number=182686, print grad=0.0017538027605041862, Depth Loss=0.0000000]
Training progress:  26%|██▌       | 520/2000 [04:02<13:10,  1.87it/s, Loss=0.0132272, Gaussian number=182686, print grad=0.0017538027605041862, Depth Loss=0.0000000]
Training progress:  26%|██▌       | 520/2000 [04:06<13:10,  1.87it/s, Loss=0.0104696, Gaussian number=182686, print grad=0.0017923706909641623, Depth Loss=0.0000000]
Training progress:  26%|██▋       | 530/2000 [04:06<12:05,  2.03it/s, Loss=0.0104696, Gaussian number=182686, print grad=0.0017923706909641623, Depth Loss=0.0000000]
Training progress:  26%|██▋       | 530/2000 [04:10<12:05,  2.03it/s, Loss=0.0141736, Gaussian number=182686, print grad=0.0018347848672419786, Depth Loss=0.0000000]
Training progress:  27%|██▋       | 540/2000 [04:10<11:18,  2.15it/s, Loss=0.0141736, Gaussian number=182686, print grad=0.0018347848672419786, Depth Loss=0.0000000]
Training progress:  27%|██▋       | 540/2000 [04:14<11:18,  2.15it/s, Loss=0.0135242, Gaussian number=182686, print grad=0.0018801687983796, Depth Loss=0.0000000]   
Training progress:  28%|██▊       | 550/2000 [04:14<10:45,  2.25it/s, Loss=0.0135242, Gaussian number=182686, print grad=0.0018801687983796, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 550/2000 [04:18<10:45,  2.25it/s, Loss=0.0108072, Gaussian number=182686, print grad=0.0019219592213630676, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 560/2000 [04:18<10:21,  2.32it/s, Loss=0.0108072, Gaussian number=182686, print grad=0.0019219592213630676, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 560/2000 [04:22<10:21,  2.32it/s, Loss=0.0144116, Gaussian number=182686, print grad=0.0019687486346811056, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 570/2000 [04:22<10:03,  2.37it/s, Loss=0.0144116, Gaussian number=182686, print grad=0.0019687486346811056, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 570/2000 [04:26<10:03,  2.37it/s, Loss=0.0124877, Gaussian number=182686, print grad=0.0020121398847550154, Depth Loss=0.0000000]
Training progress:  29%|██▉       | 580/2000 [04:26<09:49,  2.41it/s, Loss=0.0124877, Gaussian number=182686, print grad=0.0020121398847550154, Depth Loss=0.0000000]
Training progress:  29%|██▉       | 580/2000 [04:30<09:49,  2.41it/s, Loss=0.0143749, Gaussian number=182686, print grad=0.002057170495390892, Depth Loss=0.0000000] 
Training progress:  30%|██▉       | 590/2000 [04:30<09:39,  2.44it/s, Loss=0.0143749, Gaussian number=182686, print grad=0.002057170495390892, Depth Loss=0.0000000]
Training progress:  30%|██▉       | 590/2000 [04:34<09:39,  2.44it/s, Loss=0.0143782, Gaussian number=182686, print grad=0.0020988613832741976, Depth Loss=0.0000000]
Training progress:  30%|███       | 600/2000 [04:34<09:29,  2.46it/s, Loss=0.0143782, Gaussian number=182686, print grad=0.0020988613832741976, Depth Loss=0.0000000]
Training progress:  30%|███       | 600/2000 [04:44<09:29,  2.46it/s, Loss=0.0119339, Gaussian number=182702, print grad=4.003831054433249e-05, Depth Loss=0.0000000]
Training progress:  30%|███       | 610/2000 [04:44<13:35,  1.71it/s, Loss=0.0119339, Gaussian number=182702, print grad=4.003831054433249e-05, Depth Loss=0.0000000]
Training progress:  30%|███       | 610/2000 [04:48<13:35,  1.71it/s, Loss=0.0158380, Gaussian number=182702, print grad=8.642291504656896e-05, Depth Loss=0.0000000]
Training progress:  31%|███       | 620/2000 [04:48<12:11,  1.89it/s, Loss=0.0158380, Gaussian number=182702, print grad=8.642291504656896e-05, Depth Loss=0.0000000]
Training progress:  31%|███       | 620/2000 [04:52<12:11,  1.89it/s, Loss=0.0112574, Gaussian number=182702, print grad=0.00012732893810607493, Depth Loss=0.0000000]
Training progress:  32%|███▏      | 630/2000 [04:52<11:14,  2.03it/s, Loss=0.0112574, Gaussian number=182702, print grad=0.00012732893810607493, Depth Loss=0.0000000]
Training progress:  32%|███▏      | 630/2000 [04:56<11:14,  2.03it/s, Loss=0.0121596, Gaussian number=182702, print grad=0.00017756618035491556, Depth Loss=0.0000000]
Training progress:  32%|███▏      | 640/2000 [04:56<10:31,  2.15it/s, Loss=0.0121596, Gaussian number=182702, print grad=0.00017756618035491556, Depth Loss=0.0000000]
Training progress:  32%|███▏      | 640/2000 [05:00<10:31,  2.15it/s, Loss=0.0143256, Gaussian number=182702, print grad=0.00021758038201369345, Depth Loss=0.0000000]
Training progress:  32%|███▎      | 650/2000 [05:00<10:00,  2.25it/s, Loss=0.0143256, Gaussian number=182702, print grad=0.00021758038201369345, Depth Loss=0.0000000]
Training progress:  32%|███▎      | 650/2000 [05:04<10:00,  2.25it/s, Loss=0.0146131, Gaussian number=182702, print grad=0.00026596023235470057, Depth Loss=0.0000000]
Training progress:  33%|███▎      | 660/2000 [05:04<09:37,  2.32it/s, Loss=0.0146131, Gaussian number=182702, print grad=0.00026596023235470057, Depth Loss=0.0000000]
Training progress:  33%|███▎      | 660/2000 [05:08<09:37,  2.32it/s, Loss=0.0126954, Gaussian number=182702, print grad=0.0003094626881647855, Depth Loss=0.0000000] 
Training progress:  34%|███▎      | 670/2000 [05:08<09:20,  2.37it/s, Loss=0.0126954, Gaussian number=182702, print grad=0.0003094626881647855, Depth Loss=0.0000000]
Training progress:  34%|███▎      | 670/2000 [05:12<09:20,  2.37it/s, Loss=0.0119352, Gaussian number=182702, print grad=0.0003581719647627324, Depth Loss=0.0000000]
Training progress:  34%|███▍      | 680/2000 [05:12<09:07,  2.41it/s, Loss=0.0119352, Gaussian number=182702, print grad=0.0003581719647627324, Depth Loss=0.0000000]
Training progress:  34%|███▍      | 680/2000 [05:16<09:07,  2.41it/s, Loss=0.0140058, Gaussian number=182702, print grad=0.00040264002745971084, Depth Loss=0.0000000]
Training progress:  34%|███▍      | 690/2000 [05:16<08:56,  2.44it/s, Loss=0.0140058, Gaussian number=182702, print grad=0.00040264002745971084, Depth Loss=0.0000000]
Training progress:  34%|███▍      | 690/2000 [05:20<08:56,  2.44it/s, Loss=0.0139835, Gaussian number=182702, print grad=0.00044573136256076396, Depth Loss=0.0000000]
Training progress:  35%|███▌      | 700/2000 [05:20<08:48,  2.46it/s, Loss=0.0139835, Gaussian number=182702, print grad=0.00044573136256076396, Depth Loss=0.0000000]
Training progress:  35%|███▌      | 700/2000 [05:30<08:48,  2.46it/s, Loss=0.0123486, Gaussian number=182815, print grad=3.920838571502827e-05, Depth Loss=0.0000000] 
Training progress:  36%|███▌      | 710/2000 [05:30<12:35,  1.71it/s, Loss=0.0123486, Gaussian number=182815, print grad=3.920838571502827e-05, Depth Loss=0.0000000]
Training progress:  36%|███▌      | 710/2000 [05:34<12:35,  1.71it/s, Loss=0.0112578, Gaussian number=182815, print grad=8.367122063646093e-05, Depth Loss=0.0000000]
Training progress:  36%|███▌      | 720/2000 [05:34<11:18,  1.89it/s, Loss=0.0112578, Gaussian number=182815, print grad=8.367122063646093e-05, Depth Loss=0.0000000]
Training progress:  36%|███▌      | 720/2000 [05:38<11:18,  1.89it/s, Loss=0.0149119, Gaussian number=182815, print grad=0.00012582899944391102, Depth Loss=0.0000000]
Training progress:  36%|███▋      | 730/2000 [05:38<10:22,  2.04it/s, Loss=0.0149119, Gaussian number=182815, print grad=0.00012582899944391102, Depth Loss=0.0000000]
Training progress:  36%|███▋      | 730/2000 [05:42<10:22,  2.04it/s, Loss=0.0175944, Gaussian number=182815, print grad=0.00017570191994309425, Depth Loss=0.0000000]
Training progress:  37%|███▋      | 740/2000 [05:42<09:44,  2.16it/s, Loss=0.0175944, Gaussian number=182815, print grad=0.00017570191994309425, Depth Loss=0.0000000]
Training progress:  37%|███▋      | 740/2000 [05:46<09:44,  2.16it/s, Loss=0.0125473, Gaussian number=182815, print grad=0.00022265204461291432, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 750/2000 [05:46<09:16,  2.25it/s, Loss=0.0125473, Gaussian number=182815, print grad=0.00022265204461291432, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 750/2000 [05:50<09:16,  2.25it/s, Loss=0.0118706, Gaussian number=182815, print grad=0.00026699097361415625, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 760/2000 [05:50<08:54,  2.32it/s, Loss=0.0118706, Gaussian number=182815, print grad=0.00026699097361415625, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 760/2000 [05:54<08:54,  2.32it/s, Loss=0.0111549, Gaussian number=182815, print grad=0.0003151294367853552, Depth Loss=0.0000000] 
Training progress:  38%|███▊      | 770/2000 [05:54<08:37,  2.38it/s, Loss=0.0111549, Gaussian number=182815, print grad=0.0003151294367853552, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 770/2000 [05:58<08:37,  2.38it/s, Loss=0.0147428, Gaussian number=182815, print grad=0.0003587413812056184, Depth Loss=0.0000000]
Training progress:  39%|███▉      | 780/2000 [05:58<08:24,  2.42it/s, Loss=0.0147428, Gaussian number=182815, print grad=0.0003587413812056184, Depth Loss=0.0000000]
Training progress:  39%|███▉      | 780/2000 [06:02<08:24,  2.42it/s, Loss=0.0168750, Gaussian number=182815, print grad=0.00040385161992162466, Depth Loss=0.0000000]
Training progress:  40%|███▉      | 790/2000 [06:02<08:15,  2.44it/s, Loss=0.0168750, Gaussian number=182815, print grad=0.00040385161992162466, Depth Loss=0.0000000]
Training progress:  40%|███▉      | 790/2000 [06:06<08:15,  2.44it/s, Loss=0.0146024, Gaussian number=182815, print grad=0.0004523034440353513, Depth Loss=0.0000000] 
Training progress:  40%|████      | 800/2000 [06:06<08:08,  2.46it/s, Loss=0.0146024, Gaussian number=182815, print grad=0.0004523034440353513, Depth Loss=0.0000000]
Training progress:  40%|████      | 800/2000 [06:16<08:08,  2.46it/s, Loss=0.0138127, Gaussian number=182957, print grad=4.117707794648595e-05, Depth Loss=0.0000000]
Training progress:  40%|████      | 810/2000 [06:16<11:39,  1.70it/s, Loss=0.0138127, Gaussian number=182957, print grad=4.117707794648595e-05, Depth Loss=0.0000000]
Training progress:  40%|████      | 810/2000 [06:20<11:39,  1.70it/s, Loss=0.0135299, Gaussian number=182957, print grad=8.537465328117833e-05, Depth Loss=0.0000000]
Training progress:  41%|████      | 820/2000 [06:20<10:28,  1.88it/s, Loss=0.0135299, Gaussian number=182957, print grad=8.537465328117833e-05, Depth Loss=0.0000000]
Training progress:  41%|████      | 820/2000 [06:24<10:28,  1.88it/s, Loss=0.0106154, Gaussian number=182957, print grad=0.00013920692435931414, Depth Loss=0.0000000]
Training progress:  42%|████▏     | 830/2000 [06:24<09:35,  2.03it/s, Loss=0.0106154, Gaussian number=182957, print grad=0.00013920692435931414, Depth Loss=0.0000000]
Training progress:  42%|████▏     | 830/2000 [06:28<09:35,  2.03it/s, Loss=0.0116407, Gaussian number=182957, print grad=0.0001860161282820627, Depth Loss=0.0000000] 
Training progress:  42%|████▏     | 840/2000 [06:28<08:58,  2.15it/s, Loss=0.0116407, Gaussian number=182957, print grad=0.0001860161282820627, Depth Loss=0.0000000]
Training progress:  42%|████▏     | 840/2000 [06:32<08:58,  2.15it/s, Loss=0.0123243, Gaussian number=182957, print grad=0.00023511798644904047, Depth Loss=0.0000000]
Training progress:  42%|████▎     | 850/2000 [06:32<08:32,  2.25it/s, Loss=0.0123243, Gaussian number=182957, print grad=0.00023511798644904047, Depth Loss=0.0000000]
Training progress:  42%|████▎     | 850/2000 [06:36<08:32,  2.25it/s, Loss=0.0121758, Gaussian number=182957, print grad=0.000280185166047886, Depth Loss=0.0000000]  
Training progress:  43%|████▎     | 860/2000 [06:36<08:12,  2.32it/s, Loss=0.0121758, Gaussian number=182957, print grad=0.000280185166047886, Depth Loss=0.0000000]
Training progress:  43%|████▎     | 860/2000 [06:40<08:12,  2.32it/s, Loss=0.0144549, Gaussian number=182957, print grad=0.0003262853715568781, Depth Loss=0.0000000]
Training progress:  44%|████▎     | 870/2000 [06:40<07:56,  2.37it/s, Loss=0.0144549, Gaussian number=182957, print grad=0.0003262853715568781, Depth Loss=0.0000000]
Training progress:  44%|████▎     | 870/2000 [06:44<07:56,  2.37it/s, Loss=0.0133651, Gaussian number=182957, print grad=0.0003723782720044255, Depth Loss=0.0000000]
Training progress:  44%|████▍     | 880/2000 [06:44<07:44,  2.41it/s, Loss=0.0133651, Gaussian number=182957, print grad=0.0003723782720044255, Depth Loss=0.0000000]
Training progress:  44%|████▍     | 880/2000 [06:48<07:44,  2.41it/s, Loss=0.0107809, Gaussian number=182957, print grad=0.0004192800261080265, Depth Loss=0.0000000]
Training progress:  44%|████▍     | 890/2000 [06:48<07:35,  2.44it/s, Loss=0.0107809, Gaussian number=182957, print grad=0.0004192800261080265, Depth Loss=0.0000000]
Training progress:  44%|████▍     | 890/2000 [06:52<07:35,  2.44it/s, Loss=0.0138893, Gaussian number=182957, print grad=0.00046611728612333536, Depth Loss=0.0000000]
Training progress:  45%|████▌     | 900/2000 [06:52<07:27,  2.46it/s, Loss=0.0138893, Gaussian number=182957, print grad=0.00046611728612333536, Depth Loss=0.0000000]
Training progress:  45%|████▌     | 900/2000 [07:02<07:27,  2.46it/s, Loss=0.0106938, Gaussian number=183072, print grad=4.105715197511017e-05, Depth Loss=0.0000000] 
Training progress:  46%|████▌     | 910/2000 [07:02<10:38,  1.71it/s, Loss=0.0106938, Gaussian number=183072, print grad=4.105715197511017e-05, Depth Loss=0.0000000]
Training progress:  46%|████▌     | 910/2000 [07:06<10:38,  1.71it/s, Loss=0.0127602, Gaussian number=183072, print grad=8.122231520246714e-05, Depth Loss=0.0000000]
Training progress:  46%|████▌     | 920/2000 [07:06<09:31,  1.89it/s, Loss=0.0127602, Gaussian number=183072, print grad=8.122231520246714e-05, Depth Loss=0.0000000]
Training progress:  46%|████▌     | 920/2000 [07:10<09:31,  1.89it/s, Loss=0.0135561, Gaussian number=183072, print grad=0.000131524822791107, Depth Loss=0.0000000] 
Training progress:  46%|████▋     | 930/2000 [07:10<08:44,  2.04it/s, Loss=0.0135561, Gaussian number=183072, print grad=0.000131524822791107, Depth Loss=0.0000000]
Training progress:  46%|████▋     | 930/2000 [07:14<08:44,  2.04it/s, Loss=0.0121605, Gaussian number=183072, print grad=0.00017592970107216388, Depth Loss=0.0000000]
Training progress:  47%|████▋     | 940/2000 [07:14<08:10,  2.16it/s, Loss=0.0121605, Gaussian number=183072, print grad=0.00017592970107216388, Depth Loss=0.0000000]
Training progress:  47%|████▋     | 940/2000 [07:18<08:10,  2.16it/s, Loss=0.0118587, Gaussian number=183072, print grad=0.00022294220980256796, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 950/2000 [07:18<07:45,  2.26it/s, Loss=0.0118587, Gaussian number=183072, print grad=0.00022294220980256796, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 950/2000 [07:22<07:45,  2.26it/s, Loss=0.0121388, Gaussian number=183072, print grad=0.0002676294825505465, Depth Loss=0.0000000] 
Training progress:  48%|████▊     | 960/2000 [07:22<07:27,  2.32it/s, Loss=0.0121388, Gaussian number=183072, print grad=0.0002676294825505465, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 960/2000 [07:26<07:27,  2.32it/s, Loss=0.0157579, Gaussian number=183072, print grad=0.0003175665333401412, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 970/2000 [07:26<07:14,  2.37it/s, Loss=0.0157579, Gaussian number=183072, print grad=0.0003175665333401412, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 970/2000 [07:30<07:14,  2.37it/s, Loss=0.0103092, Gaussian number=183072, print grad=0.000365048908861354, Depth Loss=0.0000000] 
Training progress:  49%|████▉     | 980/2000 [07:30<07:02,  2.41it/s, Loss=0.0103092, Gaussian number=183072, print grad=0.000365048908861354, Depth Loss=0.0000000]
Training progress:  49%|████▉     | 980/2000 [07:34<07:02,  2.41it/s, Loss=0.0104714, Gaussian number=183072, print grad=0.00040667434222996235, Depth Loss=0.0000000]
Training progress:  50%|████▉     | 990/2000 [07:34<06:55,  2.43it/s, Loss=0.0104714, Gaussian number=183072, print grad=0.00040667434222996235, Depth Loss=0.0000000]
Training progress:  50%|████▉     | 990/2000 [07:38<06:55,  2.43it/s, Loss=0.0139353, Gaussian number=183072, print grad=0.00044676774996332824, Depth Loss=0.0000000]
Training progress:  50%|█████     | 1000/2000 [07:38<06:47,  2.46it/s, Loss=0.0139353, Gaussian number=183072, print grad=0.00044676774996332824, Depth Loss=0.0000000]
Training progress:  50%|█████     | 1000/2000 [07:48<06:47,  2.46it/s, Loss=0.0124860, Gaussian number=183222, print grad=3.9832619222579524e-05, Depth Loss=0.0000000]
Training progress:  50%|█████     | 1010/2000 [07:48<09:39,  1.71it/s, Loss=0.0124860, Gaussian number=183222, print grad=3.9832619222579524e-05, Depth Loss=0.0000000]
Training progress:  50%|█████     | 1010/2000 [07:52<09:39,  1.71it/s, Loss=0.0155580, Gaussian number=183222, print grad=9.328537998953834e-05, Depth Loss=0.0000000] 
Training progress:  51%|█████     | 1020/2000 [07:52<08:38,  1.89it/s, Loss=0.0155580, Gaussian number=183222, print grad=9.328537998953834e-05, Depth Loss=0.0000000]
Training progress:  51%|█████     | 1020/2000 [07:56<08:38,  1.89it/s, Loss=0.0126543, Gaussian number=183222, print grad=0.00014289650425780565, Depth Loss=0.0000000]
Training progress:  52%|█████▏    | 1030/2000 [07:56<07:54,  2.05it/s, Loss=0.0126543, Gaussian number=183222, print grad=0.00014289650425780565, Depth Loss=0.0000000]
Training progress:  52%|█████▏    | 1030/2000 [08:00<07:54,  2.05it/s, Loss=0.0133980, Gaussian number=183222, print grad=0.00019534083548933268, Depth Loss=0.0000000]
Training progress:  52%|█████▏    | 1040/2000 [08:00<07:22,  2.17it/s, Loss=0.0133980, Gaussian number=183222, print grad=0.00019534083548933268, Depth Loss=0.0000000]
Training progress:  52%|█████▏    | 1040/2000 [08:04<07:22,  2.17it/s, Loss=0.0121824, Gaussian number=183222, print grad=0.0002371928858337924, Depth Loss=0.0000000] 
Training progress:  52%|█████▎    | 1050/2000 [08:04<06:58,  2.27it/s, Loss=0.0121824, Gaussian number=183222, print grad=0.0002371928858337924, Depth Loss=0.0000000]
Training progress:  52%|█████▎    | 1050/2000 [08:08<06:58,  2.27it/s, Loss=0.0116363, Gaussian number=183222, print grad=0.0002832641766872257, Depth Loss=0.0000000]
Training progress:  53%|█████▎    | 1060/2000 [08:08<06:41,  2.34it/s, Loss=0.0116363, Gaussian number=183222, print grad=0.0002832641766872257, Depth Loss=0.0000000]
Training progress:  53%|█████▎    | 1060/2000 [08:12<06:41,  2.34it/s, Loss=0.0097158, Gaussian number=183222, print grad=0.00033567645004950464, Depth Loss=0.0000000]
Training progress:  54%|█████▎    | 1070/2000 [08:12<06:28,  2.39it/s, Loss=0.0097158, Gaussian number=183222, print grad=0.00033567645004950464, Depth Loss=0.0000000]
Training progress:  54%|█████▎    | 1070/2000 [08:16<06:28,  2.39it/s, Loss=0.0104951, Gaussian number=183222, print grad=0.0003810907364822924, Depth Loss=0.0000000] 
Training progress:  54%|█████▍    | 1080/2000 [08:16<06:18,  2.43it/s, Loss=0.0104951, Gaussian number=183222, print grad=0.0003810907364822924, Depth Loss=0.0000000]
Training progress:  54%|█████▍    | 1080/2000 [08:20<06:18,  2.43it/s, Loss=0.0133093, Gaussian number=183222, print grad=0.000429544918006286, Depth Loss=0.0000000] 
Training progress:  55%|█████▍    | 1090/2000 [08:20<06:10,  2.46it/s, Loss=0.0133093, Gaussian number=183222, print grad=0.000429544918006286, Depth Loss=0.0000000]
Training progress:  55%|█████▍    | 1090/2000 [08:24<06:10,  2.46it/s, Loss=0.0128212, Gaussian number=183222, print grad=0.0004767653881572187, Depth Loss=0.0000000]
Training progress:  55%|█████▌    | 1100/2000 [08:24<06:03,  2.48it/s, Loss=0.0128212, Gaussian number=183222, print grad=0.0004767653881572187, Depth Loss=0.0000000]
Training progress:  55%|█████▌    | 1100/2000 [08:28<06:03,  2.48it/s, Loss=0.0139024, Gaussian number=183388, print grad=4.2150062654400244e-05, Depth Loss=0.0000000]
Training progress:  56%|█████▌    | 1110/2000 [08:28<05:57,  2.49it/s, Loss=0.0139024, Gaussian number=183388, print grad=4.2150062654400244e-05, Depth Loss=0.0000000]
Training progress:  56%|█████▌    | 1110/2000 [08:32<05:57,  2.49it/s, Loss=0.0125705, Gaussian number=183388, print grad=9.312462498201057e-05, Depth Loss=0.0000000] 
Training progress:  56%|█████▌    | 1120/2000 [08:32<05:52,  2.50it/s, Loss=0.0125705, Gaussian number=183388, print grad=9.312462498201057e-05, Depth Loss=0.0000000]
Training progress:  56%|█████▌    | 1120/2000 [08:36<05:52,  2.50it/s, Loss=0.0101288, Gaussian number=183388, print grad=0.00014556836686097085, Depth Loss=0.0000000]
Training progress:  56%|█████▋    | 1130/2000 [08:36<05:47,  2.50it/s, Loss=0.0101288, Gaussian number=183388, print grad=0.00014556836686097085, Depth Loss=0.0000000]
Training progress:  56%|█████▋    | 1130/2000 [08:40<05:47,  2.50it/s, Loss=0.0126410, Gaussian number=183388, print grad=0.0001970478188013658, Depth Loss=0.0000000] 
Training progress:  57%|█████▋    | 1140/2000 [08:40<05:42,  2.51it/s, Loss=0.0126410, Gaussian number=183388, print grad=0.0001970478188013658, Depth Loss=0.0000000]
Training progress:  57%|█████▋    | 1140/2000 [08:44<05:42,  2.51it/s, Loss=0.0091015, Gaussian number=183388, print grad=0.0002466810110490769, Depth Loss=0.0000000]
Training progress:  57%|█████▊    | 1150/2000 [08:44<05:38,  2.51it/s, Loss=0.0091015, Gaussian number=183388, print grad=0.0002466810110490769, Depth Loss=0.0000000]
Training progress:  57%|█████▊    | 1150/2000 [08:48<05:38,  2.51it/s, Loss=0.0099318, Gaussian number=183388, print grad=0.0002899533719755709, Depth Loss=0.0000000]
Training progress:  58%|█████▊    | 1160/2000 [08:48<05:34,  2.51it/s, Loss=0.0099318, Gaussian number=183388, print grad=0.0002899533719755709, Depth Loss=0.0000000]
Training progress:  58%|█████▊    | 1160/2000 [08:52<05:34,  2.51it/s, Loss=0.0122590, Gaussian number=183388, print grad=0.00033810301101766527, Depth Loss=0.0000000]
Training progress:  58%|█████▊    | 1170/2000 [08:52<05:29,  2.52it/s, Loss=0.0122590, Gaussian number=183388, print grad=0.00033810301101766527, Depth Loss=0.0000000]
Training progress:  58%|█████▊    | 1170/2000 [08:56<05:29,  2.52it/s, Loss=0.0128155, Gaussian number=183388, print grad=0.0003872649685945362, Depth Loss=0.0000000] 
Training progress:  59%|█████▉    | 1180/2000 [08:56<05:25,  2.52it/s, Loss=0.0128155, Gaussian number=183388, print grad=0.0003872649685945362, Depth Loss=0.0000000]
Training progress:  59%|█████▉    | 1180/2000 [09:00<05:25,  2.52it/s, Loss=0.0120262, Gaussian number=183388, print grad=0.0004389747919049114, Depth Loss=0.0000000]
Training progress:  60%|█████▉    | 1190/2000 [09:00<05:21,  2.52it/s, Loss=0.0120262, Gaussian number=183388, print grad=0.0004389747919049114, Depth Loss=0.0000000]
Training progress:  60%|█████▉    | 1190/2000 [09:04<05:21,  2.52it/s, Loss=0.0136617, Gaussian number=183388, print grad=0.00048078506370075047, Depth Loss=0.0000000]
Training progress:  60%|██████    | 1200/2000 [09:04<05:17,  2.52it/s, Loss=0.0136617, Gaussian number=183388, print grad=0.00048078506370075047, Depth Loss=0.0000000]
Training progress:  60%|██████    | 1200/2000 [09:08<05:17,  2.52it/s, Loss=0.0105340, Gaussian number=183567, print grad=4.6298999222926795e-05, Depth Loss=0.0000000]
Training progress:  60%|██████    | 1210/2000 [09:08<05:13,  2.52it/s, Loss=0.0105340, Gaussian number=183567, print grad=4.6298999222926795e-05, Depth Loss=0.0000000]
Training progress:  60%|██████    | 1210/2000 [09:12<05:13,  2.52it/s, Loss=0.0088985, Gaussian number=183567, print grad=9.96558228507638e-05, Depth Loss=0.0000000]  
Training progress:  61%|██████    | 1220/2000 [09:12<05:09,  2.52it/s, Loss=0.0088985, Gaussian number=183567, print grad=9.96558228507638e-05, Depth Loss=0.0000000]
Training progress:  61%|██████    | 1220/2000 [09:16<05:09,  2.52it/s, Loss=0.0096501, Gaussian number=183567, print grad=0.00014562669093720615, Depth Loss=0.0000000]
Training progress:  62%|██████▏   | 1230/2000 [09:16<05:05,  2.52it/s, Loss=0.0096501, Gaussian number=183567, print grad=0.00014562669093720615, Depth Loss=0.0000000]
Training progress:  62%|██████▏   | 1230/2000 [09:20<05:05,  2.52it/s, Loss=0.0095101, Gaussian number=183567, print grad=0.0001976891653612256, Depth Loss=0.0000000] 
Training progress:  62%|██████▏   | 1240/2000 [09:20<05:02,  2.51it/s, Loss=0.0095101, Gaussian number=183567, print grad=0.0001976891653612256, Depth Loss=0.0000000]
Training progress:  62%|██████▏   | 1240/2000 [09:24<05:02,  2.51it/s, Loss=0.0095522, Gaussian number=183567, print grad=0.0002414687187410891, Depth Loss=0.0000000]
Training progress:  62%|██████▎   | 1250/2000 [09:24<04:58,  2.51it/s, Loss=0.0095522, Gaussian number=183567, print grad=0.0002414687187410891, Depth Loss=0.0000000]
Training progress:  62%|██████▎   | 1250/2000 [09:27<04:58,  2.51it/s, Loss=0.0099518, Gaussian number=183567, print grad=0.0002837417705450207, Depth Loss=0.0000000]
Training progress:  63%|██████▎   | 1260/2000 [09:27<04:54,  2.52it/s, Loss=0.0099518, Gaussian number=183567, print grad=0.0002837417705450207, Depth Loss=0.0000000]
Training progress:  63%|██████▎   | 1260/2000 [09:31<04:54,  2.52it/s, Loss=0.0121118, Gaussian number=183567, print grad=0.0003343632852192968, Depth Loss=0.0000000]
Training progress:  64%|██████▎   | 1270/2000 [09:31<04:50,  2.52it/s, Loss=0.0121118, Gaussian number=183567, print grad=0.0003343632852192968, Depth Loss=0.0000000]
Training progress:  64%|██████▎   | 1270/2000 [09:35<04:50,  2.52it/s, Loss=0.0122877, Gaussian number=183567, print grad=0.000379902747226879, Depth Loss=0.0000000] 
Training progress:  64%|██████▍   | 1280/2000 [09:35<04:47,  2.51it/s, Loss=0.0122877, Gaussian number=183567, print grad=0.000379902747226879, Depth Loss=0.0000000]
Training progress:  64%|██████▍   | 1280/2000 [09:39<04:47,  2.51it/s, Loss=0.0097122, Gaussian number=183567, print grad=0.00043156769243068993, Depth Loss=0.0000000]
Training progress:  64%|██████▍   | 1290/2000 [09:39<04:43,  2.51it/s, Loss=0.0097122, Gaussian number=183567, print grad=0.00043156769243068993, Depth Loss=0.0000000]
Training progress:  64%|██████▍   | 1290/2000 [09:43<04:43,  2.51it/s, Loss=0.0144871, Gaussian number=183567, print grad=0.0004772657703142613, Depth Loss=0.0000000] 
Training progress:  65%|██████▌   | 1300/2000 [09:43<04:39,  2.51it/s, Loss=0.0144871, Gaussian number=183567, print grad=0.0004772657703142613, Depth Loss=0.0000000]
Training progress:  65%|██████▌   | 1300/2000 [09:47<04:39,  2.51it/s, Loss=0.0135122, Gaussian number=183723, print grad=4.905753303319216e-05, Depth Loss=0.0000000]
Training progress:  66%|██████▌   | 1310/2000 [09:47<04:34,  2.51it/s, Loss=0.0135122, Gaussian number=183723, print grad=4.905753303319216e-05, Depth Loss=0.0000000]
Training progress:  66%|██████▌   | 1310/2000 [09:51<04:34,  2.51it/s, Loss=0.0131888, Gaussian number=183723, print grad=9.540915198158473e-05, Depth Loss=0.0000000]
Training progress:  66%|██████▌   | 1320/2000 [09:51<04:30,  2.51it/s, Loss=0.0131888, Gaussian number=183723, print grad=9.540915198158473e-05, Depth Loss=0.0000000]
Training progress:  66%|██████▌   | 1320/2000 [09:55<04:30,  2.51it/s, Loss=0.0104231, Gaussian number=183723, print grad=0.00014433411706704646, Depth Loss=0.0000000]
Training progress:  66%|██████▋   | 1330/2000 [09:55<04:26,  2.52it/s, Loss=0.0104231, Gaussian number=183723, print grad=0.00014433411706704646, Depth Loss=0.0000000]
Training progress:  66%|██████▋   | 1330/2000 [09:59<04:26,  2.52it/s, Loss=0.0113293, Gaussian number=183723, print grad=0.00019574737234506756, Depth Loss=0.0000000]
Training progress:  67%|██████▋   | 1340/2000 [09:59<04:21,  2.52it/s, Loss=0.0113293, Gaussian number=183723, print grad=0.00019574737234506756, Depth Loss=0.0000000]
Training progress:  67%|██████▋   | 1340/2000 [10:03<04:21,  2.52it/s, Loss=0.0150706, Gaussian number=183723, print grad=0.00023905103444121778, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1350/2000 [10:03<04:17,  2.52it/s, Loss=0.0150706, Gaussian number=183723, print grad=0.00023905103444121778, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1350/2000 [10:07<04:17,  2.52it/s, Loss=0.0092879, Gaussian number=183723, print grad=0.00028482332709245384, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1360/2000 [10:07<04:14,  2.52it/s, Loss=0.0092879, Gaussian number=183723, print grad=0.00028482332709245384, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1360/2000 [10:11<04:14,  2.52it/s, Loss=0.0170068, Gaussian number=183723, print grad=0.0003366855962667614, Depth Loss=0.0000000] 
Training progress:  68%|██████▊   | 1370/2000 [10:11<04:09,  2.52it/s, Loss=0.0170068, Gaussian number=183723, print grad=0.0003366855962667614, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1370/2000 [10:15<04:09,  2.52it/s, Loss=0.0112358, Gaussian number=183723, print grad=0.0003823636507149786, Depth Loss=0.0000000]
Training progress:  69%|██████▉   | 1380/2000 [10:15<04:05,  2.52it/s, Loss=0.0112358, Gaussian number=183723, print grad=0.0003823636507149786, Depth Loss=0.0000000]
Training progress:  69%|██████▉   | 1380/2000 [10:19<04:05,  2.52it/s, Loss=0.0101126, Gaussian number=183723, print grad=0.0004276174586266279, Depth Loss=0.0000000]
Training progress:  70%|██████▉   | 1390/2000 [10:19<04:02,  2.52it/s, Loss=0.0101126, Gaussian number=183723, print grad=0.0004276174586266279, Depth Loss=0.0000000]
Training progress:  70%|██████▉   | 1390/2000 [10:23<04:02,  2.52it/s, Loss=0.0114318, Gaussian number=183723, print grad=0.0004768151557072997, Depth Loss=0.0000000]
Training progress:  70%|███████   | 1400/2000 [10:23<03:58,  2.52it/s, Loss=0.0114318, Gaussian number=183723, print grad=0.0004768151557072997, Depth Loss=0.0000000]
Training progress:  70%|███████   | 1400/2000 [10:27<03:58,  2.52it/s, Loss=0.0124831, Gaussian number=183918, print grad=5.137465996085666e-05, Depth Loss=0.0000000]
Training progress:  70%|███████   | 1410/2000 [10:27<03:54,  2.52it/s, Loss=0.0124831, Gaussian number=183918, print grad=5.137465996085666e-05, Depth Loss=0.0000000]
Training progress:  70%|███████   | 1410/2000 [10:31<03:54,  2.52it/s, Loss=0.0111814, Gaussian number=183918, print grad=0.00010300189023837447, Depth Loss=0.0000000]
Training progress:  71%|███████   | 1420/2000 [10:31<03:50,  2.52it/s, Loss=0.0111814, Gaussian number=183918, print grad=0.00010300189023837447, Depth Loss=0.0000000]
Training progress:  71%|███████   | 1420/2000 [10:35<03:50,  2.52it/s, Loss=0.0112086, Gaussian number=183918, print grad=0.00015749959857203066, Depth Loss=0.0000000]
Training progress:  72%|███████▏  | 1430/2000 [10:35<03:46,  2.52it/s, Loss=0.0112086, Gaussian number=183918, print grad=0.00015749959857203066, Depth Loss=0.0000000]
Training progress:  72%|███████▏  | 1430/2000 [10:39<03:46,  2.52it/s, Loss=0.0108014, Gaussian number=183918, print grad=0.0002020002866629511, Depth Loss=0.0000000] 
Training progress:  72%|███████▏  | 1440/2000 [10:39<03:42,  2.52it/s, Loss=0.0108014, Gaussian number=183918, print grad=0.0002020002866629511, Depth Loss=0.0000000]
Training progress:  72%|███████▏  | 1440/2000 [10:43<03:42,  2.52it/s, Loss=0.0096095, Gaussian number=183918, print grad=0.00024744714028201997, Depth Loss=0.0000000]
Training progress:  72%|███████▎  | 1450/2000 [10:43<03:38,  2.52it/s, Loss=0.0096095, Gaussian number=183918, print grad=0.00024744714028201997, Depth Loss=0.0000000]
Training progress:  72%|███████▎  | 1450/2000 [10:47<03:38,  2.52it/s, Loss=0.0086741, Gaussian number=183918, print grad=0.00029543365235440433, Depth Loss=0.0000000]
Training progress:  73%|███████▎  | 1460/2000 [10:47<03:34,  2.52it/s, Loss=0.0086741, Gaussian number=183918, print grad=0.00029543365235440433, Depth Loss=0.0000000]
Training progress:  73%|███████▎  | 1460/2000 [10:51<03:34,  2.52it/s, Loss=0.0115416, Gaussian number=183918, print grad=0.00034387956839054823, Depth Loss=0.0000000]
Training progress:  74%|███████▎  | 1470/2000 [10:51<03:30,  2.52it/s, Loss=0.0115416, Gaussian number=183918, print grad=0.00034387956839054823, Depth Loss=0.0000000]
Training progress:  74%|███████▎  | 1470/2000 [10:55<03:30,  2.52it/s, Loss=0.0119158, Gaussian number=183918, print grad=0.0003959610185120255, Depth Loss=0.0000000] 
Training progress:  74%|███████▍  | 1480/2000 [10:55<03:26,  2.52it/s, Loss=0.0119158, Gaussian number=183918, print grad=0.0003959610185120255, Depth Loss=0.0000000]
Training progress:  74%|███████▍  | 1480/2000 [10:59<03:26,  2.52it/s, Loss=0.0123233, Gaussian number=183918, print grad=0.000447902362793684, Depth Loss=0.0000000] 
Training progress:  74%|███████▍  | 1490/2000 [10:59<03:22,  2.51it/s, Loss=0.0123233, Gaussian number=183918, print grad=0.000447902362793684, Depth Loss=0.0000000]
Training progress:  74%|███████▍  | 1490/2000 [11:03<03:22,  2.51it/s, Loss=0.0117436, Gaussian number=183918, print grad=0.0004982597311027348, Depth Loss=0.0000000]
Training progress:  75%|███████▌  | 1500/2000 [11:03<03:18,  2.52it/s, Loss=0.0117436, Gaussian number=183918, print grad=0.0004982597311027348, Depth Loss=0.0000000]
Training progress:  75%|███████▌  | 1500/2000 [11:13<03:18,  2.52it/s, Loss=0.0129901, Gaussian number=184090, print grad=4.366122084320523e-05, Depth Loss=0.0000000]
Training progress:  76%|███████▌  | 1510/2000 [11:13<04:43,  1.73it/s, Loss=0.0129901, Gaussian number=184090, print grad=4.366122084320523e-05, Depth Loss=0.0000000]
Training progress:  76%|███████▌  | 1510/2000 [11:17<04:43,  1.73it/s, Loss=0.0114714, Gaussian number=184090, print grad=8.957185491453856e-05, Depth Loss=0.0000000]
Training progress:  76%|███████▌  | 1520/2000 [11:17<04:11,  1.91it/s, Loss=0.0114714, Gaussian number=184090, print grad=8.957185491453856e-05, Depth Loss=0.0000000]
Training progress:  76%|███████▌  | 1520/2000 [11:21<04:11,  1.91it/s, Loss=0.0072303, Gaussian number=184090, print grad=0.00014270357496570796, Depth Loss=0.0000000]
Training progress:  76%|███████▋  | 1530/2000 [11:21<03:48,  2.06it/s, Loss=0.0072303, Gaussian number=184090, print grad=0.00014270357496570796, Depth Loss=0.0000000]
Training progress:  76%|███████▋  | 1530/2000 [11:25<03:48,  2.06it/s, Loss=0.0098314, Gaussian number=184090, print grad=0.00019187420548405498, Depth Loss=0.0000000]
Training progress:  77%|███████▋  | 1540/2000 [11:25<03:31,  2.18it/s, Loss=0.0098314, Gaussian number=184090, print grad=0.00019187420548405498, Depth Loss=0.0000000]
Training progress:  77%|███████▋  | 1540/2000 [11:29<03:31,  2.18it/s, Loss=0.0108631, Gaussian number=184090, print grad=0.00024408617173321545, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1550/2000 [11:29<03:18,  2.27it/s, Loss=0.0108631, Gaussian number=184090, print grad=0.00024408617173321545, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1550/2000 [11:33<03:18,  2.27it/s, Loss=0.0114345, Gaussian number=184090, print grad=0.0002993976522702724, Depth Loss=0.0000000] 
Training progress:  78%|███████▊  | 1560/2000 [11:33<03:07,  2.34it/s, Loss=0.0114345, Gaussian number=184090, print grad=0.0002993976522702724, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1560/2000 [11:37<03:07,  2.34it/s, Loss=0.0100868, Gaussian number=184090, print grad=0.00035160817787982523, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1570/2000 [11:37<02:59,  2.39it/s, Loss=0.0100868, Gaussian number=184090, print grad=0.00035160817787982523, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1570/2000 [11:41<02:59,  2.39it/s, Loss=0.0076148, Gaussian number=184090, print grad=0.0003940404567401856, Depth Loss=0.0000000] 
Training progress:  79%|███████▉  | 1580/2000 [11:41<02:52,  2.43it/s, Loss=0.0076148, Gaussian number=184090, print grad=0.0003940404567401856, Depth Loss=0.0000000]
Training progress:  79%|███████▉  | 1580/2000 [11:45<02:52,  2.43it/s, Loss=0.0108370, Gaussian number=184090, print grad=0.00043993466533720493, Depth Loss=0.0000000]
Training progress:  80%|███████▉  | 1590/2000 [11:45<02:46,  2.46it/s, Loss=0.0108370, Gaussian number=184090, print grad=0.00043993466533720493, Depth Loss=0.0000000]
Training progress:  80%|███████▉  | 1590/2000 [11:49<02:46,  2.46it/s, Loss=0.0101570, Gaussian number=184090, print grad=0.0004925850662402809, Depth Loss=0.0000000] 
Training progress:  80%|████████  | 1600/2000 [11:49<02:41,  2.48it/s, Loss=0.0101570, Gaussian number=184090, print grad=0.0004925850662402809, Depth Loss=0.0000000]
Training progress:  80%|████████  | 1600/2000 [11:53<02:41,  2.48it/s, Loss=0.0109515, Gaussian number=184264, print grad=5.031551336287521e-05, Depth Loss=0.0000000]
Training progress:  80%|████████  | 1610/2000 [11:53<02:36,  2.49it/s, Loss=0.0109515, Gaussian number=184264, print grad=5.031551336287521e-05, Depth Loss=0.0000000]
Training progress:  80%|████████  | 1610/2000 [11:56<02:36,  2.49it/s, Loss=0.0112030, Gaussian number=184264, print grad=0.00010611138714011759, Depth Loss=0.0000000]
Training progress:  81%|████████  | 1620/2000 [11:56<02:31,  2.50it/s, Loss=0.0112030, Gaussian number=184264, print grad=0.00010611138714011759, Depth Loss=0.0000000]
Training progress:  81%|████████  | 1620/2000 [12:00<02:31,  2.50it/s, Loss=0.0098718, Gaussian number=184264, print grad=0.00015496912237722427, Depth Loss=0.0000000]
Training progress:  82%|████████▏ | 1630/2000 [12:00<02:27,  2.51it/s, Loss=0.0098718, Gaussian number=184264, print grad=0.00015496912237722427, Depth Loss=0.0000000]
Training progress:  82%|████████▏ | 1630/2000 [12:04<02:27,  2.51it/s, Loss=0.0076172, Gaussian number=184264, print grad=0.0002046163281193003, Depth Loss=0.0000000] 
Training progress:  82%|████████▏ | 1640/2000 [12:04<02:23,  2.51it/s, Loss=0.0076172, Gaussian number=184264, print grad=0.0002046163281193003, Depth Loss=0.0000000]
Training progress:  82%|████████▏ | 1640/2000 [12:08<02:23,  2.51it/s, Loss=0.0100774, Gaussian number=184264, print grad=0.00025229944731108844, Depth Loss=0.0000000]
Training progress:  82%|████████▎ | 1650/2000 [12:08<02:19,  2.52it/s, Loss=0.0100774, Gaussian number=184264, print grad=0.00025229944731108844, Depth Loss=0.0000000]
Training progress:  82%|████████▎ | 1650/2000 [12:12<02:19,  2.52it/s, Loss=0.0099543, Gaussian number=184264, print grad=0.00029973112395964563, Depth Loss=0.0000000]
Training progress:  83%|████████▎ | 1660/2000 [12:12<02:14,  2.52it/s, Loss=0.0099543, Gaussian number=184264, print grad=0.00029973112395964563, Depth Loss=0.0000000]
Training progress:  83%|████████▎ | 1660/2000 [12:16<02:14,  2.52it/s, Loss=0.0093023, Gaussian number=184264, print grad=0.0003476089332252741, Depth Loss=0.0000000] 
Training progress:  84%|████████▎ | 1670/2000 [12:16<02:10,  2.52it/s, Loss=0.0093023, Gaussian number=184264, print grad=0.0003476089332252741, Depth Loss=0.0000000]
Training progress:  84%|████████▎ | 1670/2000 [12:20<02:10,  2.52it/s, Loss=0.0087025, Gaussian number=184264, print grad=0.0003992961719632149, Depth Loss=0.0000000]
Training progress:  84%|████████▍ | 1680/2000 [12:20<02:06,  2.52it/s, Loss=0.0087025, Gaussian number=184264, print grad=0.0003992961719632149, Depth Loss=0.0000000]
Training progress:  84%|████████▍ | 1680/2000 [12:24<02:06,  2.52it/s, Loss=0.0102477, Gaussian number=184264, print grad=0.0004505817196331918, Depth Loss=0.0000000]
Training progress:  84%|████████▍ | 1690/2000 [12:24<02:03,  2.52it/s, Loss=0.0102477, Gaussian number=184264, print grad=0.0004505817196331918, Depth Loss=0.0000000]
Training progress:  84%|████████▍ | 1690/2000 [12:28<02:03,  2.52it/s, Loss=0.0110316, Gaussian number=184264, print grad=0.0004974209005013108, Depth Loss=0.0000000]
Training progress:  85%|████████▌ | 1700/2000 [12:28<01:59,  2.51it/s, Loss=0.0110316, Gaussian number=184264, print grad=0.0004974209005013108, Depth Loss=0.0000000]
Training progress:  85%|████████▌ | 1700/2000 [12:32<01:59,  2.51it/s, Loss=0.0109621, Gaussian number=184471, print grad=5.1855749916285276e-05, Depth Loss=0.0000000]
Training progress:  86%|████████▌ | 1710/2000 [12:32<01:55,  2.51it/s, Loss=0.0109621, Gaussian number=184471, print grad=5.1855749916285276e-05, Depth Loss=0.0000000]
Training progress:  86%|████████▌ | 1710/2000 [12:36<01:55,  2.51it/s, Loss=0.0115770, Gaussian number=184471, print grad=9.651789150666445e-05, Depth Loss=0.0000000] 
Training progress:  86%|████████▌ | 1720/2000 [12:36<01:51,  2.52it/s, Loss=0.0115770, Gaussian number=184471, print grad=9.651789150666445e-05, Depth Loss=0.0000000]
Training progress:  86%|████████▌ | 1720/2000 [12:40<01:51,  2.52it/s, Loss=0.0105690, Gaussian number=184471, print grad=0.00014669008669443429, Depth Loss=0.0000000]
Training progress:  86%|████████▋ | 1730/2000 [12:40<01:47,  2.51it/s, Loss=0.0105690, Gaussian number=184471, print grad=0.00014669008669443429, Depth Loss=0.0000000]
Training progress:  86%|████████▋ | 1730/2000 [12:44<01:47,  2.51it/s, Loss=0.0133036, Gaussian number=184471, print grad=0.00020230516383890063, Depth Loss=0.0000000]
Training progress:  87%|████████▋ | 1740/2000 [12:44<01:43,  2.51it/s, Loss=0.0133036, Gaussian number=184471, print grad=0.00020230516383890063, Depth Loss=0.0000000]
Training progress:  87%|████████▋ | 1740/2000 [12:48<01:43,  2.51it/s, Loss=0.0129586, Gaussian number=184471, print grad=0.00025566190015524626, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1750/2000 [12:48<01:39,  2.51it/s, Loss=0.0129586, Gaussian number=184471, print grad=0.00025566190015524626, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1750/2000 [12:52<01:39,  2.51it/s, Loss=0.0109429, Gaussian number=184471, print grad=0.0003061601601075381, Depth Loss=0.0000000] 
Training progress:  88%|████████▊ | 1760/2000 [12:52<01:35,  2.52it/s, Loss=0.0109429, Gaussian number=184471, print grad=0.0003061601601075381, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1760/2000 [12:56<01:35,  2.52it/s, Loss=0.0088381, Gaussian number=184471, print grad=0.00035307437065057456, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1770/2000 [12:56<01:31,  2.52it/s, Loss=0.0088381, Gaussian number=184471, print grad=0.00035307437065057456, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1770/2000 [13:00<01:31,  2.52it/s, Loss=0.0104530, Gaussian number=184471, print grad=0.00040022857137955725, Depth Loss=0.0000000]
Training progress:  89%|████████▉ | 1780/2000 [13:00<01:27,  2.52it/s, Loss=0.0104530, Gaussian number=184471, print grad=0.00040022857137955725, Depth Loss=0.0000000]
Training progress:  89%|████████▉ | 1780/2000 [13:04<01:27,  2.52it/s, Loss=0.0097952, Gaussian number=184471, print grad=0.000441617303295061, Depth Loss=0.0000000]  
Training progress:  90%|████████▉ | 1790/2000 [13:04<01:23,  2.52it/s, Loss=0.0097952, Gaussian number=184471, print grad=0.000441617303295061, Depth Loss=0.0000000]
Training progress:  90%|████████▉ | 1790/2000 [13:08<01:23,  2.52it/s, Loss=0.0098253, Gaussian number=184471, print grad=0.000495661748573184, Depth Loss=0.0000000]
Training progress:  90%|█████████ | 1800/2000 [13:08<01:19,  2.52it/s, Loss=0.0098253, Gaussian number=184471, print grad=0.000495661748573184, Depth Loss=0.0000000]
Training progress:  90%|█████████ | 1800/2000 [13:12<01:19,  2.52it/s, Loss=0.0104290, Gaussian number=184628, print grad=5.044999488745816e-05, Depth Loss=0.0000000]
Training progress:  90%|█████████ | 1810/2000 [13:12<01:15,  2.52it/s, Loss=0.0104290, Gaussian number=184628, print grad=5.044999488745816e-05, Depth Loss=0.0000000]
Training progress:  90%|█████████ | 1810/2000 [13:16<01:15,  2.52it/s, Loss=0.0094907, Gaussian number=184628, print grad=0.0001066097611328587, Depth Loss=0.0000000]
Training progress:  91%|█████████ | 1820/2000 [13:16<01:11,  2.52it/s, Loss=0.0094907, Gaussian number=184628, print grad=0.0001066097611328587, Depth Loss=0.0000000]
Training progress:  91%|█████████ | 1820/2000 [13:20<01:11,  2.52it/s, Loss=0.0079620, Gaussian number=184628, print grad=0.000148860810440965, Depth Loss=0.0000000] 
Training progress:  92%|█████████▏| 1830/2000 [13:20<01:07,  2.52it/s, Loss=0.0079620, Gaussian number=184628, print grad=0.000148860810440965, Depth Loss=0.0000000]
Training progress:  92%|█████████▏| 1830/2000 [13:24<01:07,  2.52it/s, Loss=0.0089431, Gaussian number=184628, print grad=0.0002024450368480757, Depth Loss=0.0000000]
Training progress:  92%|█████████▏| 1840/2000 [13:24<01:03,  2.52it/s, Loss=0.0089431, Gaussian number=184628, print grad=0.0002024450368480757, Depth Loss=0.0000000]
Training progress:  92%|█████████▏| 1840/2000 [13:28<01:03,  2.52it/s, Loss=0.0096694, Gaussian number=184628, print grad=0.0002522635040804744, Depth Loss=0.0000000]
Training progress:  92%|█████████▎| 1850/2000 [13:28<00:59,  2.52it/s, Loss=0.0096694, Gaussian number=184628, print grad=0.0002522635040804744, Depth Loss=0.0000000]
Training progress:  92%|█████████▎| 1850/2000 [13:32<00:59,  2.52it/s, Loss=0.0099677, Gaussian number=184628, print grad=0.0002956428797915578, Depth Loss=0.0000000]
Training progress:  93%|█████████▎| 1860/2000 [13:32<00:55,  2.52it/s, Loss=0.0099677, Gaussian number=184628, print grad=0.0002956428797915578, Depth Loss=0.0000000]
Training progress:  93%|█████████▎| 1860/2000 [13:36<00:55,  2.52it/s, Loss=0.0112993, Gaussian number=184628, print grad=0.0003530008252710104, Depth Loss=0.0000000]
Training progress:  94%|█████████▎| 1870/2000 [13:36<00:51,  2.52it/s, Loss=0.0112993, Gaussian number=184628, print grad=0.0003530008252710104, Depth Loss=0.0000000]
Training progress:  94%|█████████▎| 1870/2000 [13:40<00:51,  2.52it/s, Loss=0.0086710, Gaussian number=184628, print grad=0.0004031932621728629, Depth Loss=0.0000000]
Training progress:  94%|█████████▍| 1880/2000 [13:40<00:47,  2.51it/s, Loss=0.0086710, Gaussian number=184628, print grad=0.0004031932621728629, Depth Loss=0.0000000]
Training progress:  94%|█████████▍| 1880/2000 [13:44<00:47,  2.51it/s, Loss=0.0097494, Gaussian number=184628, print grad=0.0004538127686828375, Depth Loss=0.0000000]
Training progress:  94%|█████████▍| 1890/2000 [13:44<00:43,  2.51it/s, Loss=0.0097494, Gaussian number=184628, print grad=0.0004538127686828375, Depth Loss=0.0000000]
Training progress:  94%|█████████▍| 1890/2000 [13:48<00:43,  2.51it/s, Loss=0.0118065, Gaussian number=184628, print grad=0.000505943491589278, Depth Loss=0.0000000] 
Training progress:  95%|█████████▌| 1900/2000 [13:48<00:39,  2.51it/s, Loss=0.0118065, Gaussian number=184628, print grad=0.000505943491589278, Depth Loss=0.0000000]
Training progress:  95%|█████████▌| 1900/2000 [13:52<00:39,  2.51it/s, Loss=0.0109937, Gaussian number=184851, print grad=4.358895603218116e-05, Depth Loss=0.0000000]
Training progress:  96%|█████████▌| 1910/2000 [13:52<00:35,  2.51it/s, Loss=0.0109937, Gaussian number=184851, print grad=4.358895603218116e-05, Depth Loss=0.0000000]
Training progress:  96%|█████████▌| 1910/2000 [13:56<00:35,  2.51it/s, Loss=0.0085533, Gaussian number=184851, print grad=9.310043242294341e-05, Depth Loss=0.0000000]
Training progress:  96%|█████████▌| 1920/2000 [13:56<00:31,  2.51it/s, Loss=0.0085533, Gaussian number=184851, print grad=9.310043242294341e-05, Depth Loss=0.0000000]
Training progress:  96%|█████████▌| 1920/2000 [14:00<00:31,  2.51it/s, Loss=0.0077664, Gaussian number=184851, print grad=0.00014471895701717585, Depth Loss=0.0000000]
Training progress:  96%|█████████▋| 1930/2000 [14:00<00:27,  2.51it/s, Loss=0.0077664, Gaussian number=184851, print grad=0.00014471895701717585, Depth Loss=0.0000000]
Training progress:  96%|█████████▋| 1930/2000 [14:04<00:27,  2.51it/s, Loss=0.0108597, Gaussian number=184851, print grad=0.0001943289244081825, Depth Loss=0.0000000] 
Training progress:  97%|█████████▋| 1940/2000 [14:04<00:23,  2.52it/s, Loss=0.0108597, Gaussian number=184851, print grad=0.0001943289244081825, Depth Loss=0.0000000]
Training progress:  97%|█████████▋| 1940/2000 [14:08<00:23,  2.52it/s, Loss=0.0083986, Gaussian number=184851, print grad=0.00024320110969711095, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1950/2000 [14:08<00:19,  2.51it/s, Loss=0.0083986, Gaussian number=184851, print grad=0.00024320110969711095, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1950/2000 [14:12<00:19,  2.51it/s, Loss=0.0131885, Gaussian number=184851, print grad=0.0002908043679781258, Depth Loss=0.0000000] 
Training progress:  98%|█████████▊| 1960/2000 [14:12<00:15,  2.52it/s, Loss=0.0131885, Gaussian number=184851, print grad=0.0002908043679781258, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1960/2000 [14:16<00:15,  2.52it/s, Loss=0.0110441, Gaussian number=184851, print grad=0.00034080189652740955, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1970/2000 [14:16<00:11,  2.52it/s, Loss=0.0110441, Gaussian number=184851, print grad=0.00034080189652740955, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1970/2000 [14:19<00:11,  2.52it/s, Loss=0.0094993, Gaussian number=184851, print grad=0.00039152655517682433, Depth Loss=0.0000000]
Training progress:  99%|█████████▉| 1980/2000 [14:19<00:07,  2.52it/s, Loss=0.0094993, Gaussian number=184851, print grad=0.00039152655517682433, Depth Loss=0.0000000]
Training progress:  99%|█████████▉| 1980/2000 [14:23<00:07,  2.52it/s, Loss=0.0093045, Gaussian number=184851, print grad=0.00044585822615772486, Depth Loss=0.0000000]
Training progress: 100%|█████████▉| 1990/2000 [14:23<00:03,  2.52it/s, Loss=0.0093045, Gaussian number=184851, print grad=0.00044585822615772486, Depth Loss=0.0000000]
Training progress: 100%|█████████▉| 1990/2000 [14:27<00:03,  2.52it/s, Loss=0.0078498, Gaussian number=184851, print grad=0.0005008344887755811, Depth Loss=0.0000000] 
Training progress: 100%|██████████| 2000/2000 [14:27<00:00,  2.52it/s, Loss=0.0078498, Gaussian number=184851, print grad=0.0005008344887755811, Depth Loss=0.0000000]
Training progress: 100%|██████████| 2000/2000 [14:27<00:00,  2.30it/s, Loss=0.0078498, Gaussian number=184851, print grad=0.0005008344887755811, Depth Loss=0.0000000]
Iteration 100 [15/11 00:24:32]

[ITER 100] Evaluating test: WD 0.019788, PSNR 12.9383 [15/11 00:24:38]

[ITER 100] Evaluating train: WD 0.020610, PSNR 13.2947 [15/11 00:24:38]
Gaussian number:182686,print gradients:2.808287490552175e-06 [15/11 00:24:38]
Iteration 200 [15/11 00:25:19]

[ITER 200] Evaluating test: WD 0.017530, PSNR 14.2225 [15/11 00:25:24]

[ITER 200] Evaluating train: WD 0.017804, PSNR 14.3882 [15/11 00:25:25]
Gaussian number:182686,print gradients:3.625852286859299e-06 [15/11 00:25:25]
Iteration 300 [15/11 00:26:05]

[ITER 300] Evaluating test: WD 0.015989, PSNR 14.9502 [15/11 00:26:11]

[ITER 300] Evaluating train: WD 0.016173, PSNR 15.2203 [15/11 00:26:12]
Gaussian number:182686,print gradients:4.13385942010791e-06 [15/11 00:26:12]
Iteration 400 [15/11 00:26:51]

[ITER 400] Evaluating test: WD 0.015291, PSNR 15.3969 [15/11 00:26:57]

[ITER 400] Evaluating train: WD 0.015470, PSNR 15.7863 [15/11 00:26:58]
Gaussian number:182686,print gradients:4.462421202333644e-06 [15/11 00:26:58]
Iteration 500 [15/11 00:27:38]

[ITER 500] Evaluating test: WD 0.014428, PSNR 15.8262 [15/11 00:27:44]

[ITER 500] Evaluating train: WD 0.015553, PSNR 15.8624 [15/11 00:27:44]
Gaussian number:182686,print gradients:4.82504674437223e-06 [15/11 00:27:44]
Iteration 600 [15/11 00:28:24]

[ITER 600] Evaluating test: WD 0.013821, PSNR 16.0756 [15/11 00:28:30]

[ITER 600] Evaluating train: WD 0.014461, PSNR 16.1207 [15/11 00:28:30]
Gaussian number:182686,print gradients:5.080390110379085e-06 [15/11 00:28:30]
Iteration 700 [15/11 00:29:10]

[ITER 700] Evaluating test: WD 0.013540, PSNR 16.2442 [15/11 00:29:16]

[ITER 700] Evaluating train: WD 0.014052, PSNR 16.2308 [15/11 00:29:16]
Gaussian number:182702,print gradients:6.7677524384635035e-06 [15/11 00:29:16]
Iteration 800 [15/11 00:29:56]

[ITER 800] Evaluating test: WD 0.012883, PSNR 16.4133 [15/11 00:30:02]

[ITER 800] Evaluating train: WD 0.013436, PSNR 16.4737 [15/11 00:30:02]
Gaussian number:182815,print gradients:6.680570550088305e-06 [15/11 00:30:02]
Iteration 900 [15/11 00:30:42]

[ITER 900] Evaluating test: WD 0.012749, PSNR 16.5160 [15/11 00:30:48]

[ITER 900] Evaluating train: WD 0.013677, PSNR 16.5352 [15/11 00:30:48]
Gaussian number:182957,print gradients:6.933573786227498e-06 [15/11 00:30:48]
Iteration 1000 [15/11 00:31:28]

[ITER 1000] Evaluating test: WD 0.012583, PSNR 16.6275 [15/11 00:31:34]

[ITER 1000] Evaluating train: WD 0.013686, PSNR 16.5405 [15/11 00:31:34]
Gaussian number:183072,print gradients:6.852382739452878e-06 [15/11 00:31:34]
Iteration 1100 [15/11 00:32:14]
Iteration 1200 [15/11 00:32:53]
Iteration 1300 [15/11 00:33:33]
Iteration 1400 [15/11 00:34:13]
Iteration 1500 [15/11 00:34:52]

[ITER 1500] Evaluating test: WD 0.011255, PSNR 17.1255 [15/11 00:34:58]

[ITER 1500] Evaluating train: WD 0.011938, PSNR 17.1931 [15/11 00:34:59]
Gaussian number:183918,print gradients:7.552069291705266e-06 [15/11 00:34:59]
Iteration 1600 [15/11 00:35:38]
Iteration 1700 [15/11 00:36:18]
Iteration 1800 [15/11 00:36:58]
Iteration 1900 [15/11 00:37:37]
Iteration 2000 [15/11 00:38:17]

[ITER 2000] Evaluating test: WD 0.010452, PSNR 17.5427 [15/11 00:38:23]

[ITER 2000] Evaluating train: WD 0.011539, PSNR 17.6241 [15/11 00:38:23]
Gaussian number:184851,print gradients:7.6677151810145e-06 [15/11 00:38:23]

[ITER 2000] Saving Gaussians [15/11 00:38:23]

Training complete. [15/11 00:38:25]
