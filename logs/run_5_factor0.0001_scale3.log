Optimizing /home/cw4287/gaussian-model/train1
Output folder: /home/cw4287/gaussian-model/train1 [15/11 00:52:08]
Tensorboard not available: not logging progress [15/11 00:52:08]
------------LLFF HOLD------------- [15/11 00:52:09]

Reading camera 1/301
Reading camera 2/301
Reading camera 3/301
Reading camera 4/301
Reading camera 5/301
Reading camera 6/301
Reading camera 7/301
Reading camera 8/301
Reading camera 9/301
Reading camera 10/301
Reading camera 11/301
Reading camera 12/301
Reading camera 13/301
Reading camera 14/301
Reading camera 15/301
Reading camera 16/301
Reading camera 17/301
Reading camera 18/301
Reading camera 19/301
Reading camera 20/301
Reading camera 21/301
Reading camera 22/301
Reading camera 23/301
Reading camera 24/301
Reading camera 25/301
Reading camera 26/301
Reading camera 27/301
Reading camera 28/301
Reading camera 29/301
Reading camera 30/301
Reading camera 31/301
Reading camera 32/301
Reading camera 33/301
Reading camera 34/301
Reading camera 35/301
Reading camera 36/301
Reading camera 37/301
Reading camera 38/301
Reading camera 39/301
Reading camera 40/301
Reading camera 41/301
Reading camera 42/301
Reading camera 43/301
Reading camera 44/301
Reading camera 45/301
Reading camera 46/301
Reading camera 47/301
Reading camera 48/301
Reading camera 49/301
Reading camera 50/301
Reading camera 51/301
Reading camera 52/301
Reading camera 53/301
Reading camera 54/301
Reading camera 55/301
Reading camera 56/301
Reading camera 57/301
Reading camera 58/301
Reading camera 59/301
Reading camera 60/301
Reading camera 61/301
Reading camera 62/301
Reading camera 63/301
Reading camera 64/301
Reading camera 65/301
Reading camera 66/301
Reading camera 67/301
Reading camera 68/301
Reading camera 69/301
Reading camera 70/301
Reading camera 71/301
Reading camera 72/301
Reading camera 73/301
Reading camera 74/301
Reading camera 75/301
Reading camera 76/301
Reading camera 77/301
Reading camera 78/301
Reading camera 79/301
Reading camera 80/301
Reading camera 81/301
Reading camera 82/301
Reading camera 83/301
Reading camera 84/301
Reading camera 85/301
Reading camera 86/301
Reading camera 87/301
Reading camera 88/301
Reading camera 89/301
Reading camera 90/301
Reading camera 91/301
Reading camera 92/301
Reading camera 93/301
Reading camera 94/301
Reading camera 95/301
Reading camera 96/301
Reading camera 97/301
Reading camera 98/301
Reading camera 99/301
Reading camera 100/301
Reading camera 101/301
Reading camera 102/301
Reading camera 103/301
Reading camera 104/301
Reading camera 105/301
Reading camera 106/301
Reading camera 107/301
Reading camera 108/301
Reading camera 109/301
Reading camera 110/301
Reading camera 111/301
Reading camera 112/301
Reading camera 113/301
Reading camera 114/301
Reading camera 115/301
Reading camera 116/301
Reading camera 117/301
Reading camera 118/301
Reading camera 119/301
Reading camera 120/301
Reading camera 121/301
Reading camera 122/301
Reading camera 123/301
Reading camera 124/301
Reading camera 125/301
Reading camera 126/301
Reading camera 127/301
Reading camera 128/301
Reading camera 129/301
Reading camera 130/301
Reading camera 131/301
Reading camera 132/301
Reading camera 133/301
Reading camera 134/301
Reading camera 135/301
Reading camera 136/301
Reading camera 137/301
Reading camera 138/301
Reading camera 139/301
Reading camera 140/301
Reading camera 141/301
Reading camera 142/301
Reading camera 143/301
Reading camera 144/301
Reading camera 145/301
Reading camera 146/301
Reading camera 147/301
Reading camera 148/301
Reading camera 149/301
Reading camera 150/301
Reading camera 151/301
Reading camera 152/301
Reading camera 153/301
Reading camera 154/301
Reading camera 155/301
Reading camera 156/301
Reading camera 157/301
Reading camera 158/301
Reading camera 159/301
Reading camera 160/301
Reading camera 161/301
Reading camera 162/301
Reading camera 163/301
Reading camera 164/301
Reading camera 165/301
Reading camera 166/301
Reading camera 167/301
Reading camera 168/301
Reading camera 169/301
Reading camera 170/301
Reading camera 171/301
Reading camera 172/301
Reading camera 173/301
Reading camera 174/301
Reading camera 175/301
Reading camera 176/301
Reading camera 177/301
Reading camera 178/301
Reading camera 179/301
Reading camera 180/301
Reading camera 181/301
Reading camera 182/301
Reading camera 183/301
Reading camera 184/301
Reading camera 185/301
Reading camera 186/301
Reading camera 187/301
Reading camera 188/301
Reading camera 189/301
Reading camera 190/301
Reading camera 191/301
Reading camera 192/301
Reading camera 193/301
Reading camera 194/301
Reading camera 195/301
Reading camera 196/301
Reading camera 197/301
Reading camera 198/301
Reading camera 199/301
Reading camera 200/301
Reading camera 201/301
Reading camera 202/301
Reading camera 203/301
Reading camera 204/301
Reading camera 205/301
Reading camera 206/301
Reading camera 207/301
Reading camera 208/301
Reading camera 209/301
Reading camera 210/301
Reading camera 211/301
Reading camera 212/301
Reading camera 213/301
Reading camera 214/301
Reading camera 215/301
Reading camera 216/301
Reading camera 217/301
Reading camera 218/301
Reading camera 219/301
Reading camera 220/301
Reading camera 221/301
Reading camera 222/301
Reading camera 223/301
Reading camera 224/301
Reading camera 225/301
Reading camera 226/301
Reading camera 227/301
Reading camera 228/301
Reading camera 229/301
Reading camera 230/301
Reading camera 231/301
Reading camera 232/301
Reading camera 233/301
Reading camera 234/301
Reading camera 235/301
Reading camera 236/301
Reading camera 237/301
Reading camera 238/301
Reading camera 239/301
Reading camera 240/301
Reading camera 241/301
Reading camera 242/301
Reading camera 243/301
Reading camera 244/301
Reading camera 245/301
Reading camera 246/301
Reading camera 247/301
Reading camera 248/301
Reading camera 249/301
Reading camera 250/301
Reading camera 251/301
Reading camera 252/301
Reading camera 253/301
Reading camera 254/301
Reading camera 255/301
Reading camera 256/301
Reading camera 257/301
Reading camera 258/301
Reading camera 259/301
Reading camera 260/301
Reading camera 261/301
Reading camera 262/301
Reading camera 263/301
Reading camera 264/301
Reading camera 265/301
Reading camera 266/301
Reading camera 267/301
Reading camera 268/301
Reading camera 269/301
Reading camera 270/301
Reading camera 271/301
Reading camera 272/301
Reading camera 273/301
Reading camera 274/301
Reading camera 275/301
Reading camera 276/301
Reading camera 277/301
Reading camera 278/301
Reading camera 279/301
Reading camera 280/301
Reading camera 281/301
Reading camera 282/301
Reading camera 283/301
Reading camera 284/301
Reading camera 285/301
Reading camera 286/301
Reading camera 287/301
Reading camera 288/301
Reading camera 289/301
Reading camera 290/301
Reading camera 291/301
Reading camera 292/301
Reading camera 293/301
Reading camera 294/301
Reading camera 295/301
Reading camera 296/301
Reading camera 297/301
Reading camera 298/301
Reading camera 299/301
Reading camera 300/301
Reading camera 301/301 [15/11 00:52:09]
Loading Training Cameras [15/11 00:52:09]
Loading Test Cameras [15/11 00:52:21]
Number of points at initialisation :  182686 [15/11 00:52:22]

Training progress:   0%|          | 0/2000 [00:00<?, ?it/s]/ext3/conda/envs/3dgs/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/ext3/conda/envs/3dgs/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)

Training progress:   0%|          | 0/2000 [00:05<?, ?it/s, Loss=0.0023783, Gaussian number=182686, print grad=1.1353915851941565e-06, Depth Loss=0.0000000]
Training progress:   0%|          | 10/2000 [00:05<18:25,  1.80it/s, Loss=0.0023783, Gaussian number=182686, print grad=1.1353915851941565e-06, Depth Loss=0.0000000]
Training progress:   0%|          | 10/2000 [00:09<18:25,  1.80it/s, Loss=0.0022315, Gaussian number=182686, print grad=2.937629233201733e-06, Depth Loss=0.0000000] 
Training progress:   1%|          | 20/2000 [00:09<15:26,  2.14it/s, Loss=0.0022315, Gaussian number=182686, print grad=2.937629233201733e-06, Depth Loss=0.0000000]
Training progress:   1%|          | 20/2000 [00:13<15:26,  2.14it/s, Loss=0.0022173, Gaussian number=182686, print grad=4.621986590791494e-06, Depth Loss=0.0000000]
Training progress:   2%|▏         | 30/2000 [00:13<14:26,  2.27it/s, Loss=0.0022173, Gaussian number=182686, print grad=4.621986590791494e-06, Depth Loss=0.0000000]
Training progress:   2%|▏         | 30/2000 [00:17<14:26,  2.27it/s, Loss=0.0023946, Gaussian number=182686, print grad=6.3824245444266126e-06, Depth Loss=0.0000000]
Training progress:   2%|▏         | 40/2000 [00:17<13:56,  2.34it/s, Loss=0.0023946, Gaussian number=182686, print grad=6.3824245444266126e-06, Depth Loss=0.0000000]
Training progress:   2%|▏         | 40/2000 [00:21<13:56,  2.34it/s, Loss=0.0018335, Gaussian number=182686, print grad=7.810323950252496e-06, Depth Loss=0.0000000] 
Training progress:   2%|▎         | 50/2000 [00:21<13:38,  2.38it/s, Loss=0.0018335, Gaussian number=182686, print grad=7.810323950252496e-06, Depth Loss=0.0000000]
Training progress:   2%|▎         | 50/2000 [00:25<13:38,  2.38it/s, Loss=0.0020387, Gaussian number=182686, print grad=9.884061000775546e-06, Depth Loss=0.0000000]
Training progress:   3%|▎         | 60/2000 [00:25<13:24,  2.41it/s, Loss=0.0020387, Gaussian number=182686, print grad=9.884061000775546e-06, Depth Loss=0.0000000]
Training progress:   3%|▎         | 60/2000 [00:29<13:24,  2.41it/s, Loss=0.0018287, Gaussian number=182686, print grad=1.2496174349507783e-05, Depth Loss=0.0000000]
Training progress:   4%|▎         | 70/2000 [00:29<13:14,  2.43it/s, Loss=0.0018287, Gaussian number=182686, print grad=1.2496174349507783e-05, Depth Loss=0.0000000]
Training progress:   4%|▎         | 70/2000 [00:33<13:14,  2.43it/s, Loss=0.0022353, Gaussian number=182686, print grad=1.4548845683748368e-05, Depth Loss=0.0000000]
Training progress:   4%|▍         | 80/2000 [00:34<13:07,  2.44it/s, Loss=0.0022353, Gaussian number=182686, print grad=1.4548845683748368e-05, Depth Loss=0.0000000]
Training progress:   4%|▍         | 80/2000 [00:38<13:07,  2.44it/s, Loss=0.0018852, Gaussian number=182686, print grad=1.666471507633105e-05, Depth Loss=0.0000000] 
Training progress:   4%|▍         | 90/2000 [00:38<13:01,  2.45it/s, Loss=0.0018852, Gaussian number=182686, print grad=1.666471507633105e-05, Depth Loss=0.0000000]
Training progress:   4%|▍         | 90/2000 [00:42<13:01,  2.45it/s, Loss=0.0018450, Gaussian number=182686, print grad=1.9180330127710477e-05, Depth Loss=0.0000000]
Training progress:   5%|▌         | 100/2000 [00:42<12:59,  2.44it/s, Loss=0.0018450, Gaussian number=182686, print grad=1.9180330127710477e-05, Depth Loss=0.0000000]
Training progress:   5%|▌         | 100/2000 [00:52<12:59,  2.44it/s, Loss=0.0021328, Gaussian number=182686, print grad=2.1910513169132173e-05, Depth Loss=0.0000000]
Training progress:   6%|▌         | 110/2000 [00:52<18:43,  1.68it/s, Loss=0.0021328, Gaussian number=182686, print grad=2.1910513169132173e-05, Depth Loss=0.0000000]
Training progress:   6%|▌         | 110/2000 [00:56<18:43,  1.68it/s, Loss=0.0017831, Gaussian number=182686, print grad=2.4492230295436457e-05, Depth Loss=0.0000000]
Training progress:   6%|▌         | 120/2000 [00:56<16:48,  1.86it/s, Loss=0.0017831, Gaussian number=182686, print grad=2.4492230295436457e-05, Depth Loss=0.0000000]
Training progress:   6%|▌         | 120/2000 [01:00<16:48,  1.86it/s, Loss=0.0020413, Gaussian number=182686, print grad=2.772423431451898e-05, Depth Loss=0.0000000] 
Training progress:   6%|▋         | 130/2000 [01:00<15:29,  2.01it/s, Loss=0.0020413, Gaussian number=182686, print grad=2.772423431451898e-05, Depth Loss=0.0000000]
Training progress:   6%|▋         | 130/2000 [01:04<15:29,  2.01it/s, Loss=0.0018662, Gaussian number=182686, print grad=3.096502405242063e-05, Depth Loss=0.0000000]
Training progress:   7%|▋         | 140/2000 [01:04<14:33,  2.13it/s, Loss=0.0018662, Gaussian number=182686, print grad=3.096502405242063e-05, Depth Loss=0.0000000]
Training progress:   7%|▋         | 140/2000 [01:08<14:33,  2.13it/s, Loss=0.0016520, Gaussian number=182686, print grad=3.389605990378186e-05, Depth Loss=0.0000000]
Training progress:   8%|▊         | 150/2000 [01:08<13:52,  2.22it/s, Loss=0.0016520, Gaussian number=182686, print grad=3.389605990378186e-05, Depth Loss=0.0000000]
Training progress:   8%|▊         | 150/2000 [01:12<13:52,  2.22it/s, Loss=0.0017397, Gaussian number=182686, print grad=3.757418380700983e-05, Depth Loss=0.0000000]
Training progress:   8%|▊         | 160/2000 [01:12<13:23,  2.29it/s, Loss=0.0017397, Gaussian number=182686, print grad=3.757418380700983e-05, Depth Loss=0.0000000]
Training progress:   8%|▊         | 160/2000 [01:16<13:23,  2.29it/s, Loss=0.0017274, Gaussian number=182686, print grad=4.049396011396311e-05, Depth Loss=0.0000000]
Training progress:   8%|▊         | 170/2000 [01:16<13:02,  2.34it/s, Loss=0.0017274, Gaussian number=182686, print grad=4.049396011396311e-05, Depth Loss=0.0000000]
Training progress:   8%|▊         | 170/2000 [01:20<13:02,  2.34it/s, Loss=0.0014829, Gaussian number=182686, print grad=4.383455234346911e-05, Depth Loss=0.0000000]
Training progress:   9%|▉         | 180/2000 [01:20<12:46,  2.37it/s, Loss=0.0014829, Gaussian number=182686, print grad=4.383455234346911e-05, Depth Loss=0.0000000]
Training progress:   9%|▉         | 180/2000 [01:24<12:46,  2.37it/s, Loss=0.0019137, Gaussian number=182686, print grad=4.674410229199566e-05, Depth Loss=0.0000000]
Training progress:  10%|▉         | 190/2000 [01:24<12:33,  2.40it/s, Loss=0.0019137, Gaussian number=182686, print grad=4.674410229199566e-05, Depth Loss=0.0000000]
Training progress:  10%|▉         | 190/2000 [01:28<12:33,  2.40it/s, Loss=0.0016599, Gaussian number=182686, print grad=5.0339371227892116e-05, Depth Loss=0.0000000]
Training progress:  10%|█         | 200/2000 [01:28<12:21,  2.43it/s, Loss=0.0016599, Gaussian number=182686, print grad=5.0339371227892116e-05, Depth Loss=0.0000000]
Training progress:  10%|█         | 200/2000 [01:38<12:21,  2.43it/s, Loss=0.0018763, Gaussian number=182686, print grad=5.398548819357529e-05, Depth Loss=0.0000000] 
Training progress:  10%|█         | 210/2000 [01:38<17:39,  1.69it/s, Loss=0.0018763, Gaussian number=182686, print grad=5.398548819357529e-05, Depth Loss=0.0000000]
Training progress:  10%|█         | 210/2000 [01:42<17:39,  1.69it/s, Loss=0.0015301, Gaussian number=182686, print grad=5.727246025344357e-05, Depth Loss=0.0000000]
Training progress:  11%|█         | 220/2000 [01:42<15:52,  1.87it/s, Loss=0.0015301, Gaussian number=182686, print grad=5.727246025344357e-05, Depth Loss=0.0000000]
Training progress:  11%|█         | 220/2000 [01:46<15:52,  1.87it/s, Loss=0.0017126, Gaussian number=182686, print grad=6.0708265664288774e-05, Depth Loss=0.0000000]
Training progress:  12%|█▏        | 230/2000 [01:46<14:36,  2.02it/s, Loss=0.0017126, Gaussian number=182686, print grad=6.0708265664288774e-05, Depth Loss=0.0000000]
Training progress:  12%|█▏        | 230/2000 [01:50<14:36,  2.02it/s, Loss=0.0021017, Gaussian number=182686, print grad=6.394595402525738e-05, Depth Loss=0.0000000] 
Training progress:  12%|█▏        | 240/2000 [01:50<13:42,  2.14it/s, Loss=0.0021017, Gaussian number=182686, print grad=6.394595402525738e-05, Depth Loss=0.0000000]
Training progress:  12%|█▏        | 240/2000 [01:54<13:42,  2.14it/s, Loss=0.0016185, Gaussian number=182686, print grad=6.754463538527489e-05, Depth Loss=0.0000000]
Training progress:  12%|█▎        | 250/2000 [01:54<13:03,  2.23it/s, Loss=0.0016185, Gaussian number=182686, print grad=6.754463538527489e-05, Depth Loss=0.0000000]
Training progress:  12%|█▎        | 250/2000 [01:59<13:03,  2.23it/s, Loss=0.0018219, Gaussian number=182686, print grad=7.090023427736014e-05, Depth Loss=0.0000000]
Training progress:  13%|█▎        | 260/2000 [01:59<12:34,  2.30it/s, Loss=0.0018219, Gaussian number=182686, print grad=7.090023427736014e-05, Depth Loss=0.0000000]
Training progress:  13%|█▎        | 260/2000 [02:03<12:34,  2.30it/s, Loss=0.0012819, Gaussian number=182686, print grad=7.444576476700604e-05, Depth Loss=0.0000000]
Training progress:  14%|█▎        | 270/2000 [02:03<12:14,  2.36it/s, Loss=0.0012819, Gaussian number=182686, print grad=7.444576476700604e-05, Depth Loss=0.0000000]
Training progress:  14%|█▎        | 270/2000 [02:07<12:14,  2.36it/s, Loss=0.0016407, Gaussian number=182686, print grad=7.848440145608038e-05, Depth Loss=0.0000000]
Training progress:  14%|█▍        | 280/2000 [02:07<11:58,  2.39it/s, Loss=0.0016407, Gaussian number=182686, print grad=7.848440145608038e-05, Depth Loss=0.0000000]
Training progress:  14%|█▍        | 280/2000 [02:11<11:58,  2.39it/s, Loss=0.0016796, Gaussian number=182686, print grad=8.227015496231616e-05, Depth Loss=0.0000000]
Training progress:  14%|█▍        | 290/2000 [02:11<11:46,  2.42it/s, Loss=0.0016796, Gaussian number=182686, print grad=8.227015496231616e-05, Depth Loss=0.0000000]
Training progress:  14%|█▍        | 290/2000 [02:15<11:46,  2.42it/s, Loss=0.0015746, Gaussian number=182686, print grad=8.618581341579556e-05, Depth Loss=0.0000000]
Training progress:  15%|█▌        | 300/2000 [02:15<11:37,  2.44it/s, Loss=0.0015746, Gaussian number=182686, print grad=8.618581341579556e-05, Depth Loss=0.0000000]
Training progress:  15%|█▌        | 300/2000 [02:25<11:37,  2.44it/s, Loss=0.0013057, Gaussian number=182686, print grad=9.025637700688094e-05, Depth Loss=0.0000000]
Training progress:  16%|█▌        | 310/2000 [02:25<16:36,  1.70it/s, Loss=0.0013057, Gaussian number=182686, print grad=9.025637700688094e-05, Depth Loss=0.0000000]
Training progress:  16%|█▌        | 310/2000 [02:29<16:36,  1.70it/s, Loss=0.0013578, Gaussian number=182686, print grad=9.318346565123647e-05, Depth Loss=0.0000000]
Training progress:  16%|█▌        | 320/2000 [02:29<14:55,  1.88it/s, Loss=0.0013578, Gaussian number=182686, print grad=9.318346565123647e-05, Depth Loss=0.0000000]
Training progress:  16%|█▌        | 320/2000 [02:33<14:55,  1.88it/s, Loss=0.0017966, Gaussian number=182686, print grad=9.668224083725363e-05, Depth Loss=0.0000000]
Training progress:  16%|█▋        | 330/2000 [02:33<13:45,  2.02it/s, Loss=0.0017966, Gaussian number=182686, print grad=9.668224083725363e-05, Depth Loss=0.0000000]
Training progress:  16%|█▋        | 330/2000 [02:37<13:45,  2.02it/s, Loss=0.0013004, Gaussian number=182686, print grad=0.000100677803857252, Depth Loss=0.0000000] 
Training progress:  17%|█▋        | 340/2000 [02:37<12:52,  2.15it/s, Loss=0.0013004, Gaussian number=182686, print grad=0.000100677803857252, Depth Loss=0.0000000]
Training progress:  17%|█▋        | 340/2000 [02:41<12:52,  2.15it/s, Loss=0.0013794, Gaussian number=182686, print grad=0.00010439599282108247, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 350/2000 [02:41<12:15,  2.24it/s, Loss=0.0013794, Gaussian number=182686, print grad=0.00010439599282108247, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 350/2000 [02:45<12:15,  2.24it/s, Loss=0.0013203, Gaussian number=182686, print grad=0.00010884200310101733, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 360/2000 [02:45<11:47,  2.32it/s, Loss=0.0013203, Gaussian number=182686, print grad=0.00010884200310101733, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 360/2000 [02:49<11:47,  2.32it/s, Loss=0.0012902, Gaussian number=182686, print grad=0.0001127632349380292, Depth Loss=0.0000000] 
Training progress:  18%|█▊        | 370/2000 [02:49<11:27,  2.37it/s, Loss=0.0012902, Gaussian number=182686, print grad=0.0001127632349380292, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 370/2000 [02:53<11:27,  2.37it/s, Loss=0.0017239, Gaussian number=182686, print grad=0.00011607328633544967, Depth Loss=0.0000000]
Training progress:  19%|█▉        | 380/2000 [02:53<11:11,  2.41it/s, Loss=0.0017239, Gaussian number=182686, print grad=0.00011607328633544967, Depth Loss=0.0000000]
Training progress:  19%|█▉        | 380/2000 [02:57<11:11,  2.41it/s, Loss=0.0015303, Gaussian number=182686, print grad=0.00012014697131235152, Depth Loss=0.0000000]
Training progress:  20%|█▉        | 390/2000 [02:57<11:00,  2.44it/s, Loss=0.0015303, Gaussian number=182686, print grad=0.00012014697131235152, Depth Loss=0.0000000]
Training progress:  20%|█▉        | 390/2000 [03:01<11:00,  2.44it/s, Loss=0.0018360, Gaussian number=182686, print grad=0.00012395351950544864, Depth Loss=0.0000000]
Training progress:  20%|██        | 400/2000 [03:01<10:50,  2.46it/s, Loss=0.0018360, Gaussian number=182686, print grad=0.00012395351950544864, Depth Loss=0.0000000]
Training progress:  20%|██        | 400/2000 [03:11<10:50,  2.46it/s, Loss=0.0015659, Gaussian number=182686, print grad=0.0001285307080252096, Depth Loss=0.0000000] 
Training progress:  20%|██        | 410/2000 [03:11<15:33,  1.70it/s, Loss=0.0015659, Gaussian number=182686, print grad=0.0001285307080252096, Depth Loss=0.0000000]
Training progress:  20%|██        | 410/2000 [03:15<15:33,  1.70it/s, Loss=0.0014033, Gaussian number=182686, print grad=0.00013283254520501941, Depth Loss=0.0000000]
Training progress:  21%|██        | 420/2000 [03:15<13:58,  1.88it/s, Loss=0.0014033, Gaussian number=182686, print grad=0.00013283254520501941, Depth Loss=0.0000000]
Training progress:  21%|██        | 420/2000 [03:19<13:58,  1.88it/s, Loss=0.0017545, Gaussian number=182686, print grad=0.00013726638280786574, Depth Loss=0.0000000]
Training progress:  22%|██▏       | 430/2000 [03:19<12:51,  2.03it/s, Loss=0.0017545, Gaussian number=182686, print grad=0.00013726638280786574, Depth Loss=0.0000000]
Training progress:  22%|██▏       | 430/2000 [03:23<12:51,  2.03it/s, Loss=0.0013674, Gaussian number=182686, print grad=0.00014141098654363304, Depth Loss=0.0000000]
Training progress:  22%|██▏       | 440/2000 [03:23<12:03,  2.16it/s, Loss=0.0013674, Gaussian number=182686, print grad=0.00014141098654363304, Depth Loss=0.0000000]
Training progress:  22%|██▏       | 440/2000 [03:27<12:03,  2.16it/s, Loss=0.0015737, Gaussian number=182686, print grad=0.00014572982036042958, Depth Loss=0.0000000]
Training progress:  22%|██▎       | 450/2000 [03:27<11:28,  2.25it/s, Loss=0.0015737, Gaussian number=182686, print grad=0.00014572982036042958, Depth Loss=0.0000000]
Training progress:  22%|██▎       | 450/2000 [03:31<11:28,  2.25it/s, Loss=0.0016267, Gaussian number=182686, print grad=0.00014988923794589937, Depth Loss=0.0000000]
Training progress:  23%|██▎       | 460/2000 [03:31<11:03,  2.32it/s, Loss=0.0016267, Gaussian number=182686, print grad=0.00014988923794589937, Depth Loss=0.0000000]
Training progress:  23%|██▎       | 460/2000 [03:35<11:03,  2.32it/s, Loss=0.0019394, Gaussian number=182686, print grad=0.0001538257347419858, Depth Loss=0.0000000] 
Training progress:  24%|██▎       | 470/2000 [03:35<10:44,  2.37it/s, Loss=0.0019394, Gaussian number=182686, print grad=0.0001538257347419858, Depth Loss=0.0000000]
Training progress:  24%|██▎       | 470/2000 [03:39<10:44,  2.37it/s, Loss=0.0012541, Gaussian number=182686, print grad=0.0001583369157742709, Depth Loss=0.0000000]
Training progress:  24%|██▍       | 480/2000 [03:39<10:30,  2.41it/s, Loss=0.0012541, Gaussian number=182686, print grad=0.0001583369157742709, Depth Loss=0.0000000]
Training progress:  24%|██▍       | 480/2000 [03:43<10:30,  2.41it/s, Loss=0.0013936, Gaussian number=182686, print grad=0.00016245788719970733, Depth Loss=0.0000000]
Training progress:  24%|██▍       | 490/2000 [03:43<10:18,  2.44it/s, Loss=0.0013936, Gaussian number=182686, print grad=0.00016245788719970733, Depth Loss=0.0000000]
Training progress:  24%|██▍       | 490/2000 [03:47<10:18,  2.44it/s, Loss=0.0010945, Gaussian number=182686, print grad=0.00016668478201609105, Depth Loss=0.0000000]
Training progress:  25%|██▌       | 500/2000 [03:47<10:09,  2.46it/s, Loss=0.0010945, Gaussian number=182686, print grad=0.00016668478201609105, Depth Loss=0.0000000]
Training progress:  25%|██▌       | 500/2000 [03:57<10:09,  2.46it/s, Loss=0.0012898, Gaussian number=182686, print grad=0.00017091503832489252, Depth Loss=0.0000000]
Training progress:  26%|██▌       | 510/2000 [03:57<14:33,  1.71it/s, Loss=0.0012898, Gaussian number=182686, print grad=0.00017091503832489252, Depth Loss=0.0000000]
Training progress:  26%|██▌       | 510/2000 [04:01<14:33,  1.71it/s, Loss=0.0013225, Gaussian number=182686, print grad=0.00017536750237923115, Depth Loss=0.0000000]
Training progress:  26%|██▌       | 520/2000 [04:01<13:06,  1.88it/s, Loss=0.0013225, Gaussian number=182686, print grad=0.00017536750237923115, Depth Loss=0.0000000]
Training progress:  26%|██▌       | 520/2000 [04:05<13:06,  1.88it/s, Loss=0.0010492, Gaussian number=182686, print grad=0.00017921888502314687, Depth Loss=0.0000000]
Training progress:  26%|██▋       | 530/2000 [04:05<12:01,  2.04it/s, Loss=0.0010492, Gaussian number=182686, print grad=0.00017921888502314687, Depth Loss=0.0000000]
Training progress:  26%|██▋       | 530/2000 [04:09<12:01,  2.04it/s, Loss=0.0014180, Gaussian number=182686, print grad=0.00018344703130424023, Depth Loss=0.0000000]
Training progress:  27%|██▋       | 540/2000 [04:09<11:17,  2.16it/s, Loss=0.0014180, Gaussian number=182686, print grad=0.00018344703130424023, Depth Loss=0.0000000]
Training progress:  27%|██▋       | 540/2000 [04:13<11:17,  2.16it/s, Loss=0.0013510, Gaussian number=182686, print grad=0.00018800600082613528, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 550/2000 [04:13<10:43,  2.25it/s, Loss=0.0013510, Gaussian number=182686, print grad=0.00018800600082613528, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 550/2000 [04:17<10:43,  2.25it/s, Loss=0.0010834, Gaussian number=182686, print grad=0.00019219177193008363, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 560/2000 [04:17<10:19,  2.32it/s, Loss=0.0010834, Gaussian number=182686, print grad=0.00019219177193008363, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 560/2000 [04:21<10:19,  2.32it/s, Loss=0.0014518, Gaussian number=182686, print grad=0.00019690724730025977, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 570/2000 [04:21<10:02,  2.38it/s, Loss=0.0014518, Gaussian number=182686, print grad=0.00019690724730025977, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 570/2000 [04:25<10:02,  2.38it/s, Loss=0.0012451, Gaussian number=182686, print grad=0.0002012238692259416, Depth Loss=0.0000000] 
Training progress:  29%|██▉       | 580/2000 [04:25<09:48,  2.41it/s, Loss=0.0012451, Gaussian number=182686, print grad=0.0002012238692259416, Depth Loss=0.0000000]
Training progress:  29%|██▉       | 580/2000 [04:29<09:48,  2.41it/s, Loss=0.0014355, Gaussian number=182686, print grad=0.00020572636276483536, Depth Loss=0.0000000]
Training progress:  30%|██▉       | 590/2000 [04:29<09:38,  2.44it/s, Loss=0.0014355, Gaussian number=182686, print grad=0.00020572636276483536, Depth Loss=0.0000000]
Training progress:  30%|██▉       | 590/2000 [04:33<09:38,  2.44it/s, Loss=0.0014419, Gaussian number=182686, print grad=0.00020994441001676023, Depth Loss=0.0000000]
Training progress:  30%|███       | 600/2000 [04:33<09:29,  2.46it/s, Loss=0.0014419, Gaussian number=182686, print grad=0.00020994441001676023, Depth Loss=0.0000000]
Training progress:  30%|███       | 600/2000 [04:43<09:29,  2.46it/s, Loss=0.0011855, Gaussian number=182665, print grad=3.950300197175238e-06, Depth Loss=0.0000000] 
Training progress:  30%|███       | 610/2000 [04:43<13:34,  1.71it/s, Loss=0.0011855, Gaussian number=182665, print grad=3.950300197175238e-06, Depth Loss=0.0000000]
Training progress:  30%|███       | 610/2000 [04:47<13:34,  1.71it/s, Loss=0.0015910, Gaussian number=182665, print grad=8.582063856010791e-06, Depth Loss=0.0000000]
Training progress:  31%|███       | 620/2000 [04:47<12:11,  1.89it/s, Loss=0.0015910, Gaussian number=182665, print grad=8.582063856010791e-06, Depth Loss=0.0000000]
Training progress:  31%|███       | 620/2000 [04:51<12:11,  1.89it/s, Loss=0.0011184, Gaussian number=182665, print grad=1.2688900824286975e-05, Depth Loss=0.0000000]
Training progress:  32%|███▏      | 630/2000 [04:51<11:12,  2.04it/s, Loss=0.0011184, Gaussian number=182665, print grad=1.2688900824286975e-05, Depth Loss=0.0000000]
Training progress:  32%|███▏      | 630/2000 [04:55<11:12,  2.04it/s, Loss=0.0012153, Gaussian number=182665, print grad=1.7718790331855416e-05, Depth Loss=0.0000000]
Training progress:  32%|███▏      | 640/2000 [04:55<10:29,  2.16it/s, Loss=0.0012153, Gaussian number=182665, print grad=1.7718790331855416e-05, Depth Loss=0.0000000]
Training progress:  32%|███▏      | 640/2000 [04:59<10:29,  2.16it/s, Loss=0.0014306, Gaussian number=182665, print grad=2.168980790884234e-05, Depth Loss=0.0000000] 
Training progress:  32%|███▎      | 650/2000 [04:59<09:58,  2.25it/s, Loss=0.0014306, Gaussian number=182665, print grad=2.168980790884234e-05, Depth Loss=0.0000000]
Training progress:  32%|███▎      | 650/2000 [05:03<09:58,  2.25it/s, Loss=0.0014554, Gaussian number=182665, print grad=2.649361158546526e-05, Depth Loss=0.0000000]
Training progress:  33%|███▎      | 660/2000 [05:03<09:36,  2.32it/s, Loss=0.0014554, Gaussian number=182665, print grad=2.649361158546526e-05, Depth Loss=0.0000000]
Training progress:  33%|███▎      | 660/2000 [05:07<09:36,  2.32it/s, Loss=0.0012588, Gaussian number=182665, print grad=3.083064439124428e-05, Depth Loss=0.0000000]
Training progress:  34%|███▎      | 670/2000 [05:07<09:19,  2.38it/s, Loss=0.0012588, Gaussian number=182665, print grad=3.083064439124428e-05, Depth Loss=0.0000000]
Training progress:  34%|███▎      | 670/2000 [05:11<09:19,  2.38it/s, Loss=0.0011889, Gaussian number=182665, print grad=3.566859959391877e-05, Depth Loss=0.0000000]
Training progress:  34%|███▍      | 680/2000 [05:11<09:06,  2.42it/s, Loss=0.0011889, Gaussian number=182665, print grad=3.566859959391877e-05, Depth Loss=0.0000000]
Training progress:  34%|███▍      | 680/2000 [05:15<09:06,  2.42it/s, Loss=0.0014048, Gaussian number=182665, print grad=4.007898678537458e-05, Depth Loss=0.0000000]
Training progress:  34%|███▍      | 690/2000 [05:15<08:54,  2.45it/s, Loss=0.0014048, Gaussian number=182665, print grad=4.007898678537458e-05, Depth Loss=0.0000000]
Training progress:  34%|███▍      | 690/2000 [05:18<08:54,  2.45it/s, Loss=0.0013994, Gaussian number=182665, print grad=4.4421372876968235e-05, Depth Loss=0.0000000]
Training progress:  35%|███▌      | 700/2000 [05:18<08:45,  2.47it/s, Loss=0.0013994, Gaussian number=182665, print grad=4.4421372876968235e-05, Depth Loss=0.0000000]
Training progress:  35%|███▌      | 700/2000 [05:29<08:45,  2.47it/s, Loss=0.0012342, Gaussian number=182638, print grad=3.897507667716127e-06, Depth Loss=0.0000000] 
Training progress:  36%|███▌      | 710/2000 [05:29<12:33,  1.71it/s, Loss=0.0012342, Gaussian number=182638, print grad=3.897507667716127e-06, Depth Loss=0.0000000]
Training progress:  36%|███▌      | 710/2000 [05:33<12:33,  1.71it/s, Loss=0.0011199, Gaussian number=182638, print grad=8.32640489534242e-06, Depth Loss=0.0000000] 
Training progress:  36%|███▌      | 720/2000 [05:33<11:15,  1.89it/s, Loss=0.0011199, Gaussian number=182638, print grad=8.32640489534242e-06, Depth Loss=0.0000000]
Training progress:  36%|███▌      | 720/2000 [05:36<11:15,  1.89it/s, Loss=0.0014753, Gaussian number=182638, print grad=1.2541570868052077e-05, Depth Loss=0.0000000]
Training progress:  36%|███▋      | 730/2000 [05:36<10:20,  2.05it/s, Loss=0.0014753, Gaussian number=182638, print grad=1.2541570868052077e-05, Depth Loss=0.0000000]
Training progress:  36%|███▋      | 730/2000 [05:40<10:20,  2.05it/s, Loss=0.0017515, Gaussian number=182638, print grad=1.7523196220281534e-05, Depth Loss=0.0000000]
Training progress:  37%|███▋      | 740/2000 [05:40<09:41,  2.17it/s, Loss=0.0017515, Gaussian number=182638, print grad=1.7523196220281534e-05, Depth Loss=0.0000000]
Training progress:  37%|███▋      | 740/2000 [05:44<09:41,  2.17it/s, Loss=0.0012582, Gaussian number=182638, print grad=2.223512638011016e-05, Depth Loss=0.0000000] 
Training progress:  38%|███▊      | 750/2000 [05:44<09:12,  2.26it/s, Loss=0.0012582, Gaussian number=182638, print grad=2.223512638011016e-05, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 750/2000 [05:48<09:12,  2.26it/s, Loss=0.0011810, Gaussian number=182638, print grad=2.666808541107457e-05, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 760/2000 [05:48<08:52,  2.33it/s, Loss=0.0011810, Gaussian number=182638, print grad=2.666808541107457e-05, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 760/2000 [05:52<08:52,  2.33it/s, Loss=0.0011008, Gaussian number=182638, print grad=3.1456962460651994e-05, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 770/2000 [05:52<08:36,  2.38it/s, Loss=0.0011008, Gaussian number=182638, print grad=3.1456962460651994e-05, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 770/2000 [05:56<08:36,  2.38it/s, Loss=0.0014483, Gaussian number=182638, print grad=3.581428245524876e-05, Depth Loss=0.0000000] 
Training progress:  39%|███▉      | 780/2000 [05:56<08:23,  2.42it/s, Loss=0.0014483, Gaussian number=182638, print grad=3.581428245524876e-05, Depth Loss=0.0000000]
Training progress:  39%|███▉      | 780/2000 [06:00<08:23,  2.42it/s, Loss=0.0016931, Gaussian number=182638, print grad=4.034915764350444e-05, Depth Loss=0.0000000]
Training progress:  40%|███▉      | 790/2000 [06:00<08:13,  2.45it/s, Loss=0.0016931, Gaussian number=182638, print grad=4.034915764350444e-05, Depth Loss=0.0000000]
Training progress:  40%|███▉      | 790/2000 [06:04<08:13,  2.45it/s, Loss=0.0014686, Gaussian number=182638, print grad=4.5210992539068684e-05, Depth Loss=0.0000000]
Training progress:  40%|████      | 800/2000 [06:04<08:06,  2.47it/s, Loss=0.0014686, Gaussian number=182638, print grad=4.5210992539068684e-05, Depth Loss=0.0000000]
Training progress:  40%|████      | 800/2000 [06:14<08:06,  2.47it/s, Loss=0.0013608, Gaussian number=182615, print grad=4.063023880007677e-06, Depth Loss=0.0000000] 
Training progress:  40%|████      | 810/2000 [06:14<11:35,  1.71it/s, Loss=0.0013608, Gaussian number=182615, print grad=4.063023880007677e-06, Depth Loss=0.0000000]
Training progress:  40%|████      | 810/2000 [06:18<11:35,  1.71it/s, Loss=0.0013297, Gaussian number=182615, print grad=8.501476258970797e-06, Depth Loss=0.0000000]
Training progress:  41%|████      | 820/2000 [06:18<10:23,  1.89it/s, Loss=0.0013297, Gaussian number=182615, print grad=8.501476258970797e-06, Depth Loss=0.0000000]
Training progress:  41%|████      | 820/2000 [06:22<10:23,  1.89it/s, Loss=0.0010532, Gaussian number=182615, print grad=1.3852286429028027e-05, Depth Loss=0.0000000]
Training progress:  42%|████▏     | 830/2000 [06:22<09:31,  2.05it/s, Loss=0.0010532, Gaussian number=182615, print grad=1.3852286429028027e-05, Depth Loss=0.0000000]
Training progress:  42%|████▏     | 830/2000 [06:26<09:31,  2.05it/s, Loss=0.0011531, Gaussian number=182615, print grad=1.8537137293606065e-05, Depth Loss=0.0000000]
Training progress:  42%|████▏     | 840/2000 [06:26<08:54,  2.17it/s, Loss=0.0011531, Gaussian number=182615, print grad=1.8537137293606065e-05, Depth Loss=0.0000000]
Training progress:  42%|████▏     | 840/2000 [06:30<08:54,  2.17it/s, Loss=0.0012275, Gaussian number=182615, print grad=2.344423410249874e-05, Depth Loss=0.0000000] 
Training progress:  42%|████▎     | 850/2000 [06:30<08:28,  2.26it/s, Loss=0.0012275, Gaussian number=182615, print grad=2.344423410249874e-05, Depth Loss=0.0000000]
Training progress:  42%|████▎     | 850/2000 [06:34<08:28,  2.26it/s, Loss=0.0012121, Gaussian number=182615, print grad=2.7896148822037503e-05, Depth Loss=0.0000000]
Training progress:  43%|████▎     | 860/2000 [06:34<08:08,  2.33it/s, Loss=0.0012121, Gaussian number=182615, print grad=2.7896148822037503e-05, Depth Loss=0.0000000]
Training progress:  43%|████▎     | 860/2000 [06:38<08:08,  2.33it/s, Loss=0.0014362, Gaussian number=182615, print grad=3.251456291764043e-05, Depth Loss=0.0000000] 
Training progress:  44%|████▎     | 870/2000 [06:38<07:53,  2.39it/s, Loss=0.0014362, Gaussian number=182615, print grad=3.251456291764043e-05, Depth Loss=0.0000000]
Training progress:  44%|████▎     | 870/2000 [06:42<07:53,  2.39it/s, Loss=0.0013342, Gaussian number=182615, print grad=3.7110556149855256e-05, Depth Loss=0.0000000]
Training progress:  44%|████▍     | 880/2000 [06:42<07:41,  2.43it/s, Loss=0.0013342, Gaussian number=182615, print grad=3.7110556149855256e-05, Depth Loss=0.0000000]
Training progress:  44%|████▍     | 880/2000 [06:46<07:41,  2.43it/s, Loss=0.0010749, Gaussian number=182615, print grad=4.178806921117939e-05, Depth Loss=0.0000000] 
Training progress:  44%|████▍     | 890/2000 [06:46<07:32,  2.46it/s, Loss=0.0010749, Gaussian number=182615, print grad=4.178806921117939e-05, Depth Loss=0.0000000]
Training progress:  44%|████▍     | 890/2000 [06:50<07:32,  2.46it/s, Loss=0.0013816, Gaussian number=182615, print grad=4.6424240281339735e-05, Depth Loss=0.0000000]
Training progress:  45%|████▌     | 900/2000 [06:50<07:24,  2.47it/s, Loss=0.0013816, Gaussian number=182615, print grad=4.6424240281339735e-05, Depth Loss=0.0000000]
Training progress:  45%|████▌     | 900/2000 [07:00<07:24,  2.47it/s, Loss=0.0010353, Gaussian number=182583, print grad=4.074639946338721e-06, Depth Loss=0.0000000] 
Training progress:  46%|████▌     | 910/2000 [07:00<10:36,  1.71it/s, Loss=0.0010353, Gaussian number=182583, print grad=4.074639946338721e-06, Depth Loss=0.0000000]
Training progress:  46%|████▌     | 910/2000 [07:04<10:36,  1.71it/s, Loss=0.0012616, Gaussian number=182583, print grad=8.027845069591422e-06, Depth Loss=0.0000000]
Training progress:  46%|████▌     | 920/2000 [07:04<09:29,  1.90it/s, Loss=0.0012616, Gaussian number=182583, print grad=8.027845069591422e-06, Depth Loss=0.0000000]
Training progress:  46%|████▌     | 920/2000 [07:08<09:29,  1.90it/s, Loss=0.0013336, Gaussian number=182583, print grad=1.3028397916059475e-05, Depth Loss=0.0000000]
Training progress:  46%|████▋     | 930/2000 [07:08<08:41,  2.05it/s, Loss=0.0013336, Gaussian number=182583, print grad=1.3028397916059475e-05, Depth Loss=0.0000000]
Training progress:  46%|████▋     | 930/2000 [07:12<08:41,  2.05it/s, Loss=0.0012123, Gaussian number=182583, print grad=1.7437045244150795e-05, Depth Loss=0.0000000]
Training progress:  47%|████▋     | 940/2000 [07:12<08:08,  2.17it/s, Loss=0.0012123, Gaussian number=182583, print grad=1.7437045244150795e-05, Depth Loss=0.0000000]
Training progress:  47%|████▋     | 940/2000 [07:16<08:08,  2.17it/s, Loss=0.0011732, Gaussian number=182583, print grad=2.2170333977555856e-05, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 950/2000 [07:16<07:43,  2.27it/s, Loss=0.0011732, Gaussian number=182583, print grad=2.2170333977555856e-05, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 950/2000 [07:20<07:43,  2.27it/s, Loss=0.0012256, Gaussian number=182583, print grad=2.662021324795205e-05, Depth Loss=0.0000000] 
Training progress:  48%|████▊     | 960/2000 [07:20<07:24,  2.34it/s, Loss=0.0012256, Gaussian number=182583, print grad=2.662021324795205e-05, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 960/2000 [07:24<07:24,  2.34it/s, Loss=0.0015486, Gaussian number=182583, print grad=3.156519596814178e-05, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 970/2000 [07:24<07:10,  2.39it/s, Loss=0.0015486, Gaussian number=182583, print grad=3.156519596814178e-05, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 970/2000 [07:28<07:10,  2.39it/s, Loss=0.0010301, Gaussian number=182583, print grad=3.6316021578386426e-05, Depth Loss=0.0000000]
Training progress:  49%|████▉     | 980/2000 [07:28<06:58,  2.43it/s, Loss=0.0010301, Gaussian number=182583, print grad=3.6316021578386426e-05, Depth Loss=0.0000000]
Training progress:  49%|████▉     | 980/2000 [07:32<06:58,  2.43it/s, Loss=0.0010440, Gaussian number=182583, print grad=4.0483173506800085e-05, Depth Loss=0.0000000]
Training progress:  50%|████▉     | 990/2000 [07:32<06:52,  2.45it/s, Loss=0.0010440, Gaussian number=182583, print grad=4.0483173506800085e-05, Depth Loss=0.0000000]
Training progress:  50%|████▉     | 990/2000 [07:36<06:52,  2.45it/s, Loss=0.0013918, Gaussian number=182583, print grad=4.4461150537244976e-05, Depth Loss=0.0000000]
Training progress:  50%|█████     | 1000/2000 [07:36<06:44,  2.47it/s, Loss=0.0013918, Gaussian number=182583, print grad=4.4461150537244976e-05, Depth Loss=0.0000000]
Training progress:  50%|█████     | 1000/2000 [07:46<06:44,  2.47it/s, Loss=0.0012343, Gaussian number=182554, print grad=3.938230747735361e-06, Depth Loss=0.0000000] 
Training progress:  50%|█████     | 1010/2000 [07:46<09:39,  1.71it/s, Loss=0.0012343, Gaussian number=182554, print grad=3.938230747735361e-06, Depth Loss=0.0000000]
Training progress:  50%|█████     | 1010/2000 [07:50<09:39,  1.71it/s, Loss=0.0015263, Gaussian number=182554, print grad=9.245083674613852e-06, Depth Loss=0.0000000]
Training progress:  51%|█████     | 1020/2000 [07:50<08:38,  1.89it/s, Loss=0.0015263, Gaussian number=182554, print grad=9.245083674613852e-06, Depth Loss=0.0000000]
Training progress:  51%|█████     | 1020/2000 [07:54<08:38,  1.89it/s, Loss=0.0012545, Gaussian number=182554, print grad=1.4171873772284016e-05, Depth Loss=0.0000000]
Training progress:  52%|█████▏    | 1030/2000 [07:54<07:55,  2.04it/s, Loss=0.0012545, Gaussian number=182554, print grad=1.4171873772284016e-05, Depth Loss=0.0000000]
Training progress:  52%|█████▏    | 1030/2000 [07:58<07:55,  2.04it/s, Loss=0.0013161, Gaussian number=182554, print grad=1.9392362446524203e-05, Depth Loss=0.0000000]
Training progress:  52%|█████▏    | 1040/2000 [07:58<07:23,  2.16it/s, Loss=0.0013161, Gaussian number=182554, print grad=1.9392362446524203e-05, Depth Loss=0.0000000]
Training progress:  52%|█████▏    | 1040/2000 [08:02<07:23,  2.16it/s, Loss=0.0012007, Gaussian number=182554, print grad=2.3524093194282614e-05, Depth Loss=0.0000000]
Training progress:  52%|█████▎    | 1050/2000 [08:02<07:01,  2.25it/s, Loss=0.0012007, Gaussian number=182554, print grad=2.3524093194282614e-05, Depth Loss=0.0000000]
Training progress:  52%|█████▎    | 1050/2000 [08:06<07:01,  2.25it/s, Loss=0.0011636, Gaussian number=182554, print grad=2.811813828884624e-05, Depth Loss=0.0000000] 
Training progress:  53%|█████▎    | 1060/2000 [08:06<06:45,  2.32it/s, Loss=0.0011636, Gaussian number=182554, print grad=2.811813828884624e-05, Depth Loss=0.0000000]
Training progress:  53%|█████▎    | 1060/2000 [08:10<06:45,  2.32it/s, Loss=0.0009696, Gaussian number=182554, print grad=3.334812936373055e-05, Depth Loss=0.0000000]
Training progress:  54%|█████▎    | 1070/2000 [08:10<06:31,  2.37it/s, Loss=0.0009696, Gaussian number=182554, print grad=3.334812936373055e-05, Depth Loss=0.0000000]
Training progress:  54%|█████▎    | 1070/2000 [08:14<06:31,  2.37it/s, Loss=0.0010392, Gaussian number=182554, print grad=3.788568210438825e-05, Depth Loss=0.0000000]
Training progress:  54%|█████▍    | 1080/2000 [08:14<06:20,  2.42it/s, Loss=0.0010392, Gaussian number=182554, print grad=3.788568210438825e-05, Depth Loss=0.0000000]
Training progress:  54%|█████▍    | 1080/2000 [08:18<06:20,  2.42it/s, Loss=0.0013110, Gaussian number=182554, print grad=4.2713105358416215e-05, Depth Loss=0.0000000]
Training progress:  55%|█████▍    | 1090/2000 [08:18<06:11,  2.45it/s, Loss=0.0013110, Gaussian number=182554, print grad=4.2713105358416215e-05, Depth Loss=0.0000000]
Training progress:  55%|█████▍    | 1090/2000 [08:22<06:11,  2.45it/s, Loss=0.0012837, Gaussian number=182554, print grad=4.743189492728561e-05, Depth Loss=0.0000000] 
Training progress:  55%|█████▌    | 1100/2000 [08:22<06:05,  2.46it/s, Loss=0.0012837, Gaussian number=182554, print grad=4.743189492728561e-05, Depth Loss=0.0000000]
Training progress:  55%|█████▌    | 1100/2000 [08:26<06:05,  2.46it/s, Loss=0.0013445, Gaussian number=182516, print grad=4.106928372493712e-06, Depth Loss=0.0000000]
Training progress:  56%|█████▌    | 1110/2000 [08:26<05:58,  2.48it/s, Loss=0.0013445, Gaussian number=182516, print grad=4.106928372493712e-06, Depth Loss=0.0000000]
Training progress:  56%|█████▌    | 1110/2000 [08:30<05:58,  2.48it/s, Loss=0.0012340, Gaussian number=182516, print grad=9.149119250650983e-06, Depth Loss=0.0000000]
Training progress:  56%|█████▌    | 1120/2000 [08:30<05:52,  2.50it/s, Loss=0.0012340, Gaussian number=182516, print grad=9.149119250650983e-06, Depth Loss=0.0000000]
Training progress:  56%|█████▌    | 1120/2000 [08:34<05:52,  2.50it/s, Loss=0.0009958, Gaussian number=182516, print grad=1.4280420145951211e-05, Depth Loss=0.0000000]
Training progress:  56%|█████▋    | 1130/2000 [08:34<05:46,  2.51it/s, Loss=0.0009958, Gaussian number=182516, print grad=1.4280420145951211e-05, Depth Loss=0.0000000]
Training progress:  56%|█████▋    | 1130/2000 [08:37<05:46,  2.51it/s, Loss=0.0012606, Gaussian number=182516, print grad=1.9365956177352928e-05, Depth Loss=0.0000000]
Training progress:  57%|█████▋    | 1140/2000 [08:37<05:41,  2.52it/s, Loss=0.0012606, Gaussian number=182516, print grad=1.9365956177352928e-05, Depth Loss=0.0000000]
Training progress:  57%|█████▋    | 1140/2000 [08:41<05:41,  2.52it/s, Loss=0.0008990, Gaussian number=182516, print grad=2.4309347281814553e-05, Depth Loss=0.0000000]
Training progress:  57%|█████▊    | 1150/2000 [08:41<05:37,  2.52it/s, Loss=0.0008990, Gaussian number=182516, print grad=2.4309347281814553e-05, Depth Loss=0.0000000]
Training progress:  57%|█████▊    | 1150/2000 [08:45<05:37,  2.52it/s, Loss=0.0009858, Gaussian number=182516, print grad=2.8676833608187735e-05, Depth Loss=0.0000000]
Training progress:  58%|█████▊    | 1160/2000 [08:45<05:33,  2.52it/s, Loss=0.0009858, Gaussian number=182516, print grad=2.8676833608187735e-05, Depth Loss=0.0000000]
Training progress:  58%|█████▊    | 1160/2000 [08:49<05:33,  2.52it/s, Loss=0.0012196, Gaussian number=182516, print grad=3.350001134094782e-05, Depth Loss=0.0000000] 
Training progress:  58%|█████▊    | 1170/2000 [08:49<05:29,  2.52it/s, Loss=0.0012196, Gaussian number=182516, print grad=3.350001134094782e-05, Depth Loss=0.0000000]
Training progress:  58%|█████▊    | 1170/2000 [08:53<05:29,  2.52it/s, Loss=0.0012557, Gaussian number=182516, print grad=3.839225246338174e-05, Depth Loss=0.0000000]
Training progress:  59%|█████▉    | 1180/2000 [08:53<05:25,  2.52it/s, Loss=0.0012557, Gaussian number=182516, print grad=3.839225246338174e-05, Depth Loss=0.0000000]
Training progress:  59%|█████▉    | 1180/2000 [08:57<05:25,  2.52it/s, Loss=0.0012098, Gaussian number=182516, print grad=4.356283170636743e-05, Depth Loss=0.0000000]
Training progress:  60%|█████▉    | 1190/2000 [08:57<05:22,  2.52it/s, Loss=0.0012098, Gaussian number=182516, print grad=4.356283170636743e-05, Depth Loss=0.0000000]
Training progress:  60%|█████▉    | 1190/2000 [09:01<05:22,  2.52it/s, Loss=0.0013364, Gaussian number=182516, print grad=4.773798355017789e-05, Depth Loss=0.0000000]
Training progress:  60%|██████    | 1200/2000 [09:01<05:17,  2.52it/s, Loss=0.0013364, Gaussian number=182516, print grad=4.773798355017789e-05, Depth Loss=0.0000000]
Training progress:  60%|██████    | 1200/2000 [09:05<05:17,  2.52it/s, Loss=0.0010324, Gaussian number=182486, print grad=4.536650976660894e-06, Depth Loss=0.0000000]
Training progress:  60%|██████    | 1210/2000 [09:05<05:13,  2.52it/s, Loss=0.0010324, Gaussian number=182486, print grad=4.536650976660894e-06, Depth Loss=0.0000000]
Training progress:  60%|██████    | 1210/2000 [09:09<05:13,  2.52it/s, Loss=0.0008797, Gaussian number=182486, print grad=9.785971997189336e-06, Depth Loss=0.0000000]
Training progress:  61%|██████    | 1220/2000 [09:09<05:09,  2.52it/s, Loss=0.0008797, Gaussian number=182486, print grad=9.785971997189336e-06, Depth Loss=0.0000000]
Training progress:  61%|██████    | 1220/2000 [09:13<05:09,  2.52it/s, Loss=0.0009552, Gaussian number=182486, print grad=1.4328110410133377e-05, Depth Loss=0.0000000]
Training progress:  62%|██████▏   | 1230/2000 [09:13<05:05,  2.52it/s, Loss=0.0009552, Gaussian number=182486, print grad=1.4328110410133377e-05, Depth Loss=0.0000000]
Training progress:  62%|██████▏   | 1230/2000 [09:17<05:05,  2.52it/s, Loss=0.0009398, Gaussian number=182486, print grad=1.9504337615217082e-05, Depth Loss=0.0000000]
Training progress:  62%|██████▏   | 1240/2000 [09:17<05:00,  2.53it/s, Loss=0.0009398, Gaussian number=182486, print grad=1.9504337615217082e-05, Depth Loss=0.0000000]
Training progress:  62%|██████▏   | 1240/2000 [09:21<05:00,  2.53it/s, Loss=0.0009472, Gaussian number=182486, print grad=2.3842323571443558e-05, Depth Loss=0.0000000]
Training progress:  62%|██████▎   | 1250/2000 [09:21<04:56,  2.53it/s, Loss=0.0009472, Gaussian number=182486, print grad=2.3842323571443558e-05, Depth Loss=0.0000000]
Training progress:  62%|██████▎   | 1250/2000 [09:25<04:56,  2.53it/s, Loss=0.0009855, Gaussian number=182486, print grad=2.805903750413563e-05, Depth Loss=0.0000000] 
Training progress:  63%|██████▎   | 1260/2000 [09:25<04:52,  2.53it/s, Loss=0.0009855, Gaussian number=182486, print grad=2.805903750413563e-05, Depth Loss=0.0000000]
Training progress:  63%|██████▎   | 1260/2000 [09:29<04:52,  2.53it/s, Loss=0.0012048, Gaussian number=182486, print grad=3.305160134914331e-05, Depth Loss=0.0000000]
Training progress:  64%|██████▎   | 1270/2000 [09:29<04:48,  2.53it/s, Loss=0.0012048, Gaussian number=182486, print grad=3.305160134914331e-05, Depth Loss=0.0000000]
Training progress:  64%|██████▎   | 1270/2000 [09:33<04:48,  2.53it/s, Loss=0.0012211, Gaussian number=182486, print grad=3.752980046556331e-05, Depth Loss=0.0000000]
Training progress:  64%|██████▍   | 1280/2000 [09:33<04:44,  2.53it/s, Loss=0.0012211, Gaussian number=182486, print grad=3.752980046556331e-05, Depth Loss=0.0000000]
Training progress:  64%|██████▍   | 1280/2000 [09:37<04:44,  2.53it/s, Loss=0.0009715, Gaussian number=182486, print grad=4.266576434019953e-05, Depth Loss=0.0000000]
Training progress:  64%|██████▍   | 1290/2000 [09:37<04:40,  2.53it/s, Loss=0.0009715, Gaussian number=182486, print grad=4.266576434019953e-05, Depth Loss=0.0000000]
Training progress:  64%|██████▍   | 1290/2000 [09:41<04:40,  2.53it/s, Loss=0.0014401, Gaussian number=182486, print grad=4.7187651944113895e-05, Depth Loss=0.0000000]
Training progress:  65%|██████▌   | 1300/2000 [09:41<04:36,  2.53it/s, Loss=0.0014401, Gaussian number=182486, print grad=4.7187651944113895e-05, Depth Loss=0.0000000]
Training progress:  65%|██████▌   | 1300/2000 [09:45<04:36,  2.53it/s, Loss=0.0013274, Gaussian number=182445, print grad=4.7744297262397595e-06, Depth Loss=0.0000000]
Training progress:  66%|██████▌   | 1310/2000 [09:45<04:32,  2.53it/s, Loss=0.0013274, Gaussian number=182445, print grad=4.7744297262397595e-06, Depth Loss=0.0000000]
Training progress:  66%|██████▌   | 1310/2000 [09:49<04:32,  2.53it/s, Loss=0.0013003, Gaussian number=182445, print grad=9.321570360043552e-06, Depth Loss=0.0000000] 
Training progress:  66%|██████▌   | 1320/2000 [09:49<04:29,  2.53it/s, Loss=0.0013003, Gaussian number=182445, print grad=9.321570360043552e-06, Depth Loss=0.0000000]
Training progress:  66%|██████▌   | 1320/2000 [09:53<04:29,  2.53it/s, Loss=0.0010350, Gaussian number=182445, print grad=1.4128841939964332e-05, Depth Loss=0.0000000]
Training progress:  66%|██████▋   | 1330/2000 [09:53<04:25,  2.53it/s, Loss=0.0010350, Gaussian number=182445, print grad=1.4128841939964332e-05, Depth Loss=0.0000000]
Training progress:  66%|██████▋   | 1330/2000 [09:57<04:25,  2.53it/s, Loss=0.0011253, Gaussian number=182445, print grad=1.9187018551747315e-05, Depth Loss=0.0000000]
Training progress:  67%|██████▋   | 1340/2000 [09:57<04:21,  2.52it/s, Loss=0.0011253, Gaussian number=182445, print grad=1.9187018551747315e-05, Depth Loss=0.0000000]
Training progress:  67%|██████▋   | 1340/2000 [10:01<04:21,  2.52it/s, Loss=0.0015055, Gaussian number=182445, print grad=2.342130392207764e-05, Depth Loss=0.0000000] 
Training progress:  68%|██████▊   | 1350/2000 [10:01<04:17,  2.52it/s, Loss=0.0015055, Gaussian number=182445, print grad=2.342130392207764e-05, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1350/2000 [10:05<04:17,  2.52it/s, Loss=0.0009230, Gaussian number=182445, print grad=2.7967394998995587e-05, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1360/2000 [10:05<04:13,  2.52it/s, Loss=0.0009230, Gaussian number=182445, print grad=2.7967394998995587e-05, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1360/2000 [10:09<04:13,  2.52it/s, Loss=0.0017007, Gaussian number=182445, print grad=3.31097689922899e-05, Depth Loss=0.0000000]  
Training progress:  68%|██████▊   | 1370/2000 [10:09<04:09,  2.53it/s, Loss=0.0017007, Gaussian number=182445, print grad=3.31097689922899e-05, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1370/2000 [10:13<04:09,  2.53it/s, Loss=0.0011053, Gaussian number=182445, print grad=3.7673285987693816e-05, Depth Loss=0.0000000]
Training progress:  69%|██████▉   | 1380/2000 [10:13<04:05,  2.52it/s, Loss=0.0011053, Gaussian number=182445, print grad=3.7673285987693816e-05, Depth Loss=0.0000000]
Training progress:  69%|██████▉   | 1380/2000 [10:16<04:05,  2.52it/s, Loss=0.0010189, Gaussian number=182445, print grad=4.215873559587635e-05, Depth Loss=0.0000000] 
Training progress:  70%|██████▉   | 1390/2000 [10:16<04:01,  2.52it/s, Loss=0.0010189, Gaussian number=182445, print grad=4.215873559587635e-05, Depth Loss=0.0000000]
Training progress:  70%|██████▉   | 1390/2000 [10:20<04:01,  2.52it/s, Loss=0.0011412, Gaussian number=182445, print grad=4.703722879639827e-05, Depth Loss=0.0000000]
Training progress:  70%|███████   | 1400/2000 [10:20<03:57,  2.52it/s, Loss=0.0011412, Gaussian number=182445, print grad=4.703722879639827e-05, Depth Loss=0.0000000]
Training progress:  70%|███████   | 1400/2000 [10:24<03:57,  2.52it/s, Loss=0.0012303, Gaussian number=182410, print grad=5.0078037929779384e-06, Depth Loss=0.0000000]
Training progress:  70%|███████   | 1410/2000 [10:24<03:54,  2.52it/s, Loss=0.0012303, Gaussian number=182410, print grad=5.0078037929779384e-06, Depth Loss=0.0000000]
Training progress:  70%|███████   | 1410/2000 [10:28<03:54,  2.52it/s, Loss=0.0011018, Gaussian number=182410, print grad=1.0093057426274754e-05, Depth Loss=0.0000000]
Training progress:  71%|███████   | 1420/2000 [10:28<03:50,  2.52it/s, Loss=0.0011018, Gaussian number=182410, print grad=1.0093057426274754e-05, Depth Loss=0.0000000]
Training progress:  71%|███████   | 1420/2000 [10:32<03:50,  2.52it/s, Loss=0.0010914, Gaussian number=182410, print grad=1.5531897588516586e-05, Depth Loss=0.0000000]
Training progress:  72%|███████▏  | 1430/2000 [10:32<03:45,  2.52it/s, Loss=0.0010914, Gaussian number=182410, print grad=1.5531897588516586e-05, Depth Loss=0.0000000]
Training progress:  72%|███████▏  | 1430/2000 [10:36<03:45,  2.52it/s, Loss=0.0010594, Gaussian number=182410, print grad=1.995796810660977e-05, Depth Loss=0.0000000] 
Training progress:  72%|███████▏  | 1440/2000 [10:36<03:41,  2.52it/s, Loss=0.0010594, Gaussian number=182410, print grad=1.995796810660977e-05, Depth Loss=0.0000000]
Training progress:  72%|███████▏  | 1440/2000 [10:40<03:41,  2.52it/s, Loss=0.0009490, Gaussian number=182410, print grad=2.4476581529597752e-05, Depth Loss=0.0000000]
Training progress:  72%|███████▎  | 1450/2000 [10:40<03:38,  2.52it/s, Loss=0.0009490, Gaussian number=182410, print grad=2.4476581529597752e-05, Depth Loss=0.0000000]
Training progress:  72%|███████▎  | 1450/2000 [10:44<03:38,  2.52it/s, Loss=0.0008524, Gaussian number=182410, print grad=2.927756213466637e-05, Depth Loss=0.0000000] 
Training progress:  73%|███████▎  | 1460/2000 [10:44<03:34,  2.52it/s, Loss=0.0008524, Gaussian number=182410, print grad=2.927756213466637e-05, Depth Loss=0.0000000]
Training progress:  73%|███████▎  | 1460/2000 [10:48<03:34,  2.52it/s, Loss=0.0011529, Gaussian number=182410, print grad=3.410028148209676e-05, Depth Loss=0.0000000]
Training progress:  74%|███████▎  | 1470/2000 [10:48<03:30,  2.51it/s, Loss=0.0011529, Gaussian number=182410, print grad=3.410028148209676e-05, Depth Loss=0.0000000]
Training progress:  74%|███████▎  | 1470/2000 [10:52<03:30,  2.51it/s, Loss=0.0011795, Gaussian number=182410, print grad=3.932155959773809e-05, Depth Loss=0.0000000]
Training progress:  74%|███████▍  | 1480/2000 [10:52<03:26,  2.52it/s, Loss=0.0011795, Gaussian number=182410, print grad=3.932155959773809e-05, Depth Loss=0.0000000]
Training progress:  74%|███████▍  | 1480/2000 [10:56<03:26,  2.52it/s, Loss=0.0012335, Gaussian number=182410, print grad=4.452626671991311e-05, Depth Loss=0.0000000]
Training progress:  74%|███████▍  | 1490/2000 [10:56<03:22,  2.52it/s, Loss=0.0012335, Gaussian number=182410, print grad=4.452626671991311e-05, Depth Loss=0.0000000]
Training progress:  74%|███████▍  | 1490/2000 [11:00<03:22,  2.52it/s, Loss=0.0011673, Gaussian number=182410, print grad=4.955954500474036e-05, Depth Loss=0.0000000]
Training progress:  75%|███████▌  | 1500/2000 [11:00<03:18,  2.52it/s, Loss=0.0011673, Gaussian number=182410, print grad=4.955954500474036e-05, Depth Loss=0.0000000]
Training progress:  75%|███████▌  | 1500/2000 [11:10<03:18,  2.52it/s, Loss=0.0012704, Gaussian number=182373, print grad=4.26372798756347e-06, Depth Loss=0.0000000] 
Training progress:  76%|███████▌  | 1510/2000 [11:10<04:43,  1.73it/s, Loss=0.0012704, Gaussian number=182373, print grad=4.26372798756347e-06, Depth Loss=0.0000000]
Training progress:  76%|███████▌  | 1510/2000 [11:14<04:43,  1.73it/s, Loss=0.0011110, Gaussian number=182373, print grad=8.77493221196346e-06, Depth Loss=0.0000000]
Training progress:  76%|███████▌  | 1520/2000 [11:14<04:11,  1.91it/s, Loss=0.0011110, Gaussian number=182373, print grad=8.77493221196346e-06, Depth Loss=0.0000000]
Training progress:  76%|███████▌  | 1520/2000 [11:18<04:11,  1.91it/s, Loss=0.0007150, Gaussian number=182373, print grad=1.4032962099008728e-05, Depth Loss=0.0000000]
Training progress:  76%|███████▋  | 1530/2000 [11:18<03:48,  2.06it/s, Loss=0.0007150, Gaussian number=182373, print grad=1.4032962099008728e-05, Depth Loss=0.0000000]
Training progress:  76%|███████▋  | 1530/2000 [11:22<03:48,  2.06it/s, Loss=0.0009654, Gaussian number=182373, print grad=1.8890437786467373e-05, Depth Loss=0.0000000]
Training progress:  77%|███████▋  | 1540/2000 [11:22<03:30,  2.18it/s, Loss=0.0009654, Gaussian number=182373, print grad=1.8890437786467373e-05, Depth Loss=0.0000000]
Training progress:  77%|███████▋  | 1540/2000 [11:26<03:30,  2.18it/s, Loss=0.0010804, Gaussian number=182373, print grad=2.412039611954242e-05, Depth Loss=0.0000000] 
Training progress:  78%|███████▊  | 1550/2000 [11:26<03:17,  2.27it/s, Loss=0.0010804, Gaussian number=182373, print grad=2.412039611954242e-05, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1550/2000 [11:30<03:17,  2.27it/s, Loss=0.0011402, Gaussian number=182373, print grad=2.9589482437586412e-05, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1560/2000 [11:30<03:07,  2.34it/s, Loss=0.0011402, Gaussian number=182373, print grad=2.9589482437586412e-05, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1560/2000 [11:34<03:07,  2.34it/s, Loss=0.0010052, Gaussian number=182373, print grad=3.478311555227265e-05, Depth Loss=0.0000000] 
Training progress:  78%|███████▊  | 1570/2000 [11:34<02:59,  2.40it/s, Loss=0.0010052, Gaussian number=182373, print grad=3.478311555227265e-05, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1570/2000 [11:38<02:59,  2.40it/s, Loss=0.0007636, Gaussian number=182373, print grad=3.898695649695583e-05, Depth Loss=0.0000000]
Training progress:  79%|███████▉  | 1580/2000 [11:38<02:52,  2.43it/s, Loss=0.0007636, Gaussian number=182373, print grad=3.898695649695583e-05, Depth Loss=0.0000000]
Training progress:  79%|███████▉  | 1580/2000 [11:42<02:52,  2.43it/s, Loss=0.0010706, Gaussian number=182373, print grad=4.350465678726323e-05, Depth Loss=0.0000000]
Training progress:  80%|███████▉  | 1590/2000 [11:42<02:46,  2.46it/s, Loss=0.0010706, Gaussian number=182373, print grad=4.350465678726323e-05, Depth Loss=0.0000000]
Training progress:  80%|███████▉  | 1590/2000 [11:46<02:46,  2.46it/s, Loss=0.0009935, Gaussian number=182373, print grad=4.872814679401927e-05, Depth Loss=0.0000000]
Training progress:  80%|████████  | 1600/2000 [11:46<02:41,  2.48it/s, Loss=0.0009935, Gaussian number=182373, print grad=4.872814679401927e-05, Depth Loss=0.0000000]
Training progress:  80%|████████  | 1600/2000 [11:50<02:41,  2.48it/s, Loss=0.0010629, Gaussian number=182321, print grad=4.855235602008179e-06, Depth Loss=0.0000000]
Training progress:  80%|████████  | 1610/2000 [11:50<02:36,  2.49it/s, Loss=0.0010629, Gaussian number=182321, print grad=4.855235602008179e-06, Depth Loss=0.0000000]
Training progress:  80%|████████  | 1610/2000 [11:54<02:36,  2.49it/s, Loss=0.0010982, Gaussian number=182321, print grad=1.0325300536351278e-05, Depth Loss=0.0000000]
Training progress:  81%|████████  | 1620/2000 [11:54<02:31,  2.50it/s, Loss=0.0010982, Gaussian number=182321, print grad=1.0325300536351278e-05, Depth Loss=0.0000000]
Training progress:  81%|████████  | 1620/2000 [11:58<02:31,  2.50it/s, Loss=0.0009825, Gaussian number=182321, print grad=1.5118928786250763e-05, Depth Loss=0.0000000]
Training progress:  82%|████████▏ | 1630/2000 [11:58<02:27,  2.51it/s, Loss=0.0009825, Gaussian number=182321, print grad=1.5118928786250763e-05, Depth Loss=0.0000000]
Training progress:  82%|████████▏ | 1630/2000 [12:02<02:27,  2.51it/s, Loss=0.0007474, Gaussian number=182321, print grad=2.0042079995619133e-05, Depth Loss=0.0000000]
Training progress:  82%|████████▏ | 1640/2000 [12:02<02:23,  2.52it/s, Loss=0.0007474, Gaussian number=182321, print grad=2.0042079995619133e-05, Depth Loss=0.0000000]
Training progress:  82%|████████▏ | 1640/2000 [12:06<02:23,  2.52it/s, Loss=0.0009937, Gaussian number=182321, print grad=2.471308471285738e-05, Depth Loss=0.0000000] 
Training progress:  82%|████████▎ | 1650/2000 [12:06<02:18,  2.52it/s, Loss=0.0009937, Gaussian number=182321, print grad=2.471308471285738e-05, Depth Loss=0.0000000]
Training progress:  82%|████████▎ | 1650/2000 [12:10<02:18,  2.52it/s, Loss=0.0009775, Gaussian number=182321, print grad=2.940020931418985e-05, Depth Loss=0.0000000]
Training progress:  83%|████████▎ | 1660/2000 [12:10<02:14,  2.52it/s, Loss=0.0009775, Gaussian number=182321, print grad=2.940020931418985e-05, Depth Loss=0.0000000]
Training progress:  83%|████████▎ | 1660/2000 [12:14<02:14,  2.52it/s, Loss=0.0009287, Gaussian number=182321, print grad=3.411792204133235e-05, Depth Loss=0.0000000]
Training progress:  84%|████████▎ | 1670/2000 [12:14<02:10,  2.52it/s, Loss=0.0009287, Gaussian number=182321, print grad=3.411792204133235e-05, Depth Loss=0.0000000]
Training progress:  84%|████████▎ | 1670/2000 [12:17<02:10,  2.52it/s, Loss=0.0008698, Gaussian number=182321, print grad=3.916938658221625e-05, Depth Loss=0.0000000]
Training progress:  84%|████████▍ | 1680/2000 [12:17<02:06,  2.52it/s, Loss=0.0008698, Gaussian number=182321, print grad=3.916938658221625e-05, Depth Loss=0.0000000]
Training progress:  84%|████████▍ | 1680/2000 [12:21<02:06,  2.52it/s, Loss=0.0010191, Gaussian number=182321, print grad=4.429581531439908e-05, Depth Loss=0.0000000]
Training progress:  84%|████████▍ | 1690/2000 [12:21<02:02,  2.53it/s, Loss=0.0010191, Gaussian number=182321, print grad=4.429581531439908e-05, Depth Loss=0.0000000]
Training progress:  84%|████████▍ | 1690/2000 [12:25<02:02,  2.53it/s, Loss=0.0011200, Gaussian number=182321, print grad=4.895733582088724e-05, Depth Loss=0.0000000]
Training progress:  85%|████████▌ | 1700/2000 [12:25<01:58,  2.52it/s, Loss=0.0011200, Gaussian number=182321, print grad=4.895733582088724e-05, Depth Loss=0.0000000]
Training progress:  85%|████████▌ | 1700/2000 [12:29<01:58,  2.52it/s, Loss=0.0010868, Gaussian number=182284, print grad=5.11050529894419e-06, Depth Loss=0.0000000] 
Training progress:  86%|████████▌ | 1710/2000 [12:29<01:54,  2.53it/s, Loss=0.0010868, Gaussian number=182284, print grad=5.11050529894419e-06, Depth Loss=0.0000000]
Training progress:  86%|████████▌ | 1710/2000 [12:33<01:54,  2.53it/s, Loss=0.0011226, Gaussian number=182284, print grad=9.550267350277863e-06, Depth Loss=0.0000000]
Training progress:  86%|████████▌ | 1720/2000 [12:33<01:50,  2.53it/s, Loss=0.0011226, Gaussian number=182284, print grad=9.550267350277863e-06, Depth Loss=0.0000000]
Training progress:  86%|████████▌ | 1720/2000 [12:37<01:50,  2.53it/s, Loss=0.0010533, Gaussian number=182284, print grad=1.4464002560998779e-05, Depth Loss=0.0000000]
Training progress:  86%|████████▋ | 1730/2000 [12:37<01:46,  2.53it/s, Loss=0.0010533, Gaussian number=182284, print grad=1.4464002560998779e-05, Depth Loss=0.0000000]
Training progress:  86%|████████▋ | 1730/2000 [12:41<01:46,  2.53it/s, Loss=0.0012958, Gaussian number=182284, print grad=1.9924329535569996e-05, Depth Loss=0.0000000]
Training progress:  87%|████████▋ | 1740/2000 [12:41<01:42,  2.52it/s, Loss=0.0012958, Gaussian number=182284, print grad=1.9924329535569996e-05, Depth Loss=0.0000000]
Training progress:  87%|████████▋ | 1740/2000 [12:45<01:42,  2.52it/s, Loss=0.0012662, Gaussian number=182284, print grad=2.5237784939236008e-05, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1750/2000 [12:45<01:38,  2.53it/s, Loss=0.0012662, Gaussian number=182284, print grad=2.5237784939236008e-05, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1750/2000 [12:49<01:38,  2.53it/s, Loss=0.0010849, Gaussian number=182284, print grad=3.027075217687525e-05, Depth Loss=0.0000000] 
Training progress:  88%|████████▊ | 1760/2000 [12:49<01:35,  2.52it/s, Loss=0.0010849, Gaussian number=182284, print grad=3.027075217687525e-05, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1760/2000 [12:53<01:35,  2.52it/s, Loss=0.0008764, Gaussian number=182284, print grad=3.496805948088877e-05, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1770/2000 [12:53<01:31,  2.52it/s, Loss=0.0008764, Gaussian number=182284, print grad=3.496805948088877e-05, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1770/2000 [12:57<01:31,  2.52it/s, Loss=0.0010454, Gaussian number=182284, print grad=3.96710165659897e-05, Depth Loss=0.0000000] 
Training progress:  89%|████████▉ | 1780/2000 [12:57<01:27,  2.52it/s, Loss=0.0010454, Gaussian number=182284, print grad=3.96710165659897e-05, Depth Loss=0.0000000]
Training progress:  89%|████████▉ | 1780/2000 [13:01<01:27,  2.52it/s, Loss=0.0009539, Gaussian number=182284, print grad=4.3859643483301625e-05, Depth Loss=0.0000000]
Training progress:  90%|████████▉ | 1790/2000 [13:01<01:23,  2.52it/s, Loss=0.0009539, Gaussian number=182284, print grad=4.3859643483301625e-05, Depth Loss=0.0000000]
Training progress:  90%|████████▉ | 1790/2000 [13:05<01:23,  2.52it/s, Loss=0.0009844, Gaussian number=182284, print grad=4.922490188619122e-05, Depth Loss=0.0000000] 
Training progress:  90%|█████████ | 1800/2000 [13:05<01:19,  2.52it/s, Loss=0.0009844, Gaussian number=182284, print grad=4.922490188619122e-05, Depth Loss=0.0000000]
Training progress:  90%|█████████ | 1800/2000 [13:09<01:19,  2.52it/s, Loss=0.0010415, Gaussian number=182238, print grad=4.905696641799295e-06, Depth Loss=0.0000000]
Training progress:  90%|█████████ | 1810/2000 [13:09<01:15,  2.52it/s, Loss=0.0010415, Gaussian number=182238, print grad=4.905696641799295e-06, Depth Loss=0.0000000]
Training progress:  90%|█████████ | 1810/2000 [13:13<01:15,  2.52it/s, Loss=0.0009321, Gaussian number=182238, print grad=1.0409829883428756e-05, Depth Loss=0.0000000]
Training progress:  91%|█████████ | 1820/2000 [13:13<01:11,  2.52it/s, Loss=0.0009321, Gaussian number=182238, print grad=1.0409829883428756e-05, Depth Loss=0.0000000]
Training progress:  91%|█████████ | 1820/2000 [13:17<01:11,  2.52it/s, Loss=0.0007817, Gaussian number=182238, print grad=1.4595088032365311e-05, Depth Loss=0.0000000]
Training progress:  92%|█████████▏| 1830/2000 [13:17<01:07,  2.52it/s, Loss=0.0007817, Gaussian number=182238, print grad=1.4595088032365311e-05, Depth Loss=0.0000000]
Training progress:  92%|█████████▏| 1830/2000 [13:21<01:07,  2.52it/s, Loss=0.0008850, Gaussian number=182238, print grad=1.9970460925833322e-05, Depth Loss=0.0000000]
Training progress:  92%|█████████▏| 1840/2000 [13:21<01:03,  2.52it/s, Loss=0.0008850, Gaussian number=182238, print grad=1.9970460925833322e-05, Depth Loss=0.0000000]
Training progress:  92%|█████████▏| 1840/2000 [13:25<01:03,  2.52it/s, Loss=0.0009356, Gaussian number=182238, print grad=2.490369115548674e-05, Depth Loss=0.0000000] 
Training progress:  92%|█████████▎| 1850/2000 [13:25<00:59,  2.52it/s, Loss=0.0009356, Gaussian number=182238, print grad=2.490369115548674e-05, Depth Loss=0.0000000]
Training progress:  92%|█████████▎| 1850/2000 [13:29<00:59,  2.52it/s, Loss=0.0009731, Gaussian number=182238, print grad=2.9257580536068417e-05, Depth Loss=0.0000000]
Training progress:  93%|█████████▎| 1860/2000 [13:29<00:55,  2.52it/s, Loss=0.0009731, Gaussian number=182238, print grad=2.9257580536068417e-05, Depth Loss=0.0000000]
Training progress:  93%|█████████▎| 1860/2000 [13:33<00:55,  2.52it/s, Loss=0.0011194, Gaussian number=182238, print grad=3.49040528817568e-05, Depth Loss=0.0000000]  
Training progress:  94%|█████████▎| 1870/2000 [13:33<00:51,  2.53it/s, Loss=0.0011194, Gaussian number=182238, print grad=3.49040528817568e-05, Depth Loss=0.0000000]
Training progress:  94%|█████████▎| 1870/2000 [13:37<00:51,  2.53it/s, Loss=0.0008581, Gaussian number=182238, print grad=3.993422069470398e-05, Depth Loss=0.0000000]
Training progress:  94%|█████████▍| 1880/2000 [13:37<00:47,  2.50it/s, Loss=0.0008581, Gaussian number=182238, print grad=3.993422069470398e-05, Depth Loss=0.0000000]
Training progress:  94%|█████████▍| 1880/2000 [13:41<00:47,  2.50it/s, Loss=0.0009639, Gaussian number=182238, print grad=4.494238237384707e-05, Depth Loss=0.0000000]
Training progress:  94%|█████████▍| 1890/2000 [13:41<00:43,  2.50it/s, Loss=0.0009639, Gaussian number=182238, print grad=4.494238237384707e-05, Depth Loss=0.0000000]
Training progress:  94%|█████████▍| 1890/2000 [13:45<00:43,  2.50it/s, Loss=0.0011420, Gaussian number=182238, print grad=5.015159695176408e-05, Depth Loss=0.0000000]
Training progress:  95%|█████████▌| 1900/2000 [13:45<00:39,  2.51it/s, Loss=0.0011420, Gaussian number=182238, print grad=5.015159695176408e-05, Depth Loss=0.0000000]
Training progress:  95%|█████████▌| 1900/2000 [13:49<00:39,  2.51it/s, Loss=0.0010661, Gaussian number=182204, print grad=4.212187377561349e-06, Depth Loss=0.0000000]
Training progress:  96%|█████████▌| 1910/2000 [13:49<00:35,  2.51it/s, Loss=0.0010661, Gaussian number=182204, print grad=4.212187377561349e-06, Depth Loss=0.0000000]
Training progress:  96%|█████████▌| 1910/2000 [13:53<00:35,  2.51it/s, Loss=0.0008332, Gaussian number=182204, print grad=9.03202726476593e-06, Depth Loss=0.0000000] 
Training progress:  96%|█████████▌| 1920/2000 [13:53<00:31,  2.51it/s, Loss=0.0008332, Gaussian number=182204, print grad=9.03202726476593e-06, Depth Loss=0.0000000]
Training progress:  96%|█████████▌| 1920/2000 [13:57<00:31,  2.51it/s, Loss=0.0007557, Gaussian number=182204, print grad=1.415357746736845e-05, Depth Loss=0.0000000]
Training progress:  96%|█████████▋| 1930/2000 [13:57<00:27,  2.52it/s, Loss=0.0007557, Gaussian number=182204, print grad=1.415357746736845e-05, Depth Loss=0.0000000]
Training progress:  96%|█████████▋| 1930/2000 [14:01<00:27,  2.52it/s, Loss=0.0010695, Gaussian number=182204, print grad=1.9071072529186495e-05, Depth Loss=0.0000000]
Training progress:  97%|█████████▋| 1940/2000 [14:01<00:23,  2.52it/s, Loss=0.0010695, Gaussian number=182204, print grad=1.9071072529186495e-05, Depth Loss=0.0000000]
Training progress:  97%|█████████▋| 1940/2000 [14:05<00:23,  2.52it/s, Loss=0.0008334, Gaussian number=182204, print grad=2.3935546778375283e-05, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1950/2000 [14:05<00:19,  2.52it/s, Loss=0.0008334, Gaussian number=182204, print grad=2.3935546778375283e-05, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1950/2000 [14:09<00:19,  2.52it/s, Loss=0.0013080, Gaussian number=182204, print grad=2.8631049644900486e-05, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1960/2000 [14:09<00:15,  2.52it/s, Loss=0.0013080, Gaussian number=182204, print grad=2.8631049644900486e-05, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1960/2000 [14:13<00:15,  2.52it/s, Loss=0.0010944, Gaussian number=182204, print grad=3.358762842253782e-05, Depth Loss=0.0000000] 
Training progress:  98%|█████████▊| 1970/2000 [14:13<00:11,  2.52it/s, Loss=0.0010944, Gaussian number=182204, print grad=3.358762842253782e-05, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1970/2000 [14:17<00:11,  2.52it/s, Loss=0.0009413, Gaussian number=182204, print grad=3.861623554257676e-05, Depth Loss=0.0000000]
Training progress:  99%|█████████▉| 1980/2000 [14:17<00:07,  2.53it/s, Loss=0.0009413, Gaussian number=182204, print grad=3.861623554257676e-05, Depth Loss=0.0000000]
Training progress:  99%|█████████▉| 1980/2000 [14:20<00:07,  2.53it/s, Loss=0.0009245, Gaussian number=182204, print grad=4.3966683733742684e-05, Depth Loss=0.0000000]
Training progress: 100%|█████████▉| 1990/2000 [14:20<00:03,  2.53it/s, Loss=0.0009245, Gaussian number=182204, print grad=4.3966683733742684e-05, Depth Loss=0.0000000]
Training progress: 100%|█████████▉| 1990/2000 [14:24<00:03,  2.53it/s, Loss=0.0007787, Gaussian number=182204, print grad=4.93892548547592e-05, Depth Loss=0.0000000]  
Training progress: 100%|██████████| 2000/2000 [14:24<00:00,  2.53it/s, Loss=0.0007787, Gaussian number=182204, print grad=4.93892548547592e-05, Depth Loss=0.0000000]
Training progress: 100%|██████████| 2000/2000 [14:24<00:00,  2.31it/s, Loss=0.0007787, Gaussian number=182204, print grad=4.93892548547592e-05, Depth Loss=0.0000000]
Iteration 100 [15/11 00:53:04]

[ITER 100] Evaluating test: WD 0.001979, PSNR 12.9384 [15/11 00:53:10]

[ITER 100] Evaluating train: WD 0.002061, PSNR 13.2951 [15/11 00:53:11]
Gaussian number:182686,print gradients:2.809113937018992e-07 [15/11 00:53:11]
Iteration 200 [15/11 00:53:51]

[ITER 200] Evaluating test: WD 0.001753, PSNR 14.2245 [15/11 00:53:57]

[ITER 200] Evaluating train: WD 0.001779, PSNR 14.3938 [15/11 00:53:57]
Gaussian number:182686,print gradients:3.625880822255567e-07 [15/11 00:53:58]
Iteration 300 [15/11 00:54:37]

[ITER 300] Evaluating test: WD 0.001602, PSNR 14.9457 [15/11 00:54:43]

[ITER 300] Evaluating train: WD 0.001626, PSNR 15.2077 [15/11 00:54:44]
Gaussian number:182686,print gradients:4.1357805002917303e-07 [15/11 00:54:44]
Iteration 400 [15/11 00:55:23]

[ITER 400] Evaluating test: WD 0.001532, PSNR 15.3880 [15/11 00:55:29]

[ITER 400] Evaluating train: WD 0.001551, PSNR 15.7803 [15/11 00:55:30]
Gaussian number:182686,print gradients:4.4613102545554284e-07 [15/11 00:55:30]
Iteration 500 [15/11 00:56:09]

[ITER 500] Evaluating test: WD 0.001443, PSNR 15.8224 [15/11 00:56:15]

[ITER 500] Evaluating train: WD 0.001552, PSNR 15.8531 [15/11 00:56:16]
Gaussian number:182686,print gradients:4.825405426345242e-07 [15/11 00:56:16]
Iteration 600 [15/11 00:56:55]

[ITER 600] Evaluating test: WD 0.001383, PSNR 16.0800 [15/11 00:57:01]

[ITER 600] Evaluating train: WD 0.001449, PSNR 16.1101 [15/11 00:57:02]
Gaussian number:182686,print gradients:5.081401468487456e-07 [15/11 00:57:02]
Iteration 700 [15/11 00:57:41]

[ITER 700] Evaluating test: WD 0.001355, PSNR 16.2423 [15/11 00:57:47]

[ITER 700] Evaluating train: WD 0.001403, PSNR 16.2207 [15/11 00:57:48]
Gaussian number:182665,print gradients:6.744082838849863e-07 [15/11 00:57:48]
Iteration 800 [15/11 00:58:27]

[ITER 800] Evaluating test: WD 0.001290, PSNR 16.4581 [15/11 00:58:33]

[ITER 800] Evaluating train: WD 0.001345, PSNR 16.4864 [15/11 00:58:33]
Gaussian number:182638,print gradients:6.674572432530113e-07 [15/11 00:58:34]
Iteration 900 [15/11 00:59:13]

[ITER 900] Evaluating test: WD 0.001269, PSNR 16.5709 [15/11 00:59:19]

[ITER 900] Evaluating train: WD 0.001364, PSNR 16.5813 [15/11 00:59:19]
Gaussian number:182615,print gradients:6.906748239998706e-07 [15/11 00:59:19]
Iteration 1000 [15/11 00:59:59]

[ITER 1000] Evaluating test: WD 0.001252, PSNR 16.6681 [15/11 01:00:04]

[ITER 1000] Evaluating train: WD 0.001354, PSNR 16.5925 [15/11 01:00:05]
Gaussian number:182583,print gradients:6.820722546763136e-07 [15/11 01:00:05]
Iteration 1100 [15/11 01:00:44]
Iteration 1200 [15/11 01:01:24]
Iteration 1300 [15/11 01:02:04]
Iteration 1400 [15/11 01:02:43]
Iteration 1500 [15/11 01:03:23]

[ITER 1500] Evaluating test: WD 0.001123, PSNR 17.1963 [15/11 01:03:29]

[ITER 1500] Evaluating train: WD 0.001196, PSNR 17.2800 [15/11 01:03:29]
Gaussian number:182410,print gradients:7.505726102863264e-07 [15/11 01:03:29]
Iteration 1600 [15/11 01:04:09]
Iteration 1700 [15/11 01:04:48]
Iteration 1800 [15/11 01:05:28]
Iteration 1900 [15/11 01:06:08]
Iteration 2000 [15/11 01:06:47]

[ITER 2000] Evaluating test: WD 0.001038, PSNR 17.6166 [15/11 01:06:53]

[ITER 2000] Evaluating train: WD 0.001152, PSNR 17.7137 [15/11 01:06:54]
Gaussian number:182204,print gradients:7.553877594546066e-07 [15/11 01:06:54]

[ITER 2000] Saving Gaussians [15/11 01:06:54]

Training complete. [15/11 01:06:55]
