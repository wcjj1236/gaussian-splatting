Optimizing /home/cw4287/gaussian-model/train_30k
Output folder: /home/cw4287/gaussian-model/train_30k [02/12 23:34:12]
Tensorboard not available: not logging progress [02/12 23:34:12]
------------LLFF HOLD------------- [02/12 23:34:13]

Reading camera 1/301
Reading camera 2/301
Reading camera 3/301
Reading camera 4/301
Reading camera 5/301
Reading camera 6/301
Reading camera 7/301
Reading camera 8/301
Reading camera 9/301
Reading camera 10/301
Reading camera 11/301
Reading camera 12/301
Reading camera 13/301
Reading camera 14/301
Reading camera 15/301
Reading camera 16/301
Reading camera 17/301
Reading camera 18/301
Reading camera 19/301
Reading camera 20/301
Reading camera 21/301
Reading camera 22/301
Reading camera 23/301
Reading camera 24/301
Reading camera 25/301
Reading camera 26/301
Reading camera 27/301
Reading camera 28/301
Reading camera 29/301
Reading camera 30/301
Reading camera 31/301
Reading camera 32/301
Reading camera 33/301
Reading camera 34/301
Reading camera 35/301
Reading camera 36/301
Reading camera 37/301
Reading camera 38/301
Reading camera 39/301
Reading camera 40/301
Reading camera 41/301
Reading camera 42/301
Reading camera 43/301
Reading camera 44/301
Reading camera 45/301
Reading camera 46/301
Reading camera 47/301
Reading camera 48/301
Reading camera 49/301
Reading camera 50/301
Reading camera 51/301
Reading camera 52/301
Reading camera 53/301
Reading camera 54/301
Reading camera 55/301
Reading camera 56/301
Reading camera 57/301
Reading camera 58/301
Reading camera 59/301
Reading camera 60/301
Reading camera 61/301
Reading camera 62/301
Reading camera 63/301
Reading camera 64/301
Reading camera 65/301
Reading camera 66/301
Reading camera 67/301
Reading camera 68/301
Reading camera 69/301
Reading camera 70/301
Reading camera 71/301
Reading camera 72/301
Reading camera 73/301
Reading camera 74/301
Reading camera 75/301
Reading camera 76/301
Reading camera 77/301
Reading camera 78/301
Reading camera 79/301
Reading camera 80/301
Reading camera 81/301
Reading camera 82/301
Reading camera 83/301
Reading camera 84/301
Reading camera 85/301
Reading camera 86/301
Reading camera 87/301
Reading camera 88/301
Reading camera 89/301
Reading camera 90/301
Reading camera 91/301
Reading camera 92/301
Reading camera 93/301
Reading camera 94/301
Reading camera 95/301
Reading camera 96/301
Reading camera 97/301
Reading camera 98/301
Reading camera 99/301
Reading camera 100/301
Reading camera 101/301
Reading camera 102/301
Reading camera 103/301
Reading camera 104/301
Reading camera 105/301
Reading camera 106/301
Reading camera 107/301
Reading camera 108/301
Reading camera 109/301
Reading camera 110/301
Reading camera 111/301
Reading camera 112/301
Reading camera 113/301
Reading camera 114/301
Reading camera 115/301
Reading camera 116/301
Reading camera 117/301
Reading camera 118/301
Reading camera 119/301
Reading camera 120/301
Reading camera 121/301
Reading camera 122/301
Reading camera 123/301
Reading camera 124/301
Reading camera 125/301
Reading camera 126/301
Reading camera 127/301
Reading camera 128/301
Reading camera 129/301
Reading camera 130/301
Reading camera 131/301
Reading camera 132/301
Reading camera 133/301
Reading camera 134/301
Reading camera 135/301
Reading camera 136/301
Reading camera 137/301
Reading camera 138/301
Reading camera 139/301
Reading camera 140/301
Reading camera 141/301
Reading camera 142/301
Reading camera 143/301
Reading camera 144/301
Reading camera 145/301
Reading camera 146/301
Reading camera 147/301
Reading camera 148/301
Reading camera 149/301
Reading camera 150/301
Reading camera 151/301
Reading camera 152/301
Reading camera 153/301
Reading camera 154/301
Reading camera 155/301
Reading camera 156/301
Reading camera 157/301
Reading camera 158/301
Reading camera 159/301
Reading camera 160/301
Reading camera 161/301
Reading camera 162/301
Reading camera 163/301
Reading camera 164/301
Reading camera 165/301
Reading camera 166/301
Reading camera 167/301
Reading camera 168/301
Reading camera 169/301
Reading camera 170/301
Reading camera 171/301
Reading camera 172/301
Reading camera 173/301
Reading camera 174/301
Reading camera 175/301
Reading camera 176/301
Reading camera 177/301
Reading camera 178/301
Reading camera 179/301
Reading camera 180/301
Reading camera 181/301
Reading camera 182/301
Reading camera 183/301
Reading camera 184/301
Reading camera 185/301
Reading camera 186/301
Reading camera 187/301
Reading camera 188/301
Reading camera 189/301
Reading camera 190/301
Reading camera 191/301
Reading camera 192/301
Reading camera 193/301
Reading camera 194/301
Reading camera 195/301
Reading camera 196/301
Reading camera 197/301
Reading camera 198/301
Reading camera 199/301
Reading camera 200/301
Reading camera 201/301
Reading camera 202/301
Reading camera 203/301
Reading camera 204/301
Reading camera 205/301
Reading camera 206/301
Reading camera 207/301
Reading camera 208/301
Reading camera 209/301
Reading camera 210/301
Reading camera 211/301
Reading camera 212/301
Reading camera 213/301
Reading camera 214/301
Reading camera 215/301
Reading camera 216/301
Reading camera 217/301
Reading camera 218/301
Reading camera 219/301
Reading camera 220/301
Reading camera 221/301
Reading camera 222/301
Reading camera 223/301
Reading camera 224/301
Reading camera 225/301
Reading camera 226/301
Reading camera 227/301
Reading camera 228/301
Reading camera 229/301
Reading camera 230/301
Reading camera 231/301
Reading camera 232/301
Reading camera 233/301
Reading camera 234/301
Reading camera 235/301
Reading camera 236/301
Reading camera 237/301
Reading camera 238/301
Reading camera 239/301
Reading camera 240/301
Reading camera 241/301
Reading camera 242/301
Reading camera 243/301
Reading camera 244/301
Reading camera 245/301
Reading camera 246/301
Reading camera 247/301
Reading camera 248/301
Reading camera 249/301
Reading camera 250/301
Reading camera 251/301
Reading camera 252/301
Reading camera 253/301
Reading camera 254/301
Reading camera 255/301
Reading camera 256/301
Reading camera 257/301
Reading camera 258/301
Reading camera 259/301
Reading camera 260/301
Reading camera 261/301
Reading camera 262/301
Reading camera 263/301
Reading camera 264/301
Reading camera 265/301
Reading camera 266/301
Reading camera 267/301
Reading camera 268/301
Reading camera 269/301
Reading camera 270/301
Reading camera 271/301
Reading camera 272/301
Reading camera 273/301
Reading camera 274/301
Reading camera 275/301
Reading camera 276/301
Reading camera 277/301
Reading camera 278/301
Reading camera 279/301
Reading camera 280/301
Reading camera 281/301
Reading camera 282/301
Reading camera 283/301
Reading camera 284/301
Reading camera 285/301
Reading camera 286/301
Reading camera 287/301
Reading camera 288/301
Reading camera 289/301
Reading camera 290/301
Reading camera 291/301
Reading camera 292/301
Reading camera 293/301
Reading camera 294/301
Reading camera 295/301
Reading camera 296/301
Reading camera 297/301
Reading camera 298/301
Reading camera 299/301
Reading camera 300/301
Reading camera 301/301 [02/12 23:34:13]
Loading Training Cameras [02/12 23:34:13]
Loading Test Cameras [02/12 23:34:29]
Number of points at initialisation :  182686 [02/12 23:34:31]

Training progress:   0%|          | 0/2000 [00:00<?, ?it/s]/ext3/conda/envs/3dgs/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/ext3/conda/envs/3dgs/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)

Training progress:   0%|          | 0/2000 [00:05<?, ?it/s, Loss=0.0232755, Gaussian number=182686, print grad=1.157429869635962e-05, Depth Loss=0.0000000]
Training progress:   0%|          | 10/2000 [00:05<18:54,  1.75it/s, Loss=0.0232755, Gaussian number=182686, print grad=1.157429869635962e-05, Depth Loss=0.0000000]
Training progress:   0%|          | 10/2000 [00:09<18:54,  1.75it/s, Loss=0.0215830, Gaussian number=182686, print grad=2.9623481168528087e-05, Depth Loss=0.0000000]
Training progress:   1%|          | 20/2000 [00:09<15:35,  2.12it/s, Loss=0.0215830, Gaussian number=182686, print grad=2.9623481168528087e-05, Depth Loss=0.0000000]
Training progress:   1%|          | 20/2000 [00:13<15:35,  2.12it/s, Loss=0.0214410, Gaussian number=182686, print grad=4.6736127842450514e-05, Depth Loss=0.0000000]
Training progress:   2%|▏         | 30/2000 [00:13<14:27,  2.27it/s, Loss=0.0214410, Gaussian number=182686, print grad=4.6736127842450514e-05, Depth Loss=0.0000000]
Training progress:   2%|▏         | 30/2000 [00:17<14:27,  2.27it/s, Loss=0.0230202, Gaussian number=182686, print grad=6.426741310860962e-05, Depth Loss=0.0000000] 
Training progress:   2%|▏         | 40/2000 [00:17<13:54,  2.35it/s, Loss=0.0230202, Gaussian number=182686, print grad=6.426741310860962e-05, Depth Loss=0.0000000]
Training progress:   2%|▏         | 40/2000 [00:21<13:54,  2.35it/s, Loss=0.0176456, Gaussian number=182686, print grad=7.894963346188888e-05, Depth Loss=0.0000000]
Training progress:   2%|▎         | 50/2000 [00:21<13:33,  2.40it/s, Loss=0.0176456, Gaussian number=182686, print grad=7.894963346188888e-05, Depth Loss=0.0000000]
Training progress:   2%|▎         | 50/2000 [00:25<13:33,  2.40it/s, Loss=0.0192942, Gaussian number=182686, print grad=0.00010007408855017275, Depth Loss=0.0000000]
Training progress:   3%|▎         | 60/2000 [00:25<13:19,  2.43it/s, Loss=0.0192942, Gaussian number=182686, print grad=0.00010007408855017275, Depth Loss=0.0000000]
Training progress:   3%|▎         | 60/2000 [00:29<13:19,  2.43it/s, Loss=0.0172644, Gaussian number=182686, print grad=0.00012570834951475263, Depth Loss=0.0000000]
Training progress:   4%|▎         | 70/2000 [00:29<13:08,  2.45it/s, Loss=0.0172644, Gaussian number=182686, print grad=0.00012570834951475263, Depth Loss=0.0000000]
Training progress:   4%|▎         | 70/2000 [00:33<13:08,  2.45it/s, Loss=0.0215175, Gaussian number=182686, print grad=0.00014647394709754735, Depth Loss=0.0000000]
Training progress:   4%|▍         | 80/2000 [00:33<13:00,  2.46it/s, Loss=0.0215175, Gaussian number=182686, print grad=0.00014647394709754735, Depth Loss=0.0000000]
Training progress:   4%|▍         | 80/2000 [00:37<13:00,  2.46it/s, Loss=0.0181226, Gaussian number=182686, print grad=0.00016833360132295638, Depth Loss=0.0000000]
Training progress:   4%|▍         | 90/2000 [00:37<12:53,  2.47it/s, Loss=0.0181226, Gaussian number=182686, print grad=0.00016833360132295638, Depth Loss=0.0000000]
Training progress:   4%|▍         | 90/2000 [00:41<12:53,  2.47it/s, Loss=0.0172426, Gaussian number=182686, print grad=0.0001935174805112183, Depth Loss=0.0000000] 
Training progress:   5%|▌         | 100/2000 [00:41<12:47,  2.47it/s, Loss=0.0172426, Gaussian number=182686, print grad=0.0001935174805112183, Depth Loss=0.0000000]
Training progress:   5%|▌         | 100/2000 [01:49<12:47,  2.47it/s, Loss=0.0201414, Gaussian number=182686, print grad=0.0002206100180046633, Depth Loss=0.0000000]
Training progress:   6%|▌         | 110/2000 [01:49<1:14:02,  2.35s/it, Loss=0.0201414, Gaussian number=182686, print grad=0.0002206100180046633, Depth Loss=0.0000000]
Training progress:   6%|▌         | 110/2000 [01:53<1:14:02,  2.35s/it, Loss=0.0166011, Gaussian number=182686, print grad=0.00024626852246001363, Depth Loss=0.0000000]
Training progress:   6%|▌         | 120/2000 [01:53<55:02,  1.76s/it, Loss=0.0166011, Gaussian number=182686, print grad=0.00024626852246001363, Depth Loss=0.0000000]  
Training progress:   6%|▌         | 120/2000 [01:57<55:02,  1.76s/it, Loss=0.0189687, Gaussian number=182686, print grad=0.00027765953564085066, Depth Loss=0.0000000]
Training progress:   6%|▋         | 130/2000 [01:57<41:56,  1.35s/it, Loss=0.0189687, Gaussian number=182686, print grad=0.00027765953564085066, Depth Loss=0.0000000]
Training progress:   6%|▋         | 130/2000 [02:01<41:56,  1.35s/it, Loss=0.0171475, Gaussian number=182686, print grad=0.0003092742117587477, Depth Loss=0.0000000] 
Training progress:   7%|▋         | 140/2000 [02:01<32:52,  1.06s/it, Loss=0.0171475, Gaussian number=182686, print grad=0.0003092742117587477, Depth Loss=0.0000000]
Training progress:   7%|▋         | 140/2000 [02:05<32:52,  1.06s/it, Loss=0.0151872, Gaussian number=182686, print grad=0.0003377940447535366, Depth Loss=0.0000000]
Training progress:   8%|▊         | 150/2000 [02:05<26:33,  1.16it/s, Loss=0.0151872, Gaussian number=182686, print grad=0.0003377940447535366, Depth Loss=0.0000000]
Training progress:   8%|▊         | 150/2000 [02:09<26:33,  1.16it/s, Loss=0.0161889, Gaussian number=182686, print grad=0.00037261220859363675, Depth Loss=0.0000000]
Training progress:   8%|▊         | 160/2000 [02:09<22:08,  1.39it/s, Loss=0.0161889, Gaussian number=182686, print grad=0.00037261220859363675, Depth Loss=0.0000000]
Training progress:   8%|▊         | 160/2000 [02:13<22:08,  1.39it/s, Loss=0.0162388, Gaussian number=182686, print grad=0.00040182165685109794, Depth Loss=0.0000000]
Training progress:   8%|▊         | 170/2000 [02:13<19:03,  1.60it/s, Loss=0.0162388, Gaussian number=182686, print grad=0.00040182165685109794, Depth Loss=0.0000000]
Training progress:   8%|▊         | 170/2000 [02:17<19:03,  1.60it/s, Loss=0.0135407, Gaussian number=182686, print grad=0.0004337626160122454, Depth Loss=0.0000000] 
Training progress:   9%|▉         | 180/2000 [02:17<16:54,  1.79it/s, Loss=0.0135407, Gaussian number=182686, print grad=0.0004337626160122454, Depth Loss=0.0000000]
Training progress:   9%|▉         | 180/2000 [02:21<16:54,  1.79it/s, Loss=0.0176431, Gaussian number=182686, print grad=0.00046276833745650947, Depth Loss=0.0000000]
Training progress:  10%|▉         | 190/2000 [02:21<15:23,  1.96it/s, Loss=0.0176431, Gaussian number=182686, print grad=0.00046276833745650947, Depth Loss=0.0000000]
Training progress:  10%|▉         | 190/2000 [02:25<15:23,  1.96it/s, Loss=0.0150355, Gaussian number=182686, print grad=0.0004972428432665765, Depth Loss=0.0000000] 
Training progress:  10%|█         | 200/2000 [02:25<14:17,  2.10it/s, Loss=0.0150355, Gaussian number=182686, print grad=0.0004972428432665765, Depth Loss=0.0000000]
Training progress:  10%|█         | 200/2000 [03:33<14:17,  2.10it/s, Loss=0.0169820, Gaussian number=182686, print grad=0.0005323354853317142, Depth Loss=0.0000000]
Training progress:  10%|█         | 210/2000 [03:33<1:10:23,  2.36s/it, Loss=0.0169820, Gaussian number=182686, print grad=0.0005323354853317142, Depth Loss=0.0000000]
Training progress:  10%|█         | 210/2000 [03:36<1:10:23,  2.36s/it, Loss=0.0137032, Gaussian number=182686, print grad=0.0005644458578899503, Depth Loss=0.0000000]
Training progress:  11%|█         | 220/2000 [03:36<52:32,  1.77s/it, Loss=0.0137032, Gaussian number=182686, print grad=0.0005644458578899503, Depth Loss=0.0000000]  
Training progress:  11%|█         | 220/2000 [03:40<52:32,  1.77s/it, Loss=0.0153175, Gaussian number=182686, print grad=0.0005981998401694, Depth Loss=0.0000000]   
Training progress:  12%|█▏        | 230/2000 [03:40<40:05,  1.36s/it, Loss=0.0153175, Gaussian number=182686, print grad=0.0005981998401694, Depth Loss=0.0000000]
Training progress:  12%|█▏        | 230/2000 [03:44<40:05,  1.36s/it, Loss=0.0192585, Gaussian number=182686, print grad=0.0006296969950199127, Depth Loss=0.0000000]
Training progress:  12%|█▏        | 240/2000 [03:44<31:24,  1.07s/it, Loss=0.0192585, Gaussian number=182686, print grad=0.0006296969950199127, Depth Loss=0.0000000]
Training progress:  12%|█▏        | 240/2000 [03:48<31:24,  1.07s/it, Loss=0.0147059, Gaussian number=182686, print grad=0.000664431368932128, Depth Loss=0.0000000] 
Training progress:  12%|█▎        | 250/2000 [03:48<25:19,  1.15it/s, Loss=0.0147059, Gaussian number=182686, print grad=0.000664431368932128, Depth Loss=0.0000000]
Training progress:  12%|█▎        | 250/2000 [03:52<25:19,  1.15it/s, Loss=0.0165877, Gaussian number=182686, print grad=0.0006962253246456385, Depth Loss=0.0000000]
Training progress:  13%|█▎        | 260/2000 [03:52<21:04,  1.38it/s, Loss=0.0165877, Gaussian number=182686, print grad=0.0006962253246456385, Depth Loss=0.0000000]
Training progress:  13%|█▎        | 260/2000 [03:56<21:04,  1.38it/s, Loss=0.0112869, Gaussian number=182686, print grad=0.0007302201120182872, Depth Loss=0.0000000]
Training progress:  14%|█▎        | 270/2000 [03:56<18:06,  1.59it/s, Loss=0.0112869, Gaussian number=182686, print grad=0.0007302201120182872, Depth Loss=0.0000000]
Training progress:  14%|█▎        | 270/2000 [04:00<18:06,  1.59it/s, Loss=0.0146709, Gaussian number=182686, print grad=0.0007669000187888741, Depth Loss=0.0000000]
Training progress:  14%|█▍        | 280/2000 [04:00<16:00,  1.79it/s, Loss=0.0146709, Gaussian number=182686, print grad=0.0007669000187888741, Depth Loss=0.0000000]
Training progress:  14%|█▍        | 280/2000 [04:04<16:00,  1.79it/s, Loss=0.0150469, Gaussian number=182686, print grad=0.000803066068328917, Depth Loss=0.0000000] 
Training progress:  14%|█▍        | 290/2000 [04:04<14:32,  1.96it/s, Loss=0.0150469, Gaussian number=182686, print grad=0.000803066068328917, Depth Loss=0.0000000]
Training progress:  14%|█▍        | 290/2000 [04:08<14:32,  1.96it/s, Loss=0.0142178, Gaussian number=182686, print grad=0.0008406238630414009, Depth Loss=0.0000000]
Training progress:  15%|█▌        | 300/2000 [04:08<13:29,  2.10it/s, Loss=0.0142178, Gaussian number=182686, print grad=0.0008406238630414009, Depth Loss=0.0000000]
Training progress:  15%|█▌        | 300/2000 [05:16<13:29,  2.10it/s, Loss=0.0116325, Gaussian number=182686, print grad=0.0008783394587226212, Depth Loss=0.0000000]
Training progress:  16%|█▌        | 310/2000 [05:16<1:06:25,  2.36s/it, Loss=0.0116325, Gaussian number=182686, print grad=0.0008783394587226212, Depth Loss=0.0000000]
Training progress:  16%|█▌        | 310/2000 [05:20<1:06:25,  2.36s/it, Loss=0.0120061, Gaussian number=182686, print grad=0.0009071583044715226, Depth Loss=0.0000000]
Training progress:  16%|█▌        | 320/2000 [05:20<49:32,  1.77s/it, Loss=0.0120061, Gaussian number=182686, print grad=0.0009071583044715226, Depth Loss=0.0000000]  
Training progress:  16%|█▌        | 320/2000 [05:24<49:32,  1.77s/it, Loss=0.0161283, Gaussian number=182686, print grad=0.0009399267146363854, Depth Loss=0.0000000]
Training progress:  16%|█▋        | 330/2000 [05:24<37:46,  1.36s/it, Loss=0.0161283, Gaussian number=182686, print grad=0.0009399267146363854, Depth Loss=0.0000000]
Training progress:  16%|█▋        | 330/2000 [05:28<37:46,  1.36s/it, Loss=0.0114479, Gaussian number=182686, print grad=0.000977870891802013, Depth Loss=0.0000000] 
Training progress:  17%|█▋        | 340/2000 [05:28<29:33,  1.07s/it, Loss=0.0114479, Gaussian number=182686, print grad=0.000977870891802013, Depth Loss=0.0000000]
Training progress:  17%|█▋        | 340/2000 [05:32<29:33,  1.07s/it, Loss=0.0122201, Gaussian number=182686, print grad=0.0010128520661965013, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 350/2000 [05:32<23:50,  1.15it/s, Loss=0.0122201, Gaussian number=182686, print grad=0.0010128520661965013, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 350/2000 [05:36<23:50,  1.15it/s, Loss=0.0118411, Gaussian number=182686, print grad=0.0010535650653764606, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 360/2000 [05:36<19:49,  1.38it/s, Loss=0.0118411, Gaussian number=182686, print grad=0.0010535650653764606, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 360/2000 [05:39<19:49,  1.38it/s, Loss=0.0110740, Gaussian number=182686, print grad=0.0010895850136876106, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 370/2000 [05:39<17:00,  1.60it/s, Loss=0.0110740, Gaussian number=182686, print grad=0.0010895850136876106, Depth Loss=0.0000000]
Training progress:  18%|█▊        | 370/2000 [05:43<17:00,  1.60it/s, Loss=0.0154916, Gaussian number=182686, print grad=0.0011210034135729074, Depth Loss=0.0000000]
Training progress:  19%|█▉        | 380/2000 [05:43<15:01,  1.80it/s, Loss=0.0154916, Gaussian number=182686, print grad=0.0011210034135729074, Depth Loss=0.0000000]
Training progress:  19%|█▉        | 380/2000 [05:47<15:01,  1.80it/s, Loss=0.0134976, Gaussian number=182686, print grad=0.0011596865952014923, Depth Loss=0.0000000]
Training progress:  20%|█▉        | 390/2000 [05:47<13:38,  1.97it/s, Loss=0.0134976, Gaussian number=182686, print grad=0.0011596865952014923, Depth Loss=0.0000000]
Training progress:  20%|█▉        | 390/2000 [05:51<13:38,  1.97it/s, Loss=0.0164970, Gaussian number=182686, print grad=0.001195769407786429, Depth Loss=0.0000000] 
Training progress:  20%|██        | 400/2000 [05:51<12:38,  2.11it/s, Loss=0.0164970, Gaussian number=182686, print grad=0.001195769407786429, Depth Loss=0.0000000]
Training progress:  20%|██        | 400/2000 [05:55<12:38,  2.11it/s, Loss=0.0140432, Gaussian number=182686, print grad=0.001238020951859653, Depth Loss=0.0000000]
Training progress:  20%|██        | 410/2000 [05:55<11:56,  2.22it/s, Loss=0.0140432, Gaussian number=182686, print grad=0.001238020951859653, Depth Loss=0.0000000]
Training progress:  20%|██        | 410/2000 [05:59<11:56,  2.22it/s, Loss=0.0123464, Gaussian number=182686, print grad=0.001278865267522633, Depth Loss=0.0000000]
Training progress:  21%|██        | 420/2000 [05:59<11:26,  2.30it/s, Loss=0.0123464, Gaussian number=182686, print grad=0.001278865267522633, Depth Loss=0.0000000]
Training progress:  21%|██        | 420/2000 [06:03<11:26,  2.30it/s, Loss=0.0156041, Gaussian number=182686, print grad=0.0013205274008214474, Depth Loss=0.0000000]
Training progress:  22%|██▏       | 430/2000 [06:03<11:03,  2.37it/s, Loss=0.0156041, Gaussian number=182686, print grad=0.0013205274008214474, Depth Loss=0.0000000]
Training progress:  22%|██▏       | 430/2000 [06:07<11:03,  2.37it/s, Loss=0.0121062, Gaussian number=182686, print grad=0.001358356443233788, Depth Loss=0.0000000] 
Training progress:  22%|██▏       | 440/2000 [06:07<10:46,  2.41it/s, Loss=0.0121062, Gaussian number=182686, print grad=0.001358356443233788, Depth Loss=0.0000000]
Training progress:  22%|██▏       | 440/2000 [06:11<10:46,  2.41it/s, Loss=0.0140009, Gaussian number=182686, print grad=0.0013974668690934777, Depth Loss=0.0000000]
Training progress:  22%|██▎       | 450/2000 [06:11<10:32,  2.45it/s, Loss=0.0140009, Gaussian number=182686, print grad=0.0013974668690934777, Depth Loss=0.0000000]
Training progress:  22%|██▎       | 450/2000 [06:15<10:32,  2.45it/s, Loss=0.0147744, Gaussian number=182686, print grad=0.0014357523759827018, Depth Loss=0.0000000]
Training progress:  23%|██▎       | 460/2000 [06:15<10:22,  2.47it/s, Loss=0.0147744, Gaussian number=182686, print grad=0.0014357523759827018, Depth Loss=0.0000000]
Training progress:  23%|██▎       | 460/2000 [06:19<10:22,  2.47it/s, Loss=0.0173593, Gaussian number=182686, print grad=0.001472514821216464, Depth Loss=0.0000000] 
Training progress:  24%|██▎       | 470/2000 [06:19<10:14,  2.49it/s, Loss=0.0173593, Gaussian number=182686, print grad=0.001472514821216464, Depth Loss=0.0000000]
Training progress:  24%|██▎       | 470/2000 [06:23<10:14,  2.49it/s, Loss=0.0110636, Gaussian number=182686, print grad=0.0015141606563702226, Depth Loss=0.0000000]
Training progress:  24%|██▍       | 480/2000 [06:23<10:07,  2.50it/s, Loss=0.0110636, Gaussian number=182686, print grad=0.0015141606563702226, Depth Loss=0.0000000]
Training progress:  24%|██▍       | 480/2000 [06:27<10:07,  2.50it/s, Loss=0.0123999, Gaussian number=182686, print grad=0.0015521980822086334, Depth Loss=0.0000000]
Training progress:  24%|██▍       | 490/2000 [06:27<10:01,  2.51it/s, Loss=0.0123999, Gaussian number=182686, print grad=0.0015521980822086334, Depth Loss=0.0000000]
Training progress:  24%|██▍       | 490/2000 [06:31<10:01,  2.51it/s, Loss=0.0093349, Gaussian number=182686, print grad=0.0015912004746496677, Depth Loss=0.0000000]
Training progress:  25%|██▌       | 500/2000 [06:31<09:56,  2.52it/s, Loss=0.0093349, Gaussian number=182686, print grad=0.0015912004746496677, Depth Loss=0.0000000]
Training progress:  25%|██▌       | 500/2000 [07:38<09:56,  2.52it/s, Loss=0.0113617, Gaussian number=182686, print grad=0.0016299545532092452, Depth Loss=0.0000000]
Training progress:  26%|██▌       | 510/2000 [07:38<57:10,  2.30s/it, Loss=0.0113617, Gaussian number=182686, print grad=0.0016299545532092452, Depth Loss=0.0000000]
Training progress:  26%|██▌       | 510/2000 [07:42<57:10,  2.30s/it, Loss=0.0117849, Gaussian number=182686, print grad=0.0016709441551938653, Depth Loss=0.0000000]
Training progress:  26%|██▌       | 520/2000 [07:42<42:40,  1.73s/it, Loss=0.0117849, Gaussian number=182686, print grad=0.0016709441551938653, Depth Loss=0.0000000]
Training progress:  26%|██▌       | 520/2000 [07:46<42:40,  1.73s/it, Loss=0.0089388, Gaussian number=182686, print grad=0.0017061581602320075, Depth Loss=0.0000000]
Training progress:  26%|██▋       | 530/2000 [07:46<32:33,  1.33s/it, Loss=0.0089388, Gaussian number=182686, print grad=0.0017061581602320075, Depth Loss=0.0000000]
Training progress:  26%|██▋       | 530/2000 [07:50<32:33,  1.33s/it, Loss=0.0122764, Gaussian number=182686, print grad=0.0017448613652959466, Depth Loss=0.0000000]
Training progress:  27%|██▋       | 540/2000 [07:50<25:30,  1.05s/it, Loss=0.0122764, Gaussian number=182686, print grad=0.0017448613652959466, Depth Loss=0.0000000]
Training progress:  27%|██▋       | 540/2000 [07:54<25:30,  1.05s/it, Loss=0.0115851, Gaussian number=182686, print grad=0.0017863386310636997, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 550/2000 [07:54<20:35,  1.17it/s, Loss=0.0115851, Gaussian number=182686, print grad=0.0017863386310636997, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 550/2000 [07:58<20:35,  1.17it/s, Loss=0.0090625, Gaussian number=182686, print grad=0.0018238562624901533, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 560/2000 [07:58<17:09,  1.40it/s, Loss=0.0090625, Gaussian number=182686, print grad=0.0018238562624901533, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 560/2000 [08:02<17:09,  1.40it/s, Loss=0.0125848, Gaussian number=182686, print grad=0.0018655916210263968, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 570/2000 [08:02<14:44,  1.62it/s, Loss=0.0125848, Gaussian number=182686, print grad=0.0018655916210263968, Depth Loss=0.0000000]
Training progress:  28%|██▊       | 570/2000 [08:06<14:44,  1.62it/s, Loss=0.0109128, Gaussian number=182686, print grad=0.0019063401268795133, Depth Loss=0.0000000]
Training progress:  29%|██▉       | 580/2000 [08:06<13:02,  1.81it/s, Loss=0.0109128, Gaussian number=182686, print grad=0.0019063401268795133, Depth Loss=0.0000000]
Training progress:  29%|██▉       | 580/2000 [08:10<13:02,  1.81it/s, Loss=0.0127894, Gaussian number=182686, print grad=0.0019479356706142426, Depth Loss=0.0000000]
Training progress:  30%|██▉       | 590/2000 [08:10<11:50,  1.98it/s, Loss=0.0127894, Gaussian number=182686, print grad=0.0019479356706142426, Depth Loss=0.0000000]
Training progress:  30%|██▉       | 590/2000 [08:14<11:50,  1.98it/s, Loss=0.0127156, Gaussian number=182686, print grad=0.001986114773899317, Depth Loss=0.0000000] 
Training progress:  30%|███       | 600/2000 [08:14<10:59,  2.12it/s, Loss=0.0127156, Gaussian number=182686, print grad=0.001986114773899317, Depth Loss=0.0000000]
Training progress:  30%|███       | 600/2000 [08:18<10:59,  2.12it/s, Loss=0.0102592, Gaussian number=182693, print grad=3.5697703424375504e-05, Depth Loss=0.0000000]
Training progress:  30%|███       | 610/2000 [08:18<10:23,  2.23it/s, Loss=0.0102592, Gaussian number=182693, print grad=3.5697703424375504e-05, Depth Loss=0.0000000]
Training progress:  30%|███       | 610/2000 [08:22<10:23,  2.23it/s, Loss=0.0139361, Gaussian number=182693, print grad=7.717069092905149e-05, Depth Loss=0.0000000] 
Training progress:  31%|███       | 620/2000 [08:22<09:56,  2.31it/s, Loss=0.0139361, Gaussian number=182693, print grad=7.717069092905149e-05, Depth Loss=0.0000000]
Training progress:  31%|███       | 620/2000 [08:26<09:56,  2.31it/s, Loss=0.0095962, Gaussian number=182693, print grad=0.00011607231863308698, Depth Loss=0.0000000]
Training progress:  32%|███▏      | 630/2000 [08:26<09:37,  2.37it/s, Loss=0.0095962, Gaussian number=182693, print grad=0.00011607231863308698, Depth Loss=0.0000000]
Training progress:  32%|███▏      | 630/2000 [08:30<09:37,  2.37it/s, Loss=0.0104957, Gaussian number=182693, print grad=0.00016018669703043997, Depth Loss=0.0000000]
Training progress:  32%|███▏      | 640/2000 [08:30<09:21,  2.42it/s, Loss=0.0104957, Gaussian number=182693, print grad=0.00016018669703043997, Depth Loss=0.0000000]
Training progress:  32%|███▏      | 640/2000 [08:34<09:21,  2.42it/s, Loss=0.0126022, Gaussian number=182693, print grad=0.00019736020476557314, Depth Loss=0.0000000]
Training progress:  32%|███▎      | 650/2000 [08:34<09:10,  2.45it/s, Loss=0.0126022, Gaussian number=182693, print grad=0.00019736020476557314, Depth Loss=0.0000000]
Training progress:  32%|███▎      | 650/2000 [08:37<09:10,  2.45it/s, Loss=0.0124370, Gaussian number=182693, print grad=0.000240862718783319, Depth Loss=0.0000000]  
Training progress:  33%|███▎      | 660/2000 [08:37<09:01,  2.47it/s, Loss=0.0124370, Gaussian number=182693, print grad=0.000240862718783319, Depth Loss=0.0000000]
Training progress:  33%|███▎      | 660/2000 [08:41<09:01,  2.47it/s, Loss=0.0110258, Gaussian number=182693, print grad=0.0002795221225824207, Depth Loss=0.0000000]
Training progress:  34%|███▎      | 670/2000 [08:41<08:53,  2.49it/s, Loss=0.0110258, Gaussian number=182693, print grad=0.0002795221225824207, Depth Loss=0.0000000]
Training progress:  34%|███▎      | 670/2000 [08:45<08:53,  2.49it/s, Loss=0.0100024, Gaussian number=182693, print grad=0.0003220797807443887, Depth Loss=0.0000000]
Training progress:  34%|███▍      | 680/2000 [08:45<08:46,  2.51it/s, Loss=0.0100024, Gaussian number=182693, print grad=0.0003220797807443887, Depth Loss=0.0000000]
Training progress:  34%|███▍      | 680/2000 [08:49<08:46,  2.51it/s, Loss=0.0122770, Gaussian number=182693, print grad=0.00036241626366972923, Depth Loss=0.0000000]
Training progress:  34%|███▍      | 690/2000 [08:49<08:40,  2.52it/s, Loss=0.0122770, Gaussian number=182693, print grad=0.00036241626366972923, Depth Loss=0.0000000]
Training progress:  34%|███▍      | 690/2000 [08:53<08:40,  2.52it/s, Loss=0.0122065, Gaussian number=182693, print grad=0.0004025832749903202, Depth Loss=0.0000000] 
Training progress:  35%|███▌      | 700/2000 [08:53<08:35,  2.52it/s, Loss=0.0122065, Gaussian number=182693, print grad=0.0004025832749903202, Depth Loss=0.0000000]
Training progress:  35%|███▌      | 700/2000 [08:57<08:35,  2.52it/s, Loss=0.0105661, Gaussian number=182788, print grad=3.6036395613336936e-05, Depth Loss=0.0000000]
Training progress:  36%|███▌      | 710/2000 [08:57<08:30,  2.53it/s, Loss=0.0105661, Gaussian number=182788, print grad=3.6036395613336936e-05, Depth Loss=0.0000000]
Training progress:  36%|███▌      | 710/2000 [09:01<08:30,  2.53it/s, Loss=0.0097402, Gaussian number=182788, print grad=7.562754035461694e-05, Depth Loss=0.0000000] 
Training progress:  36%|███▌      | 720/2000 [09:01<08:26,  2.53it/s, Loss=0.0097402, Gaussian number=182788, print grad=7.562754035461694e-05, Depth Loss=0.0000000]
Training progress:  36%|███▌      | 720/2000 [09:05<08:26,  2.53it/s, Loss=0.0134910, Gaussian number=182788, print grad=0.00011403490498196334, Depth Loss=0.0000000]
Training progress:  36%|███▋      | 730/2000 [09:05<08:21,  2.53it/s, Loss=0.0134910, Gaussian number=182788, print grad=0.00011403490498196334, Depth Loss=0.0000000]
Training progress:  36%|███▋      | 730/2000 [09:09<08:21,  2.53it/s, Loss=0.0151329, Gaussian number=182788, print grad=0.0001582147815497592, Depth Loss=0.0000000] 
Training progress:  37%|███▋      | 740/2000 [09:09<08:17,  2.54it/s, Loss=0.0151329, Gaussian number=182788, print grad=0.0001582147815497592, Depth Loss=0.0000000]
Training progress:  37%|███▋      | 740/2000 [09:13<08:17,  2.54it/s, Loss=0.0106346, Gaussian number=182788, print grad=0.00019956432515755296, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 750/2000 [09:13<08:12,  2.54it/s, Loss=0.0106346, Gaussian number=182788, print grad=0.00019956432515755296, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 750/2000 [09:17<08:12,  2.54it/s, Loss=0.0103322, Gaussian number=182788, print grad=0.00023932931071612984, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 760/2000 [09:17<08:08,  2.54it/s, Loss=0.0103322, Gaussian number=182788, print grad=0.00023932931071612984, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 760/2000 [09:21<08:08,  2.54it/s, Loss=0.0091871, Gaussian number=182788, print grad=0.0002825882693286985, Depth Loss=0.0000000] 
Training progress:  38%|███▊      | 770/2000 [09:21<08:04,  2.54it/s, Loss=0.0091871, Gaussian number=182788, print grad=0.0002825882693286985, Depth Loss=0.0000000]
Training progress:  38%|███▊      | 770/2000 [09:25<08:04,  2.54it/s, Loss=0.0130598, Gaussian number=182788, print grad=0.0003219198842998594, Depth Loss=0.0000000]
Training progress:  39%|███▉      | 780/2000 [09:25<08:00,  2.54it/s, Loss=0.0130598, Gaussian number=182788, print grad=0.0003219198842998594, Depth Loss=0.0000000]
Training progress:  39%|███▉      | 780/2000 [09:29<08:00,  2.54it/s, Loss=0.0149642, Gaussian number=182788, print grad=0.0003628755221143365, Depth Loss=0.0000000]
Training progress:  40%|███▉      | 790/2000 [09:29<07:56,  2.54it/s, Loss=0.0149642, Gaussian number=182788, print grad=0.0003628755221143365, Depth Loss=0.0000000]
Training progress:  40%|███▉      | 790/2000 [09:33<07:56,  2.54it/s, Loss=0.0128048, Gaussian number=182788, print grad=0.0004053153970744461, Depth Loss=0.0000000]
Training progress:  40%|████      | 800/2000 [09:33<07:52,  2.54it/s, Loss=0.0128048, Gaussian number=182788, print grad=0.0004053153970744461, Depth Loss=0.0000000]
Training progress:  40%|████      | 800/2000 [09:37<07:52,  2.54it/s, Loss=0.0116786, Gaussian number=182857, print grad=3.557502350304276e-05, Depth Loss=0.0000000]
Training progress:  40%|████      | 810/2000 [09:37<07:48,  2.54it/s, Loss=0.0116786, Gaussian number=182857, print grad=3.557502350304276e-05, Depth Loss=0.0000000]
Training progress:  40%|████      | 810/2000 [09:41<07:48,  2.54it/s, Loss=0.0116566, Gaussian number=182857, print grad=7.64001888455823e-05, Depth Loss=0.0000000] 
Training progress:  41%|████      | 820/2000 [09:41<07:44,  2.54it/s, Loss=0.0116566, Gaussian number=182857, print grad=7.64001888455823e-05, Depth Loss=0.0000000]
Training progress:  41%|████      | 820/2000 [09:45<07:44,  2.54it/s, Loss=0.0088942, Gaussian number=182857, print grad=0.00012286234414204955, Depth Loss=0.0000000]
Training progress:  42%|████▏     | 830/2000 [09:45<07:43,  2.52it/s, Loss=0.0088942, Gaussian number=182857, print grad=0.00012286234414204955, Depth Loss=0.0000000]
Training progress:  42%|████▏     | 830/2000 [09:48<07:43,  2.52it/s, Loss=0.0101542, Gaussian number=182857, print grad=0.00016453038551844656, Depth Loss=0.0000000]
Training progress:  42%|████▏     | 840/2000 [09:48<07:38,  2.53it/s, Loss=0.0101542, Gaussian number=182857, print grad=0.00016453038551844656, Depth Loss=0.0000000]
Training progress:  42%|████▏     | 840/2000 [09:52<07:38,  2.53it/s, Loss=0.0103616, Gaussian number=182857, print grad=0.0002073688810924068, Depth Loss=0.0000000] 
Training progress:  42%|████▎     | 850/2000 [09:52<07:33,  2.53it/s, Loss=0.0103616, Gaussian number=182857, print grad=0.0002073688810924068, Depth Loss=0.0000000]
Training progress:  42%|████▎     | 850/2000 [09:56<07:33,  2.53it/s, Loss=0.0104164, Gaussian number=182857, print grad=0.00024692501756362617, Depth Loss=0.0000000]
Training progress:  43%|████▎     | 860/2000 [09:56<07:29,  2.54it/s, Loss=0.0104164, Gaussian number=182857, print grad=0.00024692501756362617, Depth Loss=0.0000000]
Training progress:  43%|████▎     | 860/2000 [10:00<07:29,  2.54it/s, Loss=0.0122540, Gaussian number=182857, print grad=0.0002875129284802824, Depth Loss=0.0000000] 
Training progress:  44%|████▎     | 870/2000 [10:00<07:25,  2.54it/s, Loss=0.0122540, Gaussian number=182857, print grad=0.0002875129284802824, Depth Loss=0.0000000]
Training progress:  44%|████▎     | 870/2000 [10:04<07:25,  2.54it/s, Loss=0.0113660, Gaussian number=182857, print grad=0.0003296386275906116, Depth Loss=0.0000000]
Training progress:  44%|████▍     | 880/2000 [10:04<07:21,  2.54it/s, Loss=0.0113660, Gaussian number=182857, print grad=0.0003296386275906116, Depth Loss=0.0000000]
Training progress:  44%|████▍     | 880/2000 [10:08<07:21,  2.54it/s, Loss=0.0091113, Gaussian number=182857, print grad=0.00037036786670796573, Depth Loss=0.0000000]
Training progress:  44%|████▍     | 890/2000 [10:08<07:16,  2.54it/s, Loss=0.0091113, Gaussian number=182857, print grad=0.00037036786670796573, Depth Loss=0.0000000]
Training progress:  44%|████▍     | 890/2000 [10:12<07:16,  2.54it/s, Loss=0.0121683, Gaussian number=182857, print grad=0.00041310800588689744, Depth Loss=0.0000000]
Training progress:  45%|████▌     | 900/2000 [10:12<07:12,  2.54it/s, Loss=0.0121683, Gaussian number=182857, print grad=0.00041310800588689744, Depth Loss=0.0000000]
Training progress:  45%|████▌     | 900/2000 [10:16<07:12,  2.54it/s, Loss=0.0089440, Gaussian number=182933, print grad=3.612708314904012e-05, Depth Loss=0.0000000] 
Training progress:  46%|████▌     | 910/2000 [10:16<07:08,  2.54it/s, Loss=0.0089440, Gaussian number=182933, print grad=3.612708314904012e-05, Depth Loss=0.0000000]
Training progress:  46%|████▌     | 910/2000 [10:20<07:08,  2.54it/s, Loss=0.0109650, Gaussian number=182933, print grad=7.296280091395602e-05, Depth Loss=0.0000000]
Training progress:  46%|████▌     | 920/2000 [10:20<07:04,  2.54it/s, Loss=0.0109650, Gaussian number=182933, print grad=7.296280091395602e-05, Depth Loss=0.0000000]
Training progress:  46%|████▌     | 920/2000 [10:24<07:04,  2.54it/s, Loss=0.0112442, Gaussian number=182933, print grad=0.0001167363952845335, Depth Loss=0.0000000]
Training progress:  46%|████▋     | 930/2000 [10:24<07:00,  2.54it/s, Loss=0.0112442, Gaussian number=182933, print grad=0.0001167363952845335, Depth Loss=0.0000000]
Training progress:  46%|████▋     | 930/2000 [10:28<07:00,  2.54it/s, Loss=0.0104803, Gaussian number=182933, print grad=0.00015708479622844607, Depth Loss=0.0000000]
Training progress:  47%|████▋     | 940/2000 [10:28<06:57,  2.54it/s, Loss=0.0104803, Gaussian number=182933, print grad=0.00015708479622844607, Depth Loss=0.0000000]
Training progress:  47%|████▋     | 940/2000 [10:32<06:57,  2.54it/s, Loss=0.0102495, Gaussian number=182933, print grad=0.0001979456574190408, Depth Loss=0.0000000] 
Training progress:  48%|████▊     | 950/2000 [10:32<06:53,  2.54it/s, Loss=0.0102495, Gaussian number=182933, print grad=0.0001979456574190408, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 950/2000 [10:36<06:53,  2.54it/s, Loss=0.0104160, Gaussian number=182933, print grad=0.00023722912010271102, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 960/2000 [10:36<06:49,  2.54it/s, Loss=0.0104160, Gaussian number=182933, print grad=0.00023722912010271102, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 960/2000 [10:40<06:49,  2.54it/s, Loss=0.0140079, Gaussian number=182933, print grad=0.000281807646388188, Depth Loss=0.0000000]  
Training progress:  48%|████▊     | 970/2000 [10:40<06:45,  2.54it/s, Loss=0.0140079, Gaussian number=182933, print grad=0.000281807646388188, Depth Loss=0.0000000]
Training progress:  48%|████▊     | 970/2000 [10:44<06:45,  2.54it/s, Loss=0.0085583, Gaussian number=182933, print grad=0.0003235292970202863, Depth Loss=0.0000000]
Training progress:  49%|████▉     | 980/2000 [10:44<06:41,  2.54it/s, Loss=0.0085583, Gaussian number=182933, print grad=0.0003235292970202863, Depth Loss=0.0000000]
Training progress:  49%|████▉     | 980/2000 [10:47<06:41,  2.54it/s, Loss=0.0089912, Gaussian number=182933, print grad=0.0003599852789193392, Depth Loss=0.0000000]
Training progress:  50%|████▉     | 990/2000 [10:47<06:37,  2.54it/s, Loss=0.0089912, Gaussian number=182933, print grad=0.0003599852789193392, Depth Loss=0.0000000]
Training progress:  50%|████▉     | 990/2000 [10:51<06:37,  2.54it/s, Loss=0.0117024, Gaussian number=182933, print grad=0.00039513310184702277, Depth Loss=0.0000000]
Training progress:  50%|█████     | 1000/2000 [10:51<06:32,  2.55it/s, Loss=0.0117024, Gaussian number=182933, print grad=0.00039513310184702277, Depth Loss=0.0000000]
Training progress:  50%|█████     | 1000/2000 [11:59<06:32,  2.55it/s, Loss=0.0106158, Gaussian number=183008, print grad=3.584754085750319e-05, Depth Loss=0.0000000] 
Training progress:  50%|█████     | 1010/2000 [11:59<37:51,  2.29s/it, Loss=0.0106158, Gaussian number=183008, print grad=3.584754085750319e-05, Depth Loss=0.0000000]
Training progress:  50%|█████     | 1010/2000 [12:03<37:51,  2.29s/it, Loss=0.0130887, Gaussian number=183008, print grad=8.284578507300466e-05, Depth Loss=0.0000000]
Training progress:  51%|█████     | 1020/2000 [12:03<28:09,  1.72s/it, Loss=0.0130887, Gaussian number=183008, print grad=8.284578507300466e-05, Depth Loss=0.0000000]
Training progress:  51%|█████     | 1020/2000 [12:07<28:09,  1.72s/it, Loss=0.0104819, Gaussian number=183008, print grad=0.0001269166386919096, Depth Loss=0.0000000]
Training progress:  52%|█████▏    | 1030/2000 [12:07<21:24,  1.32s/it, Loss=0.0104819, Gaussian number=183008, print grad=0.0001269166386919096, Depth Loss=0.0000000]
Training progress:  52%|█████▏    | 1030/2000 [12:10<21:24,  1.32s/it, Loss=0.0112532, Gaussian number=183008, print grad=0.00017268527881242335, Depth Loss=0.0000000]
Training progress:  52%|█████▏    | 1040/2000 [12:10<16:42,  1.04s/it, Loss=0.0112532, Gaussian number=183008, print grad=0.00017268527881242335, Depth Loss=0.0000000]
Training progress:  52%|█████▏    | 1040/2000 [12:14<16:42,  1.04s/it, Loss=0.0103952, Gaussian number=183008, print grad=0.00020954458159394562, Depth Loss=0.0000000]
Training progress:  52%|█████▎    | 1050/2000 [12:14<13:26,  1.18it/s, Loss=0.0103952, Gaussian number=183008, print grad=0.00020954458159394562, Depth Loss=0.0000000]
Training progress:  52%|█████▎    | 1050/2000 [12:18<13:26,  1.18it/s, Loss=0.0093195, Gaussian number=183008, print grad=0.00024951432715170085, Depth Loss=0.0000000]
Training progress:  53%|█████▎    | 1060/2000 [12:18<11:08,  1.41it/s, Loss=0.0093195, Gaussian number=183008, print grad=0.00024951432715170085, Depth Loss=0.0000000]
Training progress:  53%|█████▎    | 1060/2000 [12:22<11:08,  1.41it/s, Loss=0.0078975, Gaussian number=183008, print grad=0.0002931807248387486, Depth Loss=0.0000000] 
Training progress:  54%|█████▎    | 1070/2000 [12:22<09:32,  1.62it/s, Loss=0.0078975, Gaussian number=183008, print grad=0.0002931807248387486, Depth Loss=0.0000000]
Training progress:  54%|█████▎    | 1070/2000 [12:26<09:32,  1.62it/s, Loss=0.0088026, Gaussian number=183008, print grad=0.0003335948567837477, Depth Loss=0.0000000]
Training progress:  54%|█████▍    | 1080/2000 [12:26<08:24,  1.82it/s, Loss=0.0088026, Gaussian number=183008, print grad=0.0003335948567837477, Depth Loss=0.0000000]
Training progress:  54%|█████▍    | 1080/2000 [12:30<08:24,  1.82it/s, Loss=0.0109655, Gaussian number=183008, print grad=0.0003751402546186, Depth Loss=0.0000000]   
Training progress:  55%|█████▍    | 1090/2000 [12:30<07:36,  1.99it/s, Loss=0.0109655, Gaussian number=183008, print grad=0.0003751402546186, Depth Loss=0.0000000]
Training progress:  55%|█████▍    | 1090/2000 [12:34<07:36,  1.99it/s, Loss=0.0111951, Gaussian number=183008, print grad=0.00041628291364759207, Depth Loss=0.0000000]
Training progress:  55%|█████▌    | 1100/2000 [12:34<07:02,  2.13it/s, Loss=0.0111951, Gaussian number=183008, print grad=0.00041628291364759207, Depth Loss=0.0000000]
Training progress:  55%|█████▌    | 1100/2000 [12:38<07:02,  2.13it/s, Loss=0.0116557, Gaussian number=183102, print grad=3.792225106735714e-05, Depth Loss=0.0000000] 
Training progress:  56%|█████▌    | 1110/2000 [12:38<06:37,  2.24it/s, Loss=0.0116557, Gaussian number=183102, print grad=3.792225106735714e-05, Depth Loss=0.0000000]
Training progress:  56%|█████▌    | 1110/2000 [12:42<06:37,  2.24it/s, Loss=0.0103720, Gaussian number=183102, print grad=8.327561954502016e-05, Depth Loss=0.0000000]
Training progress:  56%|█████▌    | 1120/2000 [12:42<06:18,  2.32it/s, Loss=0.0103720, Gaussian number=183102, print grad=8.327561954502016e-05, Depth Loss=0.0000000]
Training progress:  56%|█████▌    | 1120/2000 [12:46<06:18,  2.32it/s, Loss=0.0083516, Gaussian number=183102, print grad=0.00012798122770618647, Depth Loss=0.0000000]
Training progress:  56%|█████▋    | 1130/2000 [12:46<06:04,  2.39it/s, Loss=0.0083516, Gaussian number=183102, print grad=0.00012798122770618647, Depth Loss=0.0000000]
Training progress:  56%|█████▋    | 1130/2000 [12:50<06:04,  2.39it/s, Loss=0.0106615, Gaussian number=183102, print grad=0.00017304268840234727, Depth Loss=0.0000000]
Training progress:  57%|█████▋    | 1140/2000 [12:50<05:53,  2.43it/s, Loss=0.0106615, Gaussian number=183102, print grad=0.00017304268840234727, Depth Loss=0.0000000]
Training progress:  57%|█████▋    | 1140/2000 [12:54<05:53,  2.43it/s, Loss=0.0074339, Gaussian number=183102, print grad=0.00021518570429179817, Depth Loss=0.0000000]
Training progress:  57%|█████▊    | 1150/2000 [12:54<05:44,  2.47it/s, Loss=0.0074339, Gaussian number=183102, print grad=0.00021518570429179817, Depth Loss=0.0000000]
Training progress:  57%|█████▊    | 1150/2000 [12:58<05:44,  2.47it/s, Loss=0.0083295, Gaussian number=183102, print grad=0.0002546735049691051, Depth Loss=0.0000000] 
Training progress:  58%|█████▊    | 1160/2000 [12:58<05:37,  2.49it/s, Loss=0.0083295, Gaussian number=183102, print grad=0.0002546735049691051, Depth Loss=0.0000000]
Training progress:  58%|█████▊    | 1160/2000 [13:01<05:37,  2.49it/s, Loss=0.0102221, Gaussian number=183102, print grad=0.000296833022730425, Depth Loss=0.0000000] 
Training progress:  58%|█████▊    | 1170/2000 [13:01<05:31,  2.51it/s, Loss=0.0102221, Gaussian number=183102, print grad=0.000296833022730425, Depth Loss=0.0000000]
Training progress:  58%|█████▊    | 1170/2000 [13:05<05:31,  2.51it/s, Loss=0.0106545, Gaussian number=183102, print grad=0.0003379714034963399, Depth Loss=0.0000000]
Training progress:  59%|█████▉    | 1180/2000 [13:05<05:25,  2.52it/s, Loss=0.0106545, Gaussian number=183102, print grad=0.0003379714034963399, Depth Loss=0.0000000]
Training progress:  59%|█████▉    | 1180/2000 [13:09<05:25,  2.52it/s, Loss=0.0098564, Gaussian number=183102, print grad=0.0003829069319181144, Depth Loss=0.0000000]
Training progress:  60%|█████▉    | 1190/2000 [13:09<05:20,  2.53it/s, Loss=0.0098564, Gaussian number=183102, print grad=0.0003829069319181144, Depth Loss=0.0000000]
Training progress:  60%|█████▉    | 1190/2000 [13:13<05:20,  2.53it/s, Loss=0.0115677, Gaussian number=183102, print grad=0.0004194254579488188, Depth Loss=0.0000000]
Training progress:  60%|██████    | 1200/2000 [13:13<05:15,  2.53it/s, Loss=0.0115677, Gaussian number=183102, print grad=0.0004194254579488188, Depth Loss=0.0000000]
Training progress:  60%|██████    | 1200/2000 [13:17<05:15,  2.53it/s, Loss=0.0086458, Gaussian number=183202, print grad=4.008301402791403e-05, Depth Loss=0.0000000]
Training progress:  60%|██████    | 1210/2000 [13:17<05:11,  2.54it/s, Loss=0.0086458, Gaussian number=183202, print grad=4.008301402791403e-05, Depth Loss=0.0000000]
Training progress:  60%|██████    | 1210/2000 [13:21<05:11,  2.54it/s, Loss=0.0070599, Gaussian number=183202, print grad=8.541556599084288e-05, Depth Loss=0.0000000]
Training progress:  61%|██████    | 1220/2000 [13:21<05:06,  2.54it/s, Loss=0.0070599, Gaussian number=183202, print grad=8.541556599084288e-05, Depth Loss=0.0000000]
Training progress:  61%|██████    | 1220/2000 [13:25<05:06,  2.54it/s, Loss=0.0078355, Gaussian number=183202, print grad=0.00012401420099195093, Depth Loss=0.0000000]
Training progress:  62%|██████▏   | 1230/2000 [13:25<05:02,  2.55it/s, Loss=0.0078355, Gaussian number=183202, print grad=0.00012401420099195093, Depth Loss=0.0000000]
Training progress:  62%|██████▏   | 1230/2000 [13:29<05:02,  2.55it/s, Loss=0.0076192, Gaussian number=183202, print grad=0.0001676175743341446, Depth Loss=0.0000000] 
Training progress:  62%|██████▏   | 1240/2000 [13:29<04:58,  2.55it/s, Loss=0.0076192, Gaussian number=183202, print grad=0.0001676175743341446, Depth Loss=0.0000000]
Training progress:  62%|██████▏   | 1240/2000 [13:33<04:58,  2.55it/s, Loss=0.0076574, Gaussian number=183202, print grad=0.00020627987396437675, Depth Loss=0.0000000]
Training progress:  62%|██████▎   | 1250/2000 [13:33<04:54,  2.55it/s, Loss=0.0076574, Gaussian number=183202, print grad=0.00020627987396437675, Depth Loss=0.0000000]
Training progress:  62%|██████▎   | 1250/2000 [13:37<04:54,  2.55it/s, Loss=0.0081127, Gaussian number=183202, print grad=0.00024378181842621416, Depth Loss=0.0000000]
Training progress:  63%|██████▎   | 1260/2000 [13:37<04:50,  2.55it/s, Loss=0.0081127, Gaussian number=183202, print grad=0.00024378181842621416, Depth Loss=0.0000000]
Training progress:  63%|██████▎   | 1260/2000 [13:41<04:50,  2.55it/s, Loss=0.0103148, Gaussian number=183202, print grad=0.00028639697120524943, Depth Loss=0.0000000]
Training progress:  64%|██████▎   | 1270/2000 [13:41<04:46,  2.55it/s, Loss=0.0103148, Gaussian number=183202, print grad=0.00028639697120524943, Depth Loss=0.0000000]
Training progress:  64%|██████▎   | 1270/2000 [13:45<04:46,  2.55it/s, Loss=0.0102867, Gaussian number=183202, print grad=0.000326692737871781, Depth Loss=0.0000000]  
Training progress:  64%|██████▍   | 1280/2000 [13:45<04:42,  2.55it/s, Loss=0.0102867, Gaussian number=183202, print grad=0.000326692737871781, Depth Loss=0.0000000]
Training progress:  64%|██████▍   | 1280/2000 [13:49<04:42,  2.55it/s, Loss=0.0080305, Gaussian number=183202, print grad=0.0003710709570441395, Depth Loss=0.0000000]
Training progress:  64%|██████▍   | 1290/2000 [13:49<04:38,  2.55it/s, Loss=0.0080305, Gaussian number=183202, print grad=0.0003710709570441395, Depth Loss=0.0000000]
Training progress:  64%|██████▍   | 1290/2000 [13:52<04:38,  2.55it/s, Loss=0.0118354, Gaussian number=183202, print grad=0.00041041537770070136, Depth Loss=0.0000000]
Training progress:  65%|██████▌   | 1300/2000 [13:52<04:34,  2.55it/s, Loss=0.0118354, Gaussian number=183202, print grad=0.00041041537770070136, Depth Loss=0.0000000]
Training progress:  65%|██████▌   | 1300/2000 [13:56<04:34,  2.55it/s, Loss=0.0113403, Gaussian number=183297, print grad=4.142776015214622e-05, Depth Loss=0.0000000] 
Training progress:  66%|██████▌   | 1310/2000 [13:56<04:30,  2.55it/s, Loss=0.0113403, Gaussian number=183297, print grad=4.142776015214622e-05, Depth Loss=0.0000000]
Training progress:  66%|██████▌   | 1310/2000 [14:00<04:30,  2.55it/s, Loss=0.0109692, Gaussian number=183297, print grad=8.126544707920402e-05, Depth Loss=0.0000000]
Training progress:  66%|██████▌   | 1320/2000 [14:00<04:26,  2.55it/s, Loss=0.0109692, Gaussian number=183297, print grad=8.126544707920402e-05, Depth Loss=0.0000000]
Training progress:  66%|██████▌   | 1320/2000 [14:04<04:26,  2.55it/s, Loss=0.0086769, Gaussian number=183297, print grad=0.00012306148710194975, Depth Loss=0.0000000]
Training progress:  66%|██████▋   | 1330/2000 [14:04<04:22,  2.55it/s, Loss=0.0086769, Gaussian number=183297, print grad=0.00012306148710194975, Depth Loss=0.0000000]
Training progress:  66%|██████▋   | 1330/2000 [14:08<04:22,  2.55it/s, Loss=0.0092221, Gaussian number=183297, print grad=0.00016761526057962328, Depth Loss=0.0000000]
Training progress:  67%|██████▋   | 1340/2000 [14:08<04:18,  2.55it/s, Loss=0.0092221, Gaussian number=183297, print grad=0.00016761526057962328, Depth Loss=0.0000000]
Training progress:  67%|██████▋   | 1340/2000 [14:12<04:18,  2.55it/s, Loss=0.0126819, Gaussian number=183297, print grad=0.0002053842763416469, Depth Loss=0.0000000] 
Training progress:  68%|██████▊   | 1350/2000 [14:12<04:14,  2.55it/s, Loss=0.0126819, Gaussian number=183297, print grad=0.0002053842763416469, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1350/2000 [14:16<04:14,  2.55it/s, Loss=0.0076534, Gaussian number=183297, print grad=0.0002447953156661242, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1360/2000 [14:16<04:10,  2.55it/s, Loss=0.0076534, Gaussian number=183297, print grad=0.0002447953156661242, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1360/2000 [14:20<04:10,  2.55it/s, Loss=0.0143127, Gaussian number=183297, print grad=0.00028716097585856915, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1370/2000 [14:20<04:07,  2.55it/s, Loss=0.0143127, Gaussian number=183297, print grad=0.00028716097585856915, Depth Loss=0.0000000]
Training progress:  68%|██████▊   | 1370/2000 [14:24<04:07,  2.55it/s, Loss=0.0091857, Gaussian number=183297, print grad=0.00032706354977563024, Depth Loss=0.0000000]
Training progress:  69%|██████▉   | 1380/2000 [14:24<04:03,  2.55it/s, Loss=0.0091857, Gaussian number=183297, print grad=0.00032706354977563024, Depth Loss=0.0000000]
Training progress:  69%|██████▉   | 1380/2000 [14:28<04:03,  2.55it/s, Loss=0.0081479, Gaussian number=183297, print grad=0.0003656648041214794, Depth Loss=0.0000000] 
Training progress:  70%|██████▉   | 1390/2000 [14:28<03:59,  2.55it/s, Loss=0.0081479, Gaussian number=183297, print grad=0.0003656648041214794, Depth Loss=0.0000000]
Training progress:  70%|██████▉   | 1390/2000 [14:32<03:59,  2.55it/s, Loss=0.0092431, Gaussian number=183297, print grad=0.00040856230771169066, Depth Loss=0.0000000]
Training progress:  70%|███████   | 1400/2000 [14:32<03:55,  2.55it/s, Loss=0.0092431, Gaussian number=183297, print grad=0.00040856230771169066, Depth Loss=0.0000000]
Training progress:  70%|███████   | 1400/2000 [14:36<03:55,  2.55it/s, Loss=0.0102563, Gaussian number=183412, print grad=4.161568722338416e-05, Depth Loss=0.0000000] 
Training progress:  70%|███████   | 1410/2000 [14:36<03:51,  2.55it/s, Loss=0.0102563, Gaussian number=183412, print grad=4.161568722338416e-05, Depth Loss=0.0000000]
Training progress:  70%|███████   | 1410/2000 [14:40<03:51,  2.55it/s, Loss=0.0091477, Gaussian number=183412, print grad=8.713543502381071e-05, Depth Loss=0.0000000]
Training progress:  71%|███████   | 1420/2000 [14:40<03:47,  2.55it/s, Loss=0.0091477, Gaussian number=183412, print grad=8.713543502381071e-05, Depth Loss=0.0000000]
Training progress:  71%|███████   | 1420/2000 [14:43<03:47,  2.55it/s, Loss=0.0093766, Gaussian number=183412, print grad=0.00013355490227695554, Depth Loss=0.0000000]
Training progress:  72%|███████▏  | 1430/2000 [14:43<03:43,  2.55it/s, Loss=0.0093766, Gaussian number=183412, print grad=0.00013355490227695554, Depth Loss=0.0000000]
Training progress:  72%|███████▏  | 1430/2000 [14:47<03:43,  2.55it/s, Loss=0.0089223, Gaussian number=183412, print grad=0.0001733541866997257, Depth Loss=0.0000000] 
Training progress:  72%|███████▏  | 1440/2000 [14:47<03:39,  2.55it/s, Loss=0.0089223, Gaussian number=183412, print grad=0.0001733541866997257, Depth Loss=0.0000000]
Training progress:  72%|███████▏  | 1440/2000 [14:51<03:39,  2.55it/s, Loss=0.0081212, Gaussian number=183412, print grad=0.00021277159976307303, Depth Loss=0.0000000]
Training progress:  72%|███████▎  | 1450/2000 [14:51<03:35,  2.55it/s, Loss=0.0081212, Gaussian number=183412, print grad=0.00021277159976307303, Depth Loss=0.0000000]
Training progress:  72%|███████▎  | 1450/2000 [14:55<03:35,  2.55it/s, Loss=0.0071694, Gaussian number=183412, print grad=0.0002543387236073613, Depth Loss=0.0000000] 
Training progress:  73%|███████▎  | 1460/2000 [14:55<03:31,  2.55it/s, Loss=0.0071694, Gaussian number=183412, print grad=0.0002543387236073613, Depth Loss=0.0000000]
Training progress:  73%|███████▎  | 1460/2000 [14:59<03:31,  2.55it/s, Loss=0.0094650, Gaussian number=183412, print grad=0.0002955729723908007, Depth Loss=0.0000000]
Training progress:  74%|███████▎  | 1470/2000 [14:59<03:27,  2.55it/s, Loss=0.0094650, Gaussian number=183412, print grad=0.0002955729723908007, Depth Loss=0.0000000]
Training progress:  74%|███████▎  | 1470/2000 [15:03<03:27,  2.55it/s, Loss=0.0101339, Gaussian number=183412, print grad=0.00034024272463284433, Depth Loss=0.0000000]
Training progress:  74%|███████▍  | 1480/2000 [15:03<03:23,  2.55it/s, Loss=0.0101339, Gaussian number=183412, print grad=0.00034024272463284433, Depth Loss=0.0000000]
Training progress:  74%|███████▍  | 1480/2000 [15:07<03:23,  2.55it/s, Loss=0.0100723, Gaussian number=183412, print grad=0.0003852134686894715, Depth Loss=0.0000000] 
Training progress:  74%|███████▍  | 1490/2000 [15:07<03:19,  2.55it/s, Loss=0.0100723, Gaussian number=183412, print grad=0.0003852134686894715, Depth Loss=0.0000000]
Training progress:  74%|███████▍  | 1490/2000 [15:11<03:19,  2.55it/s, Loss=0.0098625, Gaussian number=183412, print grad=0.0004285160102881491, Depth Loss=0.0000000]
Training progress:  75%|███████▌  | 1500/2000 [15:11<03:15,  2.55it/s, Loss=0.0098625, Gaussian number=183412, print grad=0.0004285160102881491, Depth Loss=0.0000000]
Training progress:  75%|███████▌  | 1500/2000 [16:18<03:15,  2.55it/s, Loss=0.0105381, Gaussian number=183516, print grad=3.64910920325201e-05, Depth Loss=0.0000000] 
Training progress:  76%|███████▌  | 1510/2000 [16:18<18:44,  2.29s/it, Loss=0.0105381, Gaussian number=183516, print grad=3.64910920325201e-05, Depth Loss=0.0000000]
Training progress:  76%|███████▌  | 1510/2000 [16:22<18:44,  2.29s/it, Loss=0.0093214, Gaussian number=183516, print grad=7.64664146117866e-05, Depth Loss=0.0000000]
Training progress:  76%|███████▌  | 1520/2000 [16:22<13:47,  1.72s/it, Loss=0.0093214, Gaussian number=183516, print grad=7.64664146117866e-05, Depth Loss=0.0000000]
Training progress:  76%|███████▌  | 1520/2000 [16:26<13:47,  1.72s/it, Loss=0.0058297, Gaussian number=183516, print grad=0.00012015591346425936, Depth Loss=0.0000000]
Training progress:  76%|███████▋  | 1530/2000 [16:26<10:22,  1.32s/it, Loss=0.0058297, Gaussian number=183516, print grad=0.00012015591346425936, Depth Loss=0.0000000]
Training progress:  76%|███████▋  | 1530/2000 [16:30<10:22,  1.32s/it, Loss=0.0082060, Gaussian number=183516, print grad=0.00016114096797537059, Depth Loss=0.0000000]
Training progress:  77%|███████▋  | 1540/2000 [16:30<08:00,  1.04s/it, Loss=0.0082060, Gaussian number=183516, print grad=0.00016114096797537059, Depth Loss=0.0000000]
Training progress:  77%|███████▋  | 1540/2000 [16:34<08:00,  1.04s/it, Loss=0.0088939, Gaussian number=183516, print grad=0.0002064327272819355, Depth Loss=0.0000000] 
Training progress:  78%|███████▊  | 1550/2000 [16:34<06:21,  1.18it/s, Loss=0.0088939, Gaussian number=183516, print grad=0.0002064327272819355, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1550/2000 [16:38<06:21,  1.18it/s, Loss=0.0093510, Gaussian number=183516, print grad=0.0002520945272408426, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1560/2000 [16:38<05:12,  1.41it/s, Loss=0.0093510, Gaussian number=183516, print grad=0.0002520945272408426, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1560/2000 [16:42<05:12,  1.41it/s, Loss=0.0080892, Gaussian number=183516, print grad=0.0002955656673293561, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1570/2000 [16:42<04:24,  1.63it/s, Loss=0.0080892, Gaussian number=183516, print grad=0.0002955656673293561, Depth Loss=0.0000000]
Training progress:  78%|███████▊  | 1570/2000 [16:46<04:24,  1.63it/s, Loss=0.0059994, Gaussian number=183516, print grad=0.0003313497581984848, Depth Loss=0.0000000]
Training progress:  79%|███████▉  | 1580/2000 [16:46<03:50,  1.83it/s, Loss=0.0059994, Gaussian number=183516, print grad=0.0003313497581984848, Depth Loss=0.0000000]
Training progress:  79%|███████▉  | 1580/2000 [16:49<03:50,  1.83it/s, Loss=0.0084655, Gaussian number=183516, print grad=0.00037041277391836047, Depth Loss=0.0000000]
Training progress:  80%|███████▉  | 1590/2000 [16:49<03:25,  2.00it/s, Loss=0.0084655, Gaussian number=183516, print grad=0.00037041277391836047, Depth Loss=0.0000000]
Training progress:  80%|███████▉  | 1590/2000 [16:53<03:25,  2.00it/s, Loss=0.0083758, Gaussian number=183516, print grad=0.00041428074473515153, Depth Loss=0.0000000]
Training progress:  80%|████████  | 1600/2000 [16:53<03:07,  2.14it/s, Loss=0.0083758, Gaussian number=183516, print grad=0.00041428074473515153, Depth Loss=0.0000000]
Training progress:  80%|████████  | 1600/2000 [16:57<03:07,  2.14it/s, Loss=0.0086541, Gaussian number=183583, print grad=4.274744787835516e-05, Depth Loss=0.0000000] 
Training progress:  80%|████████  | 1610/2000 [16:57<02:53,  2.24it/s, Loss=0.0086541, Gaussian number=183583, print grad=4.274744787835516e-05, Depth Loss=0.0000000]
Training progress:  80%|████████  | 1610/2000 [17:01<02:53,  2.24it/s, Loss=0.0091753, Gaussian number=183583, print grad=8.870426972862333e-05, Depth Loss=0.0000000]
Training progress:  81%|████████  | 1620/2000 [17:01<02:43,  2.33it/s, Loss=0.0091753, Gaussian number=183583, print grad=8.870426972862333e-05, Depth Loss=0.0000000]
Training progress:  81%|████████  | 1620/2000 [17:05<02:43,  2.33it/s, Loss=0.0080130, Gaussian number=183583, print grad=0.00012959318701177835, Depth Loss=0.0000000]
Training progress:  82%|████████▏ | 1630/2000 [17:05<02:35,  2.38it/s, Loss=0.0080130, Gaussian number=183583, print grad=0.00012959318701177835, Depth Loss=0.0000000]
Training progress:  82%|████████▏ | 1630/2000 [17:09<02:35,  2.38it/s, Loss=0.0060089, Gaussian number=183583, print grad=0.0001710460928734392, Depth Loss=0.0000000] 
Training progress:  82%|████████▏ | 1640/2000 [17:09<02:28,  2.43it/s, Loss=0.0060089, Gaussian number=183583, print grad=0.0001710460928734392, Depth Loss=0.0000000]
Training progress:  82%|████████▏ | 1640/2000 [17:13<02:28,  2.43it/s, Loss=0.0082446, Gaussian number=183583, print grad=0.00020983525610063225, Depth Loss=0.0000000]
Training progress:  82%|████████▎ | 1650/2000 [17:13<02:21,  2.47it/s, Loss=0.0082446, Gaussian number=183583, print grad=0.00020983525610063225, Depth Loss=0.0000000]
Training progress:  82%|████████▎ | 1650/2000 [17:17<02:21,  2.47it/s, Loss=0.0081216, Gaussian number=183583, print grad=0.0002510796475689858, Depth Loss=0.0000000] 
Training progress:  83%|████████▎ | 1660/2000 [17:17<02:16,  2.49it/s, Loss=0.0081216, Gaussian number=183583, print grad=0.0002510796475689858, Depth Loss=0.0000000]
Training progress:  83%|████████▎ | 1660/2000 [17:21<02:16,  2.49it/s, Loss=0.0075973, Gaussian number=183583, print grad=0.00029130285838618875, Depth Loss=0.0000000]
Training progress:  84%|████████▎ | 1670/2000 [17:21<02:11,  2.51it/s, Loss=0.0075973, Gaussian number=183583, print grad=0.00029130285838618875, Depth Loss=0.0000000]
Training progress:  84%|████████▎ | 1670/2000 [17:25<02:11,  2.51it/s, Loss=0.0069052, Gaussian number=183583, print grad=0.00033559161238372326, Depth Loss=0.0000000]
Training progress:  84%|████████▍ | 1680/2000 [17:25<02:06,  2.52it/s, Loss=0.0069052, Gaussian number=183583, print grad=0.00033559161238372326, Depth Loss=0.0000000]
Training progress:  84%|████████▍ | 1680/2000 [17:29<02:06,  2.52it/s, Loss=0.0083327, Gaussian number=183583, print grad=0.0003782196727115661, Depth Loss=0.0000000] 
Training progress:  84%|████████▍ | 1690/2000 [17:29<02:02,  2.53it/s, Loss=0.0083327, Gaussian number=183583, print grad=0.0003782196727115661, Depth Loss=0.0000000]
Training progress:  84%|████████▍ | 1690/2000 [17:33<02:02,  2.53it/s, Loss=0.0089467, Gaussian number=183583, print grad=0.0004169745952822268, Depth Loss=0.0000000]
Training progress:  85%|████████▌ | 1700/2000 [17:33<01:58,  2.54it/s, Loss=0.0089467, Gaussian number=183583, print grad=0.0004169745952822268, Depth Loss=0.0000000]
Training progress:  85%|████████▌ | 1700/2000 [17:37<01:58,  2.54it/s, Loss=0.0088976, Gaussian number=183708, print grad=4.265012830728665e-05, Depth Loss=0.0000000]
Training progress:  86%|████████▌ | 1710/2000 [17:37<01:54,  2.54it/s, Loss=0.0088976, Gaussian number=183708, print grad=4.265012830728665e-05, Depth Loss=0.0000000]
Training progress:  86%|████████▌ | 1710/2000 [17:40<01:54,  2.54it/s, Loss=0.0096334, Gaussian number=183708, print grad=8.035661448957399e-05, Depth Loss=0.0000000]
Training progress:  86%|████████▌ | 1720/2000 [17:40<01:49,  2.55it/s, Loss=0.0096334, Gaussian number=183708, print grad=8.035661448957399e-05, Depth Loss=0.0000000]
Training progress:  86%|████████▌ | 1720/2000 [17:44<01:49,  2.55it/s, Loss=0.0082185, Gaussian number=183708, print grad=0.00012266816338524222, Depth Loss=0.0000000]
Training progress:  86%|████████▋ | 1730/2000 [17:44<01:45,  2.55it/s, Loss=0.0082185, Gaussian number=183708, print grad=0.00012266816338524222, Depth Loss=0.0000000]
Training progress:  86%|████████▋ | 1730/2000 [17:48<01:45,  2.55it/s, Loss=0.0109167, Gaussian number=183708, print grad=0.0001689792115939781, Depth Loss=0.0000000] 
Training progress:  87%|████████▋ | 1740/2000 [17:48<01:42,  2.55it/s, Loss=0.0109167, Gaussian number=183708, print grad=0.0001689792115939781, Depth Loss=0.0000000]
Training progress:  87%|████████▋ | 1740/2000 [17:52<01:42,  2.55it/s, Loss=0.0104652, Gaussian number=183708, print grad=0.00021448313782457262, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1750/2000 [17:52<01:37,  2.55it/s, Loss=0.0104652, Gaussian number=183708, print grad=0.00021448313782457262, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1750/2000 [17:56<01:37,  2.55it/s, Loss=0.0086273, Gaussian number=183708, print grad=0.00025664354325272143, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1760/2000 [17:56<01:34,  2.55it/s, Loss=0.0086273, Gaussian number=183708, print grad=0.00025664354325272143, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1760/2000 [18:00<01:34,  2.55it/s, Loss=0.0070443, Gaussian number=183708, print grad=0.0002963099395856261, Depth Loss=0.0000000] 
Training progress:  88%|████████▊ | 1770/2000 [18:00<01:30,  2.55it/s, Loss=0.0070443, Gaussian number=183708, print grad=0.0002963099395856261, Depth Loss=0.0000000]
Training progress:  88%|████████▊ | 1770/2000 [18:04<01:30,  2.55it/s, Loss=0.0085920, Gaussian number=183708, print grad=0.0003363470023032278, Depth Loss=0.0000000]
Training progress:  89%|████████▉ | 1780/2000 [18:04<01:26,  2.55it/s, Loss=0.0085920, Gaussian number=183708, print grad=0.0003363470023032278, Depth Loss=0.0000000]
Training progress:  89%|████████▉ | 1780/2000 [18:08<01:26,  2.55it/s, Loss=0.0080103, Gaussian number=183708, print grad=0.0003720729146152735, Depth Loss=0.0000000]
Training progress:  90%|████████▉ | 1790/2000 [18:08<01:22,  2.55it/s, Loss=0.0080103, Gaussian number=183708, print grad=0.0003720729146152735, Depth Loss=0.0000000]
Training progress:  90%|████████▉ | 1790/2000 [18:12<01:22,  2.55it/s, Loss=0.0077625, Gaussian number=183708, print grad=0.0004171498876530677, Depth Loss=0.0000000]
Training progress:  90%|█████████ | 1800/2000 [18:12<01:18,  2.55it/s, Loss=0.0077625, Gaussian number=183708, print grad=0.0004171498876530677, Depth Loss=0.0000000]
Training progress:  90%|█████████ | 1800/2000 [18:16<01:18,  2.55it/s, Loss=0.0084425, Gaussian number=183783, print grad=4.331555828684941e-05, Depth Loss=0.0000000]
Training progress:  90%|█████████ | 1810/2000 [18:16<01:14,  2.55it/s, Loss=0.0084425, Gaussian number=183783, print grad=4.331555828684941e-05, Depth Loss=0.0000000]
Training progress:  90%|█████████ | 1810/2000 [18:20<01:14,  2.55it/s, Loss=0.0074779, Gaussian number=183783, print grad=8.850067388266325e-05, Depth Loss=0.0000000]
Training progress:  91%|█████████ | 1820/2000 [18:20<01:10,  2.55it/s, Loss=0.0074779, Gaussian number=183783, print grad=8.850067388266325e-05, Depth Loss=0.0000000]
Training progress:  91%|█████████ | 1820/2000 [18:24<01:10,  2.55it/s, Loss=0.0063564, Gaussian number=183783, print grad=0.0001259132259292528, Depth Loss=0.0000000]
Training progress:  92%|█████████▏| 1830/2000 [18:24<01:06,  2.55it/s, Loss=0.0063564, Gaussian number=183783, print grad=0.0001259132259292528, Depth Loss=0.0000000]
Training progress:  92%|█████████▏| 1830/2000 [18:27<01:06,  2.55it/s, Loss=0.0071048, Gaussian number=183783, print grad=0.00017046350694727153, Depth Loss=0.0000000]
Training progress:  92%|█████████▏| 1840/2000 [18:27<01:02,  2.55it/s, Loss=0.0071048, Gaussian number=183783, print grad=0.00017046350694727153, Depth Loss=0.0000000]
Training progress:  92%|█████████▏| 1840/2000 [18:31<01:02,  2.55it/s, Loss=0.0077261, Gaussian number=183783, print grad=0.0002128493506461382, Depth Loss=0.0000000] 
Training progress:  92%|█████████▎| 1850/2000 [18:31<00:58,  2.55it/s, Loss=0.0077261, Gaussian number=183783, print grad=0.0002128493506461382, Depth Loss=0.0000000]
Training progress:  92%|█████████▎| 1850/2000 [18:35<00:58,  2.55it/s, Loss=0.0080542, Gaussian number=183783, print grad=0.00024906618637032807, Depth Loss=0.0000000]
Training progress:  93%|█████████▎| 1860/2000 [18:35<00:54,  2.55it/s, Loss=0.0080542, Gaussian number=183783, print grad=0.00024906618637032807, Depth Loss=0.0000000]
Training progress:  93%|█████████▎| 1860/2000 [18:39<00:54,  2.55it/s, Loss=0.0088575, Gaussian number=183783, print grad=0.00029627259937115014, Depth Loss=0.0000000]
Training progress:  94%|█████████▎| 1870/2000 [18:39<00:51,  2.55it/s, Loss=0.0088575, Gaussian number=183783, print grad=0.00029627259937115014, Depth Loss=0.0000000]
Training progress:  94%|█████████▎| 1870/2000 [18:43<00:51,  2.55it/s, Loss=0.0067698, Gaussian number=183783, print grad=0.00033769322908483446, Depth Loss=0.0000000]
Training progress:  94%|█████████▍| 1880/2000 [18:43<00:47,  2.55it/s, Loss=0.0067698, Gaussian number=183783, print grad=0.00033769322908483446, Depth Loss=0.0000000]
Training progress:  94%|█████████▍| 1880/2000 [18:47<00:47,  2.55it/s, Loss=0.0077345, Gaussian number=183783, print grad=0.00037818995770066977, Depth Loss=0.0000000]
Training progress:  94%|█████████▍| 1890/2000 [18:47<00:43,  2.55it/s, Loss=0.0077345, Gaussian number=183783, print grad=0.00037818995770066977, Depth Loss=0.0000000]
Training progress:  94%|█████████▍| 1890/2000 [18:51<00:43,  2.55it/s, Loss=0.0094221, Gaussian number=183783, print grad=0.0004219097609166056, Depth Loss=0.0000000] 
Training progress:  95%|█████████▌| 1900/2000 [18:51<00:39,  2.55it/s, Loss=0.0094221, Gaussian number=183783, print grad=0.0004219097609166056, Depth Loss=0.0000000]
Training progress:  95%|█████████▌| 1900/2000 [18:55<00:39,  2.55it/s, Loss=0.0086609, Gaussian number=183912, print grad=3.7727964809164405e-05, Depth Loss=0.0000000]
Training progress:  96%|█████████▌| 1910/2000 [18:55<00:35,  2.55it/s, Loss=0.0086609, Gaussian number=183912, print grad=3.7727964809164405e-05, Depth Loss=0.0000000]
Training progress:  96%|█████████▌| 1910/2000 [18:59<00:35,  2.55it/s, Loss=0.0066426, Gaussian number=183912, print grad=7.90769699960947e-05, Depth Loss=0.0000000]  
Training progress:  96%|█████████▌| 1920/2000 [18:59<00:31,  2.55it/s, Loss=0.0066426, Gaussian number=183912, print grad=7.90769699960947e-05, Depth Loss=0.0000000]
Training progress:  96%|█████████▌| 1920/2000 [19:03<00:31,  2.55it/s, Loss=0.0060748, Gaussian number=183912, print grad=0.00012195087037980556, Depth Loss=0.0000000]
Training progress:  96%|█████████▋| 1930/2000 [19:03<00:27,  2.55it/s, Loss=0.0060748, Gaussian number=183912, print grad=0.00012195087037980556, Depth Loss=0.0000000]
Training progress:  96%|█████████▋| 1930/2000 [19:07<00:27,  2.55it/s, Loss=0.0086793, Gaussian number=183912, print grad=0.00016277958638966084, Depth Loss=0.0000000]
Training progress:  97%|█████████▋| 1940/2000 [19:07<00:23,  2.55it/s, Loss=0.0086793, Gaussian number=183912, print grad=0.00016277958638966084, Depth Loss=0.0000000]
Training progress:  97%|█████████▋| 1940/2000 [19:11<00:23,  2.55it/s, Loss=0.0065665, Gaussian number=183912, print grad=0.00020383429364301264, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1950/2000 [19:11<00:19,  2.55it/s, Loss=0.0065665, Gaussian number=183912, print grad=0.00020383429364301264, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1950/2000 [19:15<00:19,  2.55it/s, Loss=0.0106248, Gaussian number=183912, print grad=0.00024344376288354397, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1960/2000 [19:15<00:15,  2.55it/s, Loss=0.0106248, Gaussian number=183912, print grad=0.00024344376288354397, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1960/2000 [19:18<00:15,  2.55it/s, Loss=0.0091158, Gaussian number=183912, print grad=0.00028543005464598536, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1970/2000 [19:18<00:11,  2.55it/s, Loss=0.0091158, Gaussian number=183912, print grad=0.00028543005464598536, Depth Loss=0.0000000]
Training progress:  98%|█████████▊| 1970/2000 [19:22<00:11,  2.55it/s, Loss=0.0078111, Gaussian number=183912, print grad=0.0003272157919127494, Depth Loss=0.0000000] 
Training progress:  99%|█████████▉| 1980/2000 [19:22<00:07,  2.56it/s, Loss=0.0078111, Gaussian number=183912, print grad=0.0003272157919127494, Depth Loss=0.0000000]
Training progress:  99%|█████████▉| 1980/2000 [19:26<00:07,  2.56it/s, Loss=0.0074536, Gaussian number=183912, print grad=0.0003742377448361367, Depth Loss=0.0000000]
Training progress: 100%|█████████▉| 1990/2000 [19:26<00:03,  2.56it/s, Loss=0.0074536, Gaussian number=183912, print grad=0.0003742377448361367, Depth Loss=0.0000000]
Training progress: 100%|█████████▉| 1990/2000 [19:30<00:03,  2.56it/s, Loss=0.0061733, Gaussian number=183912, print grad=0.00041869713459163904, Depth Loss=0.0000000]
Training progress: 100%|██████████| 2000/2000 [19:30<00:00,  2.56it/s, Loss=0.0061733, Gaussian number=183912, print grad=0.00041869713459163904, Depth Loss=0.0000000]
Training progress: 100%|██████████| 2000/2000 [19:30<00:00,  1.71it/s, Loss=0.0061733, Gaussian number=183912, print grad=0.00041869713459163904, Depth Loss=0.0000000]
Iteration 100 [02/12 23:35:13]

[ITER 100] Evaluating test: WD 0.019977, PSNR 12.9267,lpips 0.590495,ssim 0.452861 [02/12 23:36:09]

[ITER 100] Evaluating train: WD 0.020894, PSNR 13.2840,lpips 0.592475,ssim 0.470543 [02/12 23:36:17]
Gaussian number:182686,print gradients:2.8540957828226965e-06 [02/12 23:36:17]
Iteration 200 [02/12 23:36:56]

[ITER 200] Evaluating test: WD 0.017730, PSNR 14.2858,lpips 0.540553,ssim 0.488510 [02/12 23:37:53]

[ITER 200] Evaluating train: WD 0.017985, PSNR 14.4382,lpips 0.532219,ssim 0.502529 [02/12 23:38:00]
Gaussian number:182686,print gradients:3.616596814026707e-06 [02/12 23:38:00]
Iteration 300 [02/12 23:38:39]

[ITER 300] Evaluating test: WD 0.016271, PSNR 15.0004,lpips 0.507463,ssim 0.509182 [02/12 23:39:36]

[ITER 300] Evaluating train: WD 0.016485, PSNR 15.2435,lpips 0.496936,ssim 0.522436 [02/12 23:39:43]
Gaussian number:182686,print gradients:4.076634468219709e-06 [02/12 23:39:43]
Iteration 400 [02/12 23:40:23]
Iteration 500 [02/12 23:41:02]

[ITER 500] Evaluating test: WD 0.014836, PSNR 15.8609,lpips 0.473657,ssim 0.531463 [02/12 23:41:59]

[ITER 500] Evaluating train: WD 0.016032, PSNR 15.8458,lpips 0.472963,ssim 0.536699 [02/12 23:42:06]
Gaussian number:182686,print gradients:4.652855295717018e-06 [02/12 23:42:06]
Iteration 600 [02/12 23:42:45]
Iteration 700 [02/12 23:43:24]
Iteration 800 [02/12 23:44:04]
Iteration 900 [02/12 23:44:43]
Iteration 1000 [02/12 23:45:23]

[ITER 1000] Evaluating test: WD 0.012907, PSNR 16.6543,lpips 0.423287,ssim 0.559422 [02/12 23:46:19]

[ITER 1000] Evaluating train: WD 0.013844, PSNR 16.6546,lpips 0.426190,ssim 0.565084 [02/12 23:46:26]
Gaussian number:182933,print gradients:6.1033060774207115e-06 [02/12 23:46:26]
Iteration 1100 [02/12 23:47:05]
Iteration 1200 [02/12 23:47:44]
Iteration 1300 [02/12 23:48:24]
Iteration 1400 [02/12 23:49:03]
Iteration 1500 [02/12 23:49:42]

[ITER 1500] Evaluating test: WD 0.011643, PSNR 17.1430,lpips 0.390241,ssim 0.576459 [02/12 23:50:38]

[ITER 1500] Evaluating train: WD 0.012418, PSNR 17.3747,lpips 0.386161,ssim 0.585505 [02/12 23:50:46]
Gaussian number:183412,print gradients:6.540869890159229e-06 [02/12 23:50:46]
Iteration 1600 [02/12 23:51:25]
Iteration 1700 [02/12 23:52:04]
Iteration 1800 [02/12 23:52:43]
Iteration 1900 [02/12 23:53:22]
Iteration 2000 [02/12 23:54:01]

[ITER 2000] Evaluating test: WD 0.010785, PSNR 17.5345,lpips 0.370218,ssim 0.589249 [02/12 23:54:58]

[ITER 2000] Evaluating train: WD 0.011859, PSNR 17.9164,lpips 0.373135,ssim 0.593806 [02/12 23:55:05]
Gaussian number:183912,print gradients:6.458375082729617e-06 [02/12 23:55:05]

[ITER 2000] Saving Gaussians [02/12 23:55:05]

Training complete. [02/12 23:55:07]
